Id,OwnerUserId,CreationDate,Score,Title,Body
77434,14008,2008-09-16T21:40:29Z,171,How to access the last value in a vector?,"<p>Suppose I have a vector that is nested in a dataframe one or two levels.  Is there a quick and dirty way to access the last value, without using the <code>length()</code> function?  Something ala PERL's <code>$#</code> special var?</p>

<p>So I would like something like:</p>

<pre><code>dat$vec1$vec2[$#]
</code></pre>

<p>instead of</p>

<pre><code>dat$vec1$vec2[length(dat$vec1$vec2)]
</code></pre>
"
79709,NA,2008-09-17T03:39:16Z,3,Worse sin: side effects or passing massive objects?,"<p>I have a function inside a loop inside a function. The inner function acquires and stores a large vector of data in memory (as a global variable... I'm using ""R"" which is like ""S-Plus""). The loop loops through a long list of data to be acquired. The outer function starts the process and passes in the list of datasets to be acquired.</p>

<pre><code>for (dataset in list_of_datasets) {
  for (datachunk in dataset) {
    &lt;process datachunk&gt;
    &lt;store result? as vector? where?&gt;
  }
}
</code></pre>

<p>I programmed the inner function to store each dataset before moving to the next, so all the work of the outer function occurs as side effects on global variables... a big no-no. Is this better or worse than collecting and returning a giant, memory-hogging vector of vectors? Is there a superior third approach?</p>

<p>Would the answer change if I were storing the data vectors in a database rather than in memory? Ideally, I'd like to be able to terminate the function (or have it fail due to network timeouts) without losing all the information processed prior to termination.</p>
"
95007,15842,2008-09-18T17:59:19Z,56,Explain the quantile() function in R,"<p>I've been mystified by the R quantile function all day.  </p>

<p>I have an intuitive notion of how quantiles work, and an M.S. in stats, but boy oh boy, the documentation for it is confusing to me.  </p>

<p>From the docs:</p>

<blockquote>
  <p>Q[i](p) = (1 - gamma) x[j] + gamma
  x[j+1],</p>
</blockquote>

<p>I'm with it so far.  For a type <em>i</em> quantile, it's an interpolation between x[j] and x [j+1], based on some mysterious constant <em>gamma</em></p>

<blockquote>
  <p>where 1 &lt;= i &lt;= 9, (j-m)/n &lt;= p &lt;
  (j-m+1)/ n, x[j] is the jth order
  statistic, n is the sample size, and m
  is a constant determined by the sample
  quantile type. Here gamma depends on
  the fractional part of g = np+m-j. </p>
</blockquote>

<p>So, how calculate j?   m?</p>

<blockquote>
  <p>For the continuous sample quantile
  types (4 through 9), the sample
  quantiles can be obtained by linear
  interpolation between the kth order
  statistic and p(k): </p>
  
  <p>p(k) = (k - alpha) / (n - alpha - beta
  + 1),
  where α and β are constants determined
  by the type. Further, m = alpha + p(1
  - alpha - beta), and gamma = g.</p>
</blockquote>

<p>Now I'm really lost.  p, which was a constant before, is now apparently a function.  </p>

<p>So for Type 7 quantiles, the default...</p>

<blockquote>
  <p>Type 7</p>
  
  <p>p(k) = (k - 1) / (n - 1). In this case, p(k) = mode[F(x[k])]. This is used by S. </p>
</blockquote>

<p>Anyone want to help me out?  In particular I'm confused by the notation of p being a function and a constant, what the heck <em>m</em> is, and now to calculate j for some particular <em>p</em>.  </p>

<p>I hope that based on the answers here, we can submit some revised documentation that better explains what is going on here.  </p>

<p><a href=""https://svn.r-project.org/R/trunk/src/library/stats/R/quantile.R"" rel=""noreferrer"">quantile.R source code</a>
or type:  quantile.default</p>
"
103312,NA,2008-09-19T16:09:26Z,4,How to test for the EOF flag in R?,"<p>How can I test for the <code>EOF</code> flag in R? </p>

<p>For example:</p>

<pre><code>f &lt;- file(fname, ""rb"")
while (???) {
    a &lt;- readBin(f, ""int"", n=1)
}
</code></pre>
"
255697,1941213,2008-11-01T15:48:30Z,4,Is there an R package for learning a Dirichlet prior from counts data,"<p>I'm looking for a an <code>R</code> package which can be used to train a Dirichlet prior from counts data.  I'm asking for a colleague who's using <code>R</code>, and don't use it myself, so I'm not too sure how to look for packages.  It's a bit hard to search for, because ""R"" is such a nonspecific search string.  There doesn't seem to be anything on <a href=""http://cran.r-project.org/web/packages/index.html"" rel=""nofollow noreferrer"">CRAN</a>, but are there any other places to look?</p>
"
359438,2173,2008-12-11T14:02:06Z,4,Optimization packages for R,"<p>Does anyone know of any optimization packages out there for R (similar to NUOPT for S+)?</p>
"
439526,37751,2009-01-13T15:58:48Z,23,Thinking in Vectors with R,"<p>I know that R works most efficiently with vectors and looping should be avoided. I am having a hard time teaching myself to actually write code this way. I would like some ideas on how to 'vectorize' my code. Here's an example of creating 10 years of sample data for 10,000 non unique combinations of state (<code>st</code>), plan1 (<code>p1</code>) and plan2 (<code>p2</code>):</p>

<pre><code>st&lt;-NULL
p1&lt;-NULL
p2&lt;-NULL
year&lt;-NULL
i&lt;-0
starttime &lt;- Sys.time()

while (i&lt;10000) {
    for (years in seq(1991,2000)) {
        st&lt;-c(st,sample(c(12,17,24),1,prob=c(20,30,50)))
        p1&lt;-c(p1,sample(c(12,17,24),1,prob=c(20,30,50)))
        p2&lt;-c(p2,sample(c(12,17,24),1,prob=c(20,30,50)))    
        year &lt;-c(year,years)
    }
        i&lt;-i+1
}
Sys.time() - starttime
</code></pre>

<p>This takes about 8 minutes to run on my laptop. I end up with 4 vectors, each with 100,000 values, as expected. How can I do this faster using vector functions?</p>

<p>As a side note, if I limit the above code to 1000 loops on i it only takes 2 seconds, but 10,000 takes 8 minutes. Any idea why?</p>
"
445059,37751,2009-01-14T23:09:02Z,12,Vectorize my thinking: Vector Operations in R,"<p>So earlier I answered my own question on thinking in vectors in R. But now I have another problem which I can't 'vectorize.' I know vectors are faster and loops slower, but I can't figure out how to do this in a vector method:</p>

<p>I have a data frame (which for sentimental reasons I like to call my.data) which I want to do a full marginal analysis on. I need to remove certain elements one at a time and 'value' the data frame then I need to do the iterating again by removing only the next element. Then do again... and again... The idea is to do a full marginal analysis on a subset of my data. Anyhow, I can't conceive of how to do this in a vector efficient way. </p>

<p>I've shortened the looping part of the code down and it looks something like this:</p>

<pre><code>for (j in my.data$item[my.data$fixed==0]) { # &lt;-- selects the items I want to loop 
                                            #     through
    my.data.it &lt;- my.data[my.data$item!= j,] # &lt;-- this kicks item j out of the list
    sum.data &lt;-aggregate(my.data.it, by=list(year), FUN=sum, na.rm=TRUE) #&lt;-- do an
                                                                         # aggregation

    do(a.little.dance) &amp;&amp; make(a.little.love) -&gt; get.down(tonight) # &lt;-- a little
                                                                   #  song and dance

    delta &lt;- (get.love)                                         # &lt;-- get some love
    delta.list&lt;-append(delta.list, delta, after=length(delta.list)) #&lt;-- put my love
                                                                    #    in a vector 
}
</code></pre>

<p>So obviously I hacked out a bunch of stuff in the middle, just to make it less clumsy. The goal would be to remove the j loop using something more vector efficient. Any ideas?</p>
"
467110,11301,2009-01-21T21:33:13Z,5,Is R a compiled language?,"<p>I can't find it anywhere on the web (and I don't want to install it). Is the <a href=""http://en.wikipedia.org/wiki/R_(programming_language)"" rel=""nofollow noreferrer"">R language</a> a compiled language? How fast does it run a pre-written script? Does it do any kind of compilation, or just execute instructions line by line?</p>
"
476726,277,2009-01-24T21:56:23Z,10,Filtering data in R,"<p>I have a CSV of file of data that I can load in R using <code>read.csv()</code></p>

<p>Some of the data is missing, so I want to reduce the data frame down to set that consists entirely of non-missing data, i.e. if a <code>NULL</code> appears anywhere, I want to exclude that column and row from the filtered data set.</p>

<p>I know I can probably do this fairly simply with the inbuilt R vector operations, but I am not quite sure how to do this exactly?</p>

<p>To make my question a little more concrete, here is a quick sample of the data so you can see what I want to do.</p>

<pre><code>DocID       Anno1    Anno7  Anno8
1           7        NULL   8
2           8        NULL   3
44          10       2      3
45          6        6      6
46          1        3      4
49          3        8      5
62          4        NULL   9
63          2        NULL   4
67          11       NULL   3
91          NULL     9      7
92          NULL     7      5
93          NULL     8      8
</code></pre>

<p>So given this input, I need some code that will reduce the output to this.</p>

<pre><code>DocID       Anno8
44          3
45          6
46          4
49          5
</code></pre>

<p>As <code>Anno8</code> is the only column with non-NULL data, and there are only four rows with non-NULL data.</p>
"
495744,12677,2009-01-30T14:48:19Z,2,Operating with time intervals like 08:00-08:15,"<p>I would like to import a time-series where the first field indicates a period:</p>

<pre><code>08:00-08:15
08:15-08:30
08:30-08:45
</code></pre>

<p>Does R have any features to do this neatly?</p>

<p>Thanks!</p>

<hr>

<p><strong>Update:</strong></p>

<p>The most promising solution I found, as suggested by Godeke was the cron package and using substring() to extract the start of the interval.</p>

<p>I'm still working on related issues, so I'll update with the solution when I get there.</p>
"
498932,445,2009-01-31T14:50:28Z,3,What's the easiest way to install 100s of files in a Visual Studio setup project,"<p>I have a standard c# application that acts as a GUI front end for a an ""R"" statistics engine. ""R"" consists of approx 600 files in approx 50 different folders and can be ""installed"" on a machine through xcopy deployment.</p>

<p>I would like to package up both the R engine and my c# gui into one setup.exe so that the user doesn't need to go and install R first and then my c# application seperately.</p>

<p>I know that I can produce a setup project and then add in the R files one by one but adding all 600 files will be very tedious!</p>

<p>Is there an easier way of doing what I want? Can I add the single R folder and automatically add the subfolders and files to save me adding them in one by one? Or maybe do an unzip procedure in my setup project which will unzip the R engine in one go?</p>
"
509595,12677,2009-02-04T00:23:09Z,2,csv file with multiple time-series,"<p>I've imported a csv file with lots of columns and sections of data.</p>

<pre><code>v &lt;- read.csv2(""200109.csv"", header=TRUE, sep="","", skip=""6"", na.strings=c(""""))
</code></pre>

<p>The layout of the file is something like this:</p>

<pre><code>Dataset1
time, data, .....
0       0
0       &lt;NA&gt;
0       0

Dataset2
time, data, .....
00:00   0
0       &lt;NA&gt;
0       0
</code></pre>

<p>(The headers of the different datasets is exactly the same.</p>

<p>Now, I can plot the first dataset with:</p>

<pre><code>plot(as.numeric(as.character(v$Calls.served.by.agent[1:30])), type=""l"")
</code></pre>

<p>I am curious if there is a better way to:</p>

<ol>
<li><p>Get all the numbers read as numbers, without having to convert.</p></li>
<li><p>Address the different datasets in the file, in some meaningfull way.</p></li>
</ol>

<p>Any hints would be appreciated. Thank you.</p>

<hr>

<p>Status update:</p>

<p>I haven't really found a good solution yet in R, but I've started writing a script in Lua to seperate each individual time-series into a seperate file. I'm leaving this open for now, because I'm curious how well R will deal with all these files. I'll get 8 files per day.</p>
"
520810,63372,2009-02-06T15:49:48Z,20,Does R have quote-like operators like Perl's qw()?,"<p>Anyone know if R has quote-like operators like Perl's <code>qw()</code> for generating character vectors? </p>
"
551113,2056,2009-02-15T16:05:33Z,3,Writing a GUI for the BRCAPRO Cancer Gene Risk Calculation Engine,"<p>I think this is a completely unique question on Stack Overflow.  First some background:</p>

<p>I've been asked to write a new GUI on top of a calculation engine called BRCAPRO (brack-a-pro).  BRCAPRO implements a Mendelian computational model based on a piece of software called BayesMendel.  BRCAPRO calculation are used by doctors and surgeons specializing in cancer treatment to show patients:</p>

<ul>
<li>The probability of being diagnosed with cancer based on their genetics and family history.</li>
<li>The change in life expectancy based on different forms of treatment and/or the age at which these treatments are started.</li>
</ul>

<p>I've done enough research to know that the BRCAPRO formulas are far too complicated to reasonably implement in my own code.</p>

<p>There is an existing well-known (to cancer doctors) software package called CancerGene: <a href=""http://www8.utsouthwestern.edu/utsw/cda/dept47829/files/65844.html"" rel=""nofollow noreferrer"">http://www8.utsouthwestern.edu/utsw/cda/dept47829/files/65844.html</a>.  This program is very old, runs on Windows 95 and includes calculating engines for several forms of cancer my client does not work with.  Ideally my client would like his application to run on the web so that he can share information with other doctors easily.</p>

<p>My task is take the CancerGene application, which is built on the BRCAPRO engine, and:</p>

<ol>
<li>Duplicate 90% of its functionality</li>
<li>Remove unnecessary functionality</li>
<li>Modify the output of reports</li>
<li>If possible, make it web-based</li>
</ol>

<p>Now my question:</p>

<p>Does anybody have any idea how to code against BRCAPRO?  I have Googled for two days and found no API documentation or development information of any kind.  Wikipedia says that the BayesMendel modeling software is written in R, but I don't have any idea what BRCAPRO is written in.  I know absolutely nothing about R.  </p>

<p>To be clear, I don't need to modify the behavior or calculating engine of BRCAPRO.  I just need to know how to feed it input so that it returns numbers to me.</p>

<p>--  Edit to add more information --</p>

<p>I downloaded the CancerGene application in the above link and installed it.  There was a small amount of documentation, including the data format that BRCAPRO expects to receive.  Without getting into an unnecessary level of detail, BRCAPRO expects matrix-formatted data where each column represents a genetic trait and each row represents a family member.  Now I just need to know how to pass this matrix to the BRCAPRO engine once I collect it from my Web/Windows form.</p>

<p>Here's hoping there are a couple of doctor/developers here on Stack Overflow!</p>

<p>KN</p>
"
560329,67405,2009-02-18T09:08:38Z,2,Sort the X axis in a barplot,"<p>I have binned data that looks like this:</p>

<pre><code>  (8.048,18.05] (-21.95,-11.95] (-31.95,-21.95]   (18.05,28.05] (-41.95,-31.95]
             81              76              18              18             12
    (-132,-122]     (-122,-112]     (-112,-102]     (-162,-152]  (-102,-91.95]
              6               6               6               5              5
(-91.95,-81.95]     (-192,-182]   (28.05,38.05]   (38.05,48.05]  (58.05,68.05]
              5               4               4               4              4
  (78.05,88.05]     (98.05,108]     (-562,-552]     (-512,-502]    (-482,-472]
              4               4               3               3              3
    (-452,-442]     (-412,-402]     (-282,-272]     (-152,-142]  (48.05,58.05]
              3               3               3               3              3
  (68.05,78.05]       (118,128]       (128,138]     (-582,-572]    (-552,-542]
              3               3               3               2              2
    (-532,-522]     (-422,-412]     (-392,-382]     (-362,-352]    (-262,-252]
              2               2               2               2              2
    (-252,-242]     (-142,-132] (-81.95,-71.95]       (148,158]  (-1402,-1392]
              2               2               2               2              1
  (-1372,-1362]   (-1342,-1332]     (-942,-932]     (-862,-852]    (-822,-812]
              1               1               1               1              1
    (-712,-702]     (-682,-672]     (-672,-662]     (-632,-622]    (-542,-532]
              1               1               1               1              1
    (-502,-492]     (-492,-482]     (-472,-462]     (-462,-452]    (-442,-432]
              1               1               1               1              1
    (-432,-422]     (-352,-342]     (-332,-322]     (-312,-302]    (-302,-292]
              1               1               1               1              1
    (-202,-192]     (-182,-172]     (-172,-162] (-51.95,-41.95]  (88.05,98.05]
              1               1               1               1              1
      (108,118]       (158,168]       (168,178]       (178,188]      (298,308]
              1               1               1               1              1
      (318,328]       (328,338]       (338,348]       (368,378]      (458,468]
              1               1               1               1              1
</code></pre>

<p>How can I plot this data so that the bin is sorted from most negative on the left to most positive on the right? Currently my graph looks <a href=""http://docs.google.com/Doc?id=dcvdrfrh_5cm5qkchw"" rel=""nofollow noreferrer"">like this</a>.  Notice that it is not sorted at all.  In particular the second bar (<code>value = 76</code>) is placed to the right of the first:</p>

<pre><code> (8.048,18.05] (-21.95,-11.95]
            81              76
</code></pre>

<p>This is the command I use to plot:</p>

<pre><code>barplot(x,ylab=""Number of Unique Tags"", xlab=""Expected - Observed"")
</code></pre>
"
582653,69117,2009-02-24T17:21:30Z,13,what is the best practice of handling time in R?,"<p>I am working with a survey dataset. It has two string vectors, start and finish, indicating the time of the day when the interview was started, and finished, respectively.</p>

<p>They are character strings that look like: ""9:24 am"", ""12:35 pm"", and so forth. i am trying to calculate the duration of the interview based on these two. what is the best way of doing this?</p>

<p>i know that, for dates, there are lots of classes or functions like <code>as.date()</code>, <code>as.Date()</code>, <code>chron()</code>, or <code>as.POSIXct()</code>. So i was looking for something like <code>as.time()</code>, but could not find it. Should I just append a made-up date and convert the whole thing into a <code>POSIX()</code> date-time class, then use <code>difftime()</code>? </p>

<p>What is the best practice of handling time in R?</p>
"
596819,69117,2009-02-27T21:49:17Z,11,What is the best way to avoid passing a data frame around?,"<p>I have 12 data frames to work with. They are similar and I have to do the same processing to each one, so I wrote a function that takes a data frame, processes it, and then returns a data frame. This works. But I am afraid that I am passing around a very big structure. I may be making temporary copies (am I?) This can't be efficient. What is the best way to avoid passing a data frame around? Thank you.</p>

<pre><code>doSomething &lt;- function(df) {
  // do something with the data frame, df
  return(df)
}
</code></pre>
"
596976,69117,2009-02-27T22:45:59Z,0,What is the Y function?,"<p>A friend of mine asked me if I understood the Y function. I didn't even know what it was. <code>? Y</code> did not get me anywhere.</p>

<p>What is it?</p>
"
652136,1447,2009-03-16T20:59:36Z,159,How can I remove an element from a list?,"<p>I have a list and I want to remove a single element from it.  How can I do this?</p>

<p>I've tried looking up what I think the obvious names for this function would be in the reference manual and I haven't found anything appropriate.</p>
"
657440,67405,2009-03-18T08:59:04Z,7,Cumulative Plot with Given X-Axis,"<p>I have data that looks like this.
In which I want to plot accumulative value of dat1 with respect
to x-axis. Also plot it together with dat2.</p>

<pre><code>#x-axis dat1              dat2
-10     0.0140149       0.0140146
-9      0.00890835      0.00891768
-8      0.00672276      0.00672488
-7      0.00876399      0.00879401
-6      0.00806879      0.00808141
-5      0.0088366       0.00885121
-4      0.00856872      0.00857769
-3      0.0195384       0.0196094
-2      0.0160239       0.0161829
-1      0.0254455       0.0257845
0       0.0397413       0.0400913
1       0.0743316       0.0755453
2       0.0247501       0.0253324
3       0.0214285       0.021778
4       0.0241462       0.0244967
5       0.0150943       0.015241
6       0.0141398       0.0142373
7       0.0101515       0.0102948
8       0.0308843       0.031294
9       0.0095504       0.00960626
10      0.00729676      0.0073713
</code></pre>

<p>What's the common way to do it in R?</p>

<p>I looked at ECDF from Hmisc, it doesn't seem to do what I want.
In particular it doesn't allow us to give x-axis value.</p>
"
659725,37751,2009-03-18T19:21:41Z,5,Column Stores: Comparing Column Based Databases,"<p>I've really been struggling to make SQL Server into something that, quite frankly, it will never be. I need a database engine for my analytical work. The DB needs to be fast and does NOT need all the logging and other overhead found in typical databases (SQL Server, Oracle, DB2, etc.) </p>

<p>Yesterday I listened to <a href=""http://itc.conversationsnetwork.org/shows/detail4009.html"" rel=""noreferrer"">Michael Stonebraker speak at the Money:Tech conference</a> and I kept thinking, ""I'm not really crazy. There IS a better way!"" He talks about using <a href=""http://en.wikipedia.org/wiki/Column-oriented_DBMS"" rel=""noreferrer"">column stores</a> instead of row oriented databases. I went to the Wikipedia page for <a href=""http://en.wikipedia.org/wiki/Column-oriented_DBMS"" rel=""noreferrer"">column stores</a> and I see a few open source projects (which I like) and a few commercial/open source projects (which I don't fully understand). </p>

<p>My question is this: In an applied analytical environment, how do the different column based DB's differ? How should I be thinking about them? Anyone have practical experience with multiple column based systems? Can I leverage my SQL experience with these DBs or am I going to have to learn a new language?</p>

<p>I am ultimately going to be pulling data into R for analysis. </p>

<p><strong>EDIT:</strong> I was requested for some clarification in what exactly I am trying to do. So, here's an example of what I would like to do:
Create a table that has 4 million rows and 20 columns (5 dims, 15 facts). Create 5 aggregation tables that calculate max, min, and average for each of the facts. Join those 5 aggregations back to the starting table. Now calculate the percent deviation from mean, percent deviation of min, and percent deviation from max for each row and add it to the original table. This table data does not get new rows each day, it gets TOTALLY replaced and the process is repeated. Heaven forbid if the process must be stopped. And the logs... ohhhhh the logs! :)</p>
"
713878,NA,2009-04-03T13:23:03Z,25,How expensive is it to compute the eigenvalues of a matrix?,"<p>How expensive is it to compute the eigenvalues of a matrix? </p>

<p>What is the complexity of the best algorithms? </p>

<p>How long might it take in practice if I have a 1000 x 1000 matrix? I assume it helps if the matrix is sparse?</p>

<p>Are there any cases where the eigenvalue computation would not terminate? </p>

<p>In <code>R</code>, I can compute the eigenvalues as in the following toy example:</p>

<pre><code>m&lt;-matrix( c(13,2, 5,4), ncol=2, nrow=2 )
eigen(m, only.values=1)
$values
[1] 14  3
</code></pre>

<p>Does anyone know what algorithm it uses? </p>

<p>Are there any other (open-source) packages that compute the eigenvalue?</p>
"
717747,19410,2009-04-04T20:21:37Z,8,How do I color edges or draw rects correctly in an R dendrogram?,"<p>I generated <a href=""http://farm4.static.flickr.com/3622/3411762935_b9429d9d68_o.png"" rel=""nofollow noreferrer"">this dendrogram</a> using R's <code>hclust()</code>, <code>as.dendrogram()</code> and <code>plot.dendrogram()</code> functions.</p>

<p>I used the <code>dendrapply()</code> function and a local function to color leaves, which is working fine.</p>

<p>I have results from a statistical test that indicate if a set of nodes (<em>e.g.</em> the cluster of ""<code>_+v\_stat5a\_01_</code>"" and ""<code>_+v\_stat5b\_01_</code>"" in the lower-right corner of the tree) are significant or important.</p>

<p>I also have a local function that I can use with <code>dendrapply()</code> that finds the exact node in my dendrogram which contains significant leaves.</p>

<p>I would like to either (following the example):</p>

<ol>
<li>Color the edges that join ""<code>_+v\_stat5a\_01_</code>"" and ""<code>_+v\_stat5b\_01_</code>""; or,</li>
<li>Draw a <code>rect()</code> around ""<code>_+v\_stat5a\_01_</code>"" and ""<code>_+v\_stat5b\_01_</code>""</li>
</ol>

<p>I have the following local function (the details of the ""nodes-in-leafList-match-nodes-in-clusterList"" condition aren't important, but that it highlights significant nodes):</p>

<pre><code>markSignificantClusters &lt;&lt;- function (n) {
  if (!is.leaf(n)) {
     a &lt;- attributes(n)
     leafList &lt;- unlist(dendrapply(n, listLabels))
     for (clusterIndex in 1:length(significantClustersList[[1]])) {
       clusterList &lt;- unlist(significantClustersList[[1]][clusterIndex])
       if (nodes-in-leafList-match-nodes-in-clusterList) {
          # I now have a node ""n"" that contains significant leaves, and
          # I'd like to use a dendrapply() call to another local function
          # which colors the edges that run down to the leaves; or, draw
          # a rect() around the leaves
       }
     }
  }
}
</code></pre>

<p>From within this <code>if</code> block, I have tried calling <code>dendrapply(n, markEdges)</code>, but this did not work:</p>

<pre><code>markEdges &lt;&lt;- function (n) {
  a &lt;- attributes(n)
  attr(n, ""edgePar"") &lt;- c(a$edgePar, list(lty=3, col=""red""))
}
</code></pre>

<p>In my ideal example, the edges connecting ""<code>_+v\_stat5a\_01_</code>"" and ""<code>_+v\_stat5b\_01_</code>"" would be dashed and of a red color.</p>

<p>I have also tried using <code>rect.hclust()</code> within this <code>if</code> block:</p>

<pre><code>ma &lt;- match(leafList, orderedLabels)  
rect.hclust(scoreClusterObj, h = a$height, x = c(min(ma), max(ma)), border = 2)
</code></pre>

<p>But the result does not work with horizontal dendrograms (<em>i.e.</em> dendrograms with horizontal labels). <a href=""http://farm4.static.flickr.com/3331/3410126060_f8f06c4498_o.png"" rel=""nofollow noreferrer"">Here is an example</a> (note the red stripe in the lower-right corner). Something is not correct about the dimensions of what <code>rect.hclust()</code> generates, and I don't know how it works, to be able to write my own version.</p>

<p>I appreciate any advice for getting <code>edgePar</code> or <code>rect.hclust()</code> to work properly, or to be able to write my own <code>rect.hclust()</code> equivalent.</p>

<p><strong>UPDATE</strong></p>

<p>Since asking this question, I used <code>getAnywhere(rect.hclust())</code> to get the functional code that calculates parameters and draws the <code>rect</code> object. I wrote a custom version of this function to handle horizontal and vertical leaves, and call it with <code>dendrapply()</code>.</p>

<p>However, there is some kind of clipping effect that removes part of the <code>rect</code>. For horizontal leaves (leaves that are drawn on the right side of the tree), the rightmost edge of the <code>rect</code> either disappears or is thinner than the border width of the other three sides of the <code>rect</code>. For vertical leaves (leaves that are drawn on the bottom of the tree), the bottommost edge of the <code>rect</code> suffers the same display problem.</p>

<p>What I had done as a means of marking significant clusters is to reduce the width of the <code>rect</code> such that I render a vertical red stripe between the tips of the cluster edges and the (horizontal) leaf labels. </p>

<p>This eliminates the clipping issue, but introduces another problem, in that the space between the cluster edge tips and the leaf labels is only six or so pixels wide, which I don't have much control over. This limits the width of the vertical stripe. </p>

<p>The worse problem is that the <code>x</code>-coordinate that marks where the vertical stripe can fit between the two elements will change based on the width of the larger tree (<code>par[""usr""]</code>), which in turn depends on how the tree hierarchy ends up being structured.</p>

<p>I wrote a ""correction"" or, better termed, a hack to adjust this <code>x</code> value and the <code>rect</code> width for horizontal trees. It doesn't always work consistently, but for the trees I am making, it seems to keep from getting too close to (or overlapping) edges and labels.</p>

<p>Ultimately, a better fix would be to find out how to draw the <code>rect</code> so that there is no clipping. Or a consistent way to calculate the specific <code>x</code> position in between tree edges and labels for any given tree, so as to center and size the stripe properly.</p>

<p>I would also be very interested in a method for annotating edges with colors or line styles.</p>
"
736514,20895,2009-04-10T02:18:38Z,41,R Random Forests Variable Importance,"<p>I am trying to use the random forests package for classification in R.</p>

<p>The Variable Importance Measures listed are:</p>

<ul>
<li>mean raw importance score of variable x for class 0</li>
<li>mean raw importance score of variable x for class 1</li>
<li><code>MeanDecreaseAccuracy</code></li>
<li><code>MeanDecreaseGini</code></li>
</ul>

<p>Now I know what these ""mean"" as in I know their definitions.  What I want to know is how to use them.</p>

<p>What I really want to know is what these values mean in only the context of how accurate they are, what is a good value, what is a bad value, what are the maximums and minimums, etc.</p>

<p>If a variable has a high <code>MeanDecreaseAccuracy</code> or <code>MeanDecreaseGini</code> does that mean it is important or unimportant?  Also any information on raw scores could be useful too.
I want to know everything there is to know about these numbers that is relevant to the application of them.  </p>

<p>An explanation that uses the words 'error', 'summation', or 'permutated' would be less helpful then a simpler explanation that didn't involve any discussion of how random forests works.</p>

<p>Like if I wanted someone to explain to me how to use a radio, I wouldn't expect the explanation to involve how a radio converts radio waves into sound.</p>
"
736541,85950,2009-04-10T02:32:21Z,12,Plots without titles/labels in R,"<p>In <a href=""http://www.r-project.org/"" rel=""nofollow noreferrer"">R</a> is there any way to produce plots which have no title and which use the space the title would otherwise have taken up?</p>

<p>In <code>plot()</code>, <code>main</code>, <code>sub</code>, <code>xlab</code>, and <code>ylab</code> all default to <code>NULL</code>, but this just leaves blank space where they would have been, ditto for setting them to ''.  It would be nice if not including them meant that the entire plot space was utilized rather than leaving extra empty space on the edges.  This is all especially relevant in printing plots to file devices like <code>pdf()</code>, <code>png()</code>, etc.</p>
"
743622,14744,2009-04-13T11:13:51Z,106,Finding row index containing maximum value using R,"<p>Given the following matrix lets assume I want to find the maximum value in column two:</p>

<pre><code>mat &lt;- matrix(c(1:3,7:9,4:6), byrow = T, nc = 3)
mat
     [,1] [,2] [,3]
[1,]    1    2    3
[2,]    7    8    9
[3,]    4    5    6
</code></pre>

<p>I know <code>max(mat[,2])</code> will return 8. How can I return the row index, in this case row two?</p>
"
743812,14744,2009-04-13T12:52:51Z,125,Calculating moving average,"<p>I'm trying to use R to calculate the moving average over a series of values in a matrix. The normal R mailing list search hasn't been very helpful though. There doesn't seem to be a <a href=""http://www.statmethods.net/management/functions.html"" rel=""noreferrer"">built-in function</a> in R will allow me to calculate moving averages. Do any packages provide one? Or do I need to write my own?</p>
"
750703,85950,2009-04-15T07:55:21Z,28,"Suppressing ""null device"" output with R in batch mode","<p>I have a number of bash scripts which invoke R scripts for plotting things.  Something like:  </p>

<pre><code>#!/bin/bash
R --vanilla --slave &lt;&lt;RSCRIPT
cat(""Plotting $1 to $2\n"")
input &lt;- read.table(""$1"")
png(""$2"")
plot(as.numeric(input[1,]))
dev.off()
RSCRIPT
</code></pre>

<p>The problem is that despite <code>--slave</code>, the call to <code>dev.off()</code> prints the message <code>null device 1</code>.  Once there are a lot of plots being done, or for more complex scripts which plot to a number of files, this gets to be a real hassle.</p>

<p>Is there some way to suppress this message?</p>
"
750786,85950,2009-04-15T08:31:35Z,94,What's the best way to use R scripts on the command line (terminal)?,"<p>It's very convenient to have R scripts for doing simple plots from the command line.  However, running R from bash scripts is not convenient at all.  The ideal might be something like</p>

<pre><code>#!/path/to/R
...
</code></pre>

<p>or</p>

<pre><code>#!/usr/bin/env R
...
</code></pre>

<p>but I haven't been able to make either of those work.</p>

<p>Another option is keeping the scripts purely in R, e.g. <code>script.R</code>, and invoking it with <code>R --file=script.R</code> or similar.  However, occasionally a script will rely on obscure command line switches at which point part of the code exists outside the script.  Example: sneaking things into R from bash via a local .Rprofile, the desired switches are then everything <code>--vanilla</code> implies except <code>--no-init-file</code>.</p>

<p>Another option is a bash script to store the R flags and be painlessly executable, which then calls the R script.  The problem is that this means a single program just got split into two files which now have to be keep in sync, transferred to new machines together, etc.</p>

<p>The option I currently despise least is embedding the R in a bash script:</p>

<pre><code>#!/bin/bash
... # usage message to catch bad input without invoking R
... # any bash pre-processing of input
... # etc
R --random-flags &lt;&lt;RSCRIPT
# R code goes here
RSCRIPT
</code></pre>

<p>Everything's in a single file.  It's executable and easily handles arguments.  The problem is that combining bash and R like this pretty much eliminates the possibility of any IDE not failing on one or the other, and makes my heart hurt real bad.</p>

<p>Is there some better way I'm missing?</p>
"
775116,1447,2009-04-21T23:30:47Z,7,How can a function parameter be used without mentioning it in the function body?,"<p>I've been trying to learn more about R (and writing C extensions) and I thought it might help to read the source for some well known packages.  I decided to start with rpart which is defined as:</p>

<pre><code>rpart &lt;- function(formula, data, weights, subset,
       na.action=na.rpart, method, model=FALSE, x=FALSE, y=TRUE,
       parms, control, cost, ...)
</code></pre>

<p>I did a quick search through the source and I don't see formula mentioned anywhere in the function body yet I know that somehow rpart is using that parameter.  How is it that rpart is using formula without its name being in the function body?</p>
"
780796,84458,2009-04-23T08:29:19Z,39,Emacs ESS Mode - Tabbing for Comment Region,"<p>I am using the Emacs-Speaks-Statistics (ESS) mode for Emacs.  When editing R code, any comment lines (those starting with #) automatically get tabbed to the far right when I create a new line above it.  How should I change my .emacs.el file to fix this?</p>

<p>For example, I have:</p>

<pre><code># Comment
</code></pre>

<p>Now, after putting my cursor at the beginning of the line and pressing Enter, I get:</p>

<pre><code>                                # Comment
</code></pre>

<p>Thanks for any hints.</p>
"
789602,94704,2009-04-25T19:51:45Z,2,What does %% mean?,"<p>From the question you can probably tell that I don't know much about code! My question is this:</p>

<p>What does this code mean?</p>

<pre><code>mnlong &lt;- 280.460 + .9856474 * time
mnlong &lt;- mnlong %% 360
mnlong[mnlong &lt; 0] &lt;- mnlong[mnlong &lt; 0] + 360
</code></pre>

<p>I understand that the <code>mnlong</code> and <code>time</code> are variables but the <code>%%</code> confuses me.</p>

<p>Could someone give me a basic description?</p>
"
805027,85950,2009-04-30T01:32:43Z,4,Suppressing or setting CreationDate/ModDate in R pdf output,"<p>When R creates PDFs using pdf() it includes a CreationDate and a ModDate in the PDF.  I have a number of such generated PDFs in an svn repository and the effect is that when figures are remade by R, even with the same data, they appear as modified (rightly so) to svn.  What's the best way to get the two to play nicely together?</p>

<p>I could simply remove those lines from the PDFs outside of R, but this extra step is undesirable.<br>
I could set the system time to some fixed value as part of the running the scripts, but this is even less desirable.<br>
I could probably even convince svn to use a specialized diff which ignored changes on those lines, but that sounds like more trouble than it's worth.</p>

<p>A very pleasant solution would be if there were a way to prevent R putting those lines in the PDF file in the first place.  I have a file system to tell me when files were created and modified thank-you-very-much, I don't need that info stored within the file as well.</p>
"
855798,1811,2009-05-13T02:34:55Z,0,"In R, what is a good way to aggregate String data","<p>In R (or S-PLUS), what is a good way to aggregate String data in a data frame?</p>

<p>Consider the following:</p>

<pre><code>myList &lt;- as.data.frame(c(""Bob"", ""Mary"", ""Bob"", ""Bob"", ""Joe""))
</code></pre>

<p>I would like the output to be:</p>

<pre><code> [Bob,  3
  Mary, 1
  Joe,  1]
</code></pre>

<p>Currently, the only way I know how to do this is with the summary function.</p>

<pre><code>&gt; summary(as.data.frame(myList))

 Bob :3                                
 Joe :1                                
 Mary:1      
</code></pre>

<p>This feels like a hack. Can anyone suggest a better way?</p>
"
876711,422,2009-05-18T08:16:10Z,18,Plotting Simple Data in R,"<p>I have a comma separated file named <code>foo.csv</code> containing the following data:</p>

<pre><code>scale, serial, spawn, for, worker
5, 0.000178, 0.000288, 0.000292, 0.000300
10, 0.156986, 0.297926, 0.064509, 0.066297
12, 2.658998, 6.059502, 0.912733, 0.923606
15, 188.023411, 719.463264, 164.111459, 161.687982
</code></pre>

<p>I essentially have two questions:</p>

<p>1) How do I plot the first column (x-axis) versus the second column (y-axis)? I'm trying this (from reading <a href=""http://www.ats.ucla.edu/stat/R/gbe/scatter.htm"" rel=""noreferrer"">this site</a>):</p>

<pre><code>data &lt;- read.table(""foo.csv"", header=T,sep="","")
attach(data)
scale &lt;- data[1]
serial &lt;- data[2]
plot(scale,serial)
</code></pre>

<p>But I get this error back:</p>

<pre><code>Error in stripchart.default(x1, ...) : invalid plotting method
</code></pre>

<p>Any idea what I'm doing wrong? A <a href=""http://www.nabble.com/Problems-producing-a-simple-plot-td23347296.html"" rel=""noreferrer"">quick Google search</a> reveals someone else with the same problem but no relevant answer. UPDATE: It turns out it works fine if I skip the two assignment statements in the middle. Any idea why this is?</p>

<p>The second question follows pretty easily after the first:</p>

<p>2) How do I plot the first column (x-axis) versus all the other columns on the y-axis? I presume it's pretty easy once I get around the first problem I'm running into, but am just a bit new to R so I'm still wrapping my head around it.</p>
"
936748,57458,2009-06-01T20:56:30Z,25,Declaring a Const Variable in R,"<p>I'm working in R, and I'd like to define some variables that I (or one of my collaborators) cannot change. In C++ I'd do this:</p>

<pre><code>const std::string path( ""/projects/current"" );
</code></pre>

<p>How do I do this in the R programming language?</p>

<p>Edit for clarity: I know that I can define strings like this in R:</p>

<pre><code>path = ""/projects/current""
</code></pre>

<p>What I really want is a language construct that guarantees that nobody can ever change the value associated with the variable named ""path.""</p>

<p>Edit to respond to comments:</p>

<p>It's technically true that const is a compile-time guarantee, but it would be valid in my mind that the R interpreter would throw stop execution with an error message. For example, look what happens when you try to assign values to a numeric constant:</p>

<pre><code>&gt; 7 = 3
Error in 7 = 3 : invalid (do_set) left-hand side to assignment
</code></pre>

<p>So what I really want is a language feature that allows you to assign values once and only once, and there should be some kind of error when you try to assign a new value to a variabled declared as const. I don't care if the error occurs at run-time, especially if there's no compilation phase. This might not technically be const by the Wikipedia definition, but it's very close. It also looks like this is not possible in the R programming language.</p>
"
937346,58434,2009-06-01T23:52:20Z,3,How to link with static libraries when building an R package,"<p>I'm creating a package that is going to be used by R (the statistical program), I'm not an expert using this application but I have managed to create a very simple package, using the following logic, I have some classes in C++, as the code has to be compiled using the R compiler and it only allows C code, I have a wrapper C code that call the C++ methods, and later I have an R script that call the methods exposed by the C code, so basically is a communication like R &lt;-> C&lt;->C++.</p>

<p>The full tutorial that I used to create this package is found <a href=""http://www.stat.columbia.edu/~gelman/stuff_for_blog/AlanRPackageTutorial.pdf"" rel=""nofollow noreferrer"">here</a>, I add it as a reference.</p>

<p>Now my problem is that I need to add some functionality to the package that I already created, what I need to do is to add code for late binding to a COM object which is another product that I created and that is registered using regasm tool.</p>

<p>This is the c++ code that I'm using to try to late bind to the COM object, I'm trying to use IDispatch to do so:</p>

<pre><code>{
...
CLSID clsid;    
HRESULT hr = CLSIDFromProgID((WCHAR*)""My Com object ProgId"", &clsid);
if(FAILED(hr))                      
  return;   
...     
}
</code></pre>

<p>I didn't paste the whole code because only with these lines the compiler is giving me troubles already, the command I use to compile is </p>

<pre><code>R CMD SHLIB Cclass.cc C++class.cc</code></pre>

<p>Where ""Cclass.cc"" has the C code that call the c++ methods and ""C++class.cc"" is actually the C++ code.</p>

<p>When I compile these classes the compiler says <pre><code>""undefined reference to `CLSIDFromProgID@8'collect2: ld returned 1 exit status""</pre></code></p>

<p>I""m sure I have added all the header files that I need, that's why I believe my problem is that I'm not including ole32.lib and oleaut32.lib which are static libraries.</p>

<p>So, my question is, how can I include this libraries in order to be able to use the methods for late binding, like CLSIDFromProgID(...) or QueryInterface(...). Also if anyone believes that my problem is not linking this libraries, but something else, it would be great if can point me to which my problem may be.</p>

<p>Also have in mind that I need to link with those statics libraries in a way that they can be compiled without problem by the R compiler, which if I'm not wrong is a merely c compiler.</p>
"
952275,69749,2009-06-04T18:25:55Z,58,Regex group capture in R with multiple capture-groups,"<p>In R, is it possible to extract group capture from a regular expression match?  As far as I can tell, none of <code>grep</code>, <code>grepl</code>, <code>regexpr</code>, <code>gregexpr</code>, <code>sub</code>, or <code>gsub</code> return the group captures.</p>

<p>I need to extract key-value pairs from strings that are encoded thus:</p>

<pre><code>\((.*?) :: (0\.[0-9]+)\)
</code></pre>

<p>I can always just do multiple full-match greps, or do some outside (non-R) processing, but I was hoping I can do it all within R.  Is there's a function or a package that provides such a function to do this?</p>
"
1007495,23524,2009-06-17T14:44:04Z,3,Determining distribution so I can generate test data,"<p>I've got about 100M value/count pairs in a text file on my Linux machine.  I'd like to figure out what sort of formula I would use to generate more pairs that follow the same distribution.  </p>

<p>From a casual inspection, it looks power law-ish, but I need to be a bit more rigorous than that.  Can R do this easily?  If so, how?  Is there something else that works better?</p>
"
1022649,NA,2009-06-20T21:53:56Z,7,Weighted slope one algorithm? (porting from Python to R),"<p>I was reading about the <a href=""http://en.wikipedia.org/wiki/Slope_One#Slope_one_collaborative_filtering_for_rated_resources"" rel=""nofollow noreferrer"">Weighted slope one algorithm</a> ( and more
formally <a href=""http://www.daniel-lemire.com/fr/documents/publications/lemiremaclachlan_sdm05.pdf"" rel=""nofollow noreferrer"">here (PDF)</a>) which is supposed to take item ratings from different users and, given a user vector containing at least 1 rating and 1 missing value, predict the missing ratings.</p>

<p>I found a <a href=""http://www.serpentine.com/wordpress/wp-content/uploads/2006/12/slope_one.py.txt"" rel=""nofollow noreferrer"">Python implementation of the algorithm</a>, but I'm having a hard time porting it to <a href=""http://www.r-project.org/"" rel=""nofollow noreferrer"">R</a> (which I'm more comfortable with). Below is my attempt. Any suggestions on how to make it work?</p>

<p>Thanks in advance, folks.</p>

<pre><code># take a 'training' set, tr.set and a vector with some missing ratings, d
pred=function(tr.set,d) {
    tr.set=rbind(tr.set,d)
    n.items=ncol(tr.set)

    # tally frequencies to use as weights
    freqs=sapply(1:n.items, function(i) {
        unlist(lapply(1:n.items, function(j) {
            sum(!(i==j)&amp;!is.na(tr.set[,i])&amp;!is.na(tr.set[,j])) })) })

    # estimate product-by-product mean differences in ratings
    diffs=array(NA, dim=c(n.items,n.items))
    diffs=sapply(1:n.items, function(i) {
        unlist(lapply(1:n.items, function(j) {
            diffs[j,i]=mean(tr.set[,i]-tr.set[,j],na.rm=T) })) })

    # create an output vector with NAs for all the items the user has already rated
    pred.out=as.numeric(is.na(d))
    pred.out[!is.na(d)]=NA

    a=which(!is.na(pred.out))
    b=which(is.na(pred.out))

    # calculated the weighted slope one estimate
    pred.out[a]=sapply(a, function(i) {
        sum(unlist(lapply(b,function (j) {
            sum((d[j]+diffs[j,i])*freqs[j,i])/rowSums(freqs)[i] }))) })

    names(pred.out)=colnames(tr.set)
    return(pred.out) }
# end function

# test, using example from [3]
alice=c(squid=1.0, octopus=0.2, cuttlefish=0.5, nautilus=NA)
bob=c(squid=1.0, octopus=0.5, cuttlefish=NA, nautilus=0.2)
carole=c(squid=0.2, octopus=1.0, cuttlefish=0.4, nautilus=0.4)
dave=c(squid=NA, octopus=0.4, cuttlefish=0.9, nautilus=0.5)
tr.set2=rbind(alice,bob,carole,dave)
lucy2=c(squid=0.4, octopus=NA, cuttlefish=NA, nautilus=NA)
pred(tr.set2,lucy2)
# not correct
# correct(?): {'nautilus': 0.10, 'octopus': 0.23, 'cuttlefish': 0.25}
</code></pre>
"
1088639,57458,2009-07-06T18:48:46Z,18,Static Variables in R,"<p>I have a function in R that I call multiple times. I want to keep track of the number of times that I've called it and use that to make decisions on what to do inside of the function. Here's what I have right now:</p>

<pre><code>f = function( x ) {
   count &lt;&lt;- count + 1
   return( mean(x) )
}

count = 1
numbers = rnorm( n = 100, mean = 0, sd = 1 )
for ( x in seq(1,100) ) {
   mean = f( numbers )
   print( count )
}
</code></pre>

<p>I don't like that I have to declare the variable count outside the scope of the function. In C or C++ I could just make a static variable. Can I do a similar thing in the R programming language?</p>
"
1092506,130633,2009-07-07T13:58:31Z,2,Line functions in R,"<p>I was wondering if it was possible to graph three lines in R using functions. For instance, how could I get the functions:</p>

<pre><code>3x+1 
4x+2
x+1 
</code></pre>

<p>to show up on the same graph in r?</p>
"
1098210,84458,2009-07-08T13:51:15Z,2,Emacs and ESS: Using the correct version of R,"<p>I have installed R-2.9.1 and I am using Emacs+ESS. When I start an R process, though, the version of R that gets used by Emacs is 2.6.  I thought maybe Emacs was running R from a weird starting directory.  However, if I select my home directory ESS still starts R 2.6. (Running R at the terminal correctly brings up version 2.9.1.)</p>

<p>How do I add a new ESS process, or change the properties of the current R process, so that I can run my newer version of R?</p>
"
1105659,60628,2009-07-09T18:20:00Z,41,How to add variable key/value pair to list object?,"<p>I have two variables, <code>key</code> and <code>value</code>, and I want to add them as a key/value pair to a list:</p>

<pre><code>key = ""width""
value = 32

mylist = list()
mylist$key = value
</code></pre>

<p>The result is this:</p>

<pre><code>mylist
# $key
# [1] 32
</code></pre>

<p>But I would like this instead:</p>

<pre><code>mylist
# $width
# [1] 32
</code></pre>

<p>How can I do this?</p>
"
1107605,60628,2009-07-10T03:55:08Z,6,Is there an Emacs mode for Rscript?,"<p>Is there any usable emacs mode for <code>Rscript</code>? </p>

<p>(<code>Rscript</code> is the script front-end for the <a href=""http://www.r-project.org/"" rel=""nofollow noreferrer"">R</a> language.)</p>

<p>If I type this:</p>

<pre><code>#!/usr/bin/Rscript
print(commandArgs(TRUE))
</code></pre>

<p>and do <code>indent</code> in the <a href=""http://ess.r-project.org/"" rel=""nofollow noreferrer"">ESS</a> R-mode it indents the first line like crazy, since it sees it as a comment:</p>

<pre><code>                          #!/usr/bin/Rscript
print(commandArgs(TRUE))
</code></pre>
"
1109017,60628,2009-07-10T11:25:47Z,39,How do you print to stderr in R?,"<p>How do you print to <code>stderr</code> in <code>R</code>?</p>

<p>This would especially useful for scripts written in <code>Rscript</code>.</p>
"
1110363,60628,2009-07-10T15:46:06Z,5,Is there a package to process command line options in R?,"<p>Is there a package to process command-line options in R? </p>

<p>I know <code>commandArgs</code>, but it's too basic. Its result is basically the equivalent to <code>argc</code> and <code>argv</code> in <code>C</code>, but I'd need something on top of that, just like <code>boost::program_options</code> in <code>C++</code>, or <code>GetOptions::Long</code> in <code>perl</code>.</p>

<p>In particular, I'd like to specify in advance what options are allowed and give an error message if the user specifies something else. </p>

<p>The call would be like this (with user options --width=32 --file=foo.txt):</p>

<pre><code>R --vanilla --args --width=32 --file=foo.txt &lt; myscript.R
</code></pre>

<p>or, if <code>Rscript</code> is used:</p>

<pre><code>myscript.R --width=32 --file=foo.txt 
</code></pre>

<p>(Please don't say, ""why don't you write it yourself, it's not that hard"". In other languages you don't have to write it yourself either. :)</p>
"
1114699,136862,2009-07-11T21:36:42Z,6,Creating an adjacency list from a data.frame,"<p>I have a data.frame with 2 columns: Node A, Node B. Each entry in the frame implies an edge in a graph between node A and B. </p>

<p>There must be a nice one-liner to convert this data.frame into an adjacency list. Any hints?</p>
"
1125907,130633,2009-07-14T14:46:43Z,3,Moving an R Plot header,"<p>I was trying to create a graph in R Plot and was just wondering if there was any way to move the side header label closer to the graph.</p>

<p>I've made the font smaller and put the label into two lines, but when I put it into two lines the top line falls off the screen and the bottom line is rather far away from the numbered Y-Axis of the graph.  Is there anyway to move the label closer to the y-axis so the whole thing is visible?</p>
"
1133172,130633,2009-07-15T18:41:34Z,5,Can you use R terminal commands on a Mac computer?,"<p>I wrote some code in school to basically bring up different graphs from R and I had wanted to use it on a Mac computer.  </p>

<p>Is there are way to use R terminal commands on a Mac computer and is there a place where I could get more information about these Mac R Terminal commands? Thanks so much!</p>
"
1136709,85148,2009-07-16T10:26:36Z,9,Extend my Java application with R?,"<p>I am building an application that I want to have extended with modules that does some nr crunching and I would like to have R for that. What are my best options for extending my Java application with R?</p>
"
1142294,140049,2009-07-17T09:35:57Z,11,How do I plot a classification graph of a SVM in R,"<p>I have an SVM in R and I would now like to plot the classification space for this machine. I have found some examples on the Internet, but I can't seem to make sense of them.</p>

<p>My R script is as follows:</p>

<pre><code>library(e1071)
day_of_week &lt;- c(0,1,2,3,4,5,6)
holiday &lt;- factor( c(T, F, F, F, F, F, T) )
model &lt;- svm(day_of_week, holiday)
plot(model, day_of_week, holiday)
</code></pre>

<p>I cannot get the plot command to work. I would like a graph something like this <a href=""http://bm2.genes.nig.ac.jp/RGM2/R_current/library/e1071/man/images/plot.svm_001.png"" rel=""noreferrer"">http://bm2.genes.nig.ac.jp/RGM2/R_current/library/e1071/man/images/plot.svm_001.png</a> </p>
"
1154242,130633,2009-07-20T15:25:31Z,106,Getting rid of axis values in R Plot,"<p>I was just wondering if there is a way to get rid of axis values, either the x-axis or y-axis respectively, in an r-plot graph. I know that axes = false will get rid of the entire axis, but I would only like to get rid of the numbering.  Thanks so much!                 </p>
"
1163640,80458,2009-07-22T07:34:10Z,4,How to reduce size of R plots in EPS format?,"<p>I have a histogram with several hundred items, for which I do a Q-Q plot. This results in EPS that is 2.5 megabytes large. This is too much for a figure that is only going to be included in a publication and is not going to be viewed at 100x magnification.</p>

<p>Is there any option in R to somehow output smaller EPS? I have searched docs to no avail. Or is my best option to, say, rasterize it afterwards at 300 dpi? If that's the case, any recommendations for the tool for this job?</p>

<p>The R code for the plot is nothing fancy:</p>

<pre><code>postscript(filename)
qqnorm(n, main=title))
qqline(n)
dev.off()
</code></pre>

<p>Thanks.</p>

<p>EDIT: Doh! My question mentioned outputting EPS, and then converting it to some raster format. When of course I could just generate PNG in the first place from R. Thanks for all the answers.</p>
"
1166157,NA,2009-07-22T15:36:30Z,1,Tutorial Using R on an Amazon Ec2 using just browser for building a regression model,"<p>Assume I have huge huge data and no money for hardware for more RAM for R AND software like Windows or any non open source</p>

<p>. Just an internet connection. and an university Amazon ec2 account.</p>

<p>Could you please guide me to a step by step- copy and paste coding tutorial on building a model using any Package on Amazon ec2.</p>

<p>Note- I know BIOCEP can do this, and Robert Grossman gave a tutorial on using R on Amazon Ec2. I just need a tutorial that say uses a R GUI like Rattle to build model on Amazon Ec2.</p>

<p>Assume I am a statistican with no knowledge of Amazon ec2 or using R there</p>
"
1167448,86684,2009-07-22T19:00:09Z,29,Most mature sparse matrix package for R?,"<p>There are at least two sparse matrix packages for R.  I'm looking into these because I'm working with datasets that are too big and sparse to fit in memory with a dense representation.  I want basic linear algebra routines, plus the ability to easily write C code to operate on them.  Which library is the most mature and best to use?</p>

<p>So far I've found</p>

<ul>
<li><a href=""http://cran.r-project.org/web/packages/Matrix"" rel=""noreferrer"">Matrix</a> which has many reverse dependencies, implying it's the most used one.</li>
<li><a href=""http://cran.r-project.org/web/packages/SparseM/index.html"" rel=""noreferrer"">SparseM</a> which doesn't have as many reverse deps.</li>
<li>Various graph libraries probably have their own (implicit) versions of this; e.g. <a href=""http://cran.r-project.org/web/packages/igraph/index.html"" rel=""noreferrer"">igraph</a> and <a href=""http://cran.r-project.org/web/packages/network/index.html"" rel=""noreferrer"">network</a> (the latter is part of <a href=""http://statnetproject.org/"" rel=""noreferrer"">statnet</a>).  These are too specialized for my needs.</li>
</ul>

<p>Anyone have experience with this?</p>

<p>From searching around <a href=""http://rseek.org"" rel=""noreferrer"">RSeek.org</a> a little bit, the <a href=""http://cran.r-project.org/web/packages/Matrix"" rel=""noreferrer"">Matrix</a> package seems the most commonly mentioned one.  I often think of <a href=""http://cran.r-project.org/web/views/"" rel=""noreferrer"">CRAN Task Views</a> as fairly authoritative, and the <a href=""http://cran.r-project.org/web/views/Multivariate.html"" rel=""noreferrer"">Multivariate Task View</a> mentions Matrix and SparseM.</p>
"
1169248,2002705,2009-07-23T02:20:53Z,338,R function for testing if a vector contains a given element,"<p>In R, how do you test a vector to see if it contains a given element?</p>
"
1169330,37751,2009-07-23T02:48:01Z,6,Native vs ODBC database connections with R,"<p>I understand that some databases have native support in R (e.g. MySQL) but you can connect to other DBs like MS SQL Server using RODBC. How much speed improvement does one gain for reading/writing with the native drivers vs. RODBC? What other DBs have native drivers in R? Is reading faster or slower than writing generally?</p>
"
1169373,84458,2009-07-23T03:03:09Z,24,Memory Usage in R,"<p>After creating large objects and running out of RAM, I will try and delete the objects in my current environment using</p>

<pre><code>rm(list=ls())
</code></pre>

<p>When I check my RAM usage, nothing has changed.  Even after calling <code>gc()</code> nothing has changed.  I can only replenish my RAM by quitting R.</p>

<p>Anybody have advice for dealing with memory-intensive objects within R?</p>
"
1169376,2002705,2009-07-23T03:03:55Z,7,"Cumulative sums, moving averages, and SQL ""group by"" equivalents in R","<p>What's the most efficient way to create a moving average or rolling sum in R? How do you do the rolling function along with a ""group by""?</p>
"
1169388,84458,2009-07-23T03:10:59Z,12,Finding Multiple Elements in a Vector,"<p>Suppose I have the following vector:</p>

<pre><code>&gt; x &lt;- sample(1:10,20,replace=TRUE)
&gt; x
 [1]  8  6  9  9  7  3  2  5  5  1  6  8  5  2  9  3  5 10  8  2
</code></pre>

<p>How can I find which elements are either 8 or 9?</p>
"
1169426,84458,2009-07-23T03:24:25Z,10,Manipulating Network Data in R,"<p>I have a data frame detailing edge weights among N nodes.  Is there a package for working with this sort of data?</p>

<p>For example, I would like to plot the following information as a network:</p>

<pre><code>  p1 p2 counts
1  a  b    100
2  a  c    200
3  a  d    100
4  b  c     80
5  b  d     90
6  b  e    100
7  c  d    100
8  c  e     40
9  d  e     60
</code></pre>
"
1169456,135870,2009-07-23T03:33:18Z,337,The difference between [] and [[]] notations for accessing the elements of a list or dataframe,"<p>R provides two different methods for accessing the elements of a list or data.frame- the <code>[]</code> and <code>[[]]</code> operators.</p>

<p>What is the difference between the two? In what situations should I use one over the other?</p>
"
1169534,84458,2009-07-23T03:58:10Z,28,"Writing functions in R, keeping scoping in mind","<p>I often write functions that need to see other objects in my environment.  For example:</p>

<pre><code>&gt; a &lt;- 3
&gt; b &lt;- 3
&gt; x &lt;- 1:5
&gt; fn1 &lt;- function(x,a,b) a+b+x
&gt; fn2 &lt;- function(x) a+b+x
&gt; fn1(x,a,b)
[1]  7  8  9 10 11
&gt; fn2(x)
[1]  7  8  9 10 11
</code></pre>

<p>As expected, both these functions are identical because <code>fn2</code> can ""see"" a and b when it executes.  But whenever I start to take advantage of this, within about 30 minutes I end up calling the function without one of the necessary variables (e.g. a or b).  If I don't take advantage of this, then I feel like I am passing around objects unnecessarily.</p>

<p>Is it better to be explicit about what a function requires?  Or should this be taken care of via inline comments or other documentation of the function?  Is there a better way?</p>
"
1169539,37751,2009-07-23T04:00:09Z,58,Linear Regression and group by in R,"<p>I want to do a linear regression in R using the <code>lm()</code> function. My data is an annual time series with one field for year (22 years) and another for state (50 states). I want to fit a regression for each state so that at the end I have a vector of lm responses. I can imagine doing for loop for each state then doing the regression inside the loop and adding the results of each regression to a vector. That does not seem very R-like, however. In SAS I would do a 'by' statement and in SQL I would do a 'group by'. What's the R way of doing this?</p>
"
1169551,2002705,2009-07-23T04:04:21Z,12,SQL-like functionality in R,"<p>I am used to writing data manipulation logic in SQL and now that I am learning R I find myself sometimes just wanting to do something that would be simple in SQL but I have to learn a bunch of stuff with R to do the same manipulation on an R data frame. Is there a simple work around? </p>
"
1169573,84458,2009-07-23T04:15:08Z,7,Large loops hang in R?,"<p>Suppose I want perform a simulation using the following function:</p>

<pre><code>fn1 &lt;- function(N) {
  res &lt;- c()
  for (i in 1:N) {
    x &lt;- rnorm(2)
    res &lt;- c(res,x[2]-x[1])
  }
  res
}
</code></pre>

<p>For very large <code>N</code>, computation appears to hang.  Are there better ways of doing this?</p>

<p>(Inspired by: <a href=""https://stat.ethz.ch/pipermail/r-help/2008-February/155591.html"" rel=""noreferrer"">https://stat.ethz.ch/pipermail/r-help/2008-February/155591.html</a>)</p>
"
1172485,143813,2009-07-23T15:15:37Z,51,How to increase the number of columns using R in Linux,"<p>This may seem menial, but it affects my productivity. I am using R in terminal mode on Linux. Unlike the Windows IDE, Linux limits the number of columns to 80, thus making harder the inspection of data sets. Is there a way to set the max number of columns?</p>
"
1174799,23929,2009-07-23T22:17:24Z,86,"How to make execution pause, sleep, wait for X seconds in R?","<p>How do you pause an R script for a specified number of seconds or miliseconds? In many languages, there is a <code>sleep</code> function, but <code>?sleep</code> references a data set. And <code>?pause</code> and <code>?wait</code> don't exist.</p>

<p>The intended purpose is for self-timed animations. The desired solution works without asking for user input.</p>
"
1176455,4907,2009-07-24T08:44:49Z,2,Portable use of dyn.load to call a C function in an R package,"<p>I am creating an R package that I intend to submit to CRAN that has a function calling a routine written in C.  How do I load the compiled C routine in the R function in platform-independent way?  I am able to make my package work on my intel-based Mac with:</p>

<pre><code>function(mydata)
{
dyn.load(file.path(.Library,""mypkg/libs/i386"",paste(""mypkg"", .Platform$dynlib.ext, sep=""""))) 
try(
    output &lt;- .C(""myfunc_cversion"",
                 in_data    = as.double(mydata),
                 res_data   = as.double(res),
                 PACKAGE    = ""mypkg"")
    )
    result &lt;- as.matrix(output$res_data)
    return(result)
}
</code></pre>

<p>The problem is the call to dyn.load where I cannot figure out how to specify the full path to the shared library for my installed package in a portable way.</p>

<p>Is there another variable in R besides .Library that I should use, or is there a better function than dyn.load for this case?</p>
"
1177919,37751,2009-07-24T14:06:05Z,22,Does column exist and how to rearrange columns in R data frame,"<p>How do I add a column in the middle of an R data frame? I want to see if I have a column named ""LastName"" and then add it as the third column if it does not already exist. </p>
"
1177926,37751,2009-07-24T14:07:07Z,86,R object identification,"<p>I am often ending up with a function producing output for which I don't understand the output data type. I'm expecting a list and it ends up being a list of lists or a data frame or something else. What's a good method or workflow for figuring out the output data type when first using a function?</p>
"
1181021,2002705,2009-07-25T02:32:27Z,6,Determining if a matrix is diagonalizable in the R Programming Language,"<p>I have a matrix and I would like to know if it is diagonalizable. How do I do this in the R programming language? </p>
"
1181025,2002705,2009-07-25T02:36:06Z,22,Goodness of fit functions in R,"<p>What functions do you use in R to fit a curve to your data and test how well that curve fits?  What results are considered good?</p>
"
1182932,37751,2009-07-25T20:10:59Z,3,unexpected agrep() results related to max.distance in R,"<p><strong>EDIT:</strong> This bug was found in 32-bit versions of R was fixed in R version 2.9.2.</p>

<hr>

<p>This was tweeted to me by @leoniedu today and I don't have an answer for him so I thought I would post it here. </p>

<p>I have read the documentation for agrep() (fuzzy string matching) and it appears that I don't fully understand the max.distance parameter. Here's an example:</p>

<pre><code>pattern &lt;- ""Staatssekretar im Bundeskanzleramt""
x &lt;- ""Bundeskanzleramt""
agrep(pattern,x,max.distance=18) 
agrep(pattern,x,max.distance=19)
</code></pre>

<p>That behaves exactly like I would expect. There are 18 characters different between the strings so I would expect that to be the threshold of a match. Here's what's confusing me:</p>

<pre><code>agrep(pattern,x,max.distance=30) 
agrep(pattern,x,max.distance=31)
agrep(pattern,x,max.distance=32) 
agrep(pattern,x,max.distance=33)
</code></pre>

<p>Why are 30 and 33 matches, but not 31 and 32? To save you some counting, </p>

<pre><code>&gt; nchar(""Staatssekretar im Bundeskanzleramt"")
[1] 34
&gt; nchar(""Bundeskanzleramt"")
[1] 16
</code></pre>
"
1188544,37751,2009-07-27T14:36:31Z,3,Getting windows to start R in batch mode using the Start command,"<p>I know I must be making a simple syntax mistake, but I want to have a windows batch file that fires up 9 instances of R and runs a different routine in each one. I want these to run simultaneously (i.e. asynchronously). I can fire up 9 command prompt windows and type a command in each one, but it seems like with the START command I should be able to make them start from a single batch file. </p>

<p>Here's an example of how I start one of the instances of R:</p>

<pre><code>""C:\Program Files (x86)\R\R-2.8.1\bin\R"" CMD BATCH ""C:\Users\jd\Documents\mexico\Estado\getdata1.r"" 
</code></pre>

<p>Reading this <a href=""https://stackoverflow.com/questions/72671/how-to-create-batch-file-in-windows-using-start-with-a-path-and-command-with-sp"">previous stackoverflow question</a> along with <a href=""https://stackoverflow.com/questions/154075/using-the-dos-start-command-with-parameters-passed-to-the-started-program"">this previous question</a> makes me think I should be able to do this:</p>

<pre><code>START """" ""C:\Program Files (x86)\R\R-2.8.1\bin\R"" CMD BATCH ""C:\Users\jd\Documents\mexico\Estado\getdata1.r"" /b
</code></pre>

<p>That does not return an error, it just returns a prompt and R never starts. What am I missing?</p>
"
1191689,143813,2009-07-28T02:43:03Z,11,Hierarchical Bayes for R or Python,"<p>Hierarchical Bayes models are commonly used in Marketing, Political Science, and Econometrics. Yet, the only package I know of is <code>bayesm</code>, which is really a companion to a book (<em>Bayesian Statistics and Marketing</em>, by Rossi, et al.) Am I missing something? Is there a software package for R or Python doing the job out there, and/or a worked-out example in the associated language? </p>
"
1195826,2002705,2009-07-28T18:21:47Z,378,Drop factor levels in a subsetted data frame,"<p>I have a data frame containing a factor.  When I create a subset of this data frame using <code>subset()</code> or another indexing function, a new data frame is created.  However, the factor variable retains all of its original levels -- even when they do not exist in the new data frame.</p>

<p>This creates headaches when doing faceted plotting or using functions that rely on factor levels.</p>

<p>What is the most succinct way to remove levels from a factor in my new data frame?</p>

<p>Here's my example:</p>

<pre><code>df &lt;- data.frame(letters=letters[1:5],
                    numbers=seq(1:5))

levels(df$letters)
## [1] ""a"" ""b"" ""c"" ""d"" ""e""

subdf &lt;- subset(df, numbers &lt;= 3)
##   letters numbers
## 1       a       1
## 2       b       2
## 3       c       3    

## but the levels are still there!
levels(subdf$letters)
## [1] ""a"" ""b"" ""c"" ""d"" ""e""
</code></pre>
"
1197434,70702,2009-07-29T00:11:37Z,5,Loading data from Excel file into R or Octave,"<p>I have an Excel file with a large set of data. The built-in graphs available in Excel are <em>not</em> enough to analyze these data, so I am thinking about using some tool like octave or R.</p>

<p>I was thinking about some method to load an Excel file directly into octave or R. I searched the web and found that many people have succeeded using by exporting data from Excel into a CSV file.</p>

<p>The question:
Is there a direct way to load an Excel file in R or Octave?</p>
"
1198116,70702,2009-07-29T04:57:48Z,3,"sql command for reading a particular sheet, column","<p>This is probably a very stupid question for SQL stalwarts, but I just want one SQL command.</p>

<p>Details,</p>

<p>I am using a data analysis tool called R, this tool uses ODBC to read data from XLS. I am now trying to read data from an XLS file. The ODBC tool in R accepts SQL commands.</p>

<p>Question,</p>

<p>Can someone give me an SQL command that will read data from an XLS file's
- Specified sheet
- Specified column [by name]
- Specified row [Specified just by Row Index]</p>

<p>Thanks ... </p>
"
1203662,NA,2009-07-29T23:36:11Z,2,How to connect to R with Java (using Eclipse),"<p>Very newbie (to Java) question:</p>

<p>I opened an Rserve connection (<a href=""http://www.rforge.net/Rserve/"" rel=""nofollow noreferrer"">http://www.rforge.net/Rserve/</a>) on localhost, and I would like to use the REngine client (src/client/java-new in the Rserve package) to connect to it.</p>

<p>What do I need to do to get the ""RTest.java"" (located in src/client/java-new/Rserve; pasted below) to compile?</p>

<p>I gather that I need to compile the org.rosuda.* libraries. How can I do this using Eclipse 3.5? I tried copying the ""src/client/java-new"" folder into my Java project's ""src"" directory, right clicking in Eclipse -> Build path -> Use as source folder.  But I don't think this is enough to create the ""org.rosuda"" package, because I don't see an ""org/rosuda"" directory structure created anywhere (and those ominous red lines in Eclipse don't disappear). </p>

<p>Anyone done this recently, care to offer a pointer? Thanks plenty.</p>

<pre><code>import org.rosuda.REngine.*;
import org.rosuda.REngine.Rserve.*;

class TestException extends Exception {
    public TestException(String msg) { super(msg); }
}

public class test {
    public static void main(String[] args) {
    try {
        RConnection c = new RConnection();

        System.out.println(""&gt;&gt;""+c.eval(""R.version$version.string"").asString()+""&lt;&lt;"");

        {
            System.out.println(""* Test string and list retrieval"");
            RList l = c.eval(""{d=data.frame(\""huhu\"",c(11:20)); lapply(d,as.character)}"").asList();
            int cols = l.size();
            int rows = l.at(0).length();
            String[][] s = new String[cols][];
            for (int i=0; i&lt;cols; i++) s[i]=l.at(i).asStrings();
            System.out.println(""PASSED"");
        }

        {
        System.out.println(""* Test NA/NaN support in double vectors..."");
        double R_NA = Double.longBitsToDouble(0x7ff00000000007a2L);
        // int R_NA_int = -2147483648; // just for completeness
        double x[] = { 1.0, 0.5, R_NA, Double.NaN, 3.5 };
        c.assign(""x"",x);
        String nas = c.eval(""paste(capture.output(print(x)),collapse='\\n')"").asString();
        System.out.println(nas);
        if (!nas.equals(""[1] 1.0 0.5  NA NaN 3.5""))
            throw new TestException(""NA/NaN assign+retrieve test failed"");
        System.out.println(""PASSED"");
        }

        {
            System.out.println(""* Test assigning of lists and vectors ..."");
            RList l = new RList();
            l.put(""a"",new REXPInteger(new int[] { 0,1,2,3}));
            l.put(""b"",new REXPDouble(new double[] { 0.5,1.2,2.3,3.0}));
            System.out.println(""  assign x=pairlist"");
            c.assign(""x"", new REXPList(l));
            System.out.println(""  assign y=vector"");
            c.assign(""y"", new REXPGenericVector(l));
            System.out.println(""  assign z=data.frame"");
            c.assign(""z"", REXP.createDataFrame(l));
            System.out.println(""  pull all three back to Java"");
            REXP x = c.parseAndEval(""x"");
            System.out.println(""  x = ""+x);
            x = c.eval(""y"");
            System.out.println(""  y = ""+x);
            x = c.eval(""z"");
            System.out.println(""  z = ""+x);
            System.out.println(""PASSED"");
        }
        {
            System.out.println(""* Test support for logicals ... "");
            System.out.println(""  assign b={true,false,true}"");
            c.assign(""b"", new REXPLogical(new boolean[] { true, false, true }));
            REXP x = c.parseAndEval(""b"");
            System.out.println(""  "" + ((x != null) ? x.toDebugString() : ""NULL""));
            if (!x.isLogical() || x.length() != 3)
                throw new TestException(""boolean array assign+retrieve test failed"");
            boolean q[] = ((REXPLogical)x).isTRUE();
            if (q[0] != true || q[1] != false || q[2] != true)
                throw new TestException(""boolean array assign+retrieve test failed (value mismatch)"");
            System.out.println(""  get c(TRUE,FLASE,NA)"");
            x = c.parseAndEval(""c(TRUE,FALSE,NA)"");
            System.out.println(""  "" + ((x != null) ? x.toDebugString() : ""NULL""));
            if (!x.isLogical() || x.length() != 3)
                throw new TestException(""boolean array NA test failed"");
            boolean q1[] = ((REXPLogical)x).isTRUE();
            boolean q2[] = ((REXPLogical)x).isFALSE();
            boolean q3[] = ((REXPLogical)x).isNA();
            if (q1[0] != true || q1[1] != false || q1[2] != false ||
                q2[0] != false || q2[1] != true || q2[2] != false ||
                q3[0] != false || q3[1] != false || q3[2] != true)
                throw new TestException(""boolean array NA test failed (value mismatch)"");
        }

        { // regression: object bit was not set for Java-side generated objects before 0.5-3
            System.out.println(""* Testing functionality of assembled S3 objects ..."");
            // we have already assigned the data.frame in previous test, so we jsut re-use it
            REXP x = c.parseAndEval(""z[2,2]"");
            System.out.println(""  z[2,2] = "" + x);
            if (x == null || x.length() != 1 || x.asDouble() != 1.2)
                throw new TestException(""S3 object bit regression test failed"");
            System.out.println(""PASSED"");
        }

        { // this test does a pull and push of a data frame. It will fail when the S3 test above failed.
            System.out.println(""* Testing pass-though capability for data.frames ..."");
            REXP df = c.parseAndEval(""{data(iris); iris}"");
            c.assign(""df"", df);
            REXP x = c.eval(""identical(df, iris)"");
            System.out.println(""  identical(df, iris) = ""+x);
            if (x == null || !x.isLogical() || x.length() != 1 || !((REXPLogical)x).isTrue()[0])
                throw new TestException(""Pass-through test for a data.frame failed"");
            System.out.println(""PASSED"");
        }

            { // factors
                System.out.println(""* Test support of factors"");
                REXP f = c.parseAndEval(""factor(paste('F',as.integer(runif(20)*5),sep=''))"");
                System.out.println(""  f=""+f);
                System.out.println(""  isFactor: ""+f.isFactor()+"", asFactor: ""+f.asFactor());
                if (!f.isFactor() || f.asFactor() == null) throw new TestException(""factor test failed"");
                System.out.println(""  singe-level factor used to degenerate:"");
                f = c.parseAndEval(""factor('foo')"");
                System.out.println(""  isFactor: ""+f.isFactor()+"", asFactor: ""+f.asFactor());
                if (!f.isFactor() || f.asFactor() == null) throw new TestException(""single factor test failed (not a factor)"");
                if (!f.asFactor().at(0).equals(""foo"")) throw new TestException(""single factor test failed (wrong value)"");
                System.out.println(""  test factors with null elements contents:"");
                c.assign(""f"", new REXPFactor(new RFactor(new String[] { ""foo"", ""bar"", ""foo"", ""foo"", null, ""bar"" })));
                f = c.parseAndEval(""f"");
                if (!f.isFactor() || f.asFactor() == null) throw new TestException(""factor assign-eval test failed (not a factor)"");
                System.out.println(""  f = ""+f.asFactor());
                f = c.parseAndEval(""as.factor(c(1,'a','b',1,'b'))"");
                System.out.println(""  f = ""+f);
                if (!f.isFactor() || f.asFactor() == null) throw new TestException(""factor test failed (not a factor)"");
                System.out.println(""PASSED"");
            }


        {
            System.out.println(""* Lowess test"");
            double x[] = c.eval(""rnorm(100)"").asDoubles();
            double y[] = c.eval(""rnorm(100)"").asDoubles();
            c.assign(""x"", x);
            c.assign(""y"", y);
            RList l = c.parseAndEval(""lowess(x,y)"").asList();
            System.out.println(""  ""+l);
            x = l.at(""x"").asDoubles();
            y = l.at(""y"").asDoubles();
            System.out.println(""PASSED"");
        }

        {
            // multi-line expressions
            System.out.println(""* Test multi-line expressions"");
            if (c.eval(""{ a=1:10\nb=11:20\nmean(b-a) }\n"").asInteger()!=10)
                throw new TestException(""multi-line test failed."");
            System.out.println(""PASSED"");
        }
        {
            System.out.println(""* Matrix tests\n  matrix: create a matrix"");
            int m=100, n=100;
            double[] mat=new double[m*n];
            int i=0;
            while (i&lt;m*n) mat[i++]=i/100;
            System.out.println(""  matrix: assign a matrix"");
            c.assign(""m"", mat);
            c.voidEval(""m&lt;-matrix(m,""+m+"",""+n+"")"");
            System.out.println(""matrix: cross-product"");
            double[][] mr=c.parseAndEval(""crossprod(m,m)"").asDoubleMatrix();
            System.out.println(""PASSED"");
        }

        {
            System.out.println(""* Test serialization and raw vectors"");
            byte[] b = c.eval(""serialize(ls, NULL, ascii=FALSE)"").asBytes();
            System.out.println(""  serialized ls is ""+b.length+"" bytes long"");
            c.assign(""r"", new REXPRaw(b));
            String[] s = c.eval(""unserialize(r)()"").asStrings();
            System.out.println(""  we have ""+s.length+"" items in the workspace"");
            System.out.println(""PASSED"");
        }


        { // string encoding test (will work with Rserve 0.5-3 and higher only)
            System.out.println(""* Test string encoding support ..."");
            String t = ""ひらがな""; // hiragana (literally, in hiragana ;))
            c.setStringEncoding(""utf8"");
            // -- Just in case the console is not UTF-8 don't display it
            //System.out.println(""  unicode text: ""+t);
            c.assign(""s"", t);
            REXP x = c.parseAndEval(""nchar(s)"");
            System.out.println(""  nchar = "" + x);
            if (x == null || !x.isInteger() || x.asInteger() != 4)
                throw new TestException(""UTF-8 encoding string length test failed"");
            // we cannot really test any other encoding ..
            System.out.println(""PASSED"");
        }

        } catch (RserveException rse) {
        System.out.println(rse);
    } catch (REXPMismatchException mme) {
        System.out.println(mme);
        mme.printStackTrace();
        } catch(TestException te) {
            System.err.println(""** Test failed: ""+te.getMessage());
            te.printStackTrace();
    } catch (Exception e) {
        e.printStackTrace();
    }
    }
}
</code></pre>
"
1208627,142405,2009-07-30T18:59:05Z,4,Visualizing Data in Java,"<p>is there a good library on the market to visualize big datas in Java. Maybe a library for statistical outputs. I know the programming language R to visualize statistical data in R. I also have seen a solution to connect Java and R. It would be better if a have a pure Java solution. </p>
"
1213783,143383,2009-07-31T17:17:08Z,5,Using function arguments in update.formula,"<p>I am writing a function that takes two variables and separately regresses each of them on a set of controls expressed as a one-sided formula. Right now I'm using the following to make the formula for one of the regressions, but it feels a bit hacked-up:</p>

<pre><code>foo &lt;- function(x, y, controls) {
    cl &lt;- match.call()
    xn &lt;- cl[[""x""]]
    xf &lt;- as.formula(paste(xn, deparse(controls)))
}
</code></pre>

<p>I'd prefer to do this using <code>update.formula()</code>, but of course <code>update.formula(controls, x ~ .)</code> and <code>update.formula(controls, as.name(x) ~ .)</code> don't work. What should I be doing?</p>
"
1219480,64253,2009-08-02T18:25:39Z,2,Step-by-Step How-to on Mediation Analysis in R,"<p>I'd like to know if anybody can provide a step-by-step how to on how to use mediation analysis using <a href=""http://imai.princeton.edu/software/mediation.html"" rel=""nofollow noreferrer"">Keele, Tingley, Yamamoto and Imai's mediation package</a>. I think there are two approaches to this - <a href=""http://www.public.asu.edu/~davidpm/classes/psy536/Baron.pdf"" rel=""nofollow noreferrer"">the classic Baron and Kenny (1986)</a> and the new one by <a href=""http://kuscholarworks.ku.edu/dspace/bitstream/1808/1658/1/preacher_rucker_hayes_2007.pdf"" rel=""nofollow noreferrer"">Preacher, Rucker and Hayes (2007)</a> - I'd like to know how to do both approaches in R</p>
"
1223904,37751,2009-08-03T18:32:05Z,3,Hooking R from within Excel - DCOM? R add in for Excel?,"<p>In the past I have used a DCOM connection to call R functions from Excel and from VBA inside of Excel. I just got a new laptop and have been looking for the install files for the R add in for Excel. I find references to it all over the place but they all point to R (D)COM Server project's home page at <a href=""http://sunsite.univie.ac.at/rcom"" rel=""nofollow noreferrer"">http://sunsite.univie.ac.at/rcom</a>. That URL has been down now for some time. Is there another way to get the same functionality with another method? Is there a new project page? </p>

<p>I've never tried to use the DCOM server without the Excel Add-in. Is that a possibility?</p>
"
1231195,144601,2009-08-05T04:30:49Z,83,Multiline Comment Workarounds?,"<p>I (sort of) already know the answer to this question.  But I figured it is one that gets asked so frequently on the R Users list, that there should be one solid good answer.  <strong>To the best of my knowledge there is no multiline comment functionality in R.  So, does anyone have any good workarounds?</strong></p>

<p>While quite a bit of work in R usually involves interactive sessions (which casts doubt on the need for multiline comments), there are times when I've had to send scripts to colleagues and classmates, much of which involves nontrivial blocks of code.  And for people coming from other languages it is a fairly natural question.  </p>

<p>In the past I've used quotes. Since strings support linebreaks, running an R script with</p>

<pre><code>""
Here's my multiline comment.

""
a &lt;- 10
rocknroll.lm &lt;- lm(blah blah blah)
 ...
</code></pre>

<p>works fine.  Does anyone have a better solution?</p>
"
1233948,112882,2009-08-05T15:18:21Z,0,How to set alpha in R?,"<p>I have <a href=""http://rss.acs.unt.edu/Rdoc/library/coin/html/LocationTests.html"" rel=""nofollow noreferrer"">this example</a> from the coin package of R:</p>

<pre><code>  library(coin)
  library(multcomp)
  ### Length of YOY Gizzard Shad from Kokosing Lake, Ohio,
  ### sampled in Summer 1984, Hollander &amp; Wolfe (1999), Table 6.3, page 200
  YOY &lt;- data.frame(length = c(46, 28, 46, 37, 32, 41, 42, 45, 38, 44, 
                               42, 60, 32, 42, 45, 58, 27, 51, 42, 52, 
                               38, 33, 26, 25, 28, 28, 26, 27, 27, 27, 
                               31, 30, 27, 29, 30, 25, 25, 24, 27, 30),
                    site = factor(c(rep(""I"", 10), rep(""II"", 10),
                                    rep(""III"", 10), rep(""IV"", 10))))

  ### Nemenyi-Damico-Wolfe-Dunn test (joint ranking)
  ### Hollander &amp; Wolfe (1999), page 244 
  ### (where Steel-Dwass results are given)
  NDWD &lt;- oneway_test(length ~ site, data = YOY,
      ytrafo = function(data) trafo(data, numeric_trafo = rank),
      xtrafo = function(data) trafo(data, factor_trafo = function(x)
          model.matrix(~x - 1) %*% t(contrMat(table(x), ""Tukey""))),
      teststat = ""max"", distribution = approximate(B = 90000))

  ### global p-value
  print(pvalue(NDWD))

  ### sites (I = II) != (III = IV) at alpha = 0.01 (page 244)
  print(pvalue(NDWD, method = ""single-step""))
</code></pre>

<p>I want to assign alpha a different value, how can I do this??</p>

<p>This doesn't work!</p>

<pre><code>  library(coin)
  library(multcomp)
  ### Length of YOY Gizzard Shad from Kokosing Lake, Ohio,
  ### sampled in Summer 1984, Hollander &amp; Wolfe (1999), Table 6.3, page 200
  YOY &lt;- data.frame(length = c(46, 28, 46, 37, 32, 41, 42, 45, 38, 44, 
                               42, 60, 32, 42, 45, 58, 27, 51, 42, 52, 
                               38, 33, 26, 25, 28, 28, 26, 27, 27, 27, 
                               31, 30, 27, 29, 30, 25, 25, 24, 27, 30),
                    site = factor(c(rep(""I"", 10), rep(""II"", 10),
                                    rep(""III"", 10), rep(""IV"", 10))))

  ### Nemenyi-Damico-Wolfe-Dunn test (joint ranking)
  ### Hollander &amp; Wolfe (1999), page 244 
  ### (where Steel-Dwass results are given)
  NDWD &lt;- oneway_test(length ~ site, data = YOY,
      ytrafo = function(data) trafo(data, numeric_trafo = rank),
      xtrafo = function(data) trafo(data, factor_trafo = function(x)
          model.matrix(~x - 1) %*% t(contrMat(table(x), ""Tukey""))),
      teststat = ""max"", distribution = approximate(B = 90000),
      alpha = 0.05)

  ### global p-value
  print(pvalue(NDWD))

  ### sites (I = II) != (III = IV) at alpha = 0.05 (default was 0.01) (page 244)
  print(pvalue(NDWD, method = ""single-step""))
</code></pre>
"
1236620,70702,2009-08-06T02:03:00Z,77,Global variables in R,"<p>I am a newbie in R programming. Though I am poking into the manuals, I also wanted to ask the community <strong>""How can we set global variables inside a function?""</strong></p>

<p>Any pointers will help.</p>

<p>Question-2: Regarding plotting,</p>

<p>I am using plotting multiple graphs in a single sheet, and to differentiate each one of them, I want to add title for each one of them. Can anyone tell me how I can achieve this?</p>
"
1238250,64253,2009-08-06T11:13:22Z,0,How do you implement Velicer's MAP criterion in R,"<p>I'm looking at the <a href=""http://bm2.genes.nig.ac.jp/RGM2/R_current/library/psych/man/00.psych-package.html"" rel=""nofollow noreferrer"">psych package</a> and the <a href=""http://www.personality-project.org/R/html/VSS.html"" rel=""nofollow noreferrer"">VSS tutorial</a>, do I simply replace VSS with MAP? Like this:</p>

<pre><code>MAP(x, n = 8, rotate = ""varimax"", diagonal = FALSE, fm = ""pa"", n.obs=NULL,plot=TRUE,title=""Very Simple Structure"",...)
</code></pre>

<p>or is there another way to do this?
I've doing factor analysis right now and I'm using the elbow method on a scree plot. I'm trying to see if I can try to use Velicer's MAP criterion also</p>
"
1238933,23929,2009-08-06T13:35:24Z,6,"Should ""while loops"" be preferred to ""for loops"" for large, necessary loops in R?","<p>Realizing that loops are usually not ideal in R, sometimes they are necessary.</p>

<p>When writing large loops, doesn't </p>

<pre><code>for (i in 1:large_number) 
</code></pre>

<p>waste memory, since a vector of size large_number must be created?</p>

<p>Would this make while loops the best choice for large, necessary loops?</p>
"
1241184,144278,2009-08-06T20:23:56Z,6,Overall Title for Plotting Window,"<p>If I create a plotting window in R with m rows and n columns, how can I give the ""overall"" graphic a main title?</p>

<p>For example, I might have three scatterplots showing the relationship between GPA and SAT score for 3 different schools. How could I give one master title to all three plots, such as, ""SAT score vs. GPA for 3 schools in CA""?</p>
"
1245273,101927,2009-08-07T15:02:34Z,62,Histogram with Logarithmic Scale and custom breaks,"<p>I'm trying to generate a histogram in R with a logarithmic scale for y. Currently I do:</p>

<pre><code>hist(mydata$V3, breaks=c(0,1,2,3,4,5,25))
</code></pre>

<p>This gives me a histogram, but the density between 0 to 1 is so great (about a million values difference) that you can barely make out any of the other bars.</p>

<p>Then I've tried doing:</p>

<pre><code>mydata_hist &lt;- hist(mydata$V3, breaks=c(0,1,2,3,4,5,25), plot=FALSE)
plot(rpd_hist$counts, log=""xy"", pch=20, col=""blue"")
</code></pre>

<p>It gives me sorta what I want, but the bottom shows me the values 1-6 rather than 0, 1, 2, 3, 4, 5, 25.  It's also showing the data as points rather than bars. <code>barplot</code> works but then I don't get any bottom axis.</p>
"
1246244,37751,2009-08-07T18:14:19Z,9,Applying pnorm to columns of a data frame,"<p>I'm trying to normalize some data which I have in a data frame. I want to take each value and run it through the pnorm function along with the mean and standard deviation of the column the value lives in. Using loops, here's how I would write out what I want to do:</p>

<pre><code>#example data
hist_data &lt;- data.frame( matrix( rnorm( 200,mean=5,sd=.5 ),nrow=20 ) )

n &lt;- dim( hist_data )[2] #columns=10
k &lt;- dim( hist_data )[1] #rows   =20

#set up the data frame which we will populate with a loop
normalized &lt;- data.frame( matrix( nrow = nrow( hist_data ), ncol = ncol( hist_data ) ) )

#hot loop in loop action
for ( i in 1:n ){
   for ( j in 1:k ){
      normalized[j,i] &lt;- pnorm( hist_data[j,i], 
                                mean = mean( hist_data[,i] ), 
                                sd = sd( hist_data[,i] ) )
   }  
}
normalized
</code></pre>

<p>It seems that in R there should be a handy dandy vector way of doing this. I thought I was smart so tried using the apply function:</p>

<pre><code>#trouble ahead
hist_data &lt;- data.frame( matrix( rnorm( 200, mean = 5,sd = .5 ), nrow=10 ) )
normalized &lt;- apply( hist_data, 2, pnorm, mean = mean( hist_data ), sd = sd( hist_data ) )
normalized
</code></pre>

<p>Much to my chagrin, that does NOT produce what I expected. The upper left and bottom right elements of the output are correct, but that's it. So how can I de-loopify my life? </p>

<p>Bonus points if you can tell me what my second code block is actually doing. Kind of a mystery to me still. :)</p>
"
1249548,84458,2009-08-08T18:16:43Z,194,Side-by-side plots with ggplot2,"<p>I would like to place two plots side by side using the <a href=""http://crantastic.org/packages/ggplot2"" rel=""noreferrer"">ggplot2 package</a>, i.e. do the equivalent of <code>par(mfrow=c(1,2))</code>.</p>

<p>For example, I would like to have the following two plots show side-by-side with the same scale.</p>

<pre><code>x &lt;- rnorm(100)
eps &lt;- rnorm(100,0,.2)
qplot(x,3*x+eps)
qplot(x,2*x+eps)
</code></pre>

<p>Do I need to put them in the same data.frame?</p>

<pre><code>qplot(displ, hwy, data=mpg, facets = . ~ year) + geom_smooth()
</code></pre>
"
1252546,153440,2009-08-09T23:00:23Z,16,How to replace NA (missing values) in a data frame with neighbouring values,"<pre><code>862 2006-05-19 6.241603 5.774208     
863 2006-05-20 NA       NA      
864 2006-05-21 NA       NA      
865 2006-05-22 6.383929 5.906426      
866 2006-05-23 6.782068 6.268758      
867 2006-05-24 6.534616 6.013767      
868 2006-05-25 6.370312 5.856366      
869 2006-05-26 6.225175 5.781617      
870 2006-05-27 NA       NA     
</code></pre>

<p>I have a data frame x like above with some NA, which i want to fill using neighboring non-NA values like for 2006-05-20 it will be avg of 19&amp;22 </p>

<p>How do it is the question?</p>
"
1256347,138470,2009-08-10T18:08:30Z,9,"Plot time data in R to various resolutions (to the minute, to the hour, to the second, etc.)","<p>I have some data in CSV like:</p>

<pre><code>""Timestamp"", ""Count""
""2009-07-20 16:30:45"", 10
""2009-07-20 16:30:45"", 15
""2009-07-20 16:30:46"", 8
""2009-07-20 16:30:46"", 6
""2009-07-20 16:30:46"", 8
""2009-07-20 16:30:47"", 20
</code></pre>

<p>I can read it into R using read.cvs. I'd like to plot:</p>

<ol>
<li>Number of entries per second, so:

<pre>
""2009-07-20 16:30:45"", 2
""2009-07-20 16:30:46"", 3
""2009-07-20 16:30:47"", 1
</pre></li>
<li>Average value per second:

<pre>
""2009-07-20 16:30:45"", 12.5
""2009-07-20 16:30:46"", 7.333
""2009-07-20 16:30:47"", 20
</pre></li>
<li>Same as 1 &amp; 2 but then by Minute and then by Hour.</li>
</ol>

<p>Is there some way to do this (collect by second/min/etc &amp; plot) in R? </p>
"
1259867,23929,2009-08-11T11:45:35Z,8,How to do median splits within factor levels in R?,"<p>Here I make a new column to indicate whether myData is above or below its median</p>

<pre><code>### MedianSplits based on Whole Data
#create some test data
myDataFrame=data.frame(myData=runif(15),myFactor=rep(c(""A"",""B"",""C""),5)) 

#create column showing median split
myBreaks= quantile(myDataFrame$myData,c(0,.5,1))
myDataFrame$MedianSplitWholeData = cut(
    myDataFrame$myData,
    breaks=myBreaks, 
    include.lowest=TRUE,
    labels=c(""Below"",""Above""))

#Check if it's correct
myDataFrame$AboveWholeMedian = myDataFrame$myData &gt; median(myDataFrame$myData)
myDataFrame
</code></pre>

<p>Works fine. Now I want to do the same thing, but compute the median splits within each level of myFactor.</p>

<p>I've come up with this:</p>

<pre><code>#Median splits within factor levels
byOutput=by(myDataFrame$myData,myDataFrame$myFactor, function (x) {
     myBreaks= quantile(x,c(0,.5,1))
     MedianSplitByGroup=cut(x,
       breaks=myBreaks, 
       include.lowest=TRUE,
       labels=c(""Below"",""Above""))
     MedianSplitByGroup
     })
</code></pre>

<p>byOutput contains what I want. It categorizes each element of factors A, B, and C correctly. However I'd like to create a new column, myDataFrame$FactorLevelMedianSplit, that shows the newly-computed median split.</p>

<p>How do you convert the output of the ""by"" command into a useful data-frame column?</p>

<p>I think perhaps the ""by"" command is not R-like way to do this ... </p>

<p><strong>Update</strong>:</p>

<p>With Thierry's example of how to use factor() cleverly, and upon discovering the ""ave"" function in Spector's book, I've found this solution, which requires no additional packages.</p>

<pre><code>myDataFrame$MediansByFactor=ave(
    myDataFrame$myData,
    myDataFrame$myFactor,
    FUN=median)

myDataFrame$FactorLevelMedianSplit = factor(
    myDataFrame$myData&gt;myDataFrame$MediansByFactor, 
    levels = c(TRUE, FALSE), 
    labels = c(""Above"", ""Below""))
</code></pre>
"
1260965,37751,2009-08-11T15:06:53Z,58,Developing Geographic Thematic Maps with R,"<p>There are clearly a number of packages in R for all sorts of spatial analysis. That can by seen in the <a href=""http://cran.r-project.org/web/views/Spatial.html"" rel=""noreferrer"">CRAN Task View: Analysis of Spatial Data</a>. These packages are numerous and diverse, but all I want to do is some simple <a href=""http://images.google.com/images?q=thematic+map&amp;oe=utf-8&amp;rls=org.mozilla:en-US:official&amp;client=firefox-a&amp;um=1&amp;ie=UTF-8&amp;ei=EYiBSqywF5TYNZW8sJ0L&amp;sa=X&amp;oi=image_result_group&amp;ct=title&amp;resnum=4"" rel=""noreferrer"">thematic maps</a>. I have data with county and state FIPS codes and I have ESRI shape files of county and state boundaries and the accompanying FIPS codes which allows joining with the data. The shape files could be easily converted to other formats, if needed. </p>

<p>So what's the most straight forward way to create thematic maps with R? </p>

<p>This map looks like it was created with an ESRI Arc product, but this is the type of thing I would like to do with R:</p>

<p><a href=""http://www.infousagov.com/images/choro.jpg"" rel=""noreferrer"">alt text http://www.infousagov.com/images/choro.jpg</a> Map <a href=""http://www.infousagov.com/thematicmap.asp"" rel=""noreferrer"">copied from here</a>. </p>
"
1262911,NA,2009-08-11T21:04:53Z,2,Rows being dropped in R with read.table?,"<p>I am loading a table in which the first column is a URL and reading it into R using <code>read.table()</code>.  </p>

<p>It seems that R is dropping about 1/3 of the columns and does not return any errors.  </p>

<p>The URLs do not contain any <code>#</code> characters or tabs (my separator field), which I understand could be an issue.  If I convert the URLs to integer IDs first, the problem goes away.</p>

<p>Is there something about the field that might be causing R to drop the rows?</p>
"
1265129,23929,2009-08-12T09:22:08Z,13,How to export the definition of an R object to plain text so that others can recreate it?,"<p>Let's say you have this data in R, and you want to post a question on stackoverflow. For others to best help you, it would be nice if they could have a copy of your object (dataframe, vector, etc) to work with.</p>

<p>Let's say your data is in a data frame called site.data</p>

<pre><code>&gt; site.data
    site year     peak
1  ALBEN    5 101529.6
2  ALBEN   10 117483.4
3  ALBEN   20 132960.9
8  ALDER    5   6561.3
9  ALDER   10   7897.1
10 ALDER   20   9208.1
15 AMERI    5  43656.5
16 AMERI   10  51475.3
17 AMERI   20  58854.4
</code></pre>

<p>How do you package it up so that the users can recreate the data exactly as you have it? </p>

<p>You want to do this without having people download a text file and import it.  </p>

<p>(Note: These data subsetted from an example of the REvolutions blog)</p>
"
1266279,23929,2009-08-12T13:50:45Z,138,How to organize large R programs?,"<p>When I undertake an R project of any complexity, my scripts quickly get long and confusing. </p>

<p>What are some practices I can adopt so that my code will always be a pleasure to work with? I'm thinking about things like</p>

<ul>
<li>Placement of functions in source files</li>
<li>When to break something out to another source file</li>
<li>What should be in the master file</li>
<li>Using functions as organizational units (whether this is worthwhile given that R makes it hard to access global state)</li>
<li>Indentation / line break practices. 

<ul>
<li>Treat ( like {? </li>
<li>Put things like )} on 1 or 2 lines?</li>
</ul></li>
</ul>

<p>Basically, what are your rules of thumb for organizing large R scripts?</p>
"
1269624,32978,2009-08-13T01:44:56Z,76,How to get row from R data.frame,"<p>I have a data.frame with column headers. </p>

<p>How can I get a specific row from the data.frame as a list (with the column headers as keys for the list)?</p>

<p>Specifically, my data.frame is </p>

<pre>
      A    B    C
    1 5    4.25 4.5
    2 3.5  4    2.5
    3 3.25 4    4
    4 4.25 4.5  2.25
    5 1.5  4.5  3
</pre>

<p>And I want to get a row that's the equivalent of</p>

<pre><code>&gt; c(a=5, b=4.25, c=4.5)
  a   b   c 
5.0 4.25 4.5 
</code></pre>
"
1274171,84458,2009-08-13T19:46:34Z,11,Creating (and Accessing) a Sparse Matrix with NA default entries,"<p>After learning about the <a href=""https://stackoverflow.com/questions/1167448/most-mature-sparse-matrix-package-for-r"">options for working with sparse matrices in R</a>, I want to use the <a href=""http://cran.r-project.org/web/packages/Matrix/index.html"" rel=""nofollow noreferrer"">Matrix</a> package to create a sparse matrix from the following data frame and have all other elements be <code>NA</code>.</p>

<pre><code>     s    r d
1 1089 3772 1
2 1109  190 1
3 1109 2460 1
4 1109 3071 2
5 1109 3618 1
6 1109   38 7
</code></pre>

<p>I know I can create a sparse matrix with the following, accessing elements as usual:</p>

<pre><code>&gt; library(Matrix)
&gt; Y &lt;- sparseMatrix(s,r,x=d)
&gt; Y[1089,3772]
[1] 1
&gt; Y[1,1]
[1] 0
</code></pre>

<p>but if I want to have the default value to be NA, I tried the following:</p>

<pre><code>  M &lt;- Matrix(NA,max(s),max(r),sparse=TRUE)
  for (i in 1:nrow(X))
    M[s[i],r[i]] &lt;- d[i]
</code></pre>

<p>and got this error</p>

<pre><code>Error in checkSlotAssignment(object, name, value) : 
  assignment of an object of class ""numeric"" is not valid for slot ""x"" in an object of class ""lgCMatrix""; is(value, ""logical"") is not TRUE
</code></pre>

<p>Not only that, I find that one takes much longer to access to elements.</p>

<pre><code>&gt; system.time(Y[3,3])
   user  system elapsed 
  0.000   0.000   0.003 
&gt; system.time(M[3,3])
   user  system elapsed 
  0.660   0.032   0.995 
</code></pre>

<p>How should I be creating this matrix?  Why is one matrix so much slower to work with?</p>

<p>Here's the code snippet for the above data:</p>

<pre><code>X &lt;- structure(list(s = c(1089, 1109, 1109, 1109, 1109, 1109), r = c(3772, 
190, 2460, 3071, 3618, 38), d = c(1, 1, 1, 2, 1, 7)), .Names = c(""s"", 
""r"", ""d""), row.names = c(NA, 6L), class = ""data.frame"")
</code></pre>
"
1279003,144278,2009-08-14T17:06:15Z,13,Specify Width and Height of Plot,"<p>I have a panel containing three plots. How can I use <code>par</code> to specify the width and height of the main panel so it is always at a fixed size?</p>
"
1296646,84458,2009-08-18T21:33:18Z,956,How to sort a dataframe by column(s)?,"<p>I want to sort a data.frame by multiple columns. For example, with the data.frame below I would like to sort by column <code>z</code> (descending) then by column <code>b</code> (ascending): </p>

<pre><code>dd &lt;- data.frame(b = factor(c(""Hi"", ""Med"", ""Hi"", ""Low""), 
      levels = c(""Low"", ""Med"", ""Hi""), ordered = TRUE),
      x = c(""A"", ""D"", ""A"", ""C""), y = c(8, 3, 9, 9),
      z = c(1, 1, 1, 2))
dd
    b x y z
1  Hi A 8 1
2 Med D 3 1
3  Hi A 9 1
4 Low C 9 2
</code></pre>
"
1297698,37751,2009-08-19T03:35:02Z,2,Plotting Regression results from lme4 in R using Lattice (or something else),"<p>I have fit a regression using lme4 thanks to a <a href=""https://stackoverflow.com/questions/1169539/linear-regression-and-group-by-in-r"">previous answer</a>. Now that I have a regression fit for each state I'd like to use lattice to plot QQ plots for each state. I would also like to plot error plots for each state in a lattice format. How do I make a lattice plot using the results of a lme4 regression? </p>

<p>Below is a simple sample (yeah, I like a good alliteration) using two states. I would like to make a two panel lattice made from the object fits. </p>

<pre><code>library(lme4)
d &lt;- data.frame(state=rep(c('NY', 'CA'), c(10, 10)), year=rep(1:10, 2), response=c(rnorm(10), rnorm(10)))
fits &lt;- lmList(response ~ year | state, data=d)
</code></pre>
"
1299871,23929,2009-08-19T13:18:11Z,771,"How to join (merge) data frames (inner, outer, left, right)?","<p>Given two data frames:</p>

<pre><code>df1 = data.frame(CustomerId = c(1:6), Product = c(rep(""Toaster"", 3), rep(""Radio"", 3)))
df2 = data.frame(CustomerId = c(2, 4, 6), State = c(rep(""Alabama"", 2), rep(""Ohio"", 1)))

df1
#  CustomerId Product
#           1 Toaster
#           2 Toaster
#           3 Toaster
#           4   Radio
#           5   Radio
#           6   Radio

df2
#  CustomerId   State
#           2 Alabama
#           4 Alabama
#           6    Ohio
</code></pre>

<p>How can I do database style, i.e., <a href=""http://en.wikipedia.org/wiki/Join_%28SQL%29"" rel=""noreferrer"">sql style, joins</a>? That is, how do I get:</p>

<ul>
<li>An <a href=""http://en.wikipedia.org/wiki/Join_%28SQL%29#Inner_join"" rel=""noreferrer"">inner join</a> of <code>df1</code> and <code>df2</code>:<br>
Return only the rows in which the left table have matching keys in the right table.</li>
<li>An <a href=""http://en.wikipedia.org/wiki/Join_%28SQL%29#Outer_join"" rel=""noreferrer"">outer join</a> of <code>df1</code> and <code>df2</code>:<br>
Returns all rows from both tables, join records from the left which have matching keys in the right table.</li>
<li>A <a href=""http://en.wikipedia.org/wiki/Join_%28SQL%29#Left_outer_join"" rel=""noreferrer"">left outer join (or simply left join)</a> of <code>df1</code> and <code>df2</code><br>
Return all rows from the left table, and any rows with matching keys from the right table.</li>
<li>A <a href=""http://en.wikipedia.org/wiki/Join_%28SQL%29#Right_outer_join"" rel=""noreferrer"">right outer join</a> of <code>df1</code> and <code>df2</code><br>
Return all rows from the right table, and any rows with matching keys from the left table.</li>
</ul>

<p>Extra credit:</p>

<p>How can I do a SQL style select statement?</p>
"
1300575,143813,2009-08-19T15:09:30Z,10,Formulas in user-defined functions in R,"<p>Formulas are a very useful feature of R's statistical and graphical functions. Like everyone, I am a user of these functions. However, I have never written a function that takes a formula object as an argument. I was wondering if someone could help me, by either linking to a readable introduction to this side of R programming, or by giving a self-contained example.</p>
"
1301759,37751,2009-08-19T18:24:23Z,4,Mixed Merge in R - Subscript solution?,"<p><strong>Note:</strong> <em>I changed the example from when I first posted. My first example was too simplified to capture the real problem.</em> </p>

<p>I have two data frames which are sorted differently in one column. I want to match one column and then merge in the value from the second column. The second column needs to stay in the same order. </p>

<p>So I have this:</p>

<pre><code>state&lt;-c(""IA"",""IA"",""IA"",""IL"",""IL"",""IL"")
value1&lt;-c(1,2,3,4,5,6)
s1&lt;-data.frame(state,value1)
state&lt;-c(""IL"",""IL"",""IL"",""IA"",""IA"",""IA"")
value2&lt;-c(3,4,5,6,7,8)
s2&lt;-data.frame(state,value2)

s1
s2
</code></pre>

<p>which returns this:</p>

<pre><code>&gt; s1
  state value1
1    IA      1
2    IA      2
3    IA      3
4    IL      4
5    IL      5
6    IL      6
&gt; s2
  state value2
1    IL      3
2    IL      4
3    IL      5
4    IA      6
5    IA      7
6    IA      8
</code></pre>

<p>and I want this:</p>

<pre><code>  state value1 value2
1    IA      1      6
2    IA      2      7
3    IA      3      8
4    IL      4      3
5    IL      5      4
6    IL      6      5
</code></pre>

<p>I'm about to drive myself silly trying to solve this. Seems like it should be a simple subscript problem. </p>
"
1309263,143141,2009-08-20T22:50:43Z,98,Rolling median algorithm in C,"<p>I am currently working on an algorithm to implement a rolling median filter (analogous to a rolling mean filter) in C. From my search of the literature, there appear to be two reasonably efficient ways to do it. The first is to sort the initial window of values, then perform a binary search to insert the new value and remove the existing one at each iteration.</p>

<p>The second (from Hardle and Steiger, 1995, JRSS-C, Algorithm 296) builds a double-ended heap structure, with a maxheap on one end, a minheap on the other, and the median in the middle. This yields a linear-time algorithm instead of one that is O(n log n).</p>

<p>Here is my problem: implementing the former is doable, but I need to run this on millions of time series, so efficiency matters a lot. The latter is proving very difficult to implement. I found code in the Trunmed.c file of the code for the stats package of R, but it is rather indecipherable.</p>

<p>Does anyone know of a well-written C implementation for the linear time rolling median algorithm?</p>

<p>Edit: Link to Trunmed.c code <a href=""http://google.com/codesearch/p?hl=en&amp;sa=N&amp;cd=1&amp;ct=rc#mYw3h_Lb_e0/R-2.2.0/src/library/stats/src/Trunmed.c"" rel=""nofollow noreferrer"">http://google.com/codesearch/p?hl=en&amp;sa=N&amp;cd=1&amp;ct=rc#mYw3h_Lb_e0/R-2.2.0/src/library/stats/src/Trunmed.c</a></p>
"
1310247,76235,2009-08-21T05:45:34Z,25,Do you use attach() or call variables by name or slicing?,"<p>Many intro R books and guides start off with the practice of attaching a <code>data.frame</code> so that you can call the variables by name. I have always found it favorable to call variables with <code>$</code> notation or square bracket slicing <code>[,2]</code>. That way I can use multiple <code>data.frame</code>s without confusing them and/or use iteration to successively call columns of interest. I noticed Google recently posted <a href=""http://google-styleguide.googlecode.com/svn/trunk/google-r-style.html"" rel=""nofollow noreferrer"">coding guidelines for R</a> which included the line</p>

<blockquote>
  <p>1) attach: avoid using it </p>
</blockquote>

<p>How do people feel about this practice?</p>
"
1311920,160794,2009-08-21T13:23:57Z,11,Lagging Variables in R,"<p>What is the most efficient way to make a matrix of lagged variables in R for an arbitrary variable (i.e. not a regular time series)</p>

<p>For example:</p>

<p><strong><em>Input</em></strong>:</p>

<pre><code>x &lt;- c(1,2,3,4) 
</code></pre>

<p><strong><em>2 lags, output</em></strong>:</p>

<pre><code>[1,NA, NA]
[2, 1, NA]
[3, 2,  1]
[4, 3,  2]
</code></pre>
"
1312865,37751,2009-08-21T16:06:26Z,5,Controlling the number of panels in a lattice plot with R,"<p>How do I limit the number of panels shown on a single page using lattice? I am graphing the results of a regression for multiple states and putting 50 of these on a single page makes them unreadable. I would like to limit the output to 4 wide and as many tall as needed. </p>

<p>Here's my lattice code:</p>

<pre><code>xyplot(Predicted_value + Actual_value ~ x_value | State_CD, data=dd)
</code></pre>

<p>There are 50 different values for State_CD</p>
"
1313954,37751,2009-08-21T19:58:39Z,18,plotting two vectors of data on a GGPLOT2 scatter plot using R,"<p>I've been experimenting with both <code>ggplot2</code> and <code>lattice</code> to graph panels of data. I'm having a little trouble wrapping my mind around the <code>ggplot2</code> model. In particular, how do I plot a scatter plot with two sets of data on each panel:</p>

<p>in <code>lattice</code> I could do this:</p>

<pre><code>xyplot(Predicted_value + Actual_value ~ x_value | State_CD, data=dd)
</code></pre>

<p>and that would give me a panel for each State_CD with each column</p>

<p>I can do one column with <code>ggplot2</code>: </p>

<pre><code>pg &lt;- ggplot(dd, aes(x_value, Predicted_value)) + geom_point(shape = 2) 
      + facet_wrap(~ State_CD) + opts(aspect.ratio = 1)
print(pg)
</code></pre>

<p>What I can't grok is how to add Actual_value to the ggplot above. </p>

<p><strong>EDIT</strong> Hadley pointed out that this really would be easier with a reproducible example. Here's code that seems to work. Is there a better or more concise way to do this with ggplot? Why is the syntax for adding another set of points to ggplot so different from adding the first set of data?</p>

<pre><code>library(lattice)
library(ggplot2)

#make some example data
dd&lt;-data.frame(matrix(rnorm(108),36,3),c(rep(""A"",24),rep(""B"",24),rep(""C"",24)))
colnames(dd) &lt;- c(""Predicted_value"", ""Actual_value"", ""x_value"", ""State_CD"")

#plot with lattice
xyplot(Predicted_value + Actual_value ~ x_value | State_CD, data=dd)

#plot with ggplot
pg &lt;- ggplot(dd, aes(x_value, Predicted_value)) + geom_point(shape = 2) + facet_wrap(~ State_CD) + opts(aspect.ratio = 1)
print(pg)

pg + geom_point(data=dd,aes(x_value, Actual_value,group=State_CD), colour=""green"")
</code></pre>

<p>The lattice output looks like this:
<a href=""http://www.cerebralmastication.com/wp-content/uploads/2009/08/lattice.png"" rel=""nofollow noreferrer"">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/08/lattice.png</a></p>

<p>and ggplot looks like this:
<a href=""http://www.cerebralmastication.com/wp-content/uploads/2009/08/ggplot.png"" rel=""nofollow noreferrer"">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/08/ggplot.png</a></p>
"
1319698,143377,2009-08-23T22:12:28Z,22,"Why doesn't ""+"" operate on characters in R?","<p>Call me lazy, but I just hate typing things like <code>paste(""a"",""b"",sep='')</code> all the time. </p>

<p>I know that ""(t)his is R. There is no if, only how."" (<code>library(fortunes);(fortune(109)</code>). So, my follow up question is: Is it possible to easily change this behavior? </p>
"
1325974,125380,2009-08-25T04:02:08Z,5,Using COM in R language,"<p>I am trying to get the rcom package for R working.  It seems to have installed ok:</p>

<pre>
> install.packages(""rcom"");
--- Please select a CRAN mirror for use in this session ---
trying URL 'http://mira.sunsite.utk.edu/CRAN/bin/windows/contrib/2.9/rcom_2.2-1.zip'
Content type 'application/zip' length 204632 bytes (199 Kb)
opened URL
downloaded 199 Kb

package 'rcom' successfully unpacked and MD5 sums checked

The downloaded packages are in
        C:\Users\solomon\AppData\Local\Temp\Rtmpzb5oi4\downloaded_packages
updating HTML package descriptions
</pre>

<p>Then I try to run something:</p>

<pre>
>comCreateObject(""Excel.Application"");
Error: could not find function ""comCreateObject""
</pre>

<p>What am I missing, the <a href=""http://cran.r-project.org/web/packages/rcom/rcom.pdf"" rel=""noreferrer"">manual</a> tells me that comCreateObject is the appropriate command.  However, the manual's version is somewhat old.  Anyone else have any insights?</p>
"
1328903,162832,2009-08-25T15:09:42Z,18,What does eg %+% do? in R,"<p>This is a very basic question - but apparently google is not very good at searching for strings like ""%+%"". So my question is - what and when is ""%+%"" and similar used. I guess its a kind of merge?.</p>

<p>EDIT: Ok - I believe my question is answered. %X% is binary operator of some kind. So now I think I will google around for knowledge about how/when to use these. My question was partly inspired by yesterday's question - but only after I saw this <a href=""http://learnr.wordpress.com/2009/03/16/ggplot2-barplots/"" rel=""nofollow noreferrer"">post</a> on the ""learning R"" blog. The passage that gave rise to my question was this:<br>
    In order to do this, a new dataframe with the annual totals will be created and later merged with the existing dataset (variable names in both dataframes should be identical for this to work). Then we just change the dataframe the plot is based on.</p>

<pre><code>## add total immigration figures to the plot
total &lt;- cast(df.m, Period ~ ., sum)
total &lt;- rename(total, c(""(all)"" = ""value""))
total$Region &lt;- ""Total""
df.m.t &lt;- rbind(total, df.m)
c1 &lt;- c %+% df.m.t
</code></pre>
"
1329940,84458,2009-08-25T18:02:36Z,84,How do I make a matrix from a list of vectors in R?,"<p>Goal: from a list of vectors of equal length, create a matrix where each vector becomes a row.</p>

<p>Example:</p>

<pre><code>&gt; a &lt;- list()
&gt; for (i in 1:10) a[[i]] &lt;- c(i,1:5)
&gt; a
[[1]]
[1] 1 1 2 3 4 5

[[2]]
[1] 2 1 2 3 4 5

[[3]]
[1] 3 1 2 3 4 5

[[4]]
[1] 4 1 2 3 4 5

[[5]]
[1] 5 1 2 3 4 5

[[6]]
[1] 6 1 2 3 4 5

[[7]]
[1] 7 1 2 3 4 5

[[8]]
[1] 8 1 2 3 4 5

[[9]]
[1] 9 1 2 3 4 5

[[10]]
[1] 10  1  2  3  4  5
</code></pre>

<p>I want:</p>

<pre><code>      [,1] [,2] [,3] [,4] [,5] [,6]
 [1,]    1    1    2    3    4    5
 [2,]    2    1    2    3    4    5
 [3,]    3    1    2    3    4    5
 [4,]    4    1    2    3    4    5
 [5,]    5    1    2    3    4    5
 [6,]    6    1    2    3    4    5
 [7,]    7    1    2    3    4    5
 [8,]    8    1    2    3    4    5
 [9,]    9    1    2    3    4    5
[10,]   10    1    2    3    4    5 
</code></pre>
"
1330989,84458,2009-08-25T21:05:24Z,383,Rotating and spacing axis labels in ggplot2,"<p>I have a plot where the x-axis is a factor whose labels are long.  While probably not an ideal visualization, for now I'd like to simply rotate these labels to be vertical.  I've figured this part out with the code below, but as you can see, the labels aren't totally visible.</p>

<pre><code>data(diamonds)
diamonds$cut &lt;- paste(""Super Dee-Duper"",as.character(diamonds$cut))
q &lt;- qplot(cut,carat,data=diamonds,geom=""boxplot"")
q + opts(axis.text.x=theme_text(angle=-90))
</code></pre>

<p><a href=""https://i.stack.imgur.com/pcJr3.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/pcJr3.png"" alt=""enter image description here""></a></p>
"
1331203,84458,2009-08-25T21:44:41Z,0,Renaming large IDs,"<p>Suppose I have a data.frame with N rows.  The <code>id</code> column has 10 unique values; all those values are integers greater than 1e7.  I would like to rename them to be numbered 1 through 10 and save these new IDs as a column in my data.frame.</p>

<p>Additionally, I would like to easily determine 1) <code>id</code> given <code>id.new</code> and 2) <code>id.new</code> given <code>id</code>.</p>

<p>For example: </p>

<pre><code>&gt; set.seed(123)
&gt; ids &lt;- sample(1:1e7,10)
&gt; A &lt;- data.frame(id=sample(ids,100,replace=TRUE),
                  x=rnorm(100))
&gt; head(A)
       id          x
1 4566144  1.5164706
2 9404670 -1.5487528
3 5281052  0.5846137
4  455565  0.1238542
5 7883051  0.2159416
6 5514346  0.3796395
</code></pre>
"
1335830,84458,2009-08-26T16:06:33Z,68,Why can't R's ifelse statements return vectors?,"<p>I've found R's ifelse statements to be pretty handy from time to time.  For example:</p>

<pre><code>ifelse(TRUE,1,2)
# [1] 1
ifelse(FALSE,1,2)
# [1] 2
</code></pre>

<p>But I'm somewhat confused by the following behavior.</p>

<pre><code>ifelse(TRUE,c(1,2),c(3,4))
# [1] 1
ifelse(FALSE,c(1,2),c(3,4))
# [1] 3
</code></pre>

<p>Is this a design choice that's above my paygrade?</p>
"
1336271,41661,2009-08-26T17:15:12Z,6,How to make topographic map from sparse sampling data?,"<p>I need to make a topographic map of a terrain for which I have only fairly sparse samples of <em>(x,&nbsp;y,&nbsp;altitude)</em> data.  Obviously I can't make a completely accurate map, but I would like one that is in some sense ""smooth"".  I need to quantify ""smoothness"" (probably the reciprocal the average of the square of the surface curvature) and I want to minimize an objective function that is the sum of two quantities:</p>

<ul>
<li>The roughness of the surface</li>
<li>The mean square distance between the altitude of the surface at the sample point and the actual measured altitude at that point</li>
</ul>

<p>Since what I actually want is a topographic map, I am really looking for a way to construct contour lines of constant altitude, and there may be some clever geometric way to do that without ever having to talk about surfaces.  Of course I want contour lines also to be smooth.</p>

<p>Any and all suggestions welcome.  I'm hoping this is a well-known numerical problem.  I am quite comfortable in C and have a working knowledge of FORTRAN.  About Matlab and R I'm fairly clueless.</p>

<hr>

<p>Regarding where our samples are located: we're planning on roughly even spacing, but we'll take more samples where the topography is more interesting.  So for example we'll sample mountainous regions more densely than a plain.  But we definitely have some choices about sampling, and could take even samples if that simplifies matters.  The only issues are</p>

<ul>
<li><p>We don't know how much terrain we'll need to map in order to find features that we are looking for.</p></li>
<li><p>Taking a sample is moderately expensive, on the order of 10 minutes.  So sampling a 100x100 grid could take a long time.</p></li>
</ul>
"
1343442,NA,2009-08-27T19:55:04Z,8,maintaining an input / output log in R,"<p>Is there an easy way to have R record all input and output from your R session to disk while you are working with R interactively?  </p>

<p>In <code>R.app</code> on <code>Mac OS X</code> I can do a <code>File-&gt;Save...</code>, but it isn't much help in recovering the commands I had entered when R crashes.</p>

<p>I have tried using <code>sink(...,split=T)</code>, but it doesn't seem to do exactly what I am looking for.</p>
"
1351937,165406,2009-08-29T17:21:13Z,3,R package installation,"<p>I have basically two questions.</p>

<ol>
<li><p>How do I locate the default <code>Rprofile</code> which is running? I have not setup a <code>Rprofile</code> yet, so I am not sure where it is running from.</p></li>
<li><p>I am trying to install a few packages using the command (after doing a SUDO in the main terminal).</p></li>
</ol>



<pre><code>install.packages(""RODBC"",""/home/rama/R/i486-pc-linux-gnu-library/2.9"")
</code></pre>

<p>and I get back an error which says:</p>

<blockquote>
  <p>ERROR: failed to lock directory ‘/home/rama/R/i486-pc-linux-gnu-library/2.9’ for modifying Try removing ‘/home/rama/R/i486-pc-linux-gnu-library/2.9/00LOCK’</p>
  
  <p>The downloaded packages are in ‘/tmp/RtmpkzDMVU/downloaded_packages’ Warning message: In install.packages(""RODBC"", ""/home/rama/R/i486-pc-linux-gnu-library/2.9"") : installation of package 'RODBC' had non-zero exit status</p>
</blockquote>
"
1352863,143319,2009-08-30T02:07:13Z,7,Getting foreach() and ggplot2 to get along,"<p>I have a set of survey data, and I'd like to generate plots of a particular variable, grouped by the respondent's country.  The code I have written to generate the plots so far is:</p>

<pre><code>countries &lt;- isplit(drones, drones$v3)
foreach(country = countries) %dopar% {
  png(file = paste(output.exp, ""/Histogram of Job Satisfaction in "", country$key[[1]], "".png"", sep = """"))
  country.df &lt;- data.frame(country)  #ggplot2 doesn't appreciate the lists nextElem() produces
  ggplot(country.df, aes(x = value.v51)) + geom_histogram()
  dev.off()
}
</code></pre>

<p>The truly bizarre thing?  I can run the isplit(), set <code>country &lt;- nextElem(countries)</code>, and then run through the code without sending the foreach line - and get a lovely plot.  If I send the foreach, I get some blank .png files.</p>

<p>Thanks in advance for your help.</p>

<p>I can definitely do this with standard R loops, but I'd really like to get a better grasp on <code>foreach</code>.</p>
"
1355355,37751,2009-08-31T00:48:18Z,31,How to avoid a loop in R: selecting items from a list,"<p>I could solve this using loops, but I am trying think in vectors so my code will be more R-esque. </p>

<p>I have a list of names. The format is firstname_lastname. I want to get out of this list a separate list with only the first names. I can't seem to get my mind around how to do this. Here's some example data:</p>

<pre><code>t &lt;- c(""bob_smith"",""mary_jane"",""jose_chung"",""michael_marx"",""charlie_ivan"")
tsplit &lt;- strsplit(t,""_"")
</code></pre>

<p>which looks like this:</p>

<pre><code>&gt; tsplit
[[1]]
[1] ""bob""   ""smith""

[[2]]
[1] ""mary"" ""jane""

[[3]]
[1] ""jose""  ""chung""

[[4]]
[1] ""michael"" ""marx""   

[[5]]
[1] ""charlie"" ""ivan""   
</code></pre>

<p>I could get out what I want using loops like this:</p>

<pre><code>for (i in 1:length(tsplit)){
    if (i==1) {t_out &lt;- tsplit[[i]][1]} else{t_out &lt;- append(t_out, tsplit[[i]][1])} 
}
</code></pre>

<p>which would give me this:</p>

<pre><code>t_out
[1] ""bob""     ""mary""    ""jose""    ""michael"" ""charlie""
</code></pre>

<p>So how can I do this without loops?</p>
"
1358003,143305,2009-08-31T15:26:13Z,399,Tricks to manage the available memory in an R session,"<p>What tricks do people use to manage the available memory of an interactive R session?  I use the functions below [based on postings by Petr Pikal and David Hinds to the r-help list in 2004] to list (and/or sort) the largest objects and to occassionally <code>rm()</code> some of them. But by far the most effective solution was ... to run under 64-bit Linux with ample memory. </p>

<p>Any other nice tricks folks want to share?  One per post, please.</p>

<pre><code># improved list of objects
.ls.objects &lt;- function (pos = 1, pattern, order.by,
                        decreasing=FALSE, head=FALSE, n=5) {
    napply &lt;- function(names, fn) sapply(names, function(x)
                                         fn(get(x, pos = pos)))
    names &lt;- ls(pos = pos, pattern = pattern)
    obj.class &lt;- napply(names, function(x) as.character(class(x))[1])
    obj.mode &lt;- napply(names, mode)
    obj.type &lt;- ifelse(is.na(obj.class), obj.mode, obj.class)
    obj.size &lt;- napply(names, object.size)
    obj.dim &lt;- t(napply(names, function(x)
                        as.numeric(dim(x))[1:2]))
    vec &lt;- is.na(obj.dim)[, 1] &amp; (obj.type != ""function"")
    obj.dim[vec, 1] &lt;- napply(names, length)[vec]
    out &lt;- data.frame(obj.type, obj.size, obj.dim)
    names(out) &lt;- c(""Type"", ""Size"", ""Rows"", ""Columns"")
    if (!missing(order.by))
        out &lt;- out[order(out[[order.by]], decreasing=decreasing), ]
    if (head)
        out &lt;- head(out, n)
    out
}
# shorthand
lsos &lt;- function(..., n=10) {
    .ls.objects(..., order.by=""Size"", decreasing=TRUE, head=TRUE, n=n)
}
</code></pre>
"
1358238,61027,2009-08-31T16:35:52Z,10,Finding a curve to match data,"<p>I'm looking for a non-linear curve fitting routine (probably most likely to be found in R or Python, but I'm open to other languages) which would take x,y data and fit a curve to it.</p>

<p>I should be able to specify as a string the type of expression I want to fit.</p>

<p>Examples:</p>

<pre><code>""A+B*x+C*x*x""
""(A+B*x+C*x*x)/(D*x+E*x*x)""
""sin(A+B*x)*exp(C+D*x)+E+F*x""
</code></pre>

<p>What I would get out of this is at least the values for the constants (A, B, C, etc.) And hopefully stats about the fitness of the match.</p>

<p>There are commercial programs to do this, but I expected to be able to find something as common as fitting to a desired expression in a language library nowadays. I suspect SciPy's optimization stuff might be able to do this, but I can't see that it lets me define an equation. Likewise, I can't seem to find exactly what I want in R.</p>

<p>Is what I'm looking for out there, or do I need to roll my own? I hate to do it if it's there and I'm just having trouble finding it.</p>

<hr>

<p>Edit: I want to do this for a bit more control over the process than I get from LAB Fit. The LAB Fit UI is dreadful. I'd also like to be able to break the range into multiple pieces and have different curves represent the different pieces of the range. In the end, the result has to be able to (speed-wise) beat a LUT with linear interpolation or I'm not interested.</p>

<p>In my current set of problems, I have trig functions or exp() and I need to execute them 352,800 times per second in real time (and use only a fraction of the CPU). So I plot the curve and use the data to drive the curve fitter to get less expensive approximations. In the old days, LUTs were almost always the solution, but nowadays skipping the memory lookups and doing an approximation is sometimes faster.</p>
"
1366853,67405,2009-09-02T10:13:07Z,6,How to Superimpose Multiple Density Curves Into One Plot in R,"<p>I have a data that looks like <a href=""http://dpaste.com/88561/plain/"" rel=""nofollow noreferrer"">this</a>.</p>

<p>And I intend to create multiple density curve into one plot, where each curve
correspond to the unique ID.</p>

<p>I tried to use ""sm"" package, with this code, but without success.</p>

<pre><code>library(sm)
dat &lt;- read.table(""mydat.txt"");
plotfn &lt;- (""~/Desktop/flowgram_superimposed.pdf"");
pdf(plotfn);

sm.density.compare(dat$V1,dat$V2, xlab = ""Flow Signal"")
colfill &lt;- c(2:10);
legend(locator(1), levels(dat$V2), fill=colfill)

dev.off();
</code></pre>

<p>Please advice what's the right way to do it or if  there is
alternative way to do it?</p>

<p>I am trying to get this kind of plot  at the end. 
<a href=""http://img524.imageshack.us/img524/2736/testl.png"" rel=""nofollow noreferrer"">figure http://img524.imageshack.us/img524/2736/testl.png</a></p>
"
1374609,168019,2009-09-03T16:45:21Z,1,How do I apply underlying decision rules created from the R package randomForest onto a NEW Out of Bag test set?,"<p>Is this even possible?  I had a dataset for training that included about 1500 entries.  The randomForest created its decision rules and applied them to the randomly chosen (from the original dataset) Out of Bag training sample (bootstrapped 10,000 times).  I have a separate (unclassified) dataset that I would like to apply the 10,000 created trees to in order to predict classification for these new entries.  Is there an easy way to index the underlying Forest trees to this new unclassified dataset?</p>
"
1374842,149223,2009-09-03T17:29:39Z,0,Building and installing an R package library with a jnilib extension,"<p>I'm building an R package and need to build a jni library for OSX (called <code>myPackage.jnilib</code>) as part of my build process and then have R's automatic installation mechanisms put it inside the libs directory of my package.</p>

<p>The problem is that R's default is to try and build an object called <code>myPackage.so</code>. I'd like to be able to customize this but can't see how.</p>

<p>I can get part of the way by subverting R's mechanisms using a phony ""all"" target in Makevars (described <a href=""http://stat.ethz.ch/R-manual/R-patched/doc/manual/R-exts.html#Using-Makevars"" rel=""nofollow noreferrer"">here</a>) and then copying the file to the <code>inst</code> directory of my package.  This is OK for my own local uses but generates headaches when trying to build universal binaries and isn't very portable. I'm currently preparing the package for CRAN so this method isn't likely to work.</p>

<p>I can see two potential solutions but haven't got either to work yet</p>

<ol>
<li><p>Copy my library manually to the libs directory of my package during installation.  Since this directory is created on the fly, how would I find out what it is from within Makevars or a configure script</p></li>
<li><p>The best solution: Tell R CMD SHLIB the name of my output file so I can use R's normal package mechanisms and let it copy the file to the right directory.  </p></li>
</ol>
"
1376967,37751,2009-09-04T02:37:23Z,18,using stat_function and facet_wrap together in GGPLOT2 in R,"<p>I am trying to plot lattice type data with GGPLOT2 and then superimpose a normal distribution over the sample data to illustrate how far off normal the underlying data is. I would like to have the normal dist on top to have the same mean and stdev as the panel. </p>

<p>here's an example:</p>

<pre><code>library(ggplot2)

#make some example data
dd&lt;-data.frame(matrix(rnorm(144, mean=2, sd=2),72,2),c(rep(""A"",24),rep(""B"",24),rep(""C"",24)))
colnames(dd) &lt;- c(""x_value"", ""Predicted_value"",  ""State_CD"")

#This works
pg &lt;- ggplot(dd) + geom_density(aes(x=Predicted_value)) +  facet_wrap(~State_CD)
print(pg)
</code></pre>

<p>That all works great and produces a nice three panel graph of the data. How do I add the normal dist on top? It seems I would use stat_function, but this fails:</p>

<pre><code>#this fails
pg &lt;- ggplot(dd) + geom_density(aes(x=Predicted_value)) + stat_function(fun=dnorm) +  facet_wrap(~State_CD)
print(pg)
</code></pre>

<p>It appears that the stat_function is not getting along with the facet_wrap feature. How do I get these two to play nicely?</p>

<p><strong>------------EDIT---------</strong></p>

<p>I tried to integrate ideas from two of the answers below and I am still not there:</p>

<p>using a combination of both answers I can hack together this:</p>

<pre><code>library(ggplot)

#make some example data
dd&lt;-data.frame(matrix(rnorm(108, mean=2, sd=2),36,2),c(rep(""A"",24),rep(""B"",24),rep(""C"",24)))
colnames(dd) &lt;- c(""x_value"", ""Predicted_value"",  ""State_CD"")

DevMeanSt &lt;- ddply(dd, c(""State_CD""), function(df)mean(df$Predicted_value)) 
colnames(DevMeanSt) &lt;- c(""State_CD"", ""mean"")
DevSdSt &lt;- ddply(dd, c(""State_CD""), function(df)sd(df$Predicted_value) )
colnames(DevSdSt) &lt;- c(""State_CD"", ""sd"")
DevStatsSt &lt;- merge(DevMeanSt, DevSdSt)

pg &lt;- ggplot(dd, aes(x=Predicted_value))
pg &lt;- pg + geom_density()
pg &lt;- pg + stat_function(fun=dnorm, colour='red', args=list(mean=DevStatsSt$mean, sd=DevStatsSt$sd))
pg &lt;- pg + facet_wrap(~State_CD)
print(pg)
</code></pre>

<p>which is really close... except something is wrong with the normal dist plotting:</p>

<p><a href=""http://www.cerebralmastication.com/wp-content/uploads/2009/09/ggplot1.png"">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/09/ggplot1.png</a></p>

<p>what am I doing wrong here?</p>
"
1377003,67405,2009-09-04T02:57:00Z,3,How can I compute the probability at a point given a normal distribution in Perl?,"<p>Is there a package in Perl that allows you to compute the height of probability distribution at each given point. For example this can be done in R this way:</p>

<pre><code>&gt; dnorm(0, mean=4,sd=10)
&gt; 0.03682701
</code></pre>

<p>Namely the probability of point x=0 falls into a normal distribution, with mean=4 and sd=10, is 0.0368.
I looked at <a href=""http://search.cpan.org/~mikek/Statistics-Distributions-1.02/Distributions.pm"" rel=""nofollow noreferrer"">Statistics::Distribution</a> but it doesn't give that very 
function to do it. </p>
"
1377130,164965,2009-09-04T03:44:57Z,11,How do you deal with missing data using numpy/scipy?,"<p>One of the things I deal with most in data cleaning is missing values. R deals with this well using its ""NA"" missing data label. In python, it appears that I'll have to deal with masked arrays which seem to be a major pain to set up and don't seem to be well documented. Any suggestions on making this process easier in Python? This is becoming a deal-breaker in moving into Python for data analysis. Thanks</p>

<p><strong>Update</strong> It's obviously been a while since I've looked at the methods in the numpy.ma module. It appears that at least the basic analysis functions are available for masked arrays, and the examples provided helped me understand how to create masked arrays (thanks to the authors). I would like to see if some of the newer statistical methods in Python (being developed in this year's GSoC) incorporates this aspect, and at least does the complete case analysis.</p>
"
1377248,67405,2009-09-04T04:38:58Z,2,On Data Frame: Writing to File and Naming Binded Vector in R,"<p>I have a data that looks like <a href=""http://dpaste.com/89376/plain/"" rel=""nofollow noreferrer"">this</a>. And my code below
simply compute some value and binds the output vector to the
original data frames.</p>

<pre><code>options(width=200)

args&lt;-commandArgs(trailingOnly=FALSE)
dat &lt;- read.table(""http://dpaste.com/89376/plain/"",fill=T);

problist &lt;- c();

for (lmer in 1:10) {
   meanl &lt;- lmer;
   stdevl &lt;- (0.17*sqrt(lmer));
   err_prob &lt;- pnorm(dat$V4,mean=meanl, sd=stdevl);
   problist &lt;- cbind(problist,err_prob);
}

dat &lt;- cbind(dat,problist)
#print(dat,row.names=F, column.names=F,justify=left)

# Why this breaks?
write(dat, file=""output.txt"", sep=""\t"",append=F);
</code></pre>

<p>I have couple of questions regarding the above:</p>

<ol>
<li><p>But why the 'write()' function above gives this error. Is there a way to fix it?</p>

<p>Error in cat(list(...), file, sep, fill, labels, append) : 
  argument 1 (type 'list') cannot be handled by 'cat'
Calls: write -> cat
Execution halted</p></li>
<li><p>Names for binded vector in the data frame is added as ""errprob"" for all 10 new 
columns. Is there a way to name them like ""errprob1"", ""errprob2"", etc? </p></li>
</ol>
"
1379549,84458,2009-09-04T14:17:06Z,18,Recommendations for developing Sweave documents,"<p>I'm looking to streamline my <a href=""http://en.wikipedia.org/wiki/Sweave"" rel=""noreferrer"">Sweave</a> document creation, and I'd like to hear about people's current setups.  I feel like the holy grail goes something like this:</p>

<ul>
<li>Editing Rnw code on one half of the
screen </li>
<li>Single keybinding compiles
Sweave document and runs pdflatex </li>
<li>View PDF
on the other half of the screen; once
compiled, PDF is refreshed and centered around the portion of the document you're editing</li>
<li>If compilation has errors, replace the PDF with the results of the compilation (e.g. latex errors or Sweave errors)</li>
</ul>

<p>I am guessing/hoping that the solution is part Emacs/ESS combined with some code for the Emacs profile and/or a nice Makefile.  But I would really like to hear about everybody's preferred way of creating Sweave and/or Latex documents.</p>
"
1380694,23929,2009-09-04T17:58:53Z,17,How to fit a random effects model with Subject as random in R?,"<p>Given data of the following form</p>

<pre><code>myDat = structure(list(Score = c(1.84, 2.24, 3.8, 2.3, 3.8, 4.55, 1.13, 
2.49, 3.74, 2.84, 3.3, 4.82, 1.74, 2.89, 3.39, 2.08, 3.99, 4.07, 
1.93, 2.39, 3.63, 2.55, 3.09, 4.76), Subject = c(1L, 1L, 1L, 
2L, 2L, 2L, 3L, 3L, 3L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L, 7L, 
7L, 7L, 8L, 8L, 8L), Condition = c(0L, 0L, 0L, 1L, 1L, 1L, 0L, 
0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 
1L), Time = c(1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 
1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L)), .Names = c(""Score"", 
""Subject"", ""Condition"", ""Time""), class = ""data.frame"", row.names = c(NA, 
-24L))
</code></pre>

<p>I would like to model Score as a function of Subject, Condition and Time. Each (human) Subject's score was measured three times, indicated by the variable Time, so I have repeated measures.</p>

<p>How can I build in R a random effects model with Subject effects fitted as random?</p>

<p><strong>ADDENDUM</strong>: It's been asked how I generated these data. You guessed it, the data are fake as the day is long. Score is time plus random noise and being in Condition 1 adds a point to Score. It's instructive as a typical Psych setup. You have a task where people's score gets better with practice (time) and a drug (condition==1) that enhances score.</p>

<p>Here are some more realistic data for the purposes of this discussion. Now simulated participants have a random ""skill"" level that is added to their scores. Also, the factors are now strings.</p>

<pre><code>myDat = structure(list(Score = c(1.62, 2.18, 2.3, 3.46, 3.85, 4.7, 1.41, 
2.21, 3.32, 2.73, 3.34, 3.27, 2.14, 2.73, 2.74, 3.39, 3.59, 4.01, 
1.81, 1.83, 3.22, 3.64, 3.51, 4.26), Subject = structure(c(1L, 
1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 
6L, 7L, 7L, 7L, 8L, 8L, 8L), .Label = c(""A"", ""B"", ""C"", ""D"", ""E"", 
""F"", ""G"", ""H""), class = ""factor""), Condition = structure(c(1L, 
1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 
2L, 1L, 1L, 1L, 2L, 2L, 2L), .Label = c(""No"", ""Yes""), class = ""factor""), 
    Time = structure(c(1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 
    2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L), .Label = c(""1PM"", 
    ""2PM"", ""3PM""), class = ""factor"")), .Names = c(""Score"", ""Subject"", 
""Condition"", ""Time""), class = ""data.frame"", row.names = c(NA, 
-24L))
</code></pre>

<p>See it:</p>

<pre><code>library(ggplot2)
qplot(Time, Score, data = myDat, geom = ""line"", group = Subject, colour = factor(Condition))
</code></pre>
"
1382288,142879,2009-09-05T02:30:03Z,9,How can I remove plot margins between the axes of the plot and the plot contents in R?,"<p>I want to remove the space between the axes of the plot and the plot contents themselves. Any ideas?</p>
"
1384025,4907,2009-09-05T18:55:12Z,6,How do I print greek letters on the diagonal of a pairs plot in R?,"<p>I want to create a pairs plot in R that has labels on the diagonal written as greek letters.  I've tried creating a custom text.panel function that wraps the labels in an <code>expression()</code> call, but this does not work.</p>

<p>Here is a simple test case:</p>

<pre><code>pairs.greek &lt;- function(x, ...)
{
  panel.txt &lt;- function(x, y, labels, cex, font, ...)
  {
    lab &lt;- labels
    text(0.5, 0.5, expression(lab), cex=cex, font=font)
  }
  pairs(x, text.panel=panel.txt)
}
dat &lt;- data.frame(alpha=runif(10), beta=runif(10), gamma=runif(10))
pairs.greek(dat)
</code></pre>
"
1385873,162832,2009-09-06T15:04:43Z,1,data.frame subset long format,"<p>I guess there will be a very simple answer to this. But here goes.</p>

<p>Data in long format. like this</p>

<pre><code>d &lt;- data.frame(cbind(numbers = rnorm(10), 
                         year = rep(c(2008, 2009), 5), 
                         name = c(""john"", ""David"", ""Tom"", ""Kristin"", ""Lisa"",""Eve"",""David"",""Tom"",""Kristin"",""Lisa"")))
</code></pre>

<p>How do I get a new dataframe only with rows for names that occur in both 2008 and 2009? (i.e. with only David, Kristin, Lisa and Tom).</p>

<p>Thanks in advance</p>
"
1386767,163053,2009-09-06T21:27:41Z,26,Are there any good R object browsers?,"<p>S-Plus has a great object explorer and data editor built into its GUI.  It allows you to easily see all the objects in the workspace at a glance, and sort them by name, size, or date.  </p>

<p>As far as I'm aware, the only equivalent for R is the object browser in JGR (<a href=""http://jgr.markushelbig.org/"" rel=""noreferrer"">http://jgr.markushelbig.org/</a>).   </p>

<p>Otherwise I just use the search() and ls() commands most of the time (along with grep() when I have a lot of objects).  </p>

<pre><code># trivial example of routine:
search()
utils.list &lt;- ls(pos=""package:utils"")
utils.list[grep(""edit"",utils.list)]
</code></pre>

<p>Does anyone have any tricks or suggestions for browsing the R workspace?  Are there any point-and-click solutions?</p>
"
1389123,161259,2009-09-07T12:15:31Z,3,How come there is no 64bit build of R for Windows?,"<p>How come R does not have a 64bit windows pre-built binaries?</p>
"
1389428,12677,2009-09-07T13:27:53Z,3,Dealing with time-periods such as 5 minutes and 30 seconds in R,"<p>Is there a good way to deal with time periods such as 05:30 (5 minutes, 30 seconds) in R?</p>

<p>Alternatively what's the fastest way to convert it into an integer with just seconds?</p>

<p>I can only convert to dates and can't really find a data type for time.</p>

<p>I'm using R with zoo.</p>

<p>Thanks a lot ! </p>

<hr>

<p>Seconds was the best way to deal with this. I adapted Shane's code below to my purposes, here's the result.</p>

<pre><code># time - time in the format of dd hh:mm:ss
#       (That's the format used in cvs export from Alcatel CCS reports)
#
time.to.seconds &lt;- function(time) {

   t &lt;- strsplit(as.character(time), "" |:"")[[1]]
   seconds &lt;- NaN

   if (length(t) == 1 )
      seconds &lt;- as.numeric(t[1])
   else if (length(t) == 2)
      seconds &lt;- as.numeric(t[1]) * 60 + as.numeric(t[2])
   else if (length(t) == 3)
      seconds &lt;- (as.numeric(t[1]) * 60 * 60 
          + as.numeric(t[2]) * 60 + as.numeric(t[3]))   
   else if (length(t) == 4)
      seconds &lt;- (as.numeric(t[1]) * 24 * 60 * 60 +
         as.numeric(t[2]) * 60 * 60  + as.numeric(t[3]) * 60 +
         as.numeric(t[4]))

   return(seconds)
}
</code></pre>
"
1392868,141826,2009-09-08T09:09:10Z,1,using RSPython in MacOSX,"<p>I am trying to install the
<a href=""http://www.omegahat.org/RSPython/"" rel=""nofollow noreferrer"">R/SPlus - Python Interface (RSPython)</a> on my Mac OS X 10.4.11 with R version 2.7.2 (2008-08-25) and python 2.6.2 from fink.</p>

<p>The routine:</p>

<pre><code>sudo R CMD INSTALL -c RSPython_0.7-1.tar.gz
</code></pre>

<p>produced this error message:</p>

<pre><code>* Installing to library '/Library/Frameworks/R.framework/Resources/library'
* Installing *source* package 'RSPython' ...
checking for python... /sw/bin/python
Python version 2.6
Using threads
checking for gcc... gcc
checking for C compiler default output file name... configure: error: C compiler cannot create executables
See `config.log' for more details.
ERROR: configuration failed for package 'RSPython'
** Removing '/Library/Frameworks/R.framework/Versions/2.7/Resources/library/RSPython'
</code></pre>

<p>The config.log was not created o my system.</p>

<p>The contact e-mail address to the author does not work anymore, so I just hope somebody here tried the same already or can give me an alternative for running R routines in python.</p>

<p>Best regards,</p>

<p>Simon</p>
"
1393432,134903,2009-09-08T11:17:25Z,2,Getting data from text file (separated by spaces) using variable lengths into R,"<p>I have a text file similar to this (separated by spaces):</p>

<pre><code>x &lt;- ""DF12 This is an example 1 This
DF12 This is an 1232 This is
DF14 This is 12334 This is an
DF15 This 23 This is an example
""
</code></pre>

<p>and I know the field lengths of each variable (there is 5 variables in this data set), which are:</p>

<pre><code>varlength &lt;- c(2, 2, 18, 5, 18)
</code></pre>

<p>How can I import this kind of data into R, using the varlength variable as an field separator indicator?</p>
"
1395102,160314,2009-09-08T17:03:44Z,17,gls() vs. lme() in the nlme package,"<p>In the nlme package there are two functions for fitting linear models (lme and gls). </p>

<ol>
<li>What are the differences between
them in terms of the types of models
that can be fit, and the fitting
process?  </li>
<li>What is the design
rational for having two functions to
fit linear mixed models where most
other systems (e.g. SAS SPSS) only
have one?</li>
</ol>

<p>Update: Added bounty. Interested to know differences in the fitting process, and the rational.</p>
"
1395105,144537,2009-09-08T17:04:26Z,95,Getting LaTeX into R Plots,"<p>I would like to add <code>LaTeX</code> typesetting to elements of plots in <code>R</code> (e.g: the title, axis labels, annotations, etc.) using either the combination of <code>base/lattice</code> or with <code>ggplot2</code>.</p>

<p><strong>Questions:</strong></p>

<ul>
<li>Is there a way to get <code>LaTeX</code> into plots using these packages, and if so, how is it done?  </li>
<li>If not, are there additional packages needed to accomplish this.</li>
</ul>

<p>For example, in <code>Python matplotlib</code> compiles <code>LaTeX</code> via the <code>text.usetex</code> packages as discussed here: <a href=""http://www.scipy.org/Cookbook/Matplotlib/UsingTex"" rel=""noreferrer"">http://www.scipy.org/Cookbook/Matplotlib/UsingTex</a></p>

<p>Is there a similar process by which such plots can be generated in <code>R</code>?</p>
"
1395115,37751,2009-09-08T17:06:51Z,7,Storing R Objects in a relational database,"<p>I frequently create nonparametric statistics (loess, kernel densities, etc) on data I pull out of a relational database. To make data management easier I would like to store R output back inside my DB. This is easy with simple data frames of numbers or text, but I have not figured out how to store R objects back in my relational database. So is there a way to store a vector of kernel densities, for example, back into a relational database? </p>

<p>Right now I work around this by saving the R objects to a network drive space so others can load the objects as needed. </p>
"
1395117,154039,2009-09-08T17:07:07Z,19,How do you convert dates/times from one time zone to another in R?,"<p>If I have a date like this in London time: ""2009-06-03 19:30"", how can I convert it to the equivalent time in the US West Coast?</p>
"
1395118,NA,2009-09-08T17:07:55Z,1,Re-generate same simulated data set in a MC simulation study,"<p>Suppose I simulate a data set using </p>

<pre><code>set.seed(1234); 
rnorm(100);
</code></pre>

<p>Later, I would like to find the <code>90th</code> data value simulated without re-simulating the whole data set.  </p>

<ul>
<li>How can this be done?  </li>
<li>Does <code>.Random.seed</code> play a role?  </li>
</ul>

<p>While this may seem to be an overly simplified problem (especially when one could just run the whole code again), this type of problem occurs in more complicated <code>Monte Carlo</code> simulations where perhaps a 1,000 data sets are simulated and something goes wrong on data set #90. One would want to view data set #90 without having to simulate data sets #1- #89.</p>
"
1395136,23929,2009-09-08T17:11:03Z,4,Is there a systematic way to convert R code with loops to vectorized code?,"<p>Most looping code looks like this</p>

<pre><code>retVal=NULL
for i {
  for j {
    result &lt;- *some function of vector[i] and vector[j]* 
    retVal = rbind(retVal,result)
  }
}
</code></pre>

<p>Since this is so common, is there a systematic way of translating this idiom?</p>

<p>Can this be extended to most loops?</p>
"
1395147,161808,2009-09-08T17:12:31Z,15,Best way to plot interaction effects from a linear model,"<p>In an effort to help populate the R tag here, I am posting a few questions I have often received from students. I have developed my own answers to these over the years, but perhaps there are better ways floating around that I don't know about.</p>

<p>The question: I just ran a regression with continuous <code>y</code> and <code>x</code> but factor <code>f</code> (where <code>levels(f)</code> produces <code>c(""level1"",""level2"")</code>)</p>

<pre><code> thelm &lt;- lm(y~x*f,data=thedata)
</code></pre>

<p>Now I would like to plot the predicted values of <code>y</code> by <code>x</code> broken down by groups defined by <code>f</code>. All of the plots I get are ugly and show too many lines.</p>

<p>My answer: Try the <code>predict()</code> function.</p>

<pre><code>##restrict prediction to the valid data 
##from the model by using thelm$model rather than thedata

 thedata$yhat &lt;- predict(thelm,
      newdata=expand.grid(x=range(thelm$model$x),
                          f=levels(thelm$model$f)))

 plot(yhat~x,data=thethedata,subset=f==""level1"")
 lines(yhat~x,data=thedata,subset=f==""level2"")
</code></pre>

<p>Are there other ideas out there that are (1) easier to understand for a newcomer and/or (2) better from some other perspective?</p>
"
1395156,23929,2009-09-08T17:14:34Z,5,How to make an R function return multiple columns and append them to a data frame?,"<p>Starting with this data frame</p>

<pre><code>myDF = structure(list(Value = c(-2, -1, 0, 1, 2)), .Names = ""Value"", row.names = c(NA, 5L), class = ""data.frame"")
</code></pre>

<p>Suppose I want to run this function on every row of myDF$Value </p>

<pre><code>getNumberInfo &lt;- function(x) {
if(x %% 2 ==0) evenness = ""Even"" else evenness=""Odd""
if(x &gt; 0) positivity = ""Positive"" else positivity = ""NonPositive""
if (positivity == ""Positive"") logX = log(x) else logX=NA
c(evenness,positivity,logX)
} 
</code></pre>

<p>... to get this data frame</p>

<pre><code>structure(list(Value = c(-2, -1, 0, 1, 2), Evenness = c(""Even"", 
""Odd"", ""Even"", ""Odd"", ""Even""), Positivity = c(""NonPositive"", 
""NonPositive"", ""NonPositive"", ""Positive"", ""Positive""), Log = c(NA, 
NA, NA, ""0"", ""0.693147180559945"")), row.names = c(NA, 5L), .Names = c(""Value"", 
""Evenness"", ""Positivity"", ""Log""), class = ""data.frame"")
</code></pre>
"
1395157,170236,2009-09-08T17:14:42Z,1,Analyzing Path Data,"<p>I have data representing the paths people take across a fixed set of points (discrete, e.g., nodes and edges).  So far I have been using <code>igraph</code>. </p>

<p>I haven't found a good way yet (in <code>igraph</code> or another package) to create <code>canonical paths</code> summarizing what significant sub-groups of respondents are doing.  </p>

<p>A <code>canonical path</code> can be operationalized in any reasonable way and is just meant to represent a typical path or sub-path for a significant portion of the population.  </p>

<p>Does there already exist a function to create these within <code>igraph</code> or another package?</p>
"
1395158,168139,2009-09-08T17:15:03Z,5,Making good column names R,"<p>I read a table from Microsoft Access using RODBC. Some of the variables had a name with a space in it.</p>

<p>R has no problem with it but I do.
I cannot find out how to specify the space</p>

<pre><code>names(alltime)
 [1] ""ID""            ""LVL7""          ""Ref Pv No""     ""Ref Pv Name""   ""DOS""           ""Pt Last Name""  ""Pt First Name"" ""MRN""           ""CPT""           ""CPT Desc""      ""DxCd1""         ""DxCd2""         ""DxCd3""         ""DxCd4""        
[15] ""DOE""    
</code></pre>

<p>But what do I do if I want to do something such as this</p>

<pre><code>&gt; alltime[grep(""MIDDLE EAR EXPLORE"",alltime$CPT Desc,]
Error: unexpected symbol in ""alltime[grep(""MIDDLE EAR EXPLORE"",alltime$CPT Desc""
</code></pre>
"
1395174,23929,2009-09-08T17:18:03Z,8,How to call R from within a web server (like Apache)?,"<p>That is, is there an embedded R interpreter available?</p>
"
1395189,NA,2009-09-08T17:21:50Z,6,Questions about missing data,"<p>In a matrix, if there is some missing data recorded as `NA.</p>

<ul>
<li>how could I delete rows with <code>NA</code> in the matrix? </li>
<li>can I use <code>na.rm</code>?</li>
</ul>
"
1395191,154039,2009-09-08T17:22:50Z,10,"How to split a data frame by rows, and then process the blocks?","<p>I have a data frame with several columns, one of which is a factor called ""site"". How can I split the data frame into blocks of rows each with a unique value of ""site"", and then process each block with a function? The data look like this:</p>

<pre><code>site year peak
ALBEN 5 101529.6
ALBEN 10 117483.4
ALBEN 20 132960.9
ALBEN 50 153251.2
ALBEN 100 168647.8
ALBEN 200 184153.6
ALBEN 500 204866.5
ALDER 5 6561.3
ALDER 10 7897.1
ALDER 20 9208.1
ALDER 50 10949.3
ALDER 100 12287.6
ALDER 200 13650.2
ALDER 500 15493.6
AMERI 5 43656.5
AMERI 10 51475.3
AMERI 20 58854.4
AMERI 50 68233.3
AMERI 100 75135.9
AMERI 200 81908.3
</code></pre>

<p>and I want to create a plot of <code>year</code> vs <code>peak</code> for each site.</p>
"
1395206,170048,2009-09-08T17:24:41Z,3,"New vector based on comparing elements of two other vectors ""lagged""?","<p>I have two vectors, <code>subject</code> and <code>target</code>. I want to create a new vector based on comparisons between the two existing vectors, with elements being compared <code>lagged</code>. I've solved this okay using the loop below, but I'm essentially wondering whether there's a more elegant solution using <code>apply</code>?</p>

<pre><code>subject &lt;- c(200,195,190,185,185,185,188,189,195,200,210,210)
target &lt;- c(subject[1],subject[1]-cumsum(rep(perweek,length(subject)-1)))
adjtarget &lt;- target                                               

for (i in 1:(length(subject)-1)) {
  if (subject[i] &gt; adjtarget[i]) {                
    adjtarget[i+1] &lt;- adjtarget[i]           
   } else {                                       
    adjtarget[i+1] &lt;- adjtarget[i]-perweek  }
   }
 }
</code></pre>
"
1395229,2002705,2009-09-08T17:28:42Z,79,Increasing (or decreasing) the memory available to R processes,"<p>I would like to increase (or decrease) the amount of memory available to R.  What are the methods for achieving this?</p>
"
1395233,143383,2009-09-08T17:29:55Z,7,Lazy evaluation of supplied arguments,"<p>Say I have the following function:</p>

<pre><code>foo &lt;- function(x, y = min(m)) {
    m &lt;- 1:10
    x + y
}
</code></pre>

<p>When I run <code>foo(1)</code>, the returned value is <code>2</code>, as expected. However, I cannot run <code>foo(1, y = max(m))</code> and receive <code>11</code>, since lazy evaluation only works for default arguments. How can I supply an argument but have it evaluate lazily?</p>
"
1395266,NA,2009-09-08T17:35:35Z,5,Calling Clojure from within R?,"<p>Is there any link between R and Clojure?</p>

<p>I am aware of <a href=""http://incanter.org/"" rel=""noreferrer"">Incanter</a>, but am ideally looking for an R package for Clojure
or any future plans for one, in order to call clojure from within R.</p>
"
1395267,170236,2009-09-08T17:35:40Z,2,Creating interactive pplets from R Output,"<p>Currently, I generate results from statistical analyses (e.g., a three dimensional plot) and then ""manually"" move it to <a href=""http://www.procesing.org"" rel=""nofollow noreferrer"">processing</a> - a graphics programming language) where I can (with some simple coding) export an interactive java applet (e.g., allow the person viewing the plot to move in, out and around the data points).  Can I keep this whole process within R?  Specifically, I want to create an applet (doesn't have to be Java but would need to be web embeddable, interactive (so not a movie) and not require the user to work in R or have to download things) that can be passed on.
Thanks.</p>
"
1395271,37751,2009-09-08T17:36:30Z,11,renaming the output column with the plyr package in R,"<p>Hadley turned me on to the <a href=""http://had.co.nz/plyr/"" rel=""noreferrer"">plyr</a> package and I find myself using it all the time to do 'group by' sort of stuff. But I find myself having to always rename the resulting columns since they default to V1, V2, etc. </p>

<p>Here's an example:</p>

<pre><code>mydata&lt;-data.frame(matrix(rnorm(144, mean=2, sd=2),72,2),c(rep(""A"",24),rep(""B"",24),rep(""C"",24)))
colnames(mydata) &lt;- c(""x_value"", ""acres"",  ""state"")
groupAcres &lt;- ddply(mydata, c(""state""), function(df)c(sum(df$acres)))
colnames(groupAcres) &lt;- c(""state"",""stateAcres"")
</code></pre>

<p>Is there a way to make ddply name the resulting column for me so I can omit that last line?</p>
"
1395284,143377,2009-09-08T17:39:12Z,5,Is it possible to break axis labels into 2 lines in base graphics?,"<p>I am trying to have the x-axis labels to be split into two lines. I would also like the labels to be rotated 45 degrees. How can I do this?</p>

<p>What I have so far:</p>

<pre><code>N &lt;- 10
dnow &lt;- data.frame(x=1:N, y=runif(N), labels=paste(""This is observation "",1:N))
with(dnow, plot(x,y, xaxt=""n"", xlab=""""))
atn &lt;- seq(1,N,3)
axis(1, at=atn, labels=labels[atn])
</code></pre>
"
1395294,2002705,2009-09-08T17:41:48Z,2,Returning a vector of attributes shared by a set of objects,"<p>I have a list of <code>lm</code> (linear model) objects.</p>

<p>How can I select a particular element (such as the intercept, rank, or residuals) from all the objects in a single call?</p>
"
1395301,23929,2009-09-08T17:42:57Z,20,How to get R to recognize your working directory as its working directory?,"<p>I use R under Windows on several machines.</p>

<p>I know you can set the working directory from within an R script, like this</p>

<pre><code>setwd(""C:/Documents and Settings/username/My Documents/x/y/z"")
</code></pre>

<p>... but then this breaks the portability of the script. It's also annoying to have to reverse all the slashes (since Windows gives you backslashes)</p>

<p>Is there a way to start R in a particular working directory so that you don't need to do this at the script level?</p>
"
1395309,154039,2009-09-08T17:44:17Z,28,How to make R use all processors?,"<p>I have a quad-core laptop running Windows XP, but looking at Task Manager R only ever seems to use one processor at a time. How can I make R use all four processors and speed up my R programs?</p>
"
1395323,136862,2009-09-08T17:47:14Z,22,Fonts in R plots,"<p>What graphics devices let me use system fonts for text within charts? The base graphics system only has a small amount of documentation around the <code>par(family=...)</code> options.</p>

<p>Ideally I'd like to be able to use any font I can browse through a tool like <code>xfontsel</code> on Linux or the equivalent utilities on other platforms.</p>

<p>My current solution is to plot out as PDF and then use a 3rd party program to replace the fonts from within the PDF. This is not ideal.</p>
"
1395391,168139,2009-09-08T17:58:44Z,4,Getting value rather than formula in RGoogleDocs,"<p>Is there an easy way to read the value of the cells rather than the formula?
By the way I only get this problem in a spreadsheet that I have published but not in spreadsheets that are private.
So for instance in a cell whose value was created by simply using the value from the cell immediately to the left in the Google spreadsheet I would prefer to get the value rather than  <code>=RC[-1]</code></p>

<p>When one exports with Google Spreadsheets as a csv then that does not happen.</p>

<p>I am using the following line of code in R</p>

<pre><code>y2009&lt;-sheetAsMatrix(ts2$y2009,header=TRUE, as.data.frame=TRUE, trim=TRUE)
</code></pre>
"
1395410,23929,2009-09-08T18:02:51Z,43,How to print R graphics to multiple pages of a PDF and multiple PDFs?,"<p>I know that </p>

<pre><code> pdf(""myOut.pdf"")
</code></pre>

<p>will print to a PDF in R. What if I want to</p>

<ol>
<li><p>Make a loop that prints subsequent graphs on new pages of a PDF file (appending to the end)?</p></li>
<li><p>Make a loop that prints subsequent graphs to new PDF files (one graph per file)?</p></li>
</ol>
"
1395499,163053,2009-09-08T18:22:43Z,3,POSIXct times around DST?,"<p>I want to subtract 1 day from a POSIX date and end up at the same time around DST.  </p>

<p>For example, when I add a day:</p>

<pre><code>&gt; as.POSIXct('2009-03-08 23:00:00.000') + 86400
[1] ""2009-03-09 23:00:00 EDT""
</code></pre>

<p>But when I go past, it offsets:</p>

<pre><code>&gt; as.POSIXct('2009-03-08 23:00:00.000') - 86400
[1] ""2009-03-07 22:00:00 EST""
</code></pre>

<p>What's the best way to deal with absolute time differences around DST?  Usually I deal with this by converting the times into strings and dealing with them separately so that DST isn't applied.</p>
"
1395504,2002705,2009-09-08T18:23:42Z,0,Reading binary data of indeterminate length in R,"<p>I would like to read a binary file -- of indeterminate length -- directly from a URL in R.  Using <code>readBin</code> to read from a URL, without specifying the file size, does not work.</p>

<pre><code> anImage &lt;- readBin('http://user2010.org/pics/useR-large.png','raw')
</code></pre>

<p>Is there another approach that would allow this?</p>
"
1395517,152860,2009-09-08T18:26:02Z,3,Aspect oriented programming in r: Any libraries available?,"<p>Are there any R-project packages that implement AOP?  Or even better an example of an R package that uses any such AOP library.</p>
"
1395528,143377,2009-09-08T18:27:33Z,120,Scraping html tables into R data frames using the XML package,"<p>How do I scrape html tables using the XML package?</p>

<p>Take, for example, this wikipedia page on the <a href=""http://en.wikipedia.org/wiki/Brazil_national_football_team"" rel=""noreferrer"">Brazilian soccer team</a>. I would like to read it in R and get the ""list of all matches Brazil have played against FIFA recognised teams"" table as a data.frame. How can I do this?</p>
"
1395577,NA,2009-09-08T18:35:11Z,19,How do I set what plot() labels the x-axis with?,"<p>I have a plot() that I'm trying to make, but I do not want the x-values to be used as the axis labels...I want a different character vector that I want to use as labels, in the standard way: Use as many as will fit, drop the others, etc. What should I pass to plot() to make this happen?</p>

<p>For example, consider</p>

<pre><code>d &lt;- data.frame(x=1:5,y=10:15,x.names=c('a','b','c','d','e'))
</code></pre>

<p>In barplot, I would pass <code>barplot(height=d$y,names.arg=d$x.names)</code>, but in this case the actual x-values are important. So I would like an analog such as <code>plot(x=d$x,y=d$y,type='l',names.arg=d$x.names)</code>, but that does not work.</p>
"
1395622,143377,2009-09-08T18:42:36Z,27,Debugging lapply/sapply calls,"<p>Code written using lapply and friends is usually easier on the eyes and more Rish than loops.  I love lapply just as much as the next guy, but how do I debug it when things go wrong? For example:</p>

<pre><code>&gt; ## a list composed of numeric elements 
&gt; x &lt;- as.list(-2:2)
&gt; ## turn one of the elements into characters
&gt; x[[2]] &lt;- ""what?!?""
&gt; 
&gt; ## using sapply
&gt; sapply(x, function(x) 1/x)
Error in 1/x : non-numeric argument to binary operator
</code></pre>

<p>Had I used a  for loop:</p>

<pre><code>&gt; y &lt;- rep(NA, length(x))
&gt; for (i in 1:length(x)) {
+     y[i] &lt;-  1/x[[i]]
+ }
Error in 1/x[[i]] : non-numeric argument to binary operator
</code></pre>

<p>But I would know where the error happened:</p>

<pre><code>&gt; i
[1] 2
</code></pre>

<p>What should I do when using lapply/sapply?</p>
"
1395945,NA,2009-09-08T19:46:48Z,10,How to change color of scatterplot in ggplot2,"<p>In ggplot2, how could I change the color of coloring in scatter plot?</p>
"
1397823,70702,2009-09-09T06:17:53Z,9,plotting points on top of image in R,"<p>These days I am extensively using R to scatter plots.
Most of the plotting is concerned with image processing,
Recently I was thinking of plotting the scatter plots over an image. </p>

<p>For example, I want something like this,
The background needs to be filled with my image. With a particular scale.
And I should be able to draw points (co-ordinates) on top of this image ...</p>

<p>Is this possible in R?
If not, do you guys know of any other tool that makes this easy ...</p>
"
1399217,170792,2009-09-09T11:50:56Z,2,Changing annotations in time series plots in R,"<p>While I can change annotations with the generic plot command turning off axes and 
annotations and specifying them again using the axis command e.g.</p>

<pre><code>cars &lt;- c(1, 3, 6, 4, 9)

plot(cars, type=""o"", col=""blue"", ylim=range(0, cars), axes=FALSE, ann=FALSE)  
axis(1, at=1:5, lab=c(""Mon"",""Tue"",""Wed"",""Thu"",""Fri""))
</code></pre>

<p>I cant do it with time series object e.g.</p>

<pre><code>www &lt;- ""http://www.massey.ac.nz/~pscowper/ts/Maine.dat""  
Maine.month &lt;- read.table(www, header = TRUE)  
attach(Maine.month)  
Maine.month.ts &lt;- ts(unemploy, start = c(1996, 1), freq = 12)  
Maine.98 &lt;- window(Maine.month.ts, start = c(1998,1), end = c(1998,11))
</code></pre>

<p>How can I plot <code>Maine.98</code> with annotations looking like:</p>

<pre><code>""Jan-98""   ""Feb-98""   ""Mar-98""   ""Apr-98""   ""May-98""  etc?
</code></pre>
"
1400937,168168,2009-09-09T17:19:44Z,9,More than 9 backreferences in gsub(),"<p>How to use gsub with more than 9 backreferences? 
I would expect the output in the example below to be ""e, g, i, j, o"".</p>

<pre><code>&gt; test &lt;- ""abcdefghijklmnop""
&gt; gsub(""(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)"", ""\\5, \\7, \\9, \\10, \\15"", test, perl = TRUE)
[1] ""e, g, i, a0, a5""
</code></pre>
"
1401872,153440,2009-09-09T20:22:22Z,5,On the issue of automatic time series fitting using R,"<p>we have to fit about 2000 or odd time series every month,
they have very idiosyncratic behavior in particular, some are arma/arima, some are ewma, some are arch/garch with or without seasonality and/or trend (only thing in common is the time series aspect).</p>

<p>one can in theory build ensemble model with aic or bic criterion to choose the best fit model but is the community aware of any library which attempts to solve this problem?</p>

<p>Google made me aware of the below one by Rob J Hyndman
<a href=""http://robjhyndman.com/software/forecast"" rel=""nofollow noreferrer"">link</a></p>

<p>but are they any other alternatives? </p>
"
1401894,74658,2009-09-09T20:27:39Z,5,Calculate within and between variances and confidence intervals in R,"<p>I need to calculate the within and between run variances from some data as part of developing a new analytical chemistry method.  I also need confidence intervals from this data using the R language</p>

<p>I assume I need to use anova or something ?</p>

<p>My data is like</p>

<pre><code>&gt; variance
   Run Rep Value
1    1   1  9.85
2    1   2  9.95
3    1   3 10.00
4    2   1  9.90
5    2   2  8.80
6    2   3  9.50
7    3   1 11.20
8    3   2 11.10
9    3   3  9.80
10   4   1  9.70
11   4   2 10.10
12   4   3 10.00
</code></pre>
"
1401904,163053,2009-09-09T20:29:11Z,120,Painless way to install a new version of R?,"<p><a href=""http://www.stat.columbia.edu/~cook/movabletype/archives/2009/08/upgrading_r.html"" rel=""noreferrer"">Andrew Gelman recently lamented the lack of an easy upgrade process for R</a> (probably more relevant on Windows than Linux).  Does anyone have a good trick for doing the upgrade, from installing the software to copying all the settings/packages over?</p>

<p>This suggestion was contained in the comments and is what I've been using recently.  First you install the new version, then run this in the old verion:</p>

<pre><code>#--run in the old version of R
setwd(""C:/Temp/"")
packages &lt;- installed.packages()[,""Package""]
save(packages, file=""Rpackages"")
</code></pre>

<p>Followed by this in the new version:</p>

<pre><code>#--run in the new version
setwd(""C:/Temp/"")
load(""Rpackages"")
for (p in setdiff(packages, installed.packages()[,""Package""]))
install.packages(p)
</code></pre>
"
1402001,168542,2009-09-09T20:48:08Z,6,MS-SQL Bulk Insert with RODBC,"<p>Is it possible to perform a bulk insert into an MS-SQL Server (2000, 2005, 2008) using the RODBC package?</p>

<p>I know that I can do this using freebcp, but I'm curious if the RODBC package implements this portion of the Microsoft SQL API and if not, how difficult it would be to implement it.</p>
"
1402634,162832,2009-09-09T23:15:13Z,8,Choose variables based on name (simple regular expression),"<p>I would like to incorporate variable names that imply what I should do with them. I imagine a dataframe ""survey"".</p>

<pre><code>library(Rlab) # Needed for rbern() function.
survey &lt;- data.frame(cbind(  
id = seq(1:10),  
likert_this = sample(seq(1:7),10, replace=T),  
likert_that = sample(seq(1:7), 10, replace=T),  
dim_bern_varx = rbern(10, 0.6),  
disc_1 = sample(letters[1:5],10,replace=T)))
</code></pre>

<p>Now I would like to do certain things with all variables that contain <em>likert</em>, other things with variables that contain <em>bern</em> etc. </p>

<p>How can this be done in R?</p>
"
1403355,70702,2009-09-10T04:29:43Z,0,Real time data exchange between R and Windows application,"<p>I am using R for scatter plots, and now also for 3D cloud plots on top of an image.
I have an application that generates a lot of such 3D coordinates and I need to see those coordinates on top of the image at run-time (for debugging purposes).</p>

<p>Is it possible for my Windows application to communicate to R at run-time?</p>
"
1405571,168168,2009-09-10T14:21:45Z,13,How to assign output of cat to an object?,"<p>How would it be possible in the example below to skip the step of writing to file ""test.txt"", i.e. assign the cat-result to an object, and still achieve the same end result?</p>

<p>I thought I'd include the full example to give background to my problem.</p>

<pre><code>test &lt;- c(""V 1"", ""x"", ""1 2 3"", ""y"", ""3 5 8"", ""V 2"", ""x"", ""y"", ""V 3"", ""y"", ""7 2 1"", ""V 4"", ""x"", ""9 3 7"", ""y"")

# Write selection to file
cat(test, ""\n"", file=""test.txt"")
test2 &lt;- readLines(""test.txt"")
test3 &lt;- strsplit(test2, ""V "")[[1]][-1]

# Find results
x &lt;- gsub(""([0-9]) (?:x )?([0-9] [0-9] [0-9])?.*"", ""\\1 \\2 "", test3, perl = TRUE)
y &lt;- gsub(""([0-9]).* y ?([0-9] [0-9] [0-9])?.*"", ""\\1 \\2 "", test3, perl = TRUE)

# Eliminate tests with no results
x1 &lt;- x[regexpr(""[0-9] ([^0-9]).*"", x) == -1]
y1 &lt;- y[regexpr(""[0-9] ([^0-9]).*"", y) == -1]

# Dataframe of results
xdf1 &lt;- read.table(textConnection(x1), col.names=c(""id"",""x1"",""x2"",""x3""))
ydf1 &lt;- read.table(textConnection(y1), col.names=c(""id"",""y1"",""y2"",""y3""))
closeAllConnections()

# Dataframe of tests with no results
x2 &lt;- x[regexpr(""[0-9] ([^0-9]).*"", x) == 1]
y2 &lt;- y[regexpr(""[0-9] ([^0-9]).*"", y) == 1]

df1 &lt;- as.integer(x2[x2 == y2])
df1 &lt;- data.frame(id = df1)

# Merge dataframes
results &lt;- merge(xdf1, ydf1, all = TRUE)
results &lt;- merge(results, df1, all = TRUE)
results
</code></pre>

<p>Results in:</p>

<pre><code>  id x1 x2 x3 y1 y2 y3
1  1  1  2  3  3  5  8
2  2 NA NA NA NA NA NA
3  3 NA NA NA  7  2  1
4  4  9  3  7 NA NA NA
</code></pre>
"
1406202,37751,2009-09-10T16:05:10Z,9,Plotting a wireframe AND a cloud with lattice in R,"<p>I have a nice surface that represents nonlinear multi-part regression results on a regression with two independent variables. I would like to plot the regression predicted values as a nice 3D surface and then show the actual values as point that bounce around the surface. This would be the 3D version of plotting a regression line and showing the actuals as points around the line. I can't figure out how to do this with lattice. I'm happy to use another graphing library in R, but I don't know of others that do 3D plots. </p>

<p>Here's a simplified version of what I want to do:</p>

<pre><code>library(lattice)
#set up some simplified data
x &lt;- seq(-.8, .8, .1)
y &lt;- seq(-.8, .8, .1)
myGrid &lt;- data.frame(expand.grid(x,y))
colnames(myGrid) &lt;- c(""x"",""y"")
myGrid$z &lt;- myGrid$x + myGrid$y
noise &lt;- rnorm(length(myGrid$z),.3,.2)
myGrid$z2 &lt;- myGrid$x + myGrid$y + noise
</code></pre>

<p>z is my smooth surface and z2 are my noisy points mostly slightly above the surface. So the surface looks like this:</p>

<pre><code>wireframe(myGrid$z ~ myGrid$x * myGrid$y, xlab=""X"", ylab=""Y"", zlab=""Z"")
</code></pre>

<p><a href=""http://www.cerebralmastication.com/wp-content/uploads/2009/09/wireframe.png"" rel=""noreferrer"">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/09/wireframe.png</a></p>

<p>and the cloud of points looks like this:</p>

<pre><code>cloud(myGrid$z2 ~ myGrid$x * myGrid$y, xlab=""X"", ylab=""Y"", zlab=""Z"")
</code></pre>

<p><a href=""http://www.cerebralmastication.com/wp-content/uploads/2009/09/cloud.png"" rel=""noreferrer"">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/09/cloud.png</a></p>

<p>Is it possible to get both of these in one lattice panel?</p>
"
1407238,168139,2009-09-10T19:29:01Z,5,Relief from backslash irritation in R for Windows,"<p>Early in my R life I discovered the pain of R and windows being on different pages when it came to the separator between directories and subdirectories. Eventhough I know about the problem, I am still pained by manually having to put a backslash in front of all my backslashes or replacing all of them with forward slashes. </p>

<p>I love copying a path name or an entire filename with any one of several applications that I have running on my computer (eg. XYPlorer, Everything by voidtools) and then pasting it into Tinn-R. Is there anyway that I could automate the task that I am currently doing manually.</p>

<ul>
<li>Is there a setting in Tinn-R?</li>
<li>Is there a setting in R?</li>
<li>Is there a autohotkey script that could do it for me by default?</li>
</ul>

<hr>

<p>Background for those who don't know what I am talking about</p>

<p>Quoting from R for Windows FAQ, Version for R-2.9.2, B. D. Ripley and D. J. Murdoch</p>

<blockquote>
  <p>Backslashes have to be doubled in R
  character strings, so for example one
  needs
  `""d:\R-2.9.2\library\xgobi\scripts\xgobi.bat""'.
  You can make life easier for yourself
  by using forward slashes as path
  separators: they do work under Windows</p>
</blockquote>
"
1407449,162832,2009-09-10T20:09:55Z,13,for each group summarise means for all variables in dataframe (ddply? split?),"<p>A week ago I would have done this  manually: subset dataframe by group to new dataframes. For each dataframe compute means for each variables, then rbind. very clunky ... </p>

<p>Now i have learned about <code>split</code> and <code>plyr</code>, and I guess there must be an easier way using these tools. Please don't prove me wrong.</p>

<pre><code>test_data &lt;- data.frame(cbind(
var0 = rnorm(100),
var1 = rnorm(100,1),
var2 = rnorm(100,2),
var3 = rnorm(100,3),
var4 = rnorm(100,4),
group = sample(letters[1:10],100,replace=T),
year = sample(c(2007,2009),100, replace=T)))

test_data$var1 &lt;- as.numeric(as.character(test_data$var1))
test_data$var2 &lt;- as.numeric(as.character(test_data$var2))
test_data$var3 &lt;- as.numeric(as.character(test_data$var3))
test_data$var4 &lt;- as.numeric(as.character(test_data$var4))
</code></pre>

<p>I am toying with both <code>ddply</code> but I can't produce what I desire - i.e. a table like this, for each group</p>

<pre><code>group a |2007|2009|
________|____|____|
var1    | xx | xx |
var2    | xx | xx |
etc.    | etc| ect|
</code></pre>

<p>maybe <code>d_ply</code> and some <code>odfweave</code> output would work to. Inputs are very much appreciated.</p>

<p>p.s. I notice that data.frame converts the rnorm to factors in my data.frame? how can I avoid this - I(rnorm(100) doesn't work so I have to convert to numerics as done above</p>
"
1407647,NA,2009-09-10T20:49:30Z,15,Reading text files using read.table in R,"<p>I have a text file with an <code>id</code> and <code>name</code> column, and I'm trying to read it into a data frame in R:</p>

<pre><code>d = read.table(""foobar.txt"", sep=""\t"")
</code></pre>

<p>But for some reason, a lot of lines get merged -- e.g., in row 500 of my data frame, I'll see something like</p>

<pre><code>row 500: 500 Bob\n501\tChris\n502\tGrace
</code></pre>

<p>[So if my original text file has, say, 5000 lines, the dimensions of my table will only end up being 1000 rows and 2 columns.]</p>

<p>I've had this happen to me quite a few times. Does anyone know what the problem is, or how to fix it?</p>
"
1407680,74658,2009-09-10T20:57:57Z,4,How can I produce report quality tables from R?,"<p>If I have the following dataframe called result</p>

<pre><code>&gt; result
     Name       CV      LCB       UCB
1  within 2.768443 1.869964  5.303702
2 between 4.733483 2.123816 18.551051
3   total 5.483625 3.590745 18.772389

&gt; dput(result,"""")
structure(list(Name = structure(c(""within"", ""between"", ""total""
), .rk.invalid.fields = list(), .Label = character(0)), CV = c(2.768443, 
4.733483, 5.483625), LCB = c(1.869964, 2.123816, 3.590745), UCB = c(5.303702, 
18.551051, 18.772389)), .Names = c(""Name"", ""CV"", ""LCB"", ""UCB""
), row.names = c(NA, 3L), class = ""data.frame"")
</code></pre>

<p>What is the best way to present this data nicely?  Ideally I'd like an image file that can be pasted into a report, or possibly an HTML file to represent the table?</p>

<p>Extra points for setting number of significant figures.</p>
"
1408897,NA,2009-09-11T03:56:24Z,8,Connecting GNU R to PostgreSQL,"<p>I have <code>GNU R</code> installed (the <code>S-like</code> statistics package; version 2.8.1) and <code>PostgreSQL (8.4.1)</code>, but I cannot connect <code>GNU R</code> to my <code>RDBMS</code>.</p>

<p>When I first did this (years ago - code lost) <code>DBI</code> for <code>R</code> didn't exist. Now it does. I am also confused as to which <code>R</code> package to use. A quick search returns:</p>

<ul>
<li><a href=""http://cran.r-project.org/web/packages/RPostgreSQL/"" rel=""nofollow noreferrer"">RPostgreSQL</a> seems to be the most up-to-date</li>
<li><code>RPgSQL</code> Looks abandoned. I wish they would put a date on their webpage. ;-(</li>
</ul>

<p>My <code>Linux distribution</code> doesn't package <code>R</code> packages (irony) but I am comfortable running <code>R CMD INSTALL package.tar.gz</code>. </p>

<p>I installed <code>RPostgreSQL</code>: a lot of documentation says to call <code>dbConnect</code> but I get the following error message: <code>Error: object ""dbConnect"" not found</code>.</p>
"
1411599,143319,2009-09-11T15:23:57Z,2,Bull's-eye charts,"<p>A colleague of mine needs to plot 101 bull's-eye charts.  This is not her idea.  Rather than have her slave away in Excel or God knows what making these things, I offered to do them in R; mapping a bar plot to polar coordinates to make a bull's-eye is a breeze in <code>ggplot2</code>.</p>

<p>I'm running into a problem, however: the data is already aggregated, so Hadley's example <a href=""http://had.co.nz/ggplot2/coord_polar.html"" rel=""nofollow noreferrer"">here</a> isn't working for me.  I could expand the counts out into a factor to do this, but I feel like there's a better way - some way to tell the geom_bar how to read the data.</p>

<p>The data looks like this:</p>

<pre><code>    Zoo Animals Bears Polar Bears
1 Omaha      50    10           3
</code></pre>

<p>I'll be making a plot for each zoo - but that part I can manage.</p>

<p>and here's its <code>dput</code>:</p>

<pre><code>structure(list(Zoo = ""Omaha"", Animals = ""50"", Bears = ""10"", `Polar Bears` = ""3""), .Names = c(""Zoo"", 
""Animals"", ""Bears"", ""Polar Bears""), row.names = c(NA, -1L), class = ""data.frame"")
</code></pre>

<p>Note: it is significant that Animals >= Bears >= Polar Bears.  Also, she's out of town, so I can't just get the raw data from her (if there was ever a big file, anyway).</p>
"
1412473,172208,2009-09-11T18:11:14Z,0,Unit of Analysis Conversion,"<p>We are working on a social capital project so our data set has a list of an individual's organizational memberships. So each person gets a numeric ID and then a sub ID for each group they are in. The unit of analysis, therefore, is the group they are in. One of our variables is a three point scale for the type of group it is. Sounds simple enough?</p>

<p>We want to bring the unit of analysis to the individual level and condense the type of group it is into a variable signifying how many different types of groups they are in.</p>

<p>For instance, person one is in eight groups. Of those groups, three are (1s), three are (2s), and two are (3s). What the individual level variable would look like, ideally, is 3, because she is in all three types of groups.</p>

<p>Is this possible in the least?</p>
"
1412582,84458,2009-09-11T18:32:31Z,16,Getting the state of variables after an error occurs in R,"<p>Let's say I have just called a function, <code>f</code>, and an error occurred somewhere in the function.  I just want to be able to check out the values of different variables right before the error occurred.  </p>

<p>Suppose my gut tells me it's a small bug, so I'm too lazy to use <code>debug(f)</code> and too lazy to insert <code>browser()</code> into the part of the function where I think things are going wrong.  And I'm far too lazy to start putting in <code>print()</code> statements.</p>

<p>Here's an example:</p>

<pre><code>x &lt;- 1:5
y &lt;- x + rnorm(length(x),0,1)
f &lt;- function(x,y) {
  y &lt;- c(y,1)
  lm(y~x)
}
</code></pre>

<p>Calling <code>f(x,y)</code> we get the following error:</p>

<pre><code>Error in model.frame.default(formula = y ~ x, drop.unused.levels = TRUE) : 
  variable lengths differ (found for 'x')
</code></pre>

<p>In this example, I want grab the state of the environment just before <code>lm()</code> is called; that way I can call <code>x</code> and <code>y</code> and see that their lengths are different.  (This example may be too simple, but I hope it gets the idea across.)</p>
"
1412775,168139,2009-09-11T19:11:41Z,2,pmax (parallel maximum) equivalent for rank in R,"<p>If one has 4 judges and they each give a score for a particular performer or a particular topic then one could have 4 vectors with each containing the score.
But one would like to turn that into a rank to overcome grade inflation by one judge compared to another.
that is easy</p>

<pre><code>transform(assignment,judge1.rank=rank(judge1),judge2.rank=rank(judge2),
                     judge3.rank=rank(judge3), judge4.rank=rank(judge4))
</code></pre>

<p>But then for each row (performer or topic) I want another four columns that for each row states the rank of ranks (or parallel rank) for each judge.</p>

<p>I would like to do something such as</p>

<pre><code>prank(judge1.rank,judge2.rank,judge3.rank,judge4.rank)
</code></pre>

<p>I guess it would have to output as a dataframe.</p>

<p>I thought of using the reshape package to melt the data but that is just a preliminary thought.</p>
"
1413697,147537,2009-09-11T23:23:52Z,2,How do you write a CSV in R with the matrix names (dimnames(M)) intact in R?,"<p>Is there a command in R that will allow you to write a CSV file that has the row and column names of a matrix (dimnames(M))? Whenever I output the file, the names are gone. </p>

<pre><code>help(write)
</code></pre>

<p>doesn't mention that this is possible to do. </p>
"
1413853,84458,2009-09-12T00:28:22Z,4,Emacs ESS: Eval region vs. source(),"<p>I love the Emacs ESS combination.  I love sending lines, functions, regions, and buffers of code to the command line for evaluation without using the mouse.  </p>

<p>However, I've noticed that the <code>Eval Function</code> command in Emacs is much slower than simply running <code>source(""fns.R"")</code>, where <code>fns.R</code> is the file that contains the function I want to evaluate.</p>

<p>Why is this the case?</p>
"
1417269,162832,2009-09-13T09:10:08Z,1,How to source file.R without output,"<p>Is it possible to source a file without printing all the charts etc (already tried with echo=F)? </p>

<p>In my case I call the png(""filename%03d.png"") device early in the script. It is not to big a hassle to comment this out - but all the charts do take a lot of time to render. (the specific file I am working with now uses base-graphics - but mostly I'll be using ggplot2 - which makes the issue somewhat more important (ggplot2 is excellent, but in the current implementation not the fastest))</p>

<p>Thanks</p>
"
1419136,NA,2009-09-13T23:42:28Z,3,Automating multiple variable withdrawal from an object,"<p>Here's my situation. I have an object that I've created using <code>read.spss</code>.</p>

<pre><code>&gt; a &lt;- read.spss(...)
&gt; attach(a)
</code></pre>

<p>Now in this object <code>a</code> is a set questions that I would like to pull out that follows a sequence of question numbers:</p>

<pre><code>&gt; q3 &lt;- data.frame(q3_1, q3_2, q3_4, ... q3_27)
</code></pre>

<p>Is there a way to automate it such that it pulls out all questions starting with <code>q3_</code> from the original object into the new <code>q3 data.frame</code>?</p>

<p>I've tried using the <code>paste</code> function to no avail.</p>

<pre><code>&gt; q3 &lt;- data.frame(paste(""q3_"",1:27,sep=""""))
</code></pre>

<p>That just returns a <code>data.frame</code> with the pasted sequence. </p>

<p>Ideally, I would like something that pulls in everything from a question beginning with a <code>qX_</code>, as some values are missing or outdated. </p>
"
1419526,169462,2009-09-14T03:12:33Z,2,Difference of binomial parameters in R,"<p>I have two random variables:</p>

<pre><code>X ~ binom(n, p1)
Y ~ binom(n, p2)
</code></pre>

<p>n is a known parameter (the total number of trials), while p1 and p2 are unknown.</p>

<p>I have one sample from each distribution (x from X, and y from Y). To give some context, x and y are numbers of true positives from two different classifiers, at a fixed selectivity.</p>

<p>I would like to use R to test the null hypothesis p1=p2 against p1 > p2.</p>

<p>In particular, I would like to be able to find the p-value P(X-Y=x-y | p1=p2), and if possible, a confidence interval for the difference between p1 and p2.</p>

<p>What is the best way to go about this?</p>
"
1422247,37751,2009-09-14T15:22:22Z,6,Generate stochastic random deviates from a density object with R,"<p>I have a density object dd created like this:</p>

<pre><code>x1 &lt;- rnorm(1000) 
x2 &lt;- rnorm(1000, 3, 2) 
x &lt;- rbind(x1, x2)
dd &lt;- density(x) 
plot(dd)
</code></pre>

<p>Which produces this very non-Gaussian distribution:</p>

<p><a href=""http://www.cerebralmastication.com/wp-content/uploads/2009/09/nongaus.png"" rel=""nofollow noreferrer"">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/09/nongaus.png</a></p>

<p>I would ultimately like to get random deviates from this distribution similar to how rnorm gets deviates from a normal distribution. </p>

<p>The way I am trying to crack this is to get the CDF of my kernel and then get it to tell me the variate if I pass it a cumulative probability (inverse CDF). That way I can turn a vector of uniform random variates into draws from the density. </p>

<p>It seems like what I am trying to do should be something basic that others have done before me. Is there a simple way or a simple function to do this? I hate reinventing the wheel. </p>

<p>FWIW I found <a href=""http://tolstoy.newcastle.edu.au/R/help/01a/1957.html"" rel=""nofollow noreferrer"">this R Help article</a> but I can't grok what they are doing and the final output does not seem to produce what I am after. But it could be a step along the way that I just don't understand. </p>

<p>I've considered just going with a <a href=""http://hosho.ees.hokudai.ac.jp/~kubo/Rdoc/library/SuppDists/html/Johnson.html"" rel=""nofollow noreferrer"">Johnson distribution from the suppdists package</a> but Johnson won't give me the nice bimodal hump which my data has. </p>
"
1422987,173292,2009-09-14T17:51:00Z,43,Emacs mode for R?,"<p>Is there a mode in emacs that does syntax highlighting for the R programming language? R-mode doesn't seem to work...</p>
"
1423472,74658,2009-09-14T19:34:26Z,3,Best way to extract Mean Square Values from aov object in r,"<p>I'm trying to write a function to automate doing a variance analysis, part of which involves doing some further calculations.  The method I've been using isn't very robust, if variable names change then it stops working.</p>

<p>For this dummy data</p>

<pre><code>&gt; dput(assayvar,"""")
structure(list(Run = structure(c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 
3L, 3L, 4L, 4L, 4L), .rk.invalid.fields = list(), .Label = c(""1"", 
""2"", ""3"", ""4""), class = ""factor""), Actual = c(246.3, 253.6, 247.6, 
249, 249, 251.3, 254.9, 254.1, 253.2, 250, 248.9, 250.3)), .Names = c(""Run"", 
""Actual""), row.names = c(NA, 12L), class = ""data.frame"")

&gt; assayaov&lt;-aov(Actual~Run+Error(Run),data=assayvar)
&gt; str(summary(assayaov))
List of 2
 $ Error: Run   :List of 1
  ..$ :Classes ‘anova’ and 'data.frame':    1 obs. of  3 variables:
  .. ..$ Df     : num 3
  .. ..$ Sum Sq : num 46.5
  .. ..$ Mean Sq: num 15.5
  ..- attr(*, ""class"")= chr [1:2] ""summary.aov"" ""listof""
 $ Error: Within:List of 1
  ..$ :Classes ‘anova’ and 'data.frame':    1 obs. of  5 variables:
  .. ..$ Df     : num 8
  .. ..$ Sum Sq : num 36.4
  .. ..$ Mean Sq: num 4.55
  .. ..$ F value: num NA
  .. ..$ Pr(&gt;F) : num NA
  ..- attr(*, ""class"")= chr [1:2] ""summary.aov"" ""listof""
 - attr(*, ""class"")= chr ""summary.aovlist""
</code></pre>

<p>But for this dummy data</p>

<pre><code>&gt; dput(BGBottles,"""")
structure(list(Machine = structure(c(1L, 1L, 1L, 2L, 2L, 2L, 
3L, 3L, 3L, 4L, 4L, 4L), .rk.invalid.fields = structure(list(), .Names = character(0)), .Label = c(""1"", 
""2"", ""3"", ""4""), class = ""factor""), Weight = c(14.23, 14.96, 14.85, 
16.46, 16.74, 15.94, 14.98, 14.88, 14.87, 15.94, 16.07, 14.91
)), .Names = c(""Machine"", ""Weight""), row.names = c(NA, 12L), class = ""data.frame"")

&gt; bgaov&lt;-aov(Weight~Machine+Error(Machine),data=BGBottles)
&gt; str(summary(bgaov))
List of 2
 $ Error: Machine:List of 1
  ..$ :Classes ‘anova’ and 'data.frame':    1 obs. of  3 variables:
  .. ..$ Df     : num 3
  .. ..$ Sum Sq : num 5.33
  .. ..$ Mean Sq: num 1.78
  ..- attr(*, ""class"")= chr [1:2] ""summary.aov"" ""listof""
 $ Error: Within :List of 1
  ..$ :Classes ‘anova’ and 'data.frame':    1 obs. of  5 variables:
  .. ..$ Df     : num 8
  .. ..$ Sum Sq : num 1.45
  .. ..$ Mean Sq: num 0.182
  .. ..$ F value: num NA
  .. ..$ Pr(&gt;F) : num NA
  ..- attr(*, ""class"")= chr [1:2] ""summary.aov"" ""listof""
 - attr(*, ""class"")= chr ""summary.aovlist""
</code></pre>

<p>So the code to get the mean square value</p>

<pre><code>machine&lt;-summary(bgaov)$""Error: Machine""[[1]]$""Mean Sq""
</code></pre>

<p>Doesn't work, because the Machine but won't always be Machine.</p>

<p>Any better way to do this ?</p>
"
1423902,NA,2009-09-14T21:01:29Z,0,How to use foreach with snow for multicore in Windows XP?,"<p>Could you please give an example on how that might be done using the doSNOW ?</p>

<p>(I asked the same question <a href=""http://blog.revolution-computing.com/2009/08/parallel-programming-with-foreach-and-snow.html"" rel=""nofollow noreferrer"">here</a>, but only got a partial reply)
Tal</p>
"
1424189,143319,2009-09-14T22:18:53Z,6,More bullseye plotting in R,"<p>I'm using ggplot2 to make some bullseye charts in R.  They look delightful, and everyone is very pleased - except that they'd like to have the values of the bullseye layers plotted on the chart.  I'd be happy just to put them in the lower-right corner of the plot, or even in the plot margins, but I'm having some difficulty doing this.</p>

<p>Here's the example data again:</p>

<pre><code>critters &lt;- structure(list(Zoo = ""Omaha"", Animals = 50, Bears = 10, PolarBears = 3), .Names = c(""Zoo"", 
""Animals"", ""Bears"", ""PolarBears""), row.names = c(NA, -1L), class = ""data.frame"")
</code></pre>

<p>And how to plot it:</p>

<pre><code>d &lt;- data.frame(animal=factor(c(rep(""Animals"", critters$Animals),
       rep(""Bears"", critters$Bears), rep(""PolarBears"", critters$PolarBears)),
       levels = c(""PolarBears"", ""Bears"", ""Animals""), ordered= TRUE))
grr &lt;- ggplot(d, aes(x = factor(1), fill = factor(animal))) +  geom_bar() +
  coord_polar() + labs(x = NULL, fill = NULL) +
  scale_fill_manual(values = c(""firebrick2"", ""yellow2"", ""green3"")) +
  opts(title = paste(""Animals, Bears and Polar Bears:\nOmaha Zoo"", sep=""""))
</code></pre>

<p>I'd like to add a list to, say, the lower right corner of this plot saying,</p>

<pre><code>Animals: 50
Bears: 10
PolarBears: 3
</code></pre>

<p>But I can't figure out how.  My efforts so far with <code>annotate()</code> have been thwarted, in part by the polar coordinates.  If I have to add the numbers to the title, so be it - but I always hold out hope for a more elegant solution.  Thanks in advance.</p>

<p>EDIT:
An important note for those who come after: the bullseye is a bar plot mapped to polar coordinates.  The ggplot2 default for bar plots is, sensibly, to stack them.  However, that means that the rings of your bullseye will also be stacked (e.g. the radius in my example equals the sum of all three groups, 63, instead of the size of the largest group, 50).  I <strong>don't</strong> think that's what most people expect from a bullseye plot, especially when the groups are nested.  Using <code>geom_bar(position = position_identity())</code> will turn the stacked rings into layered circles.</p>

<p>EDIT 2: Example from <a href=""http://docs.ggplot2.org/current/coord_polar.html"" rel=""nofollow noreferrer"">ggplot2</a> docs:<br>
<img src=""https://i.stack.imgur.com/yL4zi.png"" alt=""enter image description here""></p>
"
1424351,165384,2009-09-14T23:15:22Z,5,Expanding short names for non 8dot3 directory paths to long name,"<p>In <code>R</code> on <code>Windows</code>, <code>tempdir()</code> returns a path that contains short names for <code>non 8dot3 directory names</code>. </p>

<p>How do I expand those to long names? </p>

<p>An answer that uses pure <code>R</code> code is favorable, but one that uses well-known shell commands used via <code>system()</code> is fine as a backup.</p>
"
1428174,136862,2009-09-15T16:20:45Z,6,Quickly generate the cartesian product of a matrix,"<p>Let's say I have a matrix <code>x</code> which contains 10 rows and 2 columns. I want to generate a new matrix <code>M</code> that contains each unique pair of rows from <code>x</code> - that is, a new matrix with 55 rows and 4 columns.</p>

<p>E.g.,</p>

<pre><code>x &lt;- matrix (nrow=10, ncol=2, 1:20)

M &lt;- data.frame(matrix(ncol=4, nrow=55))
k &lt;- 1
for (i in 1:nrow(x))
for (j in i:nrow(x))
{
    M[k,] &lt;- unlist(cbind (x[i,], x[j,]))
    k &lt;- k + 1
}
</code></pre>

<p>So, <code>x</code> is:</p>

<pre><code>      [,1] [,2]
 [1,]    1   11
 [2,]    2   12
 [3,]    3   13
 [4,]    4   14
 [5,]    5   15
 [6,]    6   16
 [7,]    7   17
 [8,]    8   18
 [9,]    9   19
[10,]   10   20
</code></pre>

<p>And then <code>M</code> has 4 columns, the first two are one row from <code>x</code> and the next 2 are another row from <code>x</code>:</p>

<pre><code>&gt; head(M,10)
   X1 X2 X3 X4
1   1 11  1 11
2   1 11  2 12
3   1 11  3 13
4   1 11  4 14
5   1 11  5 15
6   1 11  6 16
7   1 11  7 17
8   1 11  8 18
9   1 11  9 19
10  1 11 10 20
</code></pre>

<p>Is there either a faster or simpler (or both) way of doing this in R?</p>
"
1428750,143476,2009-09-15T18:02:24Z,8,Force stop or halt on error,"<p>I was wondering if anyone knew of a good way to get R or ESS to stop executing the rest of the code beyond the point at which an error occurs if I am evaluating a region or buffer (I've only found the opposite request in the help archives). I was looking in the R help files but <code>option(error=stop)</code> will only stop execution of the offending function or statement but not those that follow it. Thanks!</p>
"
1429476,143813,2009-09-15T20:36:36Z,6,longest common substring problem,"<p>Does anyone know of an R package that solves <a href=""http://en.wikipedia.org/wiki/Longest_common_substring_problem"" rel=""noreferrer"">the longest common substring problem</a>? I am looking for something fast that could work on vectors.</p>
"
1429907,2554948,2009-09-15T22:14:26Z,167,Workflow for statistical analysis and report writing,"<p>Does anyone have any wisdom on workflows for data analysis related to custom report writing?  The use-case is basically this:</p>

<ol>
<li><p>Client commissions a report that uses data analysis, e.g. a population estimate and related maps for a water district.</p></li>
<li><p>The analyst downloads some data, munges the data and saves the result (e.g. adding a column for population per unit, or subsetting the data based on district boundaries).</p></li>
<li><p>The analyst analyzes the data created in (2), gets close to her goal, but sees that needs more data and so goes back to (1).</p></li>
<li><p>Rinse repeat until the tables and graphics meet QA/QC and satisfy the client.</p></li>
<li><p>Write report incorporating tables and graphics.</p></li>
<li><p>Next year, the happy client comes back and wants an update.  This should be as simple as updating the upstream data by a new download (e.g. get the building permits from the last year), and pressing a ""RECALCULATE"" button, unless specifications change.</p></li>
</ol>

<p>At the moment, I just start a directory and ad-hoc it the best I can.  I would like a more systematic approach, so I am hoping someone has figured this out...  I use a mix of spreadsheets, SQL, ARCGIS, R, and Unix tools.</p>

<p>Thanks!</p>

<p>PS:</p>

<p>Below is a basic Makefile that checks for dependencies on various intermediate datasets (w/ <code>.RData</code> suffix) and scripts (<code>.R</code> suffix).  Make uses timestamps to check dependencies, so if you <code>touch ss07por.csv</code>, it will see that this file is newer than all the files / targets that depend on it, and execute the given scripts in order to update them accordingly.  This is still a work in progress, including a step for putting into SQL database, and a step for a templating language like sweave. Note that Make relies on tabs in its syntax, so read the manual before cutting and pasting. Enjoy and give feedback!</p>

<p><a href=""http://www.gnu.org/software/make/manual/html_node/index.html#Top"" rel=""noreferrer"">http://www.gnu.org/software/make/manual/html_node/index.html#Top</a></p>

<pre>
R=/home/wsprague/R-2.9.2/bin/R

persondata.RData : ImportData.R ../../DATA/ss07por.csv Functions.R
   $R --slave -f ImportData.R

persondata.Munged.RData : MungeData.R persondata.RData Functions.R
      $R --slave -f MungeData.R

report.txt:  TabulateAndGraph.R persondata.Munged.RData Functions.R
      $R --slave -f TabulateAndGraph.R > report.txt

</pre>
"
1430313,174029,2009-09-16T00:35:18Z,3,PgDn and PgUp Keys in R Graphics Viewer,"<p>I've never been able to figure out how to get the <code>PgDn/PgUp keys</code> to work in the <code>R Graphics Viewer</code>. </p>

<p>Even the <code>demo()</code> programs don't seem to support it. </p>

<p>Anyone able to point me to some code that shows how this can be implemented?</p>
"
1430557,170352,2009-09-16T02:06:30Z,0,Iterating an R Script as a function of sequential survey questions,"<p>The function below works perfectly for my purpose. The display is wonderful. Now my problem is I need to be able to do it again, many times, on other variables that fit other patterns. </p>

<p>In this example, I've output results for ""q4a"", I would like to be able to do it for sequences of questions that follow patterns like: q4 &lt; a - z > or q &lt; 4 - 10 >&lt; a - z >, automagically. </p>

<p>Is there some way to iterate this such that the specified variable (in this case q4a) changes each time?</p>

<p>Here's my function: </p>

<pre><code>require(reshape) # Using it for melt
require(foreign) # Using it for read.spss

d1 &lt;- read.spss(...) ## Read in SPSS file

attach(d1,warn.conflicts=F) ## Attach SPSS data

q4a_08 &lt;- d1[,grep(""q4a_"",colnames(d1))] ## Pull in everything matching q4a_X
q4a_08 &lt;- melt(q4a_08) ## restructure data for post-hoc

detach(d1)

q4aaov &lt;- aov(formula=value~variable,data=q4a) ## anova
</code></pre>

<p>Thanks in advance!</p>
"
1431657,NA,2009-09-16T08:22:44Z,3,How to plot a stacked column graph in R?,"<p>does anyone know how to use R to plot a histogram with the columns stacked up by more than 1 variables? Like the ""stacked column"" graph in excel. </p>

<p>Thank you!</p>
"
1432867,23929,2009-09-16T13:08:48Z,14,Boxplot schmoxplot: How to plot means and standard errors conditioned by a factor in R?,"<p>We all love robust measures like medians and interquartile ranges, but lets face it, in many fields, boxplots almost never show up in published articles, while means and standard errors do so all the time.</p>

<p>It's simple in lattice, ggplot2, etc to draw boxplots and the galleries are full of them. Is there an equally straightforward way to draw means and standard errors, conditioned by a categorical variable?</p>

<p>I'm taking about plots like these:</p>

<p><a href=""http://freakonomics.blogs.nytimes.com/2008/07/30/how-big-is-your-halo-a-guest-post/"" rel=""noreferrer"">http://freakonomics.blogs.nytimes.com/2008/07/30/how-big-is-your-halo-a-guest-post/</a></p>

<p>Or what are called ""means diamonds"" in JMP (see Figure 3):</p>

<p><a href=""http://blogs.sas.com/jmp/index.php?/archives/127-What-Good-Are-Error-Bars.html"" rel=""noreferrer"">http://blogs.sas.com/jmp/index.php?/archives/127-What-Good-Are-Error-Bars.html</a></p>
"
1433523,143813,2009-09-16T14:55:19Z,7,Interfacing R to Java,"<p>Is <a href=""http://www.rforge.net/rJava/"" rel=""nofollow noreferrer"">rjava</a> the only way to connect R to Java? I am asking because there is a disclaimer at the end of the web page:</p>

<blockquote>
  <p>This interface uses Java reflection
  API to find the correct method so it
  is much slower and may not be right
  (works for simple examples but may not
  for more complex ones). For now its
  use is discouraged in programs as it
  may change in the future.</p>
</blockquote>

<p>This is slightly concerning. How do you address this issue? I know that Rweka has a self-contained interface, so I may look into that package, but maybe many R users have already gone through the pains.</p>
"
1434411,173913,2009-09-16T17:32:00Z,8,Breaking the tapply junkie habit,"<p>I've learned R by toying, and I'm starting to think that I'm abusing the tapply function. Are there better ways to do some of the following actions? Granted, they work, but as they get more complex I wonder if I'm losing out on better options. I'm looking for some criticism, here:</p>

<pre><code>tapply(var1, list(fac1, fac2), mean, na.rm=T)

tapply(var1, fac1, sum, na.rm=T) / tapply(var2, fac1, sum, na.rm=T)

cumsum(tapply(var1, fac1, sum, na.rm=T)) / sum(var1)
</code></pre>

<p>Update: Here's some example data...</p>

<pre><code>     var1    var2 fac1           fac2
1      NA  275.54   10      (266,326]
2      NA  565.89   10      (552,818]
3      NA  815.41    6      (552,818]
4      NA  281.77    6      (266,326]
5      NA  640.24   NA      (552,818]
6      NA   78.42   NA     [78.4,266]
7      NA 1027.06   NA (818,1.55e+03]
8      NA  355.20   NA      (326,552]
9      NA  464.52   NA      (326,552]
10     NA 1397.11   10 (818,1.55e+03]
11     NA  229.82   NA     [78.4,266]
12     NA  542.77   NA      (326,552]
13     NA  829.32   NA (818,1.55e+03]
14     NA  284.78   NA      (266,326]
15     NA  194.97   10     [78.4,266]
16     NA  672.55    8      (552,818]
17     NA  348.01   10      (326,552]
18     NA 1550.79    9 (818,1.55e+03]
19 101.98  101.98    4     [78.4,266]
20     NA  292.80    6      (266,326]
</code></pre>

<p>Update data dump:</p>

<pre><code>structure(list(var1 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA, NA, NA, NA, NA, NA, 101.98, NA), var2 = c(275.54, 
565.89, 815.41, 281.77, 640.24, 78.42, 1027.06, 355.2, 464.52, 
1397.11, 229.82, 542.77, 829.32, 284.78, 194.97, 672.55, 348.01, 
1550.79, 101.98, 292.8), fac1 = c(10L, 10L, 6L, 6L, NA, NA, NA, 
NA, NA, 10L, NA, NA, NA, NA, 10L, 8L, 10L, 9L, 4L, 6L), fac2 = structure(c(2L, 
4L, 4L, 2L, 4L, 1L, 5L, 3L, 3L, 5L, 1L, 3L, 5L, 2L, 1L, 4L, 3L, 
5L, 1L, 2L), .Label = c(""[78.4,266]"", ""(266,326]"", ""(326,552]"", 
""(552,818]"", ""(818,1.55e+03]""), class = ""factor"")), .Names = c(""var1"", 
""var2"", ""fac1"", ""fac2""), row.names = c(NA, -20L), class = ""data.frame"")
</code></pre>
"
1434897,84458,2009-09-16T19:06:36Z,9,How do I load example datasets in R?,"<p>Let's say I want to reproduce an example posted on StackOverflow.  Some have suggested posters use <a href=""https://stackoverflow.com/questions/1265129/how-to-export-the-definition-of-an-r-object-to-plain-text-so-that-others-can-recr""><code>dput()</code> to help streamline this process</a> or one of the <a href=""http://stat.ethz.ch/R-manual/R-patched/library/datasets/html/00Index.html"" rel=""nofollow noreferrer"">datasets available in the base package</a>.  </p>

<p>In this case, however, suppose I have only been given the output of the dataframe:</p>

<pre><code>&gt; site.data
    site year     peak
1  ALBEN    5 101529.6
2  ALBEN   10 117483.4
3  ALBEN   20 132960.9
8  ALDER    5   6561.3
9  ALDER   10   7897.1
10 ALDER   20   9208.1
15 AMERI    5  43656.5
16 AMERI   10  51475.3
17 AMERI   20  58854.4
</code></pre>

<p>Do I have other options besides saving this as a text file and using <code>read.table()</code>?</p>
"
1435937,143377,2009-09-16T22:57:43Z,2,"R character encodings across windows, mac and linux","<p>I use OS X and I am currently cooperating with a windows user and deploying the scripts on a linux server. We use git for version control, and I keep getting R scripts from his end where the character encoding used has  mixed  latin1 and utf8 encodings. So I have a couple of questions.</p>

<ol>
<li><p>Is there a simple to use editor for windows that handle UTF8 with more grace than Winedt that my coauthor currently uses?  I use emacs, but I am having a hard time selling getting him to switch.</p></li>
<li><p>How to set up R in Windows so that it defaults to reading and writing UTF8?</p></li>
</ol>

<p>This is driving me crazy. Has anyone found a solution for it (be it in the workflow or in the software used) who cares to share?  </p>
"
1439348,74658,2009-09-17T14:47:56Z,8,How to examine the code of a function in R that's object class sensitive,"<p>I'm trying to write a function to do a particular job (in my case, analyse a data set for outliers) so the first things I want to do is look at how other people have done similar jobs.</p>

<p>I can do this to load a particular package and examine the code of a function, but some functions seem to depend on what class of object you throw at it</p>

<pre><code>&gt;library(outliers)
&gt; fix(outlier)

function (x, opposite = FALSE, logical = FALSE) 
{
    if (is.matrix(x)) 
        apply(x, 2, outlier, opposite = opposite, logical = logical)
    else if (is.data.frame(x)) 
        sapply(x, outlier, opposite = opposite, logical = logical)
    else {
        if (xor(((max(x) - mean(x)) &lt; (mean(x) - min(x))), opposite)) {
            if (!logical) 
                min(x)
            else x == min(x)
        }
        else {
            if (!logical) 
                max(x)
            else x == max(x)
        }
    }
}
</code></pre>

<p>How can you look at the code of something that changes depending on the object ?</p>

<p>Edit:</p>

<p>OK, Palm &lt;- face.  The function I used as an example just calls itself, but allt he code is there... I have seen other examples (but can't think of any offhand) where the function did do other things depending on the class of the object thrown at it, so the question stands, even though it's a bad example !</p>
"
1439513,170352,2009-09-17T15:15:26Z,17,Creating a sequential list of letters with R,"<p>I would like to be able to create a sequence of letters in R (to assist in importing data from a SPSS file)</p>

<p>It's quite easy to create a sequence of numbers, for example:</p>

<pre><code>seq(1,1000)
[1] 1 2 3 4 5 6 ... 1000

paste(""something_"",1:12,sep="""")
[1] something1 something2 ... something12
</code></pre>

<p>But is there any functionality for appending, pasting, or creating sequences of letters like this? </p>

<pre><code>paste(""This_"",a:z,sep="""")
[1]This_a This_b This_c ... This_4z
</code></pre>

<p>Thanks in advance! </p>
"
1441717,143813,2009-09-17T22:50:42Z,26,Plotting color map with zip codes in R or Python,"<p>I have some US demographic and firmographic data.<br>
I would like to plot zipcode areas in a state or a smaller region (e.g. city). Each area would be annotated by color and/or text specific to that area. The output would be similar to <a href=""http://maps.huge.info/"" rel=""nofollow noreferrer"">http://maps.huge.info/</a> but a) with annotated text; b) pdf output; c) scriptable in R or Python.</p>

<p>Is there any package and code that allows me to do this?</p>
"
1444306,74658,2009-09-18T12:36:56Z,14,How to use Outlier Tests in R Code,"<p>As part of my data analysis workflow, I want to test for outliers, and then do my further calculation with and without those outliers.  </p>

<p>I've found the outlier package, which has various tests, but I'm not sure how best to use them for my workflow.</p>
"
1445964,2554948,2009-09-18T17:47:29Z,72,R script line numbers at error?,"<p>If I am running a long R script from the command line (R --slave script.R), how can I get it to give line numbers at errors?  </p>

<p>I don't want to add debug commands to the script if at all possible -- I just want R to behave like most other scripting languages ...</p>
"
1448600,165787,2009-09-19T13:59:38Z,18,Change default prompt and output line prefix in R?,"<p>For the purposes of teaching and preparing written instructions about R, one of the things that's always frustrated me is that I can't simply copy commands and output from R and paste them into another R session. For example, if I do something trivial, such as</p>

<pre><code>&gt; x &lt;- rnorm(10)
&gt; x
 [1]  1.76975998  1.19722850 -0.39274507 -1.10979974  0.52320473 -0.08643833
 [7]  0.94437690  0.08083207  0.62260363  1.89305469
</code></pre>

<p>If I copy and paste that into a document or even here in this post, you (and my students) can not then just highlight it, copy it and paste it into an R session successfully</p>

<pre><code>&gt; &gt; x &lt;- rnorm(10)
Error: syntax error
&gt; &gt; x
Error: syntax error
&gt;  [1]  1.76975998  1.19722850 -0.39274507 -1.10979974  0.52320473 -0.08643833
Error: syntax error
&gt;  [7]  0.94437690  0.08083207  0.62260363  1.89305469
Error: syntax error
</code></pre>

<p>You might want to do this to test your installation of R, compare my output to yours, or simply to make use of a function I've offered.</p>

<p>So, what I'd like to be able to do is to change the default prompt from > to either an empty string or a blank space and also prefix all output lines with a hash mark #. That way, I could use R interactively to generate a session that looks like</p>

<pre><code>x &lt;- rnorm(10)
x
# [1]  1.76975998  1.19722850 -0.39274507 -1.10979974  0.52320473 -0.08643833
# [7]  0.94437690  0.08083207  0.62260363  1.89305469
</code></pre>

<p>which <em>could</em> be copy/pasted into an R session successfully. It would make prepping R code for a journal article, students, lectures, etc. much easier for me (and maybe for others?)</p>

<p>I've poked around the documentation with no luck... any ideas? pointers?</p>

<p>Currently, I'm using R on a Mac either via the R.app GUI or from Terminal.</p>
"
1449266,136594,2009-09-19T19:11:37Z,13,Display Values in R Plot,"<p>How can I render the value of points in a <code>plot</code> in the <code>plot</code> itself?</p>

<p>Thank you.</p>
"
1452235,163053,2009-09-20T22:50:22Z,38,Does an R compiler exist?,"<p>I'm wondering about the best way to deploy R.  Matlab has the ""matlab compiler"" (MCR).  There has been discussion about something similar in the past for R that would compile R into C or C++.  Does anyone have any experience with the <a href=""http://www.hipersoft.rice.edu/rcc/"" rel=""noreferrer"">R to C Compiler (RCC) that was developed by John Garvin at Rice</a>?</p>

<p>I've looked into it, and it seems to be the only project that worked on compiling R code into executable code.  And as far as I can tell, it isn't still being used.  </p>

<p><i> [Edit 1:]</i>: To be clear, I know that there are C and C++ (and Java, Python, etc.) interfaces to R (rJava, rcpp, Rpy, etc.).  I'm wondering about specific ways to compile and deploy R code without installing R in advance.</p>

<p><i> [Edit 2:]</i>: John Mellor-Crummey tells me that they're still working on RCC and hope to make it available in 4 months or so (at the earliest).  I'll update this further if I find anything else out.</p>
"
1453505,55362,2009-09-21T08:57:32Z,6,Best way to integrate R and Flash/Flex,"<p>I want to make a Flash or Flex front end for my R code, I want to call an R function from a website (using Flash) what is the best way to go about connecting Flash and R?</p>
"
1454211,23929,2009-09-21T12:11:50Z,73,"What does ""not run"" mean in R help pages?","<p>Sometimes on an R help page the phrase ""not run"" appears in comments. Check out this from the help page for ""with()"":</p>

<pre><code>Examples
require(stats); require(graphics)
#examples from glm:
**## Not run:** 
library(MASS)
with(anorexia, {
    anorex.1 &lt;- glm(Postwt ~ Prewt + Treat + offset(Prewt),
                    family = gaussian)
    summary(anorex.1)
})
## End(**Not run**)
</code></pre>

<p>What does the ""not run"" mean in the example code?</p>
"
1457216,NA,2009-09-21T22:26:00Z,3,visualize associations between two groups of data,"<p>Where each datapoint has a pairing of A and B and there multiple entries in A and multiple entires in B. IE multiple syndromes and multiple diagnoses, although for each datapoint there is one single syndrome-diagnoses pair.</p>

<p>Examples, suggestions, or ideas much appreciated</p>

<p>here's what the data is like. And I want to see connections between values of A and B (how many GG's are linked to TTs etc). Both are nominal datatypes.</p>

<pre><code>ID,A ,B 
1,GG,TT
2,AA,SS
3,BB,XX
4,DD,SS
5,DD,TT
6,CC,XX
7,HH,ZZ
8,AA,TT
9,CC,RR
10,DD,ZZ
11,AA,XX
12,AA,TT
13,DD,SS
14,DD,XX
15,AA,YY
16,CC,ZZ
17,FF,SS
18,FF,XX
19,BB,VV
20,GG,VV
21,GG,SS
22,AA,RR
23,AA,TT
24,AA,SS
25,CC,VV
26,CC,TT
27,FF,RR
28,GG,UU
29,CC,TT
30,BB,ZZ
31,II,TT
32,FF,RR
33,BB,SS
34,GG,YY
35,FF,RR
36,BB,VV
37,II,RR
38,CC,YY
39,FF,VV
40,AA,XX
41,AA,ZZ
42,GG,VV
43,BB,UU
44,II,UU
45,II,SS
46,DD,SS
47,AA,UU
48,BB,VV
49,GG,TT
50,BB,TT
</code></pre>
"
1457821,168139,2009-09-22T02:12:26Z,5,"Adding multiple columns, transforming with multiple variables","<p>How do I add the values from many variables?</p>

<p>If I just had two variables (columns) I could simply go:</p>

<pre><code>summation.variable &lt;- variable1 + variable2
</code></pre>

<p>or if it was all in a dataframe:</p>

<pre><code>transform(dataframe, summation.col = column1 + column2)
</code></pre>

<p>How do I do it if I have about 10 variables and I do not want to type each one as in col1+col2+col3+col4. To make matters worse my columns have quite long names and at times the exact columns that I use can change. I have a character vector with all the relevant column names in it but cannot think how to use it. </p>

<p>The following is useless since it adds every value in every column in every row and gives a single value for the whole lot.</p>

<pre><code>sum(metrics)
</code></pre>
"
1463444,2002705,2009-09-23T01:01:36Z,1,Word-wrapping in the R environment for Windows,"<p>(Asking this on behalf of a member of our Bay Area R Group.  I did not have a ready answer as I run ESS within Emacs.  I assume this question refers to running R within the command-line environment that ships in the standard Windows distribution).</p>

<p>I'm new to R, but what I've found in searching for my answer is that there isn't anything about customizing R so that I can work faster.</p>

<p>One of my main problems is the lack of word wrapping in my version running on Windows XP. I noticed that my friends with the Mac OS have word wrapping.</p>

<p>Is there a way to enable word wrapping in R running on a Windows machine?</p>
"
1467201,37751,2009-09-23T16:37:13Z,54,Forcing garbage collection to run in R with the gc() command,"<p>Periodically I program sloppily. Ok, I program sloppily all the time, but sometimes that catches up with me in the form of out of memory errors. I start exercising a little discipline in deleting objects with the rm() command and things get better. I see mixed messages online about whether I should explicitly call gc() after deleting large data objects. Some say that before R returns a memory error it will run gc() while others say that manually forcing gc is a good idea. </p>

<p>Should I run gc() after deleting large objects in order to ensure maximum memory availability?</p>
"
1467807,2554948,2009-09-23T18:28:43Z,3,Good ways to code complex tabulations in R?,"<p>Does anyone have any good thoughts on how to code complex tabulations in R?</p>

<p>I am afraid I might be a little vague on this, but I want to set up a script to create a bunch of tables of a complexity analogous to the stat abstract of the united states. </p>

<p>e.g.: <a href=""http://www.census.gov/compendia/statab/tables/09s0015.pdf"" rel=""nofollow noreferrer"">http://www.census.gov/compendia/statab/tables/09s0015.pdf</a> </p>

<p>And I would like to avoid a whole bunch of rbind and hbind statements.</p>

<p>In <code>SAS</code>, I have heard, there is a table creation specification language; I was wondering if there was something of similar power for <code>R</code>?</p>

<p>Thanks!</p>
"
1468856,135944,2009-09-23T22:25:37Z,10,how do I get the difference between two R named lists?,"<p>OK, I've got two named lists, one is ""expected"" and one is ""observed"". They may be complex in structure, with arbitrary data types. I want to get a new list containing just those elements of the observed list that are different from what's in the expected list. Here's an example:</p>

<pre><code>Lexp &lt;- list(a=1, b=""two"", c=list(3, ""four""))
Lobs &lt;- list(a=1, c=list(3, ""four""), b=""ni"")
Lwant &lt;- list(b=""ni"")
</code></pre>

<p>Lwant is what I want the result to be. I tried this:</p>

<pre><code>&gt; setdiff(Lobs, Lexp)
[[1]]
[1] ""ni""
</code></pre>

<p>Nope, that loses the name, and I don't think setdiff pays attention to the names. Order clearly doesn't matter here, and I don't want <em>a=1</em> to match with <em>b=1</em>. </p>

<p>Not sure what a good approach is... Something that loops over a list of <em>names(Lobs)</em>? Sounds clumsy and non-R-like, although workable... Got any elegant ideas?</p>
"
1468962,11858,2009-09-23T23:03:42Z,8,Correlation clustering in R,"<p>I'd like to use <code>correlation clustering</code> and I figure <code>R</code> is a good place to start.</p>

<p>I can present the data to <code>R</code> as a set of large, sparse vectors or as a table with a pre-computed dissimilarity matrix.</p>

<p>My questions are:</p>

<ul>
<li>are there existing <code>R</code> functions to turn this into a <code>hierarchical cluster</code> with <code>agnes</code> that uses <code>correlation clustering</code>?</li>
<li>will I have to implement the (admittedly simple) <code>correlation clustering</code>function by hand, if so how do I make it play well with <code>agnes</code>?</li>
</ul>
"
1474081,NA,2009-09-24T20:51:30Z,272,How do I install an R package from source?,"<p>A friend sent me along this great tutorial on <a href=""http://www.stanford.edu/~cengel/cgi-bin/anthrospace/scraping-new-york-times-articles-with-r"" rel=""noreferrer"">webscraping NYtimes with R</a>. I would really love to try it. However, the first step is to installed a package called RJSONIO from source.</p>

<p>I know R reasonably well, but I have no idea how to install a package from source.</p>

<p>I'm running Mac OSX.</p>
"
1475360,NA,2009-09-25T04:01:55Z,1,lag in apply statement doesn't work in R,"<p>I'm trying to ""apply"" a function that does ""lag""s on zoo objects in R.</p>

<p>The function works correctly if I pass a single zoo vector - it applys the lag and everything works.</p>

<p>However, if I <code>apply( data, 1, function )</code> then the lag doesn't work.  There is no error, just the equivalent of a zero lag.</p>

<p>This is also the case with a simple <code>apply( data, 1, lag )</code>.</p>

<p>Can anyone explain why this should be the case?  Is there anything I can do to make the lag to occur?</p>
"
1475631,144601,2009-09-25T05:53:31Z,3,R: update plot [xy]lims with new points() or lines() additions?,"<p><strong><em>Background:</em></strong> </p>

<p>I'm running a Monte Carlo simulation to show that a particular process (a cumulative mean) does <strong>not</strong> converge over time, and often diverges wildly in simulation (the expectation of the random variable = infinity).  I want to plot about 10 of these simulations on a line chart, where the x axis has the iteration number, and the y axis has the cumulative mean up to that point.</p>

<p><strong><em>Here's my problem:</em></strong></p>

<p>I'll run the first simulation (each sim. having 10,000 iterations), and build the main plot based on its current range.  But often one of the simulations will have a range a few orders of magnitude large than the first one, so the plot flies outside of the original range.  So, <strong>is there any way to dynamically update the ylim or xlim of a plot upon adding a new set of points or lines?</strong></p>

<p>I can think of two <strong>workarounds</strong> for this: 1. store each simulation, then pick the one with the largest range, and build the base graph off of that (not elegant, and I'd have to store a lot of data in memory, but would probably be laptop-friendly <strong>[[EDIT: as Marek points out, this is not a memory-intense example, but if you know of a nice solution that'd support far more iterations such that it becomes an issue (think high dimensional walks that require much, much larger MC samples for convergence) then jump right in]]</strong>) 2. find a seed that appears to build a nice looking version of it, and set the ylim manually, which would make the demonstration reproducible.</p>

<p>Naturally I'm holding out for something more elegant than my workarounds.  Hoping this isn't too pedestrian a problem, since I imagine it's not uncommon with simulations in R.  Any ideas?</p>
"
1476185,74658,2009-09-25T08:53:10Z,11,How to overlay a line for an lm object on a ggplot2 scatterplot,"<p>I have some data, </p>

<pre><code>calvarbyruno.1&lt;-structure(list(Nominal = c(1, 3, 6, 10, 30, 50, 150, 250), Run = structure(c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c(""1"", ""2"", ""3""), class = ""factor""), 
    PAR = c(1.25000000000000e-05, 0.000960333333333333, 0.00205833333333334, 
    0.00423333333333333, 0.0322333333333334, 0.614433333333334, 
    1.24333333333333, 1.86333333333333), PredLin = c(-0.0119152187070942, 
    0.00375925114245899, 0.0272709559167888, 0.0586198956158952, 
    0.215364594111427, 0.372109292606959, 1.15583278508462, 1.93955627756228
    ), PredQuad = c(-0.0615895732702735, -0.0501563307416599, 
    -0.0330831368244257, -0.0104619953693943, 0.100190275883806, 
    0.20675348710041, 0.6782336426345, 1.04748729725370)), .Names = c(""Nominal"", 
""Run"", ""PAR"", ""PredLin"", ""PredQuad""), row.names = c(NA, 8L), class = ""data.frame"")
calweight &lt;- -2
</code></pre>

<p>for which I've created both a linear and a quadratic lm model</p>

<pre><code>callin.1&lt;-lm(PAR~Nominal,data=calvarbyruno.1,weight=Nominal^calweight)
calquad.1&lt;-lm(PAR~Nominal+I(Nominal^2),data=calvarbyruno.1,weight=Nominal^calweight)
</code></pre>

<p>I can then plot my data values using ggplot2</p>

<pre><code>qplot(PAR,Nominal,data=calvarbyruno.1)
</code></pre>

<p>But can't work out how to overlay a line representing the two lm objects... Any ideas ?</p>
"
1476585,74658,2009-09-25T10:36:12Z,1,How to use Predict.lm in r to reverse the regression,"<p>I have some data in a dataframe calvarbyruno.1 with variables Nominal and PAR that represent the Peak Area Ratio (PAR) found from analysis of a set of standards using a particular analytical technique, and two lm models of that data (linear and quadratic) for the relationship PAR ~ Nominal.  I'm trying to use the predict.lm function to back calculate Nominal values, given my PAR values, but both predict.lm and fitted seem to only give me PAR values.  I'm slowly loosing my mojo, can anyone help ?</p>

<p>calvarbyruno.1 dataframe</p>

<pre><code>structure(list(Nominal = c(1, 3, 6, 10, 30, 50, 150, 250), Run = structure(c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c(""1"", ""2"", ""3""), class = ""factor""), 
    PAR = c(1.25000000000000e-05, 0.000960333333333333, 0.00205833333333334, 
    0.00423333333333333, 0.0322333333333334, 0.614433333333334, 
    1.24333333333333, 1.86333333333333), PredLin = c(-0.0119152187070942, 
    0.00375925114245899, 0.0272709559167888, 0.0586198956158952, 
    0.215364594111427, 0.372109292606959, 1.15583278508462, 1.93955627756228
    ), PredQuad = c(-0.0615895732702735, -0.0501563307416599, 
    -0.0330831368244257, -0.0104619953693943, 0.100190275883806, 
    0.20675348710041, 0.6782336426345, 1.04748729725370)), .Names = c(""Nominal"", 
""Run"", ""PAR"", ""PredLin"", ""PredQuad""), row.names = c(NA, 8L), class = ""data.frame"")
</code></pre>

<p>Linear Model</p>

<pre><code>summary(callin.1)

Call:
lm(formula = PAR ~ Nominal, data = calvarbyruno.1, weights = Nominal^calweight)

Residuals:
       Min         1Q     Median         3Q        Max 
-0.0041172 -0.0037785 -0.0003605  0.0024465  0.0071815 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)  
(Intercept) -0.007083   0.005037  -1.406   0.2093  
Nominal      0.005249   0.001910   2.748   0.0334 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Residual standard error: 0.004517 on 6 degrees of freedom
Multiple R-squared: 0.5572,     Adjusted R-squared: 0.4835 
F-statistic: 7.551 on 1 and 6 DF,  p-value: 0.03338 
</code></pre>

<p>Quadratic Model</p>

<pre><code>&gt; summary(calquad.1)

Call:
lm(formula = PAR ~ Nominal + I(Nominal^2), data = calvarbyruno.1)

Residuals:
        1         2         3         4         5         6         7         8 
 0.053366  0.033186  0.002766 -0.036756 -0.211640  0.177012 -0.021801  0.003867 

Coefficients:
               Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)  -6.395e-02  6.578e-02  -0.972  0.37560   
Nominal       1.061e-02  2.205e-03   4.812  0.00483 **
I(Nominal^2) -1.167e-05  9.000e-06  -1.297  0.25138   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Residual standard error: 0.128 on 5 degrees of freedom
Multiple R-squared: 0.9774,     Adjusted R-squared: 0.9684 
F-statistic: 108.2 on 2 and 5 DF,  p-value: 7.658e-05
</code></pre>

<p>But Predict gives me these values, which both seem wrong (although I can't work out what it's doing that's different for the second set ?</p>

<pre><code>&gt; predict(callin.1)
           1            2            3            4            5            6 
-0.001834123  0.008663451  0.024409812  0.045404959  0.150380698  0.255356437 
           7            8 
 0.780235132  1.305113826 
&gt; predict(callin.1,type=""terms"")
      Nominal
1 -0.32280040
2 -0.31230282
3 -0.29655646
4 -0.27556131
5 -0.17058558
6 -0.06560984
7  0.45926886
8  0.98414755
attr(,""constant"")
[1] 0.3209663
</code></pre>

<p>EDIT: As has been pointed out, I've not been very clear on what I'm trying to achieve, so I'll try to exaplian myself better.</p>

<p>The data is from analysis of a set of standards of known concentrations (Nominal) which gives a particular set of responses, or peak area ratio's (PAR).  I want to show which model best fits this data to use to then analyse unknown samples to find their concentration.</p>

<p>I'm trying to follow someone else working for this, which involves;<br>
a) Find the appropriate weight to use, by finding the within run variance of PAR and fitting that to a model of log(Variance(PAR))=a+b<em>log(Nominal), where B will be the weight to use (rounded to nearest integer)<br>
  b) Fit the data for each run to a linear model (PAR = a+b</em>Nominal) and a Quadratic Model (PAR = a+B<em>Nominal+c</em>Nominal^2)<br>
  c) Back calculate the found concentration for each standard and compare to the Nominal conentration to give the bias<br>
  d) Assess bias across the calibration range and pick the model based on the bias  </p>

<p>This question is trying to do c).  Posts to the R mailing list suggest it's not appropriate to just do the regression with the terms reversed, I can manually do the calculation for the linear model, but am struggling with the quadratic model.  It seems from searcing the R mailing list that others want to do the same thing.</p>
"
1478532,84458,2009-09-25T17:15:01Z,24,Changing shapes used for scale_shape() in ggplot2,"<p>Suppose I have the following</p>

<pre><code>y &lt;- rnorm(10)
b &lt;- as.factor(sample(1:4,10,replace=T))
qplot(1:10, y, shape=b)
</code></pre>

<p>How do I change the shapes that are used using <code>ggplot2</code>?</p>
"
1478758,143813,2009-09-25T18:01:25Z,3,Optimizing the computation of a recursive sequence,"<p>What is the fastest way in R to compute a recursive sequence defined as </p>

<pre><code>x[1] &lt;- x1 
x[n] &lt;- f(x[n-1])
</code></pre>

<p>I am assuming that the vector x of proper length is preallocated. Is there a smarter way than just looping?</p>

<p>Variant: extend this to vectors:</p>

<pre><code> x[,1] &lt;- x1 
 x[,n] &lt;- f(x[,n-1])
</code></pre>
"
1481032,92287,2009-09-26T11:34:36Z,6,Help plotting Geographic Data in R using PBSMapping and Shapefiles,"<p>Using <a href=""http://oreilly.com/catalog/9780596804770/"" rel=""noreferrer"">O'Reilly's Data Mashups in R</a> as inspiration, I'm trying to plot a handful of addresses on a shapefile of Salt Lake County, Utah found <a href=""http://gis.utah.gov/sgid-vector-download/utah-sgid-vector-gis-data-layer-download-index?fc=CensusTracts2000"" rel=""noreferrer"">here</a>.</p>

<p>I have data frame geoTable:</p>

<pre><code>&gt; geoTable
         address        Y         X EID
1    130 E 300 S 40.76271 -111.8872   1
2    875 E 900 S 40.74992 -111.8660   2
3   2200 S 700 E 40.72298 -111.8714   3
4    702 E 100 S 40.76705 -111.8707   4
5 177 East 200 S 40.76518 -111.8859   5
6    702 3rd ave 40.77264 -111.8683   6
7   2175 S 900 E 40.72372 -111.8652   7
8   803 E 2100 S 40.72556 -111.8680   8
</code></pre>

<p>And I've coerced it into an eventData object:</p>

<pre><code>&gt; addressEvents&lt;-as.EventData(geoTable,projection=NA)
&gt; addressEvents
         address        Y         X EID
1    130 E 300 S 40.76271 -111.8872   1
2    875 E 900 S 40.74992 -111.8660   2
3   2200 S 700 E 40.72298 -111.8714   3
4    702 E 100 S 40.76705 -111.8707   4
5 177 East 200 S 40.76518 -111.8859   5
6    702 3rd ave 40.77264 -111.8683   6
7   2175 S 900 E 40.72372 -111.8652   7
8   803 E 2100 S 40.72556 -111.8680   8
</code></pre>

<p>So it looks like I've got everything I need to plot-but its not working.  When I load the shapefile and plot using</p>

<pre><code>addPoints(addressEvents,col=""red"",cex=.5)
</code></pre>

<p>I'm left looking at an empty shapefile.  Additionally, when I try and run findPolys against my eventData object, it returns NULL.</p>

<pre><code>&gt; findPolys(addressEvents,myShapeFile)
NULL
</code></pre>

<p>How can I make this work?  I was able to complete the O'Reilly tutorial without any problems and am having difficulty figuring out where I'm going wrong here.  I dont know if its the shapefile, my data frame, or whateverelse.  </p>

<p>Here are the commands I use to import my data and shapefile</p>

<pre><code>slc&lt;-read.table('~/utah.txt',sep=',',header=TRUE,strip.white=TRUE,stringsAsFactors=FALSE)

myShapeFile&lt;-importShapefile(""/Users/neil/Downloads/SGID93_DEMOGRAPHIC_CensusTracts2000/SGID93_DEMOGRAPHIC_CensusTracts2000"",readDBF=TRUE)
</code></pre>
"
1484307,NA,2009-09-27T19:54:26Z,6,label of log y-axis: 1000 instead of 1e+03?,"<p>I've a problem concerning construction of log y-axis in a graphic. </p>

<p>How can I manage that the units/numbers of my log y-axis aren't shown in </p>

<pre><code>1e+03, 1e+04, 1e+05 etc....
</code></pre>

<p>But only in regular Arabic numbers (1000, 10000, 100000)?</p>
"
1484472,179848,2009-09-27T21:01:19Z,6,Adding summary statistics (or even raw data points) to dodged position boxplots,"<p>Say you have the following dataset:</p>

<pre><code>trt &amp;lt;- ifelse(runif(100)&amp;lt;0.5,""drug"",""placebo"")
inj.site &amp;lt;- ifelse(runif(100)&amp;lt;0.5,""ankle"",""wrist"")
relief &amp;lt;- 20 + 0.5*(inj.site==""ankle"") + 0.5*(trt==""drug"") + rnorm(100)
to.analyze &amp;lt;- data.frame(trt,inj.site,relief)
</code></pre>

<p>Now, the idea is to make a boxplot with injury site on the x-axis and boxes by treatment side-by-side:</p>

<pre><code>bplot &amp;lt;- ggplot(to.analyze,aes(inj.site,relief,fill=trt)) + geom_boxplot(position=""dodge"")
</code></pre>

<p>Easy enough. But now I want to add raw data points on top of the boxes. If I didn't have boxes with <code>position=""dodge""</code>, this would be easy:</p>

<pre><code>bplot + geom_point(aes(colour=trt))
</code></pre>

<p>However, this draws points in between the boxes, and adding a <code>position=""dodge""</code>to this geometry does not seem to work. How do I adjust this so that points are drawn over the boxes?</p>

<p>Bonus: same situation with using <code>stat_summary(blah,y.fun=mean,shape=""+"")</code> to overplot the means, which has the same issue.</p>
"
1484904,177541,2009-09-28T00:28:43Z,6,Renaming rows and columns in R,"<p>I'm running the following script: </p>

<pre><code>cause = c(1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2); 
time =  c(1, 1, 2, 3, 3, 2, 2, 1, 1, 2, 2); 
table(cause, time)
</code></pre>

<p>And I get the following:</p>

<pre><code>    time
cause 1 2 3
    1 2 2 2
    2 2 3 0
</code></pre>

<p>What I want is this:</p>

<pre><code>      time
cause     1 2 3
Maltreat  2 2 2
Non-Maltr 2 3 0
</code></pre>

<p>So, my question is: how do you rename the rows of a table in R?</p>

<p>In the same vein, how would you rename the columns of that table?</p>
"
1487320,163053,2009-09-28T14:23:24Z,16,Blogging with R: easy way to embed R in a blog post?,"<p>There is <a href=""http://mars.wiwi.hu-berlin.de/mediawiki/sk/index.php/R_Extension_for_MediaWiki"" rel=""noreferrer"">a very nice Mediawiki plugin for R</a> which allows you to embed R code in any wiki page.  It takes a little effort to configure, but it's really useful once you have it in place.</p>

<p>Does anyone know of an equivalent for embedding R in a blog post?  The only thing I could find was <a href=""http://lixiaoxu.lxxm.com/RwebFriend/"" rel=""noreferrer"">this wordpress plugin called RWebFriend</a>, but it only allows you to send code to <a href=""http://bayes.math.montana.edu/Rweb/"" rel=""noreferrer"">Rweb</a>.  I'm envisioning something where you can embed your code between two tags and it is executed and returned.</p>
"
1489199,180626,2009-09-28T20:28:35Z,5,How can I take multiple vectors and recode their datatypes in R?,"<h3>I'm looking for an elegant way to change multiple vectors' datatypes in R.</h3>

<p>I'm working with an educational dataset: 426 students' answers to eight multiple choice questions (<code>1</code> = correct, <code>0</code> = incorrect), plus a column indicating which instructor (<code>1, 2, or 3</code>) taught their course.</p>

<p>As it stands, my data is sitting pretty in <code>data.df</code>, like this:</p>

<p><pre><code>    str(data.df)
    'data.frame': 426 obs. of  9 variables:
    $ ques01: int  1 1 1 1 1 1 0 0 0 1 ...
    $ ques02: int  0 0 1 1 1 1 1 1 1 1 ...
    $ ques03: int  0 0 1 1 0 0 1 1 0 1 ...
    $ ques04: int  1 0 1 1 1 1 1 1 1 1 ...
    $ ques05: int  0 0 0 0 1 0 0 0 0 0 ...
    $ ques06: int  1 0 1 1 0 1 1 1 1 1 ...
    $ ques07: int  0 0 1 1 0 1 1 0 0 1 ...
    $ ques08: int  0 0 1 1 1 0 1 1 0 1 ...
    $ inst  : num  1 1 1 1 1 1 1 1 1 1 ...
</code></pre></p></p>

<p>But those <code>ques0x</code> values aren't <strong>really</strong> integers. Rather, I think it's better to have R treat them as experimental factors. Same goes for the ""inst"" values.</p>

<h3>I'd love to turn all those <code>int</code>s and <code>num</code>s into <code>factors</code>
</h3>

<p>
Ideally, an elegant solution should produce a dataframe&mdash;I call it <code>factorData.df</code>&mdash;that looks like this:
</p>

<pre><code>    str(factorData.df)
    'data.frame': 426 obs. of  9 variables:
    $ ques01: Factor w/ 2 levels ""0"",""1"": 2 2 2 2 2 2 1 1 1 2 ...
    $ ques02: Factor w/ 2 levels ""0"",""1"": 1 1 2 2 2 2 2 2 2 2 ...
    $ ques03: Factor w/ 2 levels ""0"",""1"": 1 1 2 2 1 1 2 2 1 2 ...
    $ ques04: Factor w/ 2 levels ""0"",""1"": 2 1 2 2 2 2 2 2 2 2 ...
    $ ques05: Factor w/ 2 levels ""0"",""1"": 1 1 1 1 2 1 1 1 1 1 ...
    $ ques06: Factor w/ 2 levels ""0"",""1"": 2 1 2 2 1 2 2 2 2 2 ...
    $ ques07: Factor w/ 2 levels ""0"",""1"": 1 1 2 2 1 2 2 1 1 2 ...
    $ ques08: Factor w/ 2 levels ""0"",""1"": 1 1 2 2 2 1 2 2 1 2 ...
    $ inst  : Factor w/ 3 levels ""1"",""2"",""3"": 1 1 1 1 1 1 1 1 1 1 ...
</code></pre>

<p><p>I'm fairly certain that whatever solution you folks come up with, it ought to be easy to generalize to any n number of variables that'd need to get reclassified, and would work across most common conversions (<code>int -> factor</code> and <code>num -> int</code>, for example).</p>

<h3> No matter what solution you folks generate, it's <strong>bound</strong> to be more elegant than mine</h3>

<p><p>Because my current clunky code is just 9 separate <code>factor()</code> statements, one for each variable, like this</p>

<pre>    factorData.df$ques01 </pre>

<p>
I'm brand-new to R, programming, and stackoverflow. Please be gentle, and thanks in advance for your help!
</p>
"
1489526,92287,2009-09-28T21:42:03Z,4,Trying to loop through a dataframe and reference multiple fields,"<p>I have a dataframe with Address, City, State, Zip entities.  From there, I'm trying to use the Yahoo APIs to Geocode each address.</p>

<p>I'm basing this off the code in O'Reilly's Data Mashups using R Tutorial.  The original example takes a vector of street addresses and uses a hard-coded city.  I'm trying to make a dynamic example that supports multiple cities.</p>

<p>The abbreviated version of the code is:</p>

<pre><code>    geocodeAddresses&lt;-function(myStreets)
    }
  appid&lt;-'&lt;put your appid here&gt;'
          baseURL&lt;-""http://local.yahooapis.com/MapsService/V1/geocode?appid=""
          myGeoTable&lt;-data.frame(address=character(),lat=numeric(),long=numeric(),EID=numeric())
          for (myStreet in myStreets){  
            requestUrl&lt;-paste(baseURL, appid, ""&amp;street="", URLencode(myStreet$address),""&amp;city="",URLencode(myStreet$city),""&amp;state="",URLencode(myStreet$state),sep="""")
            xmlResult&lt;-xmlTreeParse(requestUrl,isURL=TRUE,addAttributeNamespaces=TRUE)
            geoResult&lt;-xmlResult$doc$children$ResultSet$children$Result
            lat&lt;-xmlValue(geoResult[['Latitude']])
            long&lt;-xmlValue(geoResult[['Longitude']])
            myGeoTable&lt;-rbind(myGeoTable,data.frame(address=myStreet,Y=lat,X=long,EID=NA))
          }
    }
</code></pre>

<p>When I try and reference myStreet$City and myStreet$Address, I receive error</p>

<pre><code>$ operator is invalid for atomic vectors
</code></pre>

<p>Other than looping through data frame myStreets, I don't know how I can make the call to the Yahoo API only once for each row and store both the long/lat for each member.</p>
"
1489788,NA,2009-09-28T23:02:27Z,3,Trying to return a specified number of characters from a gene sequence in R,"<p>I have a DNA sequence like: <code>cgtcgctgtttgtcaaagtcg....</code></p>

<p>that is possibly 1000+ letters long.  </p>

<p>However, I only want to look at letters 5 to 200, for example, and to define this subset of the string as a new object.</p>

<p>I tried looking at the <code>nchar</code> function, but haven't found something that would do this.</p>
"
1491124,74936,2009-09-29T07:52:21Z,7,Rounding output from by function in R,"<p>I'm trying to round an output from a simple <code>by()</code> function in <code>R</code>. This is what I have:</p>

<pre><code>&gt; by(glaciers[,1:3],glaciers$activity.level,mean)

glaciers$activity.level: Active
       aspect  sun.duration      latitude 
-9.444444e+00  1.771778e+03  3.247643e+09 
-------------------------------------------
glaciers$activity.level: Inactive
      aspect sun.duration     latitude 
1.041667e+01 2.067583e+03 4.048301e+09 
-------------------------------------------
glaciers$activity.level: Relict
      aspect sun.duration     latitude 
1.766667e+01 2.168000e+03 2.759283e+09 
</code></pre>

<p>How can I get my output to round to say 5 decimal places, and still keep the factors?</p>

<p>I've tried: <code>round(by(glaciers[,1:3],glaciers$activity.level,mean),5)</code> but get an error: <code>Non-numeric argument to mathematical function</code>.</p>
"
1493969,160588,2009-09-29T17:35:31Z,36,How to insert elements into a vector?,"<p>I have a logical vector, for which I wish to insert new elements at particular indexes. I've come up with a clumsy solution below, but is there a neater way?</p>

<pre><code>probes &lt;- rep(TRUE, 15)
ind &lt;- c(5, 10)
probes.2 &lt;- logical(length(probes)+length(ind))
probes.ind &lt;- ind + 1:length(ind)
probes.original &lt;- (1:length(probes.2))[-probes.ind]
probes.2[probes.ind] &lt;- FALSE
probes.2[probes.original] &lt;- probes

print(probes)
</code></pre>

<p>gives</p>

<pre><code>[1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
</code></pre>

<p>and</p>

<pre><code>print(probes.2)
</code></pre>

<p>gives</p>

<pre><code>[1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE
[13]  TRUE  TRUE  TRUE  TRUE  TRUE
</code></pre>

<p>So it works but is ugly looking - any suggestions?</p>
"
1496582,177541,2009-09-30T07:29:28Z,7,How to convert vector from 1-row table in R,"<p>In R, I have a 1-row table. How do I convert that to a vector?</p>

<p>Specifically, the table is this:</p>

<pre><code> 0  1  2  3  4 
21 35 46 62 36 
</code></pre>

<p>I've tried bracket notation but to no avail!</p>
"
1496647,74658,2009-09-30T07:51:00Z,1,How to apply Min or Max to each result of a function separately?,"<p>I have a function to calculate the inverse of a quadratic equation.  By default it gives the two possible solutions:</p>

<pre><code>invquad&lt;-function(a,b,c,y,roots=""both"")
{
    #Calculate the inverse of a quadratic function y=ax^2+bx+c (i.e. find x when given y.)
    #Gives NaN with non real solutions.
    root1&lt;-sqrt((y-(c-b^2/(4*a)))/a)-(b/(2*a))
    root2&lt;--sqrt((y-(c-b^2/(4*a)))/a)-(b/(2*a))
    if (roots==""both"")
        result&lt;-c(root1,root2)
    if (roots==""min"")
        result&lt;-min(root1,root2)
    if (roots==""max"")
        result&lt;-max(root1,root2)
    result
}
</code></pre>

<p>This works fine if given a single value of y, but if I give it a list or a column from a dataframe, then the min and max elements give me the minimum value of the whole list. I want it to return just the minimum result for that element.  I'm assuming iterating over the list is possible, but it is not very efficient.</p>

<p>Any ideas ?</p>
"
1497539,177541,2009-09-30T11:23:08Z,71,Fitting a density curve to a histogram in R,"<p>Is there a function in R that fits a curve to a histogram?</p>

<p>Let's say you had the following histogram</p>

<pre><code>hist(c(rep(65, times=5), rep(25, times=5), rep(35, times=10), rep(45, times=4)))
</code></pre>

<p>It looks normal, but it's skewed. I want to fit a normal curve that is skewed to wrap around this histogram.</p>

<p>This question is rather basic, but I can't seem to find the answer for R on the internet.</p>
"
1502910,182378,2009-10-01T09:32:31Z,39,How can I count runs in a sequence?,"<p>In R, what would be the most efficient/simplest way to count runs of identical elements in a sequence?</p>

<p>For example, how to count the numbers of consecutive zeros in a sequence of non-negative integers:</p>

<pre><code>x &lt;- c(1,0,0,0,1,0,0,0,0,0,2,0,0) # should give 3,5,2
</code></pre>
"
1504318,162832,2009-10-01T14:31:33Z,4,Associate .Rnw with vim latex suite,"<p>This I am sure is really basic stuff. I am just beginning using gvim and latex-suite. However I would like latex-suite to load when I edit a sweavefile with.Rnw extension.</p>

<p>my .vimrc looks like this</p>

<pre><code>"" These settings are needed for latex-suite
filetype indent on
filetype plugin on
filetype on
let g:tex_flavor='latex'
set grepprg=grep\ -nH\ $*
""let g:Tex_Folding=0 ""I don't like folding.
set iskeyword+=:
</code></pre>

<p>and I guess there is some option I can set here that makes vim treat Rnw as .tex?</p>
"
1504709,147427,2009-10-01T15:39:53Z,1,Pipe ESS to terminal outside of Emacs?,"<p>I'm not sure if this is possible, but does anyone know if I can pipe ESS commands (i.e. evaluate region) to a R process running outside of Emacs? The Emacs terminal hangs up a bit (more often than Apple's terminal) and I'd like to just ditch it, while still using ESS commands. Currently I am doing the less efficient copy and paste technique :-)</p>

<p>Vince</p>
"
1504832,170792,2009-10-01T16:00:14Z,2,"Help me replace a for loop with an ""apply"" function","<p>...if that is possible</p>

<p>My task is to find the longest streak of continuous days a user participated in a game.</p>

<p>Instead of writing an sql function, I chose to use the R's rle function, to get the longest streaks and then update my db table with the results.</p>

<p>The (attached) dataframe is something like this:</p>

<pre><code>    day      user_id
2008/11/01    2001
2008/11/01    2002
2008/11/01    2003
2008/11/01    2004
2008/11/01    2005
2008/11/02    2001
2008/11/02    2005
2008/11/03    2001
2008/11/03    2003
2008/11/03    2004
2008/11/03    2005
2008/11/04    2001
2008/11/04    2003
2008/11/04    2004
2008/11/04    2005
</code></pre>

<p>I tried the following to get per user longest streak</p>

<pre><code># turn it to a contingency table
my_table &lt;- table(user_id, day)

# get the streaks
rle_table &lt;- apply(my_table,1,rle)

# verify the longest streak of ""1""s for user 2001
# as.vector(tapply(rle_table$'2001'$lengths, rle_table$'2001'$values, max)[""1""])

# loop to get the results
# initiate results matrix
res&lt;-matrix(nrow=dim(my_table)[1], ncol=2)

for (i in 1:dim(my_table)[1]) {
string &lt;- paste(""as.vector(tapply(rle_table$'"", rownames(my_table)[i], ""'$lengths, rle_table$'"", rownames(my_table)[i], ""'$values, max)['1'])"", sep="""")
res[i,]&lt;-c(as.integer(rownames(my_table)[i]) , eval(parse(text=string)))
}
</code></pre>

<p>Unfortunately this for loop takes too long and I' wondering if there is a way to produce the res matrix using a function from the ""apply"" family.</p>

<p>Thank you in advance </p>
"
1508513,140823,2009-10-02T09:16:36Z,0,Selectively replacing columns in R with their delta values,"<p>I've got data being read into a data frame R, by column.  Some of the columns will increase in value; for those columns only, I want to replace each value (n) with its difference from the previous value in that column.  For example, looking at an individual column, I want</p>

<pre><code>c(1,2,5,7,8)
</code></pre>

<p>to be replaced by</p>

<pre><code>c(1,3,2,1)
</code></pre>

<p>which are the differences between successive elements</p>

<p>However, it's getting really late in the day, and I think my brain has just stopped working.  Here's my code at present</p>

<pre><code>col1 &lt;- c(1,2,3,4,NA,2,3,1) # This column rises and falls, so we want to ignore it
col2 &lt;- c(1,2,3,5,NA,5,6,7) # Note: this column always rises in value, so we want to replace it with deltas
col3 &lt;- c(5,4,6,7,NA,9,3,5) # This column rises and falls, so we want to ignore it
d &lt;- cbind(col1, col2, col3)
d
fix_data &lt;- function(data) {
    # Iterate through each column...
    for (column in data[,1:dim(data)[2]]) {
        lastvalue &lt;- 0
        # Now walk through each value in the column, 
        # checking to see if the column consistently rises in value
        for (value in column) {
            if (is.na(value) == FALSE) { # Need to ignore NAs
                if (value &gt;= lastvalue) {
                    alwaysIncrementing &lt;- TRUE
                } else {
                    alwaysIncrementing &lt;- FALSE
                    break
                }
            }
        }

        if (alwaysIncrementing) {
            print(paste(""Column"", column, ""always increments""))
        }

        # If a column is always incrementing, alwaysIncrementing will now be TRUE
        # In this case, I want to replace each element in the column with the delta between successive
        # elements.  The size of the column shrinks by 1 in doing this, so just prepend a copy of
        # the 1st element to the start of the list to ensure the column length remains the same
        if (alwaysIncrementing) {
            print(paste(""This is an incrementing column:"", colnames(column)))
            column &lt;- c(column[1], diff(column, lag=1))
        }
    }
    data
}

fix_data(d)
d
</code></pre>

<p>If you copy/paste this code into RGui, you'll see that it doesn't do anything to the supplied data frame.</p>

<p>Besides losing my mind, what am I doing wrong??</p>

<p>Thanks in advance</p>
"
1508889,74658,2009-10-02T10:57:21Z,7,How to count number of Numeric values in a column,"<p>I have a dataframe, and I want to produce a table of summary statistics including number of valid numeric values, mean and sd by group for each of three columns.  I can't seem to find any function to count the number of numeric values in R.  I can use length() which tells me how many values there are, and I can use colSums(is.na(x)) to count the number of NA values, but colSums(is.numeric(x)) doesn't work the same way.</p>

<p>I could use tapply with { length - number of NA values - number of blank values - number of text values } but surely there's an easier way.</p>

<p>My data (I want to group by Nominal, and produce summary stats on Actual, LinPred and QualPred)</p>

<pre><code>structure(list(Nominal = c(1, 3, 6, 10, 30, 50, 150, 250, 1, 
3, 6, 10, 30, 50, 150, 250, 1, 3, 6, 10, 30, 50, 150, 250, 1, 
3, 6, 10, 30, 50, 150, 250, 1, 3, 6, 10, 30, 50, 150, 250, 1, 
3, 6, 10, 30, 50, 150, 250, 1, 3, 6, 10, 30, 50, 150, 250, 1, 
3, 6, 10, 30, 50, 150, 250, 1, 3, 6, 10, 30, 50, 150, 250), Actual = c(NA, 
0.422, 0.782, 1.25, 3.85, 6.94, 18.8, 31.2, 0.118, 0.361, 0.747, 
1.18, 3.58, 5.82, 16.7, 29, 0.113, 0.382, 0.692, 1.12, 3.51, 
5.43, 17.1, 28.7, 0.134, 0.402, 0.718, 1.25, 3.65, 6.52, NA, 
28.8, 0.123, 0.396, 0.664, 1.12, 3.83, 5.6, NA, 28.1, 0.112, 
0.341, 0.7, 1.08, 3.25, 5.97, NA, 27.1, 0.106, 0.35, 0.674, 1.14, 
3.28, 5.5, 17.3, 30, 0.122, 0.321, 0.673, 1.22, 3.41, 5.85, 17.6, 
28.1, 0.129, 0.351, 0.737, 1.06, 3.39, 5.53, 15.9, 28.5), LinPred = c(NA, 
3.49519490135683, 6.4706724568458, 10.3387932789814, 31.8283534019573, 
57.3678690865708, 155.393324109068, 257.881995464799, 0.982569410055046, 
2.99101676001009, 6.18138991672881, 9.76022819874748, 29.5967452353405, 
48.1108278028274, 138.036371702049, 239.698521514589, 0.941243332895477, 
3.16458628408028, 5.72680306797355, 9.26431527283265, 29.0181801551066, 
44.887393784381, 141.342457874815, 237.218956885015, 1.07941778099747, 
3.36900393602722, 6.0686652233011, 10.6136646056736, 31.1174212178803, 
55.6364968333108, NA, 245.979704049963, 0.98544222985819, 3.3177445444967, 
5.60733069952645, 9.50304445584572, 32.6552029637958, 47.7767234652982, 
NA, 239.999441704736, 0.89146667871891, 2.8478667888003, 5.91488704870955, 
9.1613151789756, 27.7001284491792, 50.9377192763467, NA, 231.456209782983, 
0.887738051402174, 3.04188235451485, 5.9023034783202, 10.0163659588551, 
28.9092709123842, 48.5084526866061, 152.684283738776, 264.805729023739, 
1.02899341554071, 2.78585700701375, 5.89347501806154, 10.7226427795477, 
30.0569707460098, 51.5984137771366, 155.332821816374, 248.031654532288, 
1.09079263735132, 3.05071081477351, 6.45849647461568, 9.31008913816238, 
29.8804015408367, 48.7733064943658, 140.324439376654, 251.563038635751
), QuadPred = c(NA, 3.46077095737974, 6.38659713413108, 10.1956079501556, 
31.4700369979564, 57.0089799611706, 157.775316006369, 268.303966059862, 
0.99289436409299, 2.96536517477853, 6.10198249392715, 9.62549220297933, 
29.2517496204359, 47.7196128593832, 139.600469198163, 248.272682787657, 
0.95232583127381, 3.13590297331348, 5.65480031033985, 9.13693141349813, 
28.6769820181676, 44.4936547741659, 143.050878627236, 245.555818447238, 
1.08417831830729, 3.33895371044810, 6.00044125019758, 10.4882228621509, 
30.8451526869812, 55.4331759085967, NA, 256.446833964951, 0.991679220421247, 
3.28844923081897, 5.54540949253351, 9.3907657095483, 32.3793538902883, 
47.5218142460371, NA, 249.828516445647, 0.899183876120787, 2.82554368740693, 
5.84875388286628, 9.05319326862309, 27.4395572248486, 50.7001828907023, 
NA, 240.411024762687, 0.884412915928806, 3.05257006009469, 5.93046554432476, 
10.0673979669, 29.0311859234644, 48.645035648271, 151.914544909710, 
261.273991566153, 1.02660962824666, 2.79491765184684, 5.92158513760114, 
10.7773327827008, 30.1813919027873, 51.7318741314584, 154.518856412401, 
245.027488125567, 1.08881969774848, 3.06145444119556, 6.48990638077339, 
9.35738460692028, 30.0044505131336, 48.9096796323938, 139.747394069421, 
248.451100154569)), .Names = c(""Nominal"", ""Actual"", ""LinPred"", 
""QuadPred""), row.names = c(NA, -72L), class = ""data.frame"")
</code></pre>
"
1510039,144537,2009-10-02T14:55:17Z,6,Finding uncommon elements across multiple vectors,"<p>I am attempting to find the elements that are not common across multiple vectors. That is, I want to know exactly the elements (not just their position, etc.) that are not shared across all vectors.</p>

<p>The best implementation I could come up with uses a nested-loop, which I realize is probably the least efficient, most notably because the execution is still running as I write this.  Here is what I came up with. (each *.id is a vector of Supreme Court case ID's stored as strings).</p>

<pre><code>check.cases&lt;-TRUE

if(check.cases) {
    all.cases&lt;-c(AMKennedy.id,AScalia.id,CThomas.id,DHSouter.id,JGRoberts.id,JPStevens.id,RBGinsburg.id,SAAlito.id,SGBreyer.id)
    bad.cases&lt;-c()
    for(b in all.cases) {
        for(t in all.cases) {
            m&lt;-match(t,b)
            bad&lt;-t[which(is.na(m))]
            bad.cases&lt;-append(bad.cases,bad)
        }
    }
    bad.cases&lt;-unique(bad.cases)
}

print(bad.cases)
</code></pre>

<p>There must be a more efficient way of doing this?</p>
"
1511431,165452,2009-10-02T19:44:08Z,8,Count by factor in ggplot2 chart,"<p>Given the following ggplot2 chart:</p>

<pre><code>ggplot(my_data, aes(colour=my_factor) +   
                geom_point(aes(x=prior, y=current)) +   
                facet_grid(gender ~ age)
</code></pre>

<p>I would like to make the size of the points be proportional to the count of my_factor for that prior/current combination.</p>

<pre><code>ggplot(my_data, aes(colour=my_factor, 
                size=&lt;something-here&gt;(my_factor)) +   
                geom_point(aes(x=prior, y=current)) + 
                facet_grid(gender ~ age)
</code></pre>

<p>Any ideas?</p>

<p>== Edit ==</p>

<p>Here's a very trivial example based on mpg dataset. Let's define ""great_hwy"" as hwy > 35, and ""great_cty"" as cty > 25:</p>

<pre><code>mpg$great_hwy[mpg$hwy &gt; 35]  &lt;-1
mpg$great_hwy[mpg$hwy &lt;= 35] &lt;-0
mpg$great_hwy &lt;- factor(mpg$great_hwy)

mpg$great_cty[mpg$cty &gt; 25]  &lt;- 1
mpg$great_cty[mpg$cty &lt;= 25] &lt;- 0
mpg$great_cty &lt;- factor(mpg$great_cty)
</code></pre>

<p>If we plot great_hwy vs. great_cty, it won't tell us much:</p>

<pre><code>ggplot(mpg) + geom_point(aes(x=great_cty, y=great_hwy))
</code></pre>

<p>How could I make the data points bigger in size depending on the number of x/y points? Hope this clears it up, but let me know otherwise.</p>
"
1515143,142879,2009-10-03T23:30:02Z,2,Platform-specific graphic device,"<p>I'd like to write a function that takes a filename and produces a .pdf file on a *nix platform and a .wmf on a windows platform with that filename and width of 6 inches height 4.</p>

<pre><code>graph &lt;- function(filename){
setwd(""graphics"")
ext &lt;- ifelse(.Platform$OS.type == ""unix"", ""pdf"", ""wmf"")
name &lt;- paste(filename, ext, sep=""."")
ifelse(.Platform$OS.type == ""unix"", pdf(name, width=6, height=4), wmf(name, width=6, height=4))
}
</code></pre>

<p>That's my attempt but I'm getting this error</p>

<p>Error in ans[test &amp; !nas] &lt;- rep(yes, length.out = length(ans))[test &amp;  : 
  replacement has length zero</p>

<p>any ideas? I feel like I'm overlooking something.</p>
"
1515193,142477,2009-10-03T23:53:14Z,8,converting a matrix of lists to a regular matrix,"<p>Take the following code:</p>

<pre><code>foo &lt;- list()
foo[[1]] &lt;- list(a=1, b=2)
foo[[2]] &lt;- list(a=11, b=22)
foo[[3]] &lt;- list(a=111, b=222)
result &lt;- do.call(rbind, foo)
result[,'a']
</code></pre>

<p>In this case, <code>result[,'a']</code> shows a list.  Is there a more elegant way such that <code>result</code> is a ""regular"" matrix of vectors?  I imagine there are manual ways of going about this, but I was wondering if there was an obvious step that I was missing.</p>
"
1521390,180626,2009-10-05T17:37:12Z,3,Conditionally grouped histograms from my dataset,"<p>My current dataset <code>data.df</code> comes from about 420 students who took an 8-question survey under one of 3 instructors. <code>escore</code> is my outcome variable of interest.
</p></p>

<pre><code>
    'data.frame':   426 obs. of  10 variables:
     $ ques01: int  1 1 1 1 1 1 0 0 0 1 ...
     $ ques02: int  0 0 1 1 1 1 1 1 1 1 ...
     $ ques03: int  0 0 1 1 0 0 1 1 0 1 ...
     $ ques04: int  1 0 1 1 1 1 1 1 1 1 ...
     $ ques05: int  0 0 0 0 1 0 0 0 0 0 ...
     $ ques06: int  1 0 1 1 0 1 1 1 1 1 ...
     $ ques07: int  0 0 1 1 0 1 1 0 0 1 ...
     $ ques08: int  0 0 1 1 1 0 1 1 0 1 ...
     $ inst  : Factor w/ 3 levels ""1"",""2"",""3"": 1 1 1 1 1 1 1 1 1 1 ...
     $ escore: int  3 1 5 5 3 3 4 4 2 5 ...
     </code></pre>

<p>
I'm wondering how I can generate <code>escore</code> histograms that are conditionally separated based upon the value of <code>inst</code> for a given observation. In my head, the pseudo-code might look like this:</p>

<p>
<pre><code>
    par(mfrow=c(1,3)) 
    hist(escore, data.df$inst = 1)
    hist(escore, data.df$inst = 2)
    hist(escore, data.df$inst = 3)
</code></pre>
</p>

<p>but of course that won't work :-(</p>

<p>Ideally, my histograms would look like this:</p>

<p><a href=""http://terpconnect.umd.edu/~briandk/escoreHistogramsbyInstructor-1.png"" rel=""nofollow noreferrer"">3 separate histograms of ~140 observations each, grouped according to their &quot;inst&quot; value http://terpconnect.umd.edu/~briandk/escoreHistogramsbyInstructor-1.png</a></p>

<p>As usual, I sense there's got to be an easy way to do this. In whatever ""conditional/grouping"" sense I can extract these graphs from my data, I assume it's <strong>got</strong> to be generalizable for all sorts of plots you'd want to make based on certain conditions.</p>

<p>Also, I'm really sorry if this question has been answered before. My primary difficulty is in figuring out how to ask it in a way that makes sense.</p>

<p>Thanks in advance for your help!</p></p>
"
1523126,144157,2009-10-06T00:55:21Z,82,How to read data when some numbers contain commas as thousand separator?,"<p>I have a csv file where some of the numerical values are expressed as strings with commas as thousand separator, e.g. <code>""1,513""</code> instead of <code>1513</code>. What is the simplest way to read the data into R?</p>

<p>I can use <code>read.csv(..., colClasses=""character"")</code>, but then I have to strip out the commas from the relevant elements before converting those columns to numeric, and I can't find a neat way to do that.</p>
"
1523298,37751,2009-10-06T02:12:38Z,7,Plotting predefined density functions using ggplot and R,"<p>I have three data sets of different lengths and I would like to plot density functions of all three on the same plot. This is straight forward with base graphics:</p>

<pre><code>n &lt;- c(rnorm(10000), rnorm(10000))
a &lt;- c(rnorm(10001), rnorm(10001, 0, 2))
p &lt;- c(rnorm(10002), rnorm(10002, 2, .5))

plot(density(n))
lines(density(a))
lines(density(p))
</code></pre>

<p>Which gives me something like this:</p>

<p><a href=""http://www.cerebralmastication.com/wp-content/uploads/2009/10/density.png"" rel=""nofollow noreferrer"">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/10/density.png</a></p>

<p>But I really want to do this with GGPLOT2 because I want to add other features that are only available with GGPLOT2. It seems that GGPLOT really wants to take my empirical data and calculate the density for me. And it gives me a bunch of lip because my data sets are of different lengths. So how do I get these three densities to plot in GGPLOT2?</p>
"
1524088,147427,2009-10-06T07:34:10Z,3,Installing a local package that's not a .tar.gz,"<p>I'm working on a script that creates a package in the current directory (using pdInfoBuilder from BioConductor), and I'd like to install it while the script is running. <code>install.packages()</code> with repo=NULL seems like an obvious choice, but this seems to only except package directories tarballed and gzipped. Is there a way I can override this, since the <code>create.pkg()</code> function doesn't create a *.tar.gz? Currently I am using:</p>

<pre><code>R CMD INSTALL package.name
</code></pre>

<p>Thanks,
Vince</p>
"
1528428,185281,2009-10-06T22:27:55Z,2,MCMClogit confusion,"<p>Could anybody explain to me why</p>

<pre><code>simulatedCase &lt;- rbinom(100,1,0.5)
simDf &lt;- data.frame(CASE = simulatedCase)
posterior_m0 &lt;&lt;- MCMClogit(CASE ~ 1, data = simDf, b0 = 0, B0 = 1)
</code></pre>

<p>always results in a MCMC acceptance ratio of 0? Any explanation would be greatly appreciated!</p>
"
1529559,182378,2009-10-07T05:00:23Z,3,How do I dichotomise efficiently,"<p>Is there a more ""R-minded"" way to dichotomise efficiently? Thanks.</p>

<pre><code>y&lt;-c(0,3,2,1,0,0,2,5,0,1,0,0);b&lt;-vector()

for (k in 1:length(y)) {
    if (y[k] == 0) b[k] = 0
    else
        b[k] = 1
}
y;b
</code></pre>
"
1530999,185556,2009-10-07T11:17:16Z,1,LanguageR/ lme4: any help on p-values for models with random correlation parameters?,"<p>I used the package languageR for mixed effect models with the syntax at the end of this posting. I can use pvals.fnc to get p-values for model 1 and 3 (hd_lmer1 and hd_lmer2). Using this with model two gives the following error message:</p>

<blockquote>
  <p>p2 = pvals.fnc(hd_lmer2)
  Error in pvals.fnc(hd_lmer2) : 
    MCMC sampling is not yet implemented in lme4_0.999375
    for models with random correlation parameters</p>
</blockquote>

<p>I'd be grateful if any one could help me out on how to get p-values for such models.</p>

<p>Models:</p>

<pre><code> hd_lmer1 &lt;- lmer(rot~ time + group + sex + gen + (1 | subject) + (1|rot.pre), data = data_long,REML = TRUE)
 hd_lmer2 &lt;- lmer(rot~ time + group + sex + gen + (time | subject) + (1|rot.pre), data = data_long,REML = TRUE)
 hd_lmer3 &lt;- lmer(rot~ time*group + sex + gen + (1 | subject) + (1|rot.pre), data = data_long,REML = TRUE)
</code></pre>
"
1532535,37751,2009-10-07T15:56:02Z,8,Showing multiple axis labels using ggplot2 with facet_wrap in R,"<p>I've got a nice facet_wrap density plot that I have created with ggplo2. I would like for each panel to have x and y axis labels instead of only having the y axis labels along the left side and the x labels along the bottom. What I have right now looks like this:</p>

<pre><code>library(ggplot2)
myGroups &lt;- sample(c(""Mo"", ""Larry"", ""Curly""), 100, replace=T)
myValues &lt;- rnorm(300)
df &lt;- data.frame(myGroups, myValues)


p &lt;- ggplot(df)  + 
  geom_density(aes(myValues), fill = alpha(""#335785"", .6)) + 
  facet_wrap(~ myGroups)
p
</code></pre>

<p>Which returns:</p>

<p><a href=""http://www.cerebralmastication.com/wp-content/uploads/2009/10/3stooges.png"" rel=""nofollow noreferrer"">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/10/3stooges.png</a></p>

<p>It seems like this should be simple, but my Google Fu has been too poor to find an answer. </p>
"
1535086,176696,2009-10-08T01:12:24Z,0,Problem with R rendering base Graphics in CentOS 4,"<p>Hi we're trying to get R with the standard gui loaded onto CentOS 4, and under certain users R will not render certain graphics.  When logged in as root the graphics render, but under the restricted user they don't.  The graphics don't render with the error:</p>

<pre><code>&gt; testdata &lt;- rbind(c(1,2,3,4,5,6),c(3,4,5,4,6,2),c(3,6,7,2,2,1),c(5,4,9,8,9,1))
&gt; pairs(testdata)
Error in text.default(x, y, txt, cex = cex, font = font) : 
 X11 font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 1 at size 16 could not be loaded
</code></pre>

<p>Anyone come across this one or have any ideas?</p>

<p>Thanks</p>
"
1536486,143476,2009-10-08T08:44:56Z,1,"emacs, auctex, noweb-mode - how to keep screen from recentering around point?","<p>When in auctex and noweb-mode (using Sweave in emacs), I find it distracting when the screen recenters itself as I use next-line, previous-line, etc. (C-n, C-p, and mouse-1). Does anyone know how to turn it off? Thanks much!</p>
"
1536590,85514,2009-10-08T09:07:24Z,18,How to select rows from data.frame with 2 conditions,"<p>I have an aggregated table:</p>

<pre><code>&gt; aggdata[1:4,]
  Group.1 Group.2         x
1       4    0.05 0.9214660
2       6    0.05 0.9315789
3       8    0.05 0.9526316
4      10    0.05 0.9684211
</code></pre>

<p>How can I select the x value when I have values for Group.1 and Group.2?</p>

<p>I tried:</p>

<pre><code>aggdata[aggdata[,""Group.1""]==l &amp;&amp; aggdata[,""Group.2""]==lamda,""x""]
</code></pre>

<p>but that replies all x's.</p>

<p>More info:
I want to use this like this:</p>

<pre><code>table = data.frame();
for(l in unique(aggdata[,""Group.1""])) {
    for(lambda in unique(aggdata[,""Group.2""])) {
        table[l,lambda] = aggdata[aggdata[,""Group.1""]==l &amp; aggdata[,""Group.2""]==lambda,""x""]
    }
}
</code></pre>

<p>Any suggestions that are even easier and giving this result I appreciate!</p>
"
1538798,121704,2009-10-08T16:06:06Z,6,Reorder dataframe columns while ignoring unidentified columns,"<p>I'm thinking there's got to be a better way to do this.</p>

<p>I'm trying to reorder the columns in a dataframe. I have a list, <code>ordered.colnames</code>, representing the new ordering -- but <em>some of the columns don't exist</em> in <code>dataset</code>. To avoid the Error ""<code>undefined columns selected</code>"", I've wrapped the relevant slicing in a <code>try()</code> function.</p>

<p>The following method works, but is there a better way to do this?</p>

<pre><code>&gt; ordered.colnames[1:5]
[1] ""lady_22102""         ""attentions_83249""   ""perseverance_17864""
[4] ""cecil_84477""        ""cecilia_133476""

dataset.reordered = c() 
for (i in 1:length(ordered.colnames)) {
    col = NA
    col = try(cbind(dataset[,ordered.colnames[i]]),silent=TRUE)
    if (!inherits(col,""try-error"")) {
        colnames(col) = ordered.colnames[i]
        dataset.reordered = cbind(dataset.reordered, col) 
    }
}
</code></pre>
"
1541679,186891,2009-10-09T03:43:15Z,7,Preventing overwriting of files when using save() or save.image(),"<p>I am trying to find a way to stop accidental overwriting of files when using the save() and save.image() function in R. </p>
"
1544907,162832,2009-10-09T16:49:34Z,17,melt to two variable columns,"<p>I have the following variables in a data frame:</p>

<pre><code>[1] ""Type""   ""I.alt""  ""idx06""  ""idx07""  ""idx08"" ""farve1"" ""farve2""
</code></pre>

<p>If I do:</p>

<pre><code>dm &lt;- melt(d, id=c(""Type"",""I.alt""))
</code></pre>

<p>I get these variables:</p>

<pre><code>""Type""     ""I.alt""    ""variable"" ""value""   
</code></pre>

<p>Where ""idx06"", ""idx07"",  ""idx08"", ""farve1"", ""farve2"" are represented in ""variable"".</p>

<p>But what I really want is something like this:</p>

<pre><code>""Type""     ""I.alt""    ""variable"" ""value"" ""variable2"" ""value2""
</code></pre>

<p>Where ""farve1"" and ""farve2"" are represented in variable2 and value2.</p>

<p>The reason I want to do this, is that I'd like something where the line color is green if the value is falling and red if rising.
<strong>EDIT: Shane has shown how to reshape the data via two melts merged. But my strategy seams to be ill conceived from the beginning - WRONG in one word. See my comment to Shane's solution.</strong></p>

<pre><code>ggplot(dm, aes(x=variable,y=value,group=Type,col=variable2, label=Type,size=I.alt))+
geom_line()+
geom_text(data=subset(dm, variable==""idx08""),hjust=-0.2, size=2.5)+
theme_bw()+
scale_x_discrete(expand=c(0,1))+
opts(legend.position=""none"")
</code></pre>

<p>I assume I need to cast the molten frame - but I can't figure it out.
The data:</p>

<pre><code>d &lt;- structure(list(Type = structure(c(8L, 21L, 23L, 20L, 6L, 14L, 
3L, 24L, 2L, 28L, 32L, 22L, 15L, 29L, 1L, 17L, 18L, 33L, 25L, 
13L, 30L, 11L, 26L, 9L, 12L, 4L, 5L, 27L, 16L, 19L, 10L, 31L, 
7L), .Label = c(""Alvorligere vold"", ""Andre strafferetlige særlove"", 
""Andre tyverier"", ""Bedrageri"", ""Brandstiftelse"", ""Butikstyverier m.v."", 
""Dokumentfalsk"", ""Færdselslovovertræd. i øvrigt"", ""Færdselsuheld med spiritus"", 
""Falsk forklaring i øvrigt"", ""Forbr. mod off. myndighed m.v."", 
""Freds- og ærekrænkelser"", ""Hæleri"", ""Hærværk"", ""Indbrud i bank, forretn. m.v."", 
""Indbrud i fritidshuse, garager mv"", ""Indbrud i villaer, lejligheder mv"", 
""Love vedr. forsvaret og lign."", ""Love vedr. spil, bev., næring"", 
""Lov om euforiserende stoffer"", ""Mangler ved køretøj"", ""Røveri"", 
""Simpel vold"", ""Spiritus- og promillekørsel"", ""Trusler"", ""Tyv./brugstyv. af andet"", 
""Tyv./brugstyv. af cykel"", ""Tyv./brugstyv. af indr. køretøj"", 
""Tyv/brugstyv. af knallert"", ""Tyveri fra bil, båd m.v."", ""Ulovlig omgang med hittegods"", 
""Våbenloven"", ""Vold o.l. mod off. myndighed""), class = ""factor""), 
I.alt = c(16137L, 9519L, 5930L, 5502L, 4887L, 3582L, 3101L, 
1738L, 1660L, 1649L, 1551L, 1412L, 1338L, 1164L, 1154L, 1057L, 
931L, 907L, 857L, 724L, 681L, 644L, 641L, 505L, 450L, 419L, 
405L, 328L, 324L, 324L, 320L, 281L, 262L), idx06 = c(1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), idx07 = c(0.972675591417568, 
0.766866371450899, 0.931743805516597, 0.813047711781889, 
0.88728323699422, 0.96420233463035, 0.855743544078362, 1.03710247349823, 
0.751470588235294, 0.90443686006826, 0.808403361344538, 0.902834008097166, 
0.718181818181818, 0.904555314533623, 1.02717391304348, 0.68957345971564, 
1.10324483775811, 0.93030303030303, 0.805309734513274, 0.843003412969283, 
0.74914089347079, 0.824786324786325, 1.04060913705584, 1.09150326797386, 
0.977941176470588, 0.892405063291139, 0.966666666666667, 
0.828125, 0.696, 0.813559322033898, 0.697841726618705, 0.88235294117647, 
0.62280701754386), idx08 = c(0.986612873647533, 0.712685595207085, 
0.840579710144927, 0.865628042843233, 0.93757225433526, 0.823346303501945, 
0.905609973285841, 1.03356890459364, 0.689705882352941, 0.909556313993174, 
0.798319327731092, 0.955465587044534, 0.714545454545455, 
0.620390455531453, 1.10869565217391, 0.815165876777251, 0.64306784660767, 
0.818181818181818, 0.722713864306785, 0.627986348122867, 
0.59106529209622, 0.927350427350427, 1.21319796954315, 1.20915032679739, 
1.33088235294118, 0.759493670886076, 1.40833333333333, 0.734375, 
0.896, 0.932203389830508, 0.60431654676259, 0.872549019607843, 
0.675438596491228), farve1 = c(""green"", ""green"", ""green"", 
""green"", ""green"", ""green"", ""green"", ""red"", ""green"", ""green"", 
""green"", ""green"", ""green"", ""green"", ""red"", ""green"", ""red"", 
""green"", ""green"", ""green"", ""green"", ""green"", ""red"", ""red"", 
""green"", ""green"", ""green"", ""green"", ""green"", ""green"", ""green"", 
""green"", ""green""), farve2 = c(""red"", ""green"", ""green"", ""red"", 
""red"", ""green"", ""red"", ""green"", ""green"", ""red"", ""green"", 
""red"", ""green"", ""green"", ""red"", ""red"", ""green"", ""green"", 
""green"", ""green"", ""green"", ""red"", ""red"", ""red"", ""red"", ""green"", 
""red"", ""green"", ""red"", ""red"", ""green"", ""green"", ""red"")), .Names = c(""Type"", 
""I.alt"", ""idx06"", ""idx07"", ""idx08"", ""farve1"", ""farve2""), class = ""data.frame"", row.names = c(NA, -33L))
</code></pre>
"
1545302,124603,2009-10-09T18:15:47Z,2,Multiple data points in one R ggplot2 plot,"<p>I have two sets of data points that both relate to the same primary axis, but who differ in secondary axis. Is there some way to plot them on top of each other in R using ggplot2? </p>

<p>What I am looking for is basically something that looks like this:</p>

<pre>
4+           |
 | x       . + 220
3+     . .   |
 |   x       |
2+   .       + 210
 |     x     |
1+ .     x x |
 |           + 200
0+-+-+-+-+-+-+
     time   

   . temperatur
   x car sale
</pre>

<p>(This is just a example of possible data)</p>
"
1545591,162832,2009-10-09T19:12:53Z,4,how to make a (ggplot) line plot with different color segments conditional on direction,"<p>As per Shanes excellent <a href=""https://stackoverflow.com/questions/1544907/melt-to-two-variable-columns"" title=""excellent solution"">solution</a> of another question, I now realise that I do not know how to do this.</p>

<p>My original approach was to use melt the data (thanks again shane):</p>

<pre><code>dm1 &lt;- melt(d[,c(""Type"",""I.alt"",""idx06"",""idx07"",""idx08"")], id=c(""Type"",""I.alt""))
dm2 &lt;- melt(d[,c(""Type"",""I.alt"",""farve1"",""farve2"")], id=c(""Type"",""I.alt""))
colnames(dm2) &lt;- c(""Type"", ""I.alt"", ""variable2"", ""value2"")
dm &lt;- merge(dm1, dm2)
</code></pre>

<p>And then make the plot:</p>

<pre><code>ggplot(dm, aes(x=variable,y=value,group=Type,label=Type,size=I.alt))+
  geom_line(aes(col=value2))+
  geom_text(data=subset(dm, variable==""idx08""),hjust=-0.2, size=2.5)+
  theme_bw()+
  scale_x_discrete(expand=c(0,1))+
  opts(legend.position=""none"")+
  scale_colour_manual(values=c(""green"",""red""))
</code></pre>

<p>But it's not working (all the individual line pieces going ""up"" should be red, all going ""down"" should be green):</p>

<p><a href=""http://wana.dk/wp-content/uploads/2009/10/damn.png"" rel=""nofollow noreferrer"">BTW:does the png device insist on geom_point? http://wana.dk/wp-content/uploads/2009/10/damn.png</a></p>

<p>(bonus question 1: how can I use expand to only expand to the right? (where my labels ' at.))</p>

<p>(bonus question 2: Both png and pdf device shows up like above - i.e. with geom_points - this does not happen on my screen)</p>

<p>This is my data:</p>

<pre><code>d &lt;- structure(list(Type = structure(c(8L, 21L, 23L, 20L, 6L, 14L, 
3L, 24L, 2L, 28L, 32L, 22L, 15L, 29L, 1L, 17L, 18L, 33L, 25L, 
13L, 30L, 11L, 26L, 9L, 12L, 4L, 5L, 27L, 16L, 19L, 10L, 31L, 
7L), .Label = c(""Alvorligere vold"", ""Andre strafferetlige særlove"", 
""Andre tyverier"", ""Bedrageri"", ""Brandstiftelse"", ""Butikstyverier m.v."", 
""Dokumentfalsk"", ""Færdselslovovertræd. i øvrigt"", ""Færdselsuheld med spiritus"", 
""Falsk forklaring i øvrigt"", ""Forbr. mod off. myndighed m.v."", 
""Freds- og ærekrænkelser"", ""Hæleri"", ""Hærværk"", ""Indbrud i bank, forretn. m.v."", 
""Indbrud i fritidshuse, garager mv"", ""Indbrud i villaer, lejligheder mv"", 
""Love vedr. forsvaret og lign."", ""Love vedr. spil, bev., næring"", 
""Lov om euforiserende stoffer"", ""Mangler ved køretøj"", ""Røveri"", 
""Simpel vold"", ""Spiritus- og promillekørsel"", ""Trusler"", ""Tyv./brugstyv. af andet"", 
""Tyv./brugstyv. af cykel"", ""Tyv./brugstyv. af indr. køretøj"", 
""Tyv/brugstyv. af knallert"", ""Tyveri fra bil, båd m.v."", ""Ulovlig omgang med hittegods"", 
""Våbenloven"", ""Vold o.l. mod off. myndighed""), class = ""factor""), 
I.alt = c(16137L, 9519L, 5930L, 5502L, 4887L, 3582L, 3101L, 
1738L, 1660L, 1649L, 1551L, 1412L, 1338L, 1164L, 1154L, 1057L, 
931L, 907L, 857L, 724L, 681L, 644L, 641L, 505L, 450L, 419L, 
405L, 328L, 324L, 324L, 320L, 281L, 262L), idx06 = c(1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), idx07 = c(0.972675591417568, 
0.766866371450899, 0.931743805516597, 0.813047711781889, 
0.88728323699422, 0.96420233463035, 0.855743544078362, 1.03710247349823, 
0.751470588235294, 0.90443686006826, 0.808403361344538, 0.902834008097166, 
0.718181818181818, 0.904555314533623, 1.02717391304348, 0.68957345971564, 
1.10324483775811, 0.93030303030303, 0.805309734513274, 0.843003412969283, 
0.74914089347079, 0.824786324786325, 1.04060913705584, 1.09150326797386, 
0.977941176470588, 0.892405063291139, 0.966666666666667, 
0.828125, 0.696, 0.813559322033898, 0.697841726618705, 0.88235294117647, 
0.62280701754386), idx08 = c(0.986612873647533, 0.712685595207085, 
0.840579710144927, 0.865628042843233, 0.93757225433526, 0.823346303501945, 
0.905609973285841, 1.03356890459364, 0.689705882352941, 0.909556313993174, 
0.798319327731092, 0.955465587044534, 0.714545454545455, 
0.620390455531453, 1.10869565217391, 0.815165876777251, 0.64306784660767, 
0.818181818181818, 0.722713864306785, 0.627986348122867, 
0.59106529209622, 0.927350427350427, 1.21319796954315, 1.20915032679739, 
1.33088235294118, 0.759493670886076, 1.40833333333333, 0.734375, 
0.896, 0.932203389830508, 0.60431654676259, 0.872549019607843, 
0.675438596491228), farve1 = c(""green"", ""green"", ""green"", 
""green"", ""green"", ""green"", ""green"", ""red"", ""green"", ""green"", 
""green"", ""green"", ""green"", ""green"", ""red"", ""green"", ""red"", 
""green"", ""green"", ""green"", ""green"", ""green"", ""red"", ""red"", 
""green"", ""green"", ""green"", ""green"", ""green"", ""green"", ""green"", 
""green"", ""green""), farve2 = c(""red"", ""green"", ""green"", ""red"", 
""red"", ""green"", ""red"", ""green"", ""green"", ""red"", ""green"", 
""red"", ""green"", ""green"", ""red"", ""red"", ""green"", ""green"", 
""green"", ""green"", ""green"", ""red"", ""red"", ""red"", ""red"", ""green"", 
""red"", ""green"", ""red"", ""red"", ""green"", ""green"", ""red"")), .Names = c(""Type"", 
""I.alt"", ""idx06"", ""idx07"", ""idx08"", ""farve1"", ""farve2""), class = ""data.frame"", row.names = c(NA, -33L))
</code></pre>
"
1548913,56376,2009-10-10T19:57:34Z,4,Time series in R,"<p>I am tracking my body weight in a spread sheet but I want to improve the experience by using R. I was trying to find some information about time series analysis in R but I was not succesful.</p>

<p>The data I have here is in the following format:</p>

<p>date -> weight  -> body-fat-percentage  -> water-percentage</p>

<p>e.g.
10/08/09 -> 84.30 -> 18.20 -> 55.3</p>

<p>What I want to do</p>

<p>plot weight and exponential moving average against time</p>

<p>How can I achieve that?</p>
"
1551554,NA,2009-10-11T19:37:49Z,4,Constrained least squares,"<p>I am fitting a simple regression in R on gas usage per capita. The regression formulas looks like:</p>

<pre><code>gas_b &lt;- lm(log(gasq_pop) ~ log(gasp) + log(pcincome) + log(pn) +
            log(pd) + log(ps) + log(years), 
            data=gas)
summary(gas_b)
</code></pre>

<p>I want to include a linear constraint that the beta coefficients of <code>log(pn)+log(pd)+log(ps)=1</code> (sum to one).  Is there a simple way of implementing this (possibly in the <code>lm</code> function) in R without having to use <code>constrOptim()</code> function?</p>
"
1552438,NA,2009-10-12T02:37:07Z,1,Working with Data.frames in R (Using SAS code to describe what I want)r,"<p>I've been mostly working in SAS of late, but not wanting to lose what familiarity with R I have, I'd like to replicate something basic I've done. You'll forgive me if my SAS code isn't perfect, I'm doing this from memory since I don't have SAS at home.</p>

<p>In SAS I have a dataset that roughly is like the following example (. is equivalent of NA in SAS)</p>

<pre><code>A  B
1  1
1  3
0  .
0  1
1  0
0  0
</code></pre>

<p>If the dataset above was work.foo then I could do something like the following.</p>

<pre><code>/* create work.bar from dataset work.foo */
data work.bar;
set work.foo;

/* generate a third variable and add it to work.bar */
if a = 0 and b ge 1 then c = 1;
if a = 0 and b = 0  then c = 2;
if a = 1 and b ge 1 then c = 3;
if a = 1 and b = 0  then c = 4;
run;
</code></pre>

<p>and I'd get something like</p>

<pre><code>A  B  C
1  1  3
1  3  3
0  .  .
0  1  1
1  0  4
0  0  2
</code></pre>

<p>And I could then proc sort by C and then perform various operations using C to create 4 subgroups.  For example I could get the means of each group with</p>

<pre><code>proc means noprint data =work.bar; 
by c;
var a b;
output out = work.means mean(a b) = a b;
run;
</code></pre>

<p>and I'd get a data of variables by groups called work.means
something like:</p>

<pre><code>C  A  B
1  0  1
2  0  0
3  2  2
4  1  0
</code></pre>

<p>I think I may also get a . row, but I don't care about that for my purposes.  </p>

<p>Now in R. I have the same data set that's been read in properly, but I have no idea how to add a variable to the end (like CC) or how to do an operation on a subgroup (like the by cc command in proc means).  Also, I should note that my variables aren't named in any sort of order, but according to what they represent.</p>

<p>I figure if somebody can show me how to do the above, I can generalize it to what I need to do.</p>
"
1554942,107437,2009-10-12T14:36:58Z,1,Placement of axis labels at minor breaks with ggplot2,"<p>I am using ggplot2 to do some plotting of genomic data, so the basic format is that there is a chromosome and a position along it.  I convert the positions to be on a continuous scale, then put the breaks at the boundaries of the chromosomes with:</p>

<p><code>scale_x_continuous(""Genome Position"", breaks = c(0, cumsum(chromosome_length)))</code></p>

<p>That looks great, as far as the actual plotting is concerned, but the labels are then put at the start and end of the chromosomes.  I would like them to be centered along each chromosome, at the position where the minor break is drawn by default.</p>

<p>Is this possible?</p>
"
1557137,NA,2009-10-12T21:50:24Z,9,Double For loops in R,"<p>How do you properly write a double <code>for</code> loop in R?</p>

<p>For example, in C I would do</p>

<pre><code>int i, j;
for (i = 1; i &lt; 6; i++) {
    for (j=i; j &lt;= 3; j++) {
        printf(""%i,%i\n"",i,j);
    }
    // Do more operations for i &gt; 3...
}
</code></pre>

<p>which would generate the (artificial) sequence:</p>

<pre><code>1,1
1,2
1,3
2,2
2,3
3,3
</code></pre>

<p>In R you do not get the same behaviour when you write</p>

<pre><code>for (i in 1:6) {
    for (j in i:3) {
        print(paste(i,j,sep="",""))
    }
}
</code></pre>

<p>so I've been reduced to doing something like</p>

<pre><code>for (i in 1:6) {
    j &lt;- i
    while (j &lt;= 3) {
        print(paste(i,j,sep="",""))
        j &lt;- j+1
    }
}       
</code></pre>

<p>Is there a better way?</p>

<p>As Shane mentioned, maybe I should make this clear: I am particularly interested in the code-style matching the mathematics to make it easier for students to understand. It seems that students are the most comfortable with <code>for</code> loops.</p>

<p>In particular, I want my students to simulate a <a href=""http://en.wikipedia.org/wiki/LIBOR_market_model"" rel=""nofollow noreferrer"">LIBOR market model</a>. The dynamics of the forward rate are to be simulated under the same probability measure. As such, for each time step and each 
 forward rate, the appropriate drift correction \mu_i needs to be calculated and added.</p>
"
1559724,189035,2009-10-13T11:47:31Z,2,Can you use the lapply() function to alter the value of input?,"<p>I was wondering whether it is possible to use the lapply() function to alter the value of the input, similar to:</p>

<pre><code>a1&lt;-runif(100)
a2&lt;-function(i){
a1[i]&lt;-a1[i-1]*a1[i];a1[i]
}
a3&lt;-lapply(2:100,a2)
</code></pre>

<p>I'm looking for something akin to a for() loop, but using the lapply() infrastructure. I haven't been able to get rapply() to do this.</p>

<p>The reason is that the ""real"" a2 function is a difficult function that only needs to be evaluated if the value of a1[i-1] meets some criteria.</p>

<p>re-phrasing: so i'm trying to replace the for() in the code below by a lapply()-type thing:</p>

<pre><code>    a1&lt;-runif(100)
    a2&lt;-function(i, a1){
        a1[i]&lt;-a1[i-1]*2
        a1[i]
    }
    a3&lt;-as.numeric(lapply(2:100, a2, a1=a1))
#compare the output of a3 with that of a1 after the recursive loop
    a2&lt;-a1 #saved for comparison
    for(i in 2:length(a1)){
        a1[i]&lt;-a1[i-1]*2
    }
cbind(a1[2:100],a3)
#actually this is would be like writting a lapply() version of the cumprod() function
cbind(a1,cumprod(a2))
</code></pre>

<p>The R mailing list has advised looking unto the Reduce() function....as in:</p>

<pre><code>a1&lt;-runif(100)
cadd&lt;-function(x) Reduce(""*"", x, accumulate = TRUE)
cadd(a1)
</code></pre>

<p>which gives the same result as cumprod(a1)...but is even slower than the loop:</p>

<pre><code>a1&lt;-runif(100000)
cadd&lt;-function(x) Reduce(""*"", x, accumulate = TRUE)
looop&lt;-function(a1){
j&lt;-length(a1)
    for(i in 2:j){
        a1[i]&lt;-a1[i-1]*a1[i]
    }
a1
}

&gt; system.time(cadd(a1))
   user  system elapsed 
  1.344   0.004   1.353 
&gt; system.time(cumprod(a1))
   user  system elapsed 
  0.004   0.000   0.002 
&gt; system.time(loop(a1))
   user  system elapsed 
  0.772   0.000   0.775 
&gt; 
</code></pre>

<p>Any idea ? </p>
"
1560397,163053,2009-10-13T13:52:23Z,4,How to view the contents of parsed R functions?,"<p>R is <a href=""http://en.wikipedia.org/wiki/Functional_programming"" rel=""nofollow noreferrer"">a functional programming language</a>, and one of it's primary benefits is it's ability to create open and transparent functions.</p>

<p>As John Chambers says <a href=""http://books.google.com/books?id=UXneuOIvhEAC&amp;printsec=frontcover"" rel=""nofollow noreferrer"">in his excellent book ""Software for Data Analysis: Programming with R""</a>:</p>

<blockquote>
  <p>Computations are organized around functions, which can encapsulate specific, meaningful computational results, with implementations that can be examined for correctness.</p>
</blockquote>

<p>Notions such as ""reproducible research"" and ""trustworthy software"" are at the heart of R development.  In general, it is easy to examine a function just by typing its name without parenthesis.  For instance:</p>

<pre><code>&gt; which
function (x, arr.ind = FALSE) 
{
    if (!is.logical(x)) 
        stop(""argument to 'which' is not logical"")
    wh &lt;- seq_along(x)[x &amp; !is.na(x)]
    dl &lt;- dim(x)
...
</code></pre>

<p>My question is: how do you example the contents of functions such as <code>for()</code> or <code>if()</code> without downloading the R source code?</p>

<p><i>Edit:</i> Incidentally, I understand that this won't help viewing compiled code (such as C, C++, or Java) that may be called from R.  I'm really wondering if there is an R function which output's R functions.</p>
"
1562124,170364,2009-10-13T18:35:47Z,19,Merge many data frames from csv files,"<p>I'd like to merge a bunch of data frames together (because it seems many operations are easier if you're only dealing w/ one, but correct me if I'm wrong).</p>

<p>Currently I have one data frame like this:</p>

<pre><code>ID, var1, var2
A,  2,    2
B,  4,    5
.
.
Z,  3,    2
</code></pre>

<p>Each ID is on a single row w/ several single measurements</p>

<p>I also have a csv file w/ repeated measurement for each ID, like:</p>

<p>filename = ID_B.csv</p>

<pre><code>time, var4, var5
0,    1,    2
1,    4,    5
2,    1,    6
...
</code></pre>

<p>What I'd like is:</p>

<pre><code>ID, time, va1, var2, var4, var5
...
B,  0,    4,   5,    1,    2,
B,  1,    4,   5,    4,    5,
B,  2,    4,   5,    1,    6,
...
</code></pre>

<p>I don't really care about the column order.  The only solution I can think of is to add the ID column to each csv file then loop through them calling <code>merge()</code> several times.  Is there a more elegant approach?</p>
"
1563961,129475,2009-10-14T02:28:40Z,13,How to find top n% of records in a column of a dataframe using R,"<p>I have a dataset showing the exchange rate of the Australian Dollar versus the US dollar once a day over a period of about 20 years.  I have the data in a data frame, with the first column being the date, and the second column being the exchange rate.   Here's a sample from the data:</p>

<pre><code>&gt;data
             V1     V2
1    12/12/1983 0.9175
2    13/12/1983 0.9010
3    14/12/1983 0.9000
4    15/12/1983 0.8978
5    16/12/1983 0.8928
6    19/12/1983 0.8770
7    20/12/1983 0.8795
8    21/12/1983 0.8905
9    22/12/1983 0.9005
10   23/12/1983 0.9005
</code></pre>

<p>How would I go about displaying the top n% of these records?  E.g. say I want to see the days and exchange rates for those days where the exchange rate falls in the top 5% of all exchange rates in the dataset?</p>
"
1567718,144601,2009-10-14T17:14:22Z,37,Getting a function name as a string,"<p>Say I have a bunch of functions, each with something like<code>MyFunction.1</code>, etc.  I want to pass these functions into another function, which prints out a small report.  Ideally I'd like to be able to label sections of a report by which function is being used to generate the results.  </p>

<p>So are there any nice ways of getting the name of a predefined function as a string?</p>
"
1568511,168168,2009-10-14T19:41:17Z,73,How do I sort one vector based on values of another,"<p>I have a vector x, that I would like to sort based on the order of values in vector y. The two vectors are not of the same length.</p>

<pre><code>x &lt;- c(2, 2, 3, 4, 1, 4, 4, 3, 3)
y &lt;- c(4, 2, 1, 3)
</code></pre>

<p>The expected result would be:</p>

<pre><code>[1] 4 4 4 2 2 1 3 3 3
</code></pre>
"
1570050,178297,2009-10-15T02:46:18Z,3,cross-platform zip file creation,"<p>I'd like to create a zip archive from within R, and need maximal cross-platform compatibility, so I would prefer not to use a <code>system(""zip"")</code> command.</p>

<p>Within utils there's <code>zip.file.extract</code> (aka unzip), which uses [a lot of] c code, derived from zlib 1.1.3 within a file called dounzip.c I couldn't find any similar capabilities for creating zip files.</p>

<p>It's also tricky to construct a specific google query for ""cran create zip"" or equivalent!</p>

<p>Also, a tar will not suffice, I need to creating zip's to use as input for another set of non-R tools.</p>

<p>I'd appreciate any pointers?</p>

<p>cheers,
mark</p>
"
1570263,142477,2009-10-15T04:24:13Z,5,Alternatives to using text() to adding text to a plot,"<p>This may be a naive question, but I was wondering if there's a better way than using <code>text()</code> to adding text to a plot.  Note, I'm also using <code>layout()</code> as well.  Specifically, I have a section of a plot where I would like to add some text with headings followed by regular text. </p>

<p><code>text()</code> is fine it seems for simple annotations, but to get the spacing right for several lines of text seems to require a lot of manual manipulation of the <code>x</code> and <code>y</code> and <code>cex</code> parameters.  Any suggestions?</p>
"
1570379,190352,2009-10-15T05:07:06Z,9,Adding stat_smooth in to only 1 facet in ggplot2,"<p>I have some data for which, at one level of a factor, there is a significant correlation.  At the other level, there is none.  Plotting these side-by-side is simple.  Adding a line to both of them with stat_smooth, also straightforward.  However, I do not want the line or its fill displayed in one of the two facets.  Is there a simple way to do this?  Perhaps specifying a blank color for the fill and colour of one of the lines somehow? </p>
"
1576201,NA,2009-10-16T05:18:59Z,1,How do I find peak values/row numbers?,"<p>I have a large dataset (202k points).  I know that there are 8 values over 0.5.  I want to subset on those rows.</p>

<p>How do I find/return a list the row numbers where the values are > 0.5?</p>
"
1577480,182378,2009-10-16T11:19:00Z,0,R: Occurrence times -> binary sequence?,"<p>What are the better options to convert a non-decreasing seq of occurrence times to a 0-1 seq? Thanks.</p>

<pre><code>d&lt;-c(3,5,9,12,15);
c(rep(0,d[1]-1),1,unlist(rbind(mapply(rep,0,diff(d)-1),1)))
</code></pre>
"
1580308,142879,2009-10-16T20:46:03Z,1,R2HTML number formatting,"<p>I want to output a dataframe using R2HTML, and remove scientific notation. Ideas?</p>
"
1581232,142879,2009-10-17T02:24:16Z,34,add commas into number for output,"<p>I'm outputting a dataframe to html via <code>xtable</code>. I want to add commas to numbers in a couple columns of the table. I figured before I did my own paste hack I'd check if there is a built in way to do this.</p>
"
1586744,135944,2009-10-19T02:44:16Z,3,Complex object initialization scope issues with nested functions,"<p>OK, so I'm trying to use S4 classes to build a very complex object, with slots including a half-dozen matrices, a few lists, and probably a kitchen sink or two in there. The object is initialized by referring to and unpacking a configuration object which I've already defined. It's easy enough to define the class with setClass(), but I'm having difficulty figuring out an elegant way of setting the slots in the setMethod(""initialize""). </p>

<p>The problem is that I need to set particular elements of those half-dozen matrices based on parts of that configuration object. For each element of the configuration object, I may have to set specific elements of several of the matrices. Note that the matrices are in the scope/environment of the initialize function. I then have nested functions within the initialize function that do the actual assignment to the matrices, or that's the idea anyway. Those functions can of course <em>see</em> the matrices, but they can't <em>modify</em> them because the &lt;- operator creates a new matrix if the original variable was not defined in the current environment. R is pass-by-value, and means it. This is even true for slots of the .Object I'm trying to initialize. So I can't use nested functions to do the initialization.</p>

<p>Unfortunately, these nested functions have to modify several of the matrices, so returning values and doing the assignment in the main initialize function is not practical or elegant. (But it is possible, if I stuffed copies of the matrices into returned lists and then combined them in the main initialize function. Ugly though, and would require a lot of extra code.)</p>

<p>And iteration (which would prevent this scoping issue) is not very practical either because of the hierarchical nature of the configuration object, which really wants to be traversed with recursive calls.</p>

<p>The last option I can think of would be to use the assign() function with the envir option to force the assignment to apply to the nonlocal variable. But using environments like that seems icky, like a goto statement... </p>

<p>So, what is the most piratical approach? Stick with pure functional programming and build ugly data structures just to inefficiently pass around redundant matrices? Try to find an iterative solution that avoids functions altogether? Use deep magic by playing with environments?</p>
"
1594121,182378,2009-10-20T12:04:19Z,14,How do I best simulate an arbitrary univariate random variate using its probability function?,"<p>In R, what's the best way to simulate an arbitrary univariate random variate if only its probability density function is available?</p>
"
1607413,62389,2009-10-22T13:57:31Z,0,Using summary.lm function in rapache,"<p>I have installed <a href=""http://biostat.mc.vanderbilt.edu/rapache/"" rel=""nofollow noreferrer"">rapache</a> and i am trying to fit a linear model inside the R script file. I have configured the RFileHandler in the http.conf. When i am trying to invoke the summary(model) it is giving me a segment fault error ( i see this in the apache log file). I am guessing that it is trying to print to the console and that is why it is failing. </p>

<p>Has any one encountered a similar problem with R and rapache? I am relatively new to R and summary is doing a lot of things that are not directly exposed as functions so i am hoping i could get it to work</p>

<p>Here is my r script</p>

<pre><code>mydata&lt;- read.table(""/home/user/test.csv"",header=TRUE,sep="","")
fit&lt;- lm(y~x1+x2+x3,data=mydata)
setContentType(""text/html"")
cat('&lt;HTML&gt;&lt;BODY&gt;')
cat(summary(fit)$adj.r.squared)
cat('&lt;/BODY&gt;&lt;/HTML&gt;\n')
DONE
</code></pre>

<p>if i replace </p>

<pre><code>    cat(summary(fit)$adj.r.squared)
</code></pre>

<p>with this</p>

<pre><code>    cat(coef(fit))
</code></pre>

<p>it is working!</p>

<p>Thanks
Bharani</p>
"
1608130,2554948,2009-10-22T15:44:16Z,95,"Equivalent of ""throw"" in R","<p>How does one ""throw"" an error in R?  I have a function that takes a data frame and some column names and does stuff with them.  If the columns don't exist, I want the function to stop and to stop all functions depending on it. </p>

<p>I have looked at <code>recover</code> and <code>browse</code> and <code>traceback</code> but, well, they seemed to be close but not what I am looking for.</p>
"
1614331,16363,2009-10-23T15:47:32Z,2,Write Plot Text/Binary into Variable,"<p>Is there a way to have an <code>R</code> Device (postscript would be great) write the output into a variable instead of a file?</p>

<p>For example I know this:</p>

<pre><code>postscript(file=""|cat"")
plot(1:10)
dev.off()
</code></pre>

<p>Will send the postscript text to <code>STDOUT</code>.  How can I get that text into a variable within <code>R</code>?</p>
"
1614889,142477,2009-10-23T17:30:59Z,7,how do you know which functions in R are flagged for debugging?,"<p>I've been using <code>debug()</code> more often now, but sometimes I wonder which functions have been flagged for debugging.  I know that you can use <code>isdebugged()</code> to find out if a particular function is flagged.  But is there a way for R to list all the functions that are being debugged?</p>
"
1616983,144278,2009-10-24T04:44:15Z,11,Building R Packages using Alternate GCC,"<p>The systems I work with have GCC 4.5 (experimental) in /usr/local/bin/gcc which has proven to be problematic for some R packages. I would like to instead use system GCC in /usr/bin/gcc.</p>

<p>I have tried setting CC and CXX in the Bash configuration files (.bashrc, .bash_profile etc.) as well as on the command line, but although Bash recognizes the change, R does not.</p>

<p>How can I get R to use the version of GCC in /usr/bin instead of the one in /usr/local/bin/? </p>
"
1617061,84458,2009-10-24T05:31:18Z,22,Including missing values in table() results in R,"<p>I have a vector of integers between 0 and 5.  I want to compute a histogram of counts.  For example:</p>

<pre><code>y &lt;- c(0, 0, 1, 3, 4, 4)
table(y)
# y
# 0 1 3 4 
# 2 1 1 2 
</code></pre>

<p>However, I also want the results to include the fact that there are zero 2's and zero 5's, ie. I want the returned vector to have length 6. Can I use <code>table()</code> for this?</p>

<p>Desired result:</p>

<pre><code># y
# 0 1 2 3 4 5 
# 2 1 0 1 2 0
</code></pre>
"
1621848,196288,2009-10-25T19:37:59Z,5,Looping through a column in R,"<p>I am using the <code>R's stats</code> package and would like to loop through <code>column[x]</code> in <code>all the rows of a dataframe</code>, operate on the data in <code>each cell</code> in the column with a function and pass the result to a new column (with the <code>calculated result</code> in the <code>new column</code> aligned with the data in <code>column[x]</code>)</p>

<p>I've got two problems:  </p>

<ol>
<li>I can't get it to work </li>
<li>looping seems to be discouraged in the <code>R articles</code> I've read.  Is there an alternative approach and if not, does anyone have an example of how to carry out the loop?</li>
</ol>
"
1622419,189035,2009-10-25T23:10:38Z,4,(all the) directions perpendicular to hyperplane through p data points,"<p>I have a simple question: 
given p points (non-collinear) in R^p i find the hyperplane passing by these points (to help clarify i type everything in R):</p>

<pre><code>p&lt;-2
x&lt;-matrix(rnorm(p^2),p,p)
b&lt;-solve(crossprod(cbind(1,x[,-2])))%*%crossprod(cbind(1,x[,-2]),x[,2])
</code></pre>

<p>then, given a p+1^th points not collinear with first p points, i find the direction perpendicular to b:</p>

<pre><code>x2&lt;-matrix(rnorm(p),p,1)
b2&lt;-solve(c(-b[-1],1)%*%t(c(-b[-1],1))+x2%*%t(x2))%*%x2
</code></pre>

<p>That is, b2 defines a p dimensional hyperplane perpendicular to b and passing by x2.
Now, my questions are:</p>

<p>The formula comes from <a href=""http://en.wikipedia.org/wiki/Surface_normal"" rel=""nofollow noreferrer"">my interpretation of this wikipedia entry</a> (""solve(A)"" is the R command for A^-1). Why this doesn't work for p>2 ? What am i doing wrong ?</p>

<p>PS: I have seen this post (on stakeoverflow edit:sorry cannot post more than one link) but somehow it doesn't help me.</p>

<p>Thanks in advance,</p>

<p>i have a problem implementation/understanding of Liu's solution when p>2:</p>

<p>shouldn't the dot product between the qr decomposition of the sweeped matrix and the direction of the hyperplane be 0 ? (i.e. if the qr vectors are perpendicular to the hyperplane)</p>

<p>i.e, when p=2 this </p>

<pre><code>c(-b[2:p],1)%*%c(a1)
</code></pre>

<p>gives 0. When p>2 it does not. </p>

<hr>

<p>Here is my attempt to implement Victor Liu's solution.</p>

<p>a) given p linearly independent observations in R^p:</p>

<pre><code>p&lt;-2;x&lt;-matrix(rnorm(p^2),p,p);x
      [,1]       [,2]
[1,] -0.4634923 -0.2978151
[2,]  1.0284040 -0.3165424
</code></pre>

<p>b) stake them in a matrix and subtract the first row:</p>

<pre><code>a0&lt;-sweep(x,2,x[1,],FUN=""-"");a0
        [,1]        [,2]
[1,] 0.000000  0.00000000
[2,] 1.491896 -0.01872726
</code></pre>

<p>c) perform a QR decomposition of the matrix a0. The vector in the nullspace is the direction im looking for:</p>

<pre><code>qr(a0)
          [,1]       [,2]
[1,] -1.491896 0.01872726
[2,]  1.000000 0.00000000
</code></pre>

<p>Indeed; this direction is the same as the one given by application of the formula from wikipedia (using x2=(0.4965321,0.6373157)): </p>

<pre><code>       [,1]
[1,]  2.04694853
[2,] -0.02569464
</code></pre>

<p>...with the advantage that it works in higher dimensions.</p>

<p>I have one last question: what is the meaning of the other p-1 (i.e. (1,0) here) QR vector when p>2 ?
-thanks in advance, </p>
"
1622797,143377,2009-10-26T02:09:00Z,6,debugging littler/Rscripts,"<p>How do I debug <code>Rscripts</code> that are run from the command line? </p>

<p>I am currently using the <code>getopt</code> package to pass command line options, nut when there's a bug, it is hard for me to: </p>

<ol>
<li>see what exactly went wrong; </li>
<li>debug interactively in <code>R</code> (since the script expects command line options.)</li>
</ol>

<p>Does anyone have example code and willing to share? </p>
"
1628383,160588,2009-10-27T02:01:22Z,7,Finding the minimum difference between each element of one vector and another vector,"<p>I have two vectors of integers, and for each element of the second vector I want to find the minumum distance to any element of the first vector - for example</p>

<pre><code>obj1 &lt;- seq(0, 1000, length.out=11)
obj2 &lt;- 30:50
min_diff &lt;- sapply(obj2, function(x) min(abs(obj1-x)))
min_diff
</code></pre>

<p>returns</p>

<pre><code>[1] 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
</code></pre>

<p>Is there a more efficient way? I want to scale this up to thousands (millions?) of both obj1 &amp; obj2.</p>

<p>Thanks, 
Aaron</p>
"
1630724,197321,2009-10-27T13:14:48Z,6,Can I gracefully include formatted SQL strings in an R script?,"<p>I'm working in an R script that uses a long SQL string, and I would like to keep the query relatively free of other markup so as to allow copying and pasting between editors and applications. I'd also like the ability to split the query across lines for better readability. </p>

<p>In the RODBC documentation, the <code>paste</code> function is used to build the query out of separate chunks, but I'd prefer something less kludgy and with fewer quotes and commas. Thanks for your help.</p>
"
1632772,168139,2009-10-27T18:28:21Z,60,Appending rows to a dataframe - the factor problem,"<p>I have a large dataframe (14552 rows by 15 columns) containing billing data from 2001 to 2007. I have used sqlFetch to get 2008 data. In order to append the 2008 data to the data of the preceding 7 years one would do as follows</p>

<p><code>alltime &lt;-rbind(alltime,all2008)</code></p>

<p>Unfortunately that generates</p>

<blockquote>
  <p>Warning message:
  In <code>[&lt;-.factor</code>(<code>*tmp*</code>, ri, value = c(NA, NA, NA, NA, NA, NA, NA,  :
    invalid factor level, NAs generated</p>
</blockquote>

<p>My guess is that there are some new patients whose names were not in the previous dataframe and therefore it would not know what level to give it. Another column is for the name of the referring doctor. A new referring doctor would cause the same problem.</p>

<p>The way R imports data and automatically works out what is numeric and what is not (and thereby makes it a factor) is wonderful - untill you have to manipulate it further and then it becomes a pain. How do I overcome my problem elegantly?</p>
"
1635278,160314,2009-10-28T04:59:10Z,11,Saving a data frame as a binary file,"<p>I would like to save a whole bunch of relatively large data frames while minimizing the space that the files take up. When opening the files, I need to be able to control what names they are given in the workspace. </p>

<p>Basically I'm looking for the symantics of dput and dget but with binary files.</p>

<p>Example:</p>

<pre><code>n&lt;-10000

for(i in 1:100){
    dat&lt;-data.frame(a=rep(c(""Item 1"",""Item 2""),n/2),b=rnorm(n),
        c=rnorm(n),d=rnorm(n),e=rnorm(n))
    dput(dat,paste(""data"",i,sep=""""))
}


##much later


##extract 3 random data sets and bind them
for(i in 1:10){
    nums&lt;-sample(1:100,3)
    comb&lt;-rbind(dget(paste(""data"",nums[1],sep="""")),
            dget(paste(""data"",nums[2],sep="""")),
            dget(paste(""data"",nums[3],sep="""")))
    ##do stuff here
}
</code></pre>
"
1641488,147427,2009-10-29T03:38:43Z,1,"Lattice problems: lattice objects coming from JAGS, but device can't be set","<p>I ran <code>JAGS</code> with <code>runjags</code> in <code>R</code> and I got a giant list back (named results for this example). </p>

<p>Whenever I access <code>results$density</code>, two <code>lattice plots</code> (one for each parameter) pop up in the default quartz device. </p>

<p>I need to combine these with <code>par(mfrow=c(2, 1))</code> or with a similar approach, and send them to the <code>pdf device</code>. </p>

<p>Nothing I tried is working. Any ideas?</p>

<p>I've tried <code>dev.print</code>, <code>pdf()</code> with <code>dev.off()</code>, etc. with no luck.</p>
"
1642119,NA,2009-10-29T07:31:24Z,2,"Consensus tree or ""bootstrap proportions"" from multiple hclust objects","<p>I have a list of hclust objects resulting from slight variations in one variable (for calculating the distance matrix)</p>

<ul>
<li>now I would like to make a consensus tree from this list.</li>
</ul>

<p>Is there a generic package to do this? I am hacking my way through
some code from maanova and it seems to work - but it's ugly and it
needs a lot of hacking since I am not doing ""normal"" bootstrapping (it's
chemical data).</p>

<p>/Palle Villesen, Denmark</p>

<pre><code>c1_list &lt;- seq(10,100,by=10)
c2 &lt;- 30
e&lt;- 1
mboot &lt;- list()
for (i in 1: length(c1_list) ) {
   c1 &lt;- c1_list[i]
   cat(""Doing C1="",c1,""..."")
   x &lt;- hclust(custom_euclidean(t(log2(data[, all]+1)), c1,c2,e), method='average')
   cat(""..done\n"")
   mboot[[i]] &lt;- x # To get hclust object back use mbot[[i]] to get i'th object
}

#### Now extract the robust groups from mboot...
</code></pre>
"
1642201,11410,2009-10-29T08:03:44Z,10,Your experiences with Matlab/F#/R for data analysis and modeling algorithms,"<p>I've been using F# for a while now to model algorithms before coding them in C++, and also using it afterwards to check the results of the C++ code, and also against real-world recorded data.</p>

<p>For the modeling side of things, it's very handy, but for the 'data mashup' kind of stuff, pulling in data from CSV and other sources, generating statistics, drawing charts etc., my colleague teases me no end (""why are you coding that yourself? It's built in to MatLab"").</p>

<p>And I have another colleague who swears by R, which also has charting stuff 'built-in'.</p>

<p>I know that MatLab, R and F# are not strictly comparable, so I'm not asking for a 'feature comparison shoot out'. I just wondered what other people are using for these kind of pre- and post-analysis scenarios, and how happy they are with it. </p>

<p>(If there's anyone out there working on wrapping Microsoft Charts into something F#-friendly, let me know, I'd be happy to participate...)</p>

<p><em>(Note: answers to this question will be subjective, but based on experience, please)</em></p>
"
1644661,25571,2009-10-29T15:44:48Z,12,Add a vertical line with different intercept for each panel in ggplot2,"<p>I'm using ggplot2 to create panels of histograms, and I'd like to be able to add a vertical line at the mean of each group.  But geom_vline() uses the same intercept for each panel (i.e. the global mean):</p>

<pre><code>require(""ggplot2"")
# setup some sample data
N &lt;- 1000
cat1 &lt;- sample(c(""a"",""b"",""c""), N, replace=T)
cat2 &lt;- sample(c(""x"",""y"",""z""), N, replace=T)
val &lt;- rnorm(N) + as.numeric(factor(cat1)) + as.numeric(factor(cat2))
df &lt;- data.frame(cat1, cat2, val)

# draws a single histogram with vline at mean
qplot(val, data=df, geom=""histogram"", binwidth=0.2) + 
  geom_vline(xintercept=mean(val), color=""red"")

# draws panel of histograms with vlines at global mean
qplot(val, data=df, geom=""histogram"", binwidth=0.2, facets=cat1~cat2) + 
  geom_vline(xintercept=mean(val), color=""red"")
</code></pre>

<p>How can I get it to use each panel's group mean as the x-intercept?  (Bonus points if you can also add a text label by the line with the value of the mean.)</p>
"
1647236,178787,2009-10-29T23:50:05Z,5,Matching strings across columns in R,"<p>I've got a data frame with 2 character columns. I'd like to find the rows which one column contains the other, however grepl is being strange. Any ideas?</p>

<pre><code>&gt; ( df &lt;- data.frame(letter=c('a','b'),food = c('apple','pear','bun','beets')) )
  letter  food
1      a apple
2      b  pear
3      a   bun
4      b beets 

&gt; grepl(df$letter,df$food)

[1]  TRUE  TRUE FALSE FALSE
</code></pre>

<p>but i want T F F T</p>

<p>Thanks.</p>
"
1649503,198894,2009-10-30T12:24:28Z,2,Strange Problem with RPy2,"<p>After installing RPy2 from </p>

<p><a href=""http://rpy.sourceforge.net/rpy2.html"" rel=""nofollow noreferrer"">http://rpy.sourceforge.net/rpy2.html</a></p>

<p>I'm trying to use it in Python 2.6 IDLE but I'm getting this error:</p>

<pre><code>&gt;&gt;&gt; import rpy2.robjects as robjects
&gt;&gt;&gt; robjects.r['pi']

&lt;RVector - Python:0x0121D8F0 / R:0x022A1760&gt;
</code></pre>

<p>What I'm doing wrong?</p>
"
1652522,170408,2009-10-30T21:51:12Z,14,rbind dataframes in a list of lists,"<p>I have a list of lists that looks like this: <code>x[[state]][[year]]</code>. Each element of this is a data frame, and accessing them individually is not a problem. </p>

<p>However, I'd like to rbind data frames across multiple lists. More specifically, I'd like to have as output as many dataframes as I have years, that is rbind all the state data frames within each year. In other words, I'd like to combine all my state data, year by year, into separate data frames.</p>

<p>I know that I can combine a single list into a data frame with <code>do.call(""rbind"",list)</code>. But I don't know how I can do so across lists of lists.</p>
"
1653271,200022,2009-10-31T03:06:06Z,3,how do you find the median of 2 columns using R?,"<p>I am trying to compute the median vector of a data set <code>s</code> with column <code>A1</code> and <code>B1</code>. The median vector is the median for each  observation from both columns. </p>

<p>I tried to do this and it did not work. </p>

<pre><code>median(s[c(""A1"",""B1"")])
</code></pre>

<p>Is there another way to do it? </p>
"
1653710,170792,2009-10-31T07:39:46Z,1,r analogous to sql inner join selection,"<p>Suppose we have the contents of tables x and y in two dataframes in R. Which is the suggested way to perform an operation like the following in sql:</p>

<pre><code>Select x.X1, x.X2, y.X3
into z
from x inner join y on x.X1 = y.X1
</code></pre>

<p>I tried the following in R. Is there a better way? 
Thank you</p>

<pre><code>x&lt;-data.frame(cbind('X1'=c(5,9,7,6,4,8,3,1,10,2),'X2'=c(5,9,7,6,4,8,3,1,10,2)^2))
y&lt;-data.frame(cbind('X1'=c(9,5,8,2),'X3'=c('nine','five','eight','two')))

z&lt;-cbind(x[which(x$X1 %in% (y$X1)), c(1:2)][order(x[which(x$X1 %in% (y$X1)), c(1:2)]$X1),],y[order(y$X1),2])
</code></pre>
"
1655454,200022,2009-10-31T19:57:29Z,2,How do you make a new dataset given a set of vectors?,"<p>Is there a way in R to build a new dataset consisting of a given set of vectors -- median1, median2, median3, median4 -- which are median vectors from a previous dataset s? </p>

<pre><code>median1 = apply(s[,c(""A1"",""B1"",""C1"",""D1"",""E1"",""F1"",""G1"",""H1"",""I1"")],1,median)
median2 = apply(s[,c(""A2"",""B2"",""C2"",""D2"",""E2"",""F2"",""G2"",""H2"",""I2"")],1,median)
median3 = apply(s[,c(""A3"",""B3"",""C3"",""D3"",""E3"",""F3"",""G3"",""H3"",""I3"")],1,median)
median4 = apply(s[,c(""A4"",""B4"",""C4"",""D4"",""E4"",""F4"",""G4"",""H4"",""I4"")],1,median)

plot(median1,median2, pch = ""."")
</code></pre>
"
1655792,200303,2009-10-31T22:26:18Z,3,R lag over missing data,"<p>Is there a variant of lag somewhere that keeps NAs in position? I want to compute returns of price data where data could be missing.</p>

<p>Col 1 is the price data
Col 2 is the lag of price
Col 3 shows p - lag(p) - the return from 99 to 104 is effectively missed, so the path length of the computed returns will differ from the true.
Col 4 shows the lag with NA position preserved
Col 5 shows the new difference - now the return of 5 for 2009-11-07 is available</p>

<p>Cheers, Dave</p>

<pre><code>x &lt;- xts(c(100, 101, 97, 95, 99, NA, 104, 103, 103, 100), as.Date(""2009-11-01"") + 0:9)

# fake the lag I want, with NA kept in position
x.pos.lag &lt;- lag.xts(x.pos)
x.pos.lag &lt;- lag.xts(x.pos)
x.pos.lag['2009-11-07']=99
x.pos.lag['2009-11-06']=NA

cbind(x, lag.xts(x), x - lag.xts(x), x.pos.lag, x-x.pos.lag)
           ..1 ..2 ..3 ..4 ..5
2009-11-01 100  NA  NA  NA  NA
2009-11-02 101 100   1 100   1
2009-11-03  97 101  -4 101  -4
2009-11-04  95  97  -2  97  -2
2009-11-05  99  95   4  95   4
2009-11-06  NA  99  NA  NA  NA
2009-11-07 104  NA  NA  99   5
2009-11-08 103 104  -1 104  -1
2009-11-09 103 103   0 103   0
2009-11-10 100 103  -3 103  -3
</code></pre>
"
1656026,200022,2009-11-01T00:29:06Z,1,Why doesn't R add the title at the top of the page?,"<p>I'm trying to add a title at the top of the page scatterplots, however whenever I use the command <em>title</em> it doesn't add the title at the top of page and overwrites my plots. Is there a way to fix this ?</p>

<pre><code>plot(median, pch = ""."")
title(main = ""Scatterplot of the median vectors "",line = 0,font=2)
</code></pre>
"
1658032,189035,2009-11-01T19:13:17Z,6,Draw hyperplane in R?,"<p>How does one go about drawing an hyperplane (given the equation) in 3D in R ?
(i.e. 3d equivalent to ""abline"")</p>

<p>Thanks in advance, </p>
"
1660124,177541,2009-11-02T09:01:28Z,170,How to sum a variable by group?,"<p>Let's say I have two columns of data. The first contains categories such as ""First"", ""Second"", ""Third"", etc. The second has numbers which represent the number of times I saw ""First"".</p>

<p>For example:</p>

<pre><code>Category     Frequency
First        10
First        15
First        5
Second       2
Third        14
Third        20
Second       3
</code></pre>

<p>I want to sort the data by Category and sum the Frequencies:</p>

<pre><code>Category     Frequency
First        30
Second       5
Third        34
</code></pre>

<p>How would I do this in R?</p>
"
1661479,143476,2009-11-02T14:01:35Z,11,matplotlib for R user?,"<p>I regularly make figures (the exploratory data analysis type) in R. I also program in Python and was wondering if there are features or concepts in matplotlib that would be worth learning. For instance, I am quite happy with R - but its image() function will produce large files with pixelated output, whereas Matlab's equivalent figure (I also program regularly in Matlab) seems to be manageable in file size and also 'smoothed' - does matplotlib also provide such reductions...? But more generally, I wonder what other advantages matplotlib might confer. I don't mean this to be a trolling question. Thanks.</p>
"
1663370,296954,2009-11-02T20:05:10Z,9,Loop over string variables in R,"<p>When programming in Stata I often find myself using the loop index in the programming. For example, I'll loop over a list of the variables nominalprice and realprice:  </p>

<pre><code>local list = ""nominalprice realprice""
foreach i of local list {
  summarize `i'
  twoway (scatter `i' time)
  graph export ""C:\TimePlot-`i'.png""
}
</code></pre>

<p>This will plot the time series of nominal and real prices and export one graph called TimePlot-nominalprice.png and another called TimePlot-realprice.png.  </p>

<p>In R the method I've come up with to do the same thing would be:  </p>

<pre><code>clist &lt;- c(""nominalprice"", ""realprice"")
for (i in clist) {
  e &lt;- paste(""png(\""c:/TimePlot-"",i,"".png\"")"", sep="""")
  eval(parse(text=e))
  plot(time, eval(parse(text=i)))
  dev.off() 
}
</code></pre>

<p>This R code looks unintuitive and messy to me and I haven't found a good way to do this sort of thing in R yet. Maybe I'm just not thinking about the problem the right way? Can you suggest a better way to loop using strings? </p>
"
1663536,NA,2009-11-02T20:37:27Z,2,Summing by Categorical Variable,"<p>I have a data set of comic book unit sales by volume (ex. Naruto v10) that I need to reduce to sales by series (so all Naruto volume unit sales would be added together into a single observation).  I have a variable ""series"" that identifies the series of each observation.  The equivalent code in Stata would be: </p>

<pre><code>by series, sort:replace unitssales=sum(unitssales);
by series, sort:keep if _n==_N
</code></pre>

<p>But I'm trying to figure out how to do this in R.  Any help would be much appreciated!  Thanks in advance!</p>
"
1664473,182378,2009-11-02T23:58:52Z,2,"ARIMA, ARMA and AICs?","<pre><code>data &lt;-c(88, 84, 85, 85, 84, 85, 83, 85, 88, 89, 91, 99, 104, 112, 126, 138, 146,151,   150, 148, 147, 149, 143, 132, 131, 139, 147, 150, 148, 145, 140, 134, 131, 131, 129, 126, 126, 132, 137, 140, 142, 150, 159, 167, 170, 171, 172, 172, 174, 175, 172, 172, 174, 174, 169, 165, 156, 142, 131, 121, 112, 104, 102, 99, 99, 95, 88, 84, 84, 87, 89, 88, 85, 86, 89, 91, 91, 94, 101, 110, 121, 135, 145, 149, 156, 165, 171, 175, 177, 182, 193, 204, 208, 210, 215, 222, 228, 226, 222, 220)
</code></pre>

<p>Why do the ARMA models acting on the first differences of the data differ from the corresponding ARIMA models?</p>

<pre><code>for (p in 0:5)
{
for (q in 0:5)
{
#data.arma = arima(diff(data), order = c(p, 0, q));cat(""p ="", p, "", q ="", q, ""AIC ="",  data.arma$aic, ""\n"");
data.arma = arima(data, order = c(p, 1, q));cat(""p ="", p, "", q ="", q, ""AIC ="", data.arma$aic, ""\n"");
}
}
</code></pre>

<p>Same with <code>Arima(data,c(5,1,4))</code> and <code>Arima(diff(data),c(5,0,4))</code> in the forecast package. I can get the desired consistency with</p>

<pre><code>auto.arima(diff(data),max.p=5,max.q=5,d=0,approximation=FALSE, stepwise=FALSE, ic =""aic"", trace=TRUE);
auto.arima(data,max.p=5,max.q=5,d=1,approximation=FALSE, stepwise=FALSE, ic =""aic"", trace=TRUE);
</code></pre>

<p>but it seems the holder of the minimum AIC estimate for these data has not been considered by the algorithm behind auto.arima; hence the suboptimal choice of ARMA(3,0) instead of ARMA(5,4) acting on the first differences. A related question is how much the two AIC estimates should differ before one considers one model better than the other has little to do wuth programming - the smallest AIC holder should at least be considered/reported, even though 9 coefficients may be a bit too much for a forecast from 100 observations.</p>

<p>My R questions are:</p>

<p>1) Vectorised version of the double loop so it is faster?</p>

<p>2) Why does <code>arima(5,1,4)</code> acting on the data differ from <code>arma(5,4)</code> acting on the first differences of the data? Which one is to be reported?</p>

<p>3) How do I sort the AICs output so that the smaller come first?</p>

<p>Thanks.</p>
"
1670803,202190,2009-11-03T23:20:58Z,0,Bootstrap output matrix missing,"<p>When I try to calculate Gest in spatstat I get the error:</p>

<blockquote>
  <p>bootstrap output matrix missing.</p>
</blockquote>

<p>Does anyone know what am I doing wrong?</p>
"
1671521,98130,2009-11-04T03:21:29Z,1,How to get vertex eigenvalue centralities in R with igraph,"<p>I have a network loaded into an igraph object <code>G</code> that has 198 vertices and 214 edges.  If I run:</p>

<pre><code>eig&lt;-evcent(G)$vector
</code></pre>

<p>The resulting <code>eig</code> is a vector with 2172 elements, rather than 198 elements.   <a href=""http://igraph.sourceforge.net/doc/R/evcent.html"" rel=""nofollow noreferrer"">The documentation on the package</a> claims it returns the ""centralities of positions <code>v</code>.""  Any ideas on how to get the eigenvalue centralities for each vertex?</p>
"
1676990,202996,2009-11-04T22:04:49Z,33,Split a string vector in R,"<p>I have the following vector:</p>

<pre><code>tmp3 &lt;- c(""1500 2"", ""1500 1"", ""1510 2"", ""1510 1"", ""1520 2"", ""1520 1"", ""1530 2"", 
""1530 1"", ""1540 2"", ""1540 1"")
</code></pre>

<p>I would like to just retain the second number in each of the atoms of this vector, so it would read:  </p>

<pre><code>c(2,1,2,1,2,1,2,1,2,1)
</code></pre>
"
1677021,9382,2009-11-04T22:10:59Z,6,Is R language interpreted?,"<p>I am trying to find out whether the <a href=""http://en.wikipedia.org/wiki/R_(programming_language)"" rel=""nofollow noreferrer"">R programming language</a> is interpreted or compiled.  Can't seem to find this info.</p>

<hr>

<p><strong>Edit</strong>
I should have said interpreted or compiled to begin with.  Commenters are absolutely right - static or dynamic has nothing to do with whether the language is interpreted or dynamic.</p>
"
1677489,126353,2009-11-04T23:52:06Z,2,Is R Embeddable,"<p>I'm thinking to start learning <strong>R</strong>, but I want to know one thing, Is it embeddable(Windows CE, Palm OS)?</p>
"
1685181,3788,2009-11-06T03:13:55Z,13,Making R package work in both Windows and Linux,"<p>I have written a very basic package in R. In fact, I followed <a href=""http://cran.r-project.org/doc/contrib/Leisch-CreatingPackages.pdf"" rel=""nofollow noreferrer"">this tutorial</a> for creating a basic package.</p>

<p>My package works just fine in linux. eg:</p>

<pre>
> install.packages(""linmod"", repos=NULL)
Warning in install.packages(""linmod"", repos = NULL) :
  argument 'lib' is missing: using '/home/jpgoel/R/i486-pc-linux-gnu-library/2.9'
* Installing *source* package ‘linmod’ ...
** R
** data
** preparing package for lazy loading
** help
*** installing help indices
 >>> Building/Updating help pages for package 'linmod'
     Formats: text html latex example 
** building package indices ...
* DONE (linmod)
> library(linmod)
> data(mod1)
> mod1
Call:
linmod.default(x = x, y = y)

Coefficients:
     Const        Bwt 
-0.3566624  4.0340627 

</pre>

<p>Now, I took my ""linmod"" folder, copied it to Windows XP, and tried the following:</p>

<pre>
> install.packages(""C:\\Documents\ and\ Settings\\foo\\Desktop\\linmod"",repos=NULL)
Error in gzfile(file, ""r"") : cannot open the connection
In addition: Warning messages:
1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
2: In gzfile(file, ""r"") :
  cannot open compressed file 'linmod/DESCRIPTION', probable reason 'No such file or directory'
> 
</pre>

<p>Okay. So then I took that folder and placed it into a .zip file. Then I went to Packages -> Install package(s) from local zip files... and selected my package.</p>

<pre>
> utils:::menuInstallLocal()
updating HTML package descriptions

> library(linmod)
Error in library(linmod) : 'linmod' is not a valid installed package

</pre>

<p>I'm stumped. My package doesn't have any native code (eg, no extensions written in C.)</p>

<p>Feel free to download the .zip <a href=""http://www.2shared.com/file/8966494/44855d78/linmod.html"" rel=""nofollow noreferrer"">from here</a> (the link to download is all the way at the bottom, ""Save file to your PC"")</p>
"
1686569,101419,2009-11-06T09:58:58Z,76,Filtering a data.frame,"<p>let's suppose that I have data frame like</p>

<pre><code>   expr_value     cell_type
1    5.345618 bj fibroblast
2    5.195871 bj fibroblast
3    5.247274 bj fibroblast
4    5.929771          hesc
5    5.873096          hesc
6    5.665857          hesc
7    6.791656          hips
8    7.133673          hips
9    7.574058          hips
10   7.208041          hips
11   7.402100          hips
12   7.167792          hips
13   7.156971          hips
14   7.197543          hips
15   7.035404          hips
16   7.269474          hips
17   6.715059          hips
18   7.434339          hips
19   6.997586          hips
20   7.619770          hips
21   7.490749          hips
</code></pre>

<p>What I want to is to get a new data frame which looks the same but only has the data for one cell_type. E.g.</p>

<pre><code>   expr_value     cell_type
1    5.929771          hesc
2    5.873096          hesc
3    5.665857          hesc
</code></pre>

<p>or for two classes like</p>

<pre><code>   expr_value     cell_type
1    5.345618 bj fibroblast
2    5.195871 bj fibroblast
3    5.247274 bj fibroblast
4    5.929771          hesc
5    5.873096          hesc
6    5.665857          hesc
</code></pre>

<p>Is there any easy way to do this?</p>

<p>What I've tried already is something like</p>

<pre><code>&gt; expr[expr[2] == 'hesc']
[1] ""5.929771"" ""5.873096"" ""5.665857"" ""hesc""     ""hesc""     ""hesc""    
&gt;
</code></pre>

<p>if the original data frame is called expr but it gives the results in wrong format as you can see.</p>
"
1688228,192720,2009-11-06T15:12:51Z,0,Per panel smoothing in ggplot2,"<p>I'm plotting a group of curves, using facet in ggplot2. I'd like to have a smoother applied to plots where there are enough points to smooth, but not on plots with very few points. In particular I'd like to stop the plot failing when one of the panels only has 1 or 2 points.</p>

<p>Example:</p>

<pre><code>a &lt;- data.frame( x=1:100, y=sin(seq(0.1,10,0.1) )) 
b &lt;- data.frame( x=1:5, y=sin(seq(0.1,0.2,0.1) )) 
l &lt;- melt(list(a=a,b=b),id.vars=""x"") 
qplot( x, value, data=l ) + geom_smooth() + facet_wrap( ~ L1 )
</code></pre>
"
1692336,143377,2009-11-07T07:39:09Z,7,Applying a function to a distance matrix in R,"<p>This question came today in the manipulatr mailing list.</p>

<pre><code>http://groups.google.com/group/manipulatr/browse_thread/thread/fbab76945f7cba3f
</code></pre>

<p>I am rephrasing.</p>

<p>Given a distance matrix (calculated with <code>dist</code>) apply a function to the rows of the distance matrix.</p>

<p>Code:</p>

<pre><code>library(plyr)
N &lt;- 100
a &lt;- data.frame(b=1:N,c=runif(N))
d &lt;- dist(a,diag=T,upper=T)
sumd &lt;- adply(as.matrix(d),1,sum)
</code></pre>

<p>The problem is that to apply the function by row you have to store the whole matrix (instead of just the lower triangular part. So it uses too much memory for large matrices. It fails in my computer for matrices of dimensions ~ 10000.</p>

<p>Any ideas?</p>
"
1699046,87661,2009-11-09T04:08:53Z,116,For each row in an R dataframe,"<p>I have a dataframe, and for each row in that dataframe I have to do some complicated lookups and append some data to a file.</p>

<p>The dataFrame contains scientific results for selected wells from 96 well plates used in biological research so I want to do something like:</p>

<pre><code>for (well in dataFrame) {
  wellName &lt;- well$name    # string like ""H1""
  plateName &lt;- well$plate  # string like ""plate67""
  wellID &lt;- getWellID(wellName, plateName)
  cat(paste(wellID, well$value1, well$value2, sep="",""), file=outputFile)
}
</code></pre>

<p>In my procedural world, I'd do something like:</p>

<pre><code>for (row in dataFrame) {
    #look up stuff using data from the row
    #write stuff to the file
}
</code></pre>

<p>What is the ""R way"" to do this?</p>
"
1704324,30176,2009-11-09T22:21:39Z,4,Is there a free Statistics Package for Delphi?,"<p>Is there an open source and/or free statistics package or library for <a href=""http://en.wikipedia.org/wiki/Delphi_programming_language"" rel=""nofollow noreferrer"">Delphi</a>? I'm looking for something that can compile directly into the executable, so no DLL's. It needs to be compatible with Delphi 2009 and later (the Unicode versions).</p>

<p>Hopefully there is something comprehensive available out there. By comparison, I am used to the amazing features of <a href=""http://www.sas.com/technologies/analytics/statistics/stat/index.html"" rel=""nofollow noreferrer"">SAS</a> and <a href=""http://www.r-project.org/"" rel=""nofollow noreferrer"">R</a>.  </p>

<p>I'm looking for distribution functions (normal, binomial, chi square, <a href=""http://en.wikipedia.org/wiki/Logit"" rel=""nofollow noreferrer"">logit</a>) and regression (linear, non-linear, multinomial) and if possible predictors (e.g. <a href=""http://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average"" rel=""nofollow noreferrer"">ARIMA</a>).</p>
"
1708074,134830,2009-11-10T13:47:12Z,10,Debugging generic functions in R,"<p>How do you debug a generic function (using debug, or mtrace in the debug package)?</p>

<p>As an example, I want to debug cenreg in the NADA package, specifically the method that takes a formula input.</p>

<p>You can retrieve the method details like this:</p>

<pre><code>library(NADA)
getMethod(""cenreg"", c(""formula"", ""missing"", ""missing""))

function (obs, censored, groups, ...) 
{
    .local &lt;- function (obs, censored, groups, dist, conf.int = 0.95, 
        ...) 
    {
        dist = ifelse(missing(dist), ""lognormal"", dist)

...
}
</code></pre>

<p>The problem is that cenreg itself looks like this:</p>

<pre><code>body(cenreg)
# standardGeneric(""cenreg"")
</code></pre>

<p>I don't know how to step through the underlying method, rather than the generic wrapper.</p>
"
1710340,101419,2009-11-10T18:57:44Z,10,Generating non-duplicate permutation pairs in R,"<p>Sorry for the non-descriptive title but I don't know whether there's a word for what I'm trying to achieve.</p>

<p>Let's assume that I have a list of names of different classes like</p>

<pre><code>c( '1', '2', '3', '4')
</code></pre>

<p>I'd like to generate all possible permutation pairs out of this so that there are no reverse-duplicates. So what I'd like to have is something like</p>

<pre><code>'1' '2'
'1' '3'
'1' '4'
'2' '3'
'2' '4'
'3' '4'
</code></pre>

<p>Note that I don't have e.g. <code>'2' '1'</code> because I already have <code>'1' '2'</code>. Is there an easy way to achieve this in R?</p>
"
1710853,2002705,2009-11-10T20:10:25Z,20,"How to run R on a server without X11, and avoid broken dependencies","<p>I'm running R 2.9 on a large EC2 Ubuntu instance, loaded with RAM, but without a terminal.  When I load a library that has display dependencies, such as the sqldf package, I receive the following error:</p>

<pre><code>library(sqldf)
...
Loading required package: tcltk
Loading Tcl/Tk interface ... Error in fun(...) : couldn't connect to display ""localhost:11.0""
Error : .onLoad failed in 'loadNamespace' for 'tcltk'
Error: package 'tcltk' could not be loaded
</code></pre>

<p>This seems to be a general problem, and I'm wondering how others have solved it.  Installing an X11 server is not a desirable solution.</p>
"
1712316,86684,2009-11-11T00:56:18Z,0,Strange error when using sparse matrices and glmnet,"<p>I'm getting a weird error when training a glmnet regression.</p>

<pre><code>invalid class ""dgCMatrix"" object: length(Dimnames[[2]])' must match Dim[2] 
</code></pre>

<p>It only happens occasionally, and perhaps only under larger datasets.</p>

<p>I'm not sure whether it's consistent it happens given a certain dataset.</p>

<p>Any clues?</p>
"
1714280,141789,2009-11-11T10:19:32Z,30,Multivariate time series modelling in R,"<p>I want do fit some sort of multi-variate time series model using R. </p>

<p>Here is a sample of my data:</p>

<pre><code>   u     cci     bci     cpi     gdp    dum1 dum2 dum3    dx  
 16.50   14.00   53.00   45.70   80.63  0   0    1     6.39 
 17.45   16.00   64.00   46.30   80.90  0   0    0     6.00 
 18.40   12.00   51.00   47.30   82.40  1   0    0     6.57 
 19.35   7.00    42.00   48.40   83.38  0   1    0     5.84 
 20.30   9.00    34.00   49.50   84.38  0   0    1     6.36 
 20.72   10.00   42.00   50.60   85.17  0   0    0     5.78 
 21.14   6.00    45.00   51.90   85.60  1   0    0     5.16 
 21.56   9.00    38.00   52.60   86.14  0   1    0     5.62 
 21.98   2.00    32.00   53.50   86.23  0   0    1     4.94 
 22.78   8.00    29.00   53.80   86.24  0   0    0     6.25 
</code></pre>

<p>The data is quarterly, the dummy variables are for seasonality.</p>

<p>What I would like to do is to predict dx with reference to some of the others, while (possibly) allowing for seasonality. For argument's sake, lets say I want to use ""u"", ""cci"" and ""gdp"".</p>

<p>How would I go about doing this?</p>
"
1714818,167584,2009-11-11T12:14:34Z,0,How to export data from ROCR package,"<p>I am trying to export biometric data from an analysis using the ROCR package.  Here is the code that I've done so far:</p>

<pre><code>pred = performance(Matching.Score,Distribution)
perf = prediction(pred,""fnr"", ""fpr"")

An object of class “performance”

Slot ""x.name"":

[1] ""False positive rate""

Slot ""y.name"":

[1] ""False negative rate""

Slot ""alpha.name"":

[1] ""Cutoff""

Slot ""x.values"":

[[1]]

[1] 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000
[15] 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000
  ......

Slot ""y.values"":

[[1]]

[1] 1.00000 0.99999 0.99998 0.99997 0.99996 0.99995
[15] 0.99986 0.99985 0.99984 0.99983 0.99982 0.99981
    ......

Slot ""alpha.values"":

[[1]]

[1]  Inf      1.0427800 1.0221150 1.0056240 1.0032630 0.9999599
[12] 0.9644779 0.9633058 0.9628996 0.9626501 0.9607665 0.9605930
    .......
</code></pre>

<p>This results in several Slots.  I would like to export the resulting values into a text file for Excel modification using: </p>

<p><code>write(pred, ""filename"")</code></p>

<p>However, when I try to write the file, I get an error stating:</p>

<pre><code>Error in cat(list(...), file, sep, fill, labels, append) : 
  argument 1 (type 'S4') cannot be handled by 'cat'
</code></pre>

<p>Is there any way around this?</p>

<p>I'd appreciate any advice.  Thank you! </p>

<p>Matt Peterson</p>
"
1716012,142068,2009-11-11T15:39:27Z,24,Stopwatch function in R,"<p>Is there an R timer or stopwatch function similar to MATLAB's <a href=""http://www.mathworks.com/access/helpdesk/help/techdoc/ref/tic.html"" rel=""noreferrer"">tic/toc</a>?</p>
"
1716600,197321,2009-11-11T17:00:03Z,1,ggplot2: using the geom_area() function,"<p>I have a data frame showing four classes for each year, along with their respective shares of the total for that year. </p>

<pre><code>&gt; head(df)
      class year share
1    class1 1975 0.806
2    class2 1975 0.131
3    class3 1975 0.018
4    class4 1975 0.045
5    class1 1976 0.788
6    class2 1976 0.151
</code></pre>

<p>When I run <code>ggplot</code> with no <code>fill</code> specified, I get a uniform gray box, as expected.</p>

<pre><code>&gt; ggplot(df, aes(x=year, y=share, group=class)) + geom_area() + scale_fill_brewer()
</code></pre>

<p>So I try to add <code>fill=class</code>, and it doesn't work.</p>

<pre><code>&gt; ggplot(df, aes(x=year, y=share, group=class, fill=class)) + geom_area() + scale_fill_brewer()

Error in inherits(x, ""factor"") : object ""base_size"" not found
In addition: Warning message:
In inherits(x, ""factor"") : restarting interrupted promise evaluation
&gt; 
</code></pre>

<p>What can I do to the <code>class</code> factor to get it working properly with <code>scale_fill_brewer()</code>? The idea, obviously, is to shade each area of the graph according to its class.</p>

<p>Thanks.</p>
"
1719447,3788,2009-11-12T02:07:18Z,7,outer() equivalent for non-vector lists in R,"<p>I understand how outer() works in R:</p>

<pre><code>&gt; outer(c(1,2,4),c(8,16,32), ""*"")

     [,1] [,2] [,3]
[1,]    8   16   32
[2,]   16   32   64
[3,]   32   64  128
</code></pre>

<p>It basically takes 2 vectors, finds the crossproduct of those vectors, and then applies the function to each pair in the crossproduct.</p>

<p>I don't have two vectors, however. I have two lists of matrices:</p>

<p>M = list();</p>

<pre><code>M[[1]] = matrix(...)
M[[2]] = matrix(...)
M[[3]] = matrix(...)
</code></pre>

<p>And I want to do an operation on my list of matricies. I want to do:</p>

<pre><code>outer(M, M, ""*"")
</code></pre>

<p>In this case, I want to take the dot product of each combination of matrices I have.</p>

<p>Actually, I am trying to generate a kernel matrix (and I have written a kernel function), so I want to do:</p>

<pre><code>outer(M, M, kernelFunction)
</code></pre>

<p>where <code>kernelFunction</code> calculates a distance between my two matrices.</p>

<p>The problem is that outer() only takes ""vector"" arguments, rather than ""list""s etc. Is there a function that does the equivalent of outer() for non-vector entities?</p>

<p>Alternately, I could use a for-loop to do this:</p>

<pre><code>M = list() # Each element in M is a matrix

for (i in 1:numElements)
{
   for (j in 1:numElements)
   {
      k = kernelFunction(M[[i]], M[[j]])
      kernelMatrix[i,j] = k;
   }
} 
</code></pre>

<p>but I am trying to avoid this in favor of an R construct (which might be more efficient). (Yes I know I can modify the for-loop to compute the diagonal matrix and save 50% of the computations. But that's not the code that I'm trying to optimize!)</p>

<p>Is this possible? Any thoughts/suggestions?</p>
"
1721536,117357,2009-11-12T11:20:48Z,7,Changing the order of dodged bars in ggplot2 barplot,"<p>I have a dataframe <code>df.all</code> and I'm plotting it in a bar plot with ggplot2 using the code below. I'd like to make it so that the order of the dodged bars is flipped. That is, so that the bars labeled ""Singular"" come before the bars labeled ""Plural"".</p>

<pre><code>ggplot(df.all, aes(gram, V1, fill=number)) + 
    geom_bar(stat=""identity"", position=""dodge"") + 
    scale_x_discrete(labels=c(""Grammatical"",""Ungrammatical"")) +
    scale_y_continuous(formatter=""percent"", limits=c(0,1)) +
    facet_grid(. ~ experiment) + 
    scale_fill_hue(""Attractor"", breaks=c(""S"",""P""), labels=c(""Singular"",""Plural""))
</code></pre>

<p>I've tried doing <code>levels(df.all$number) = c(""S"", ""P"")</code> thinking that maybe ggplot uses the order of the levels to decide plotting order, but that didn't work. I'm not sure what else to try. Any ideas?</p>

<p>The contents of <code>df.all</code>, in case it's useful:</p>

<pre><code>&gt; df.all
  number gram     experiment        V1
1      S    G BERIMBAU_AGR_A 0.8133333
2      S    G BERIMBAU_AGR_B 0.8658537
3      S    U BERIMBAU_AGR_A 0.5436242
4      S    U BERIMBAU_AGR_B 0.4597701
5      P    G BERIMBAU_AGR_A 0.8580645
6      P    G BERIMBAU_AGR_B 0.8536585
7      P    U BERIMBAU_AGR_A 0.3087248
8      P    U BERIMBAU_AGR_B 0.3975904

&gt; str(df.all)
'data.frame':   8 obs. of  4 variables:
 $ number    : Factor w/ 2 levels ""S"",""P"": 2 2 2 2 1 1 1 1
  ..- attr(*, ""scores"")= num [1:2(1d)] 0 -1
  .. ..- attr(*, ""dimnames"")=List of 1
  .. .. ..$ : chr  ""P"" ""S""
 $ gram      : Factor w/ 2 levels ""G"",""U"": 1 1 2 2 1 1 2 2
 $ experiment: Factor w/ 4 levels ""BERIMBAU_AGR_A"",..: 1 4 1 4 1 4 1 4
 $ V1        : num  0.813 0.866 0.544 0.46 0.858 ...
</code></pre>
"
1721961,209563,2009-11-12T12:49:05Z,1,R statistical package: wrapping GOFrame objects,"<p>I'm trying to generate GOFrame objects to generate a gene ontology mapping in R for unsupported organisms (see <a href=""http://www.bioconductor.org/packages/release/bioc/vignettes/GOstats/inst/doc/GOstatsForUnsupportedOrganisms.pdf"" rel=""nofollow noreferrer"">http://www.bioconductor.org/packages/release/bioc/vignettes/GOstats/inst/doc/GOstatsForUnsupportedOrganisms.pdf</a>).</p>

<p>However, following the instructions literally doesn't help me.
Here's the code I execute (R 2.9.2 on ubuntu koala 64 bit)</p>

<pre><code>library(""AnnotationDbi"")
library(""org.Hs.eg.db"")
frame = toTable(org.Hs.egGO)
goframeData = data.frame(frame$go_id, frame$Evidence, frame$gene_id)
goFrame = GOFrame(goframeData, organism = ""Homo sapiens"")
</code></pre>

<p>However, when i try to map my dataframe into a goFrame object, I get this mistake</p>

<pre><code>Error: could not find function ""GOFrame""
</code></pre>

<p>I'm pretty sure the GOFrame wrapper is in the AnnotationDBI library, so I'm puzzled.
Any help is extra appreciated :-)</p>
"
1724024,170364,2009-11-12T17:38:08Z,14,Using C++ libraries in an R package,"<p>What is the best way to make use of a C++ library in R, hopefully preserving the C++ data structures.  I'm not at all a C++ user, so I'm not clear on the relative merits of the available approaches.  The R-ext manual seems to suggest wrapping every C++ function in C.   However, at least four or five other means of incorporating C++ exist.</p>

<p>Two ways are packages w/ similar lineage, the Rcpp (maintained by the prolific overflower Dirk Eddelbuettel) and RcppTemplate packages (both on CRAN), what are the differences between the two?  </p>

<p>Another package, rcppbind available, on R forge that claims to take a different approach to binding C++ and R (I'm not knowledgeable to tell).</p>

<p>The package inline available on CRAN, claims to allow inline C/C++ I'm not sure this differs from the built in functionality, aside for allowing the code to be inline w/R.  </p>

<p>And, finally RSwig which appears to be <a href=""http://www.swig.org/Doc1.3/R.html"" rel=""noreferrer"">in the wild</a> but it is unclear how supported it is, as the <a href=""http://www.omegahat.org/RSWIG/GettingStarted.html"" rel=""noreferrer"">author's page</a> hasn't been updated for years.</p>

<p>My question is, what are the relative merits of these different approaches.  Which are the most portable and robust, which are the easiest to implement.  If you were planning to distribute a package on CRAN which of the methods would you use?</p>
"
1725609,NA,2009-11-12T21:40:18Z,9,R and HDF5 Troubles,"<p>I am trying to load an hdf5 into R and running into some problems.  Here are the steps I took to configure my environment:</p>

<ul>
<li>R 2.10.0 (x64) on Mac OS X 10.6</li>
<li>hdf5 1.8.3 installed via macports</li>
<li>hdf5_1.6.9.tar.gz from CRAN</li>
</ul>

<p>I suspect the problem I am having relates to incompatibilities in my version of HDF5 and the one the R module expects.  For completeness here is how I installed the R module:</p>

<blockquote>
  <p>R CMD INSTALL --configure-vars='CPPFLAGS=-I/opt/local/include' --configure-args='--with-hdf5=/opt/local' hdf5_1.6.9.tar.gz</p>
</blockquote>

<p>This builds fine.  The library seems to load without issue, but no data is returned when I try to load a file:</p>

<blockquote>
  <p>library(hdf5)</p>
  
  <p>hdf5load(""test.h5"")</p>
  
  <p>NULL</p>
</blockquote>

<p>Yet,</p>

<blockquote>
  <p>osx:data scott$ h5dump test.h5 
  HDF5 ""test.h5"" {
  GROUP ""/"" {
     DATASET ""dset"" {
        DATATYPE  H5T_STD_I32LE
        DATASPACE  SIMPLE { ( 31 ) / ( 31 ) }
        DATA {
        (0): 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192,
        (14): 16384, 32768, 65536, 131072, 262144, 524288, 1048576, 2097152,
        (22): 4194304, 8388608, 16777216, 33554432, 67108864, 134217728,
        (28): 268435456, 536870912, 1073741824
        }
     }
  }
  }</p>
</blockquote>

<p>Any thoughts?</p>

<p>Thanks in advance.</p>
"
1727772,162436,2009-11-13T07:53:33Z,391,Quickly reading very large tables as dataframes in R,"<p>I have very large tables (30 million rows) that I would like to load as a dataframes in R.  <code>read.table()</code> has a lot of convenient features, but it seems like there is a lot of logic in the implementation that would slow things down.  In my case, I am assuming I know the types of the columns ahead of time, the table does not contain any column headers or row names, and does not have any pathological characters that I have to worry about.</p>

<p>I know that reading in a table as a list using <code>scan()</code> can be quite fast, e.g.:</p>

<pre><code>datalist &lt;- scan('myfile',sep='\t',list(url='',popularity=0,mintime=0,maxtime=0)))
</code></pre>

<p>But some of my attempts to convert this to a dataframe appear to decrease the performance of the above by a factor of 6:</p>

<pre><code>df &lt;- as.data.frame(scan('myfile',sep='\t',list(url='',popularity=0,mintime=0,maxtime=0))))
</code></pre>

<p>Is there a better way of doing this?  Or quite possibly completely different approach to the problem?</p>
"
1734896,211082,2009-11-14T17:15:32Z,21,R - capturing elements of R output into text files,"<p>I am trying to run an analysis by invoking R through the command line as follows: </p>

<pre><code>R --no-save &lt; SampleProgram.R &gt; SampleProgram.opt
</code></pre>

<p>For example, consider the simple R program below: </p>

<pre><code>mydata = read.csv(""test.txt"", header=T)
attach(mydata)
summary(Variable1)
q()
</code></pre>

<p>The output is displayed in SampleProgram.opt (only partially shown): </p>

<pre><code>&gt; mydata = read.csv(""test.txt"", header=T)
&gt; attach(mydata)
&gt; summary(Variable1)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
   1.00    1.00    2.00    2.47    3.00    4.00
&gt; q()
</code></pre>

<p>This simple R program is going to be executed by a script that needs to use the summary statistics displayed for Variable1. </p>

<p>The question is this: Is there any way in R to capture the output of summary(Variable1) and write the results into an output file? In other words, I need R to run the summary statistics for Variable1, capture the ""Min"", ""Median"" and ""Max"" values and write those alone to an output text file. In this example, the output file should contain only one line with the values ""1.00, 2.00, 4.00"" (i.e. the ""Min"", ""Median"" and ""Max"" values). </p>

<p>The example above talks about the summary function. But, I need to do that with other commands as well (such as glm)</p>

<p>I am fairly new to R and was wondering if there was a way in R that I could do this? </p>

<p>Thanks for the help.  </p>
"
1735540,37751,2009-11-14T20:46:51Z,16,Creating a Pareto Chart with ggplot2 and R,"<p>I have been struggling with how to make a <a href=""http://en.wikipedia.org/wiki/Pareto_chart"" rel=""noreferrer"">Pareto Chart</a> in R using the ggplot2 package. In many cases when making a bar chart or histogram we want items sorted by the X axis. In a Pareto Chart we want the items ordered descending by the value in the Y axis. Is there a way to get ggplot to plot items ordered by the value in the Y axis? I tried sorting the data frame first but it seems ggplot reorders them. </p>

<p>Example:</p>

<pre><code>val &lt;- read.csv(""http://www.cerebralmastication.com/wp-content/uploads/2009/11/val.txt"")
val&lt;-with(val, val[order(-Value), ])
p &lt;- ggplot(val)
p + geom_bar(aes(State, Value, fill=variable), stat = ""identity"", position=""dodge"") + scale_fill_brewer(palette = ""Set1"")
</code></pre>

<p>the data frame val is sorted but the output looks like this:</p>

<p><a href=""http://www.cerebralmastication.com/wp-content/uploads/2009/11/exp.png"" rel=""noreferrer"">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/11/exp.png</a></p>

<p>Hadley correctly pointed out that this produces a much better graphic for showing actuals vs. predicted:</p>

<pre><code>ggplot(val, aes(State, Value)) + geom_bar(stat = ""identity"", subset = .(variable == ""estimate""), fill = ""grey70"") + geom_crossbar(aes(ymin = Value, ymax = Value), subset = .(variable == ""actual""))
</code></pre>

<p>which returns:</p>

<p><a href=""http://www.cerebralmastication.com/wp-content/uploads/2009/11/exp1.png"" rel=""noreferrer"">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/11/exp1.png</a></p>

<p>But it's still not a Pareto Chart. Any tips?</p>
"
1740774,182378,2009-11-16T08:12:24Z,3,0-1 sequence without spaces,"<p>Spaces are redundant when reporting a binary sequence. This code</p>

<pre><code>x &lt;- '1 0 0 0 0 0 1 1 0 1 0 1 1 0 '
y&lt;-gsub(' +', '', x)
</code></pre>

<p>does the job so I can copy and paste from R. How do I do the same for 0-1 sequences (and other one-digit data) in others formats, e.g.,</p>

<pre><code>x &lt;- c(1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0)
</code></pre>

<p>or</p>

<pre><code>toString(x)
</code></pre>

<p>or whatever (for the sake of learning various options)? Thanks.</p>
"
1741820,203420,2009-11-16T12:14:51Z,428,Assignment operators in R: '=' and '<-',"<p>What are differences in the assignment operators '=' and '&lt;-' in R? I know that operators are slightly different as this example shows</p>

<pre><code>x &lt;- y &lt;- 5
x = y = 5
x = y &lt;- 5
x &lt;- y = 5
# Error in (x &lt;- y) = 5 : could not find function ""&lt;-&lt;-""
</code></pre>

<p>But is this the only difference? </p>
"
1743698,209467,2009-11-16T17:39:31Z,180,Evaluate expression given as a string,"<p>I'm curious to know if R can use its <code>eval()</code> function to perform calculations provided by e.g. a string.</p>

<p>This is a common case:</p>

<pre><code>eval(""5+5"")
</code></pre>

<p>However, instead of 10 I get:</p>

<pre><code>[1] ""5+5""
</code></pre>

<p>Any solution?</p>
"
1745514,3788,2009-11-16T23:19:22Z,11,How to define argument types for R functions?,"<p>I am writing an R function, and I want to make sure that the argument of my R function is of a certain class (eg, ""matrix"").</p>

<p>What is the best way to do this?</p>

<p>Say I have a function ""foo"" which computes the inverse of a matrix:</p>

<pre><code>foo &lt;- function(x)
{
   # I want to make sure x is of type ""matrix""
   solve(x)
}
</code></pre>

<p>How can I say - as you might in C - <code>function(matrix x)</code> to denote that ""<code>x</code> must be of type <code>matrix</code>, and if it isn't, then return an error""?</p>
"
1745622,3788,2009-11-16T23:44:25Z,30,"Best way to allocate matrix in R, NULL vs NA?","<p>I am writing R code to create a square matrix. So my approach is:</p>

<ol>
<li>Allocate a matrix of the correct size</li>
<li>Loop through each element of my matrix and fill it with an appropriate value</li>
</ol>

<p>My question is really simple: what is the best way to pre-allocate this matrix? Thus far, I have two ways:</p>

<pre><code>&gt; x &lt;- matrix(data=NA,nrow=3,ncol=3)
&gt; x
     [,1] [,2] [,3]
[1,]   NA   NA   NA
[2,]   NA   NA   NA
[3,]   NA   NA   NA
</code></pre>

<p>or</p>

<pre><code>&gt; x &lt;- list()
&gt; length(x) &lt;- 3^2
&gt; dim(x) &lt;- c(3,3)
&gt; x
     [,1] [,2] [,3]
[1,] NULL NULL NULL
[2,] NULL NULL NULL
[3,] NULL NULL NULL
</code></pre>

<p>As far as I can see, the former is a more concise method than the latter. Also, the former fills the matrix with NAs, whereas the latter is filled with NULLs.</p>

<p>Which is the ""better"" way to do this? In this case, I'm defining ""better"" as ""better performance"", because this is statistical computing and this operation will be taking place with large datasets.</p>

<p>While the former is more concise, it isn't breathtakingly easier to understand, so I feel like this could go either way.</p>

<p>Also, what is the difference between NA and NULL in R? ?NA and ?NULL tell me that ""NA"" has a length of ""1"" whereas NULL has a length of ""0"" - but is there more here? Or a best practice? This will affect which method I use to create my matrix.</p>
"
1748590,209467,2009-11-17T12:36:48Z,5,REvolution for R,"<p>since the latest Ubuntu release (karmic koala), I noticed that the internal R package advertises on start-up the <a href=""http://www.revolution-computing.com/"" rel=""nofollow noreferrer"">REvolution</a> package.
It seems to be a library collection for high-performance matrix calculations. And it seems to really work, apparently. For example on a matrix transposition with REvolution:</p>

<pre><code>&gt; system.time(t(matrix(rnorm(10000000),ncol=1000)))
   user  system elapsed 
  1.280   0.150   1.556 
</code></pre>

<p>And without REvolution:</p>

<pre><code>&gt; system.time(t(matrix(rnorm(10000000),ncol=1000)))
   user  system elapsed 
  1.320   0.170   1.725 
</code></pre>

<p>Is anyone using it? Is it really working? Which specific types of calculation is it improving and how? Any drawback?</p>

<p>Thanks :-)</p>
"
1751540,142477,2009-11-17T20:27:56Z,3,specifying column names of a data frame within a function ahead of time,"<p>Suppose you're trying to create a data frame within a function.  I would like to be able to define the column names ahead of time as one of the parameters of the function.  Take the following code:</p>

<pre><code>  foo &lt;- function(a) {
    answer &lt;- data.frame(a=1:5)
    return(answer)
    }
</code></pre>

<p>In the above example, I would like to be able to specify the value of the column name in the function <code>foo()</code>, e.g. <code>foo('my.name')</code> so that answer has the column name <code>my.name</code> instead of <code>a</code>.  I imagine you could code this up within the function using <code>colnames()</code>, but I was interested in an alternative approach.</p>
"
1753299,3788,2009-11-18T02:42:43Z,6,Help using predict() for kernlab's SVM in R?,"<p>I am trying to use the <code>kernlab</code> R package to do Support Vector Machines (SVM). For my very simple example, I have two pieces of training data. A and B.</p>

<p>(A and B are of type <code>matrix</code> - they are adjacency matrices for graphs.)</p>

<p>So I wrote a function which takes A+B and generates a kernel matrix.</p>

<pre><code>&gt; km
         [,1]     [,2]
[1,] 14.33333 18.47368
[2,] 18.47368 38.96053
</code></pre>

<p>Now I use <code>kernlab</code>'s <code>ksvm</code> function to generate my predictive model. Right now, I'm just trying to get the darn thing to work - I'm not worried about training error, etc.</p>

<p>So, <strong>Question 1</strong>: Am I generating my model correctly? Reasonably?</p>

<pre><code># y are my classes. In this case, A is in class ""1"" and B is in class ""-1""
&gt; y
[1]  1 -1

&gt; model2 =  ksvm(km, y, type=""C-svc"", kernel = ""matrix"");
&gt; model2
Support Vector Machine object of class ""ksvm"" 

SV type: C-svc  (classification) 
 parameter : cost C = 1 

[1] "" Kernel matrix used as input.""

Number of Support Vectors : 2 

Objective Function Value : -0.1224 
Training error : 0 
</code></pre>

<p>So far so good. We created our custom kernel matrix, and then we created a ksvm model using that matrix. We have our training data labeled as ""1"" and ""-1"".</p>

<p>Now to predict:</p>

<pre><code>&gt; A
     [,1] [,2] [,3]
[1,]    0    1    1
[2,]    1    0    1
[3,]    0    0    0

&gt; predict(model2, A)
Error in as.matrix(Z) : object 'Z' not found
</code></pre>

<p>Uh-oh. This is okay. Kind of expected, really. ""Predict"" wants some sort of vector, not a matrix.</p>

<p>So lets try some things:</p>

<pre><code>&gt; predict(model2, c(1))
Error in as.matrix(Z) : object 'Z' not found
&gt; predict(model2, c(1,1))
Error in as.matrix(Z) : object 'Z' not found
&gt; predict(model2, c(1,1,1))
Error in as.matrix(Z) : object 'Z' not found
&gt; predict(model2, c(1,1,1,1))
Error in as.matrix(Z) : object 'Z' not found
&gt; predict(model2, km)
Error in as.matrix(Z) : object 'Z' not found
</code></pre>

<p>Some of the above tests are nonsensical, but that is my point: no matter what I do, I just can't get predict() to look at my data and do a prediction. Scalars don't work, vectors don't work. A 2x2 matrix doesn't work, nor does a 3x3 matrix.</p>

<p><strong>What am I doing wrong here?</strong></p>

<p>(Once I figure out what ksvm <em>wants</em>, then I can make sure that my test data can conform to that format in a sane/reasonable/mathematically sound way.)</p>
"
1753950,213513,2009-11-18T05:59:51Z,0,Passing a function argument through R-function nlm,"<p>I am probably being unreasonable asking for help debugging a program, but I have spent a day and a half on this pretty simple bit of code and have run out of ideas. I am trying to optimise a function called ""log.pr.data"" with respect to its first argument. </p>

<p>Because the function optimise requires you to set bounds on the argument I decided to use nlm which only requires a starting point. I have checked with simple exampels that nlm is indeed able to pass functions as arguments. My problem is that I am unable to pass a function as an argument in this particular case. </p>

<p>So here is the objective function (with two print diagnostics). I want to maximise it with respect to the argument lambda.s. (As a matter of interest, I am not maximising a likelihood here. I am trying to optimise an importance sampler.)</p>

<pre><code>log.pr.data&lt;-function(lambda.s,n1,n0,lambda.star,psi0,tobs,g=T.chan){
           print(""Function log.pr.data"")
           print(g)
          psi.s&lt;-boundary(lambda.s,g,psi0,tobs,n1,n0)
         -my.dbinom(n0*lambda.s,n0,lambda.star,log=TRUE)
}
</code></pre>

<p>I have no problems with the command:</p>

<pre><code>nlm(log.pr.data,p=0.6,n1=n1,n0=n0,lambda.star=lambda.star,psi0=psi0,tobs=tobs)
</code></pre>

<p>It works fine. But I want to be able to chance the function g=T.chan. So I redefined the function leaving g unspecified in log.pr.data. In other words, I just removed the ""=T.chan"" in the argument list. I checked that the function works OK. For instance with the command</p>

<pre><code> log.pr.data(l,n1,n0,lambda.star,psi0,tobs,T.chan)
</code></pre>

<p>for a range of values of ""l"" and it works fine and gives the same values as the previous function where g=T.chan is specified in the argument list. So the function T.chan is being passed properly it appears.</p>

<p>I then try to optimise</p>

<pre><code>nlm(log.pr.data,p=0.6,n1=n1,n0=n0,lambda.star=lambda.star,psi0=psi0,tobs=tobs,g=T.chan)
</code></pre>

<p>and I get the error</p>

<blockquote>
  <p>Error in nlm(function(x) f(x, ...), p,
  hessian, typsize, fscale, msg,  : 
          invalid NA value in parameter</p>
</blockquote>

<p>It is also interesting that there does not seem to be a single call to log.pr.data because ""Function log.pr.data"" is not printed. In earlier attempts to trouble shoot this problem, I realised that I was using the symbol ""f"" for the function being passed and that this might cause problems because nlm called its obejctive function ""f"". So I changed it to ""g"" throughout.</p>
"
1755642,141789,2009-11-18T12:28:26Z,1,How to plot fitted model over observed time series,"<p>This is a really really simple question to which I seem to be entirely unable to get a solution. I would like to do a scatter plot of an observed time series in R, and over this I want to plot the fitted model.</p>

<p>So I try something like:</p>

<pre><code>model &lt;- lm(x~y+z)
plot(x)
lines(fitted(model))
</code></pre>

<p>But this just plots x with lines.</p>

<p>Thanks</p>
"
1756209,177390,2009-11-18T14:01:56Z,5,R demo() and example() methods?,"<p>Is there a simple way to check if <code>R functions</code> and <code>packages</code> have <code>demo()</code> and <code>example()</code> methods?</p>

<p>When building a package, does the package need to have the necessary objects so that <code>demo()</code> and <code>example()</code> can be called on it?</p>

<p><strong>Edit:</strong> In trying to answer this, I checked the source code of <code>demo()</code></p>

<pre><code>demo(package = .packages(all.available = TRUE)) # check which packages have demo
</code></pre>
"
1760068,214198,2009-11-19T00:16:15Z,4,Adding a line to ggplot,"<p>I am trying to add a line to a plot of points, and I can't figure it out.  My y values are numbers from 0 to Inf, while my x values are from an ordered factor.</p>

<p>Here is the plotting code, which only displays points:</p>

<pre><code>g = ggplot() +
  layer(data = ratesdf, mapping = aes(x = age, y = rates), geom = ""point"", stat=""identity"") +
  layer(data = ratesdf, mapping = aes(x = age, y = rates), geom = ""smooth"", stat = ""smooth"", method = loess)
print(g)
</code></pre>

<p>Here is the dataframe:</p>

<pre><code>          rates      age
[0,5)    0.00000000    [0,5)
[5,10)   0.00000000   [5,10)
[10,15)  0.00000000  [10,15)
[15,20)  0.02017059  [15,20)
[20,25)  0.32707402  [20,25)
[25,30)  0.54013169  [25,30)
[30,35)  0.71698958  [30,35)
[35,40)  0.81120944  [35,40)
[40,45)  0.87283637  [40,45)
[45,50)  0.91411649  [45,50)
[50,55)  0.91273334  [50,55)
[55,60)  0.95627322  [55,60)
[60,65)  0.92879819  [60,65)
[65,70)  0.98088779  [65,70)
[70,75)  0.90406674  [70,75)
[75,80)  1.00000000  [75,80)
[80,85)  1.00000000  [80,85)
[85,Inf] 1.00000000 [85,Inf]
</code></pre>

<p>Thanks to everyone in advance!</p>

<p>(Hadley, I promise to buy your book as soon as I get my annual birthday giftcards :)  )</p>
"
1761852,141789,2009-11-19T08:56:41Z,1,R: Use VAR model to predict response to change in values of certain variables,"<p>I've fitted a VECM model in R, and converted in to a VAR representation. I would like to use this model to predict the future value of a response variable based on different scenarios for the explanatory variables.</p>

<p>Here is the code for the model:</p>

<pre><code>library(urca)
library(vars)

input &lt;-read.csv(""data.csv"")
ts &lt;- ts(input[16:52,],c(2000,1),frequency=4)
dat1 &lt;- cbind(ts[,""dx""], ts[,""u""], ts[,""cci""],ts[,""bci""],ts[,""cpi""],ts[,""gdp""])

args('ca.jo')
vecm &lt;- ca.jo(dat1, type = 'trace', K = 2, season = NULL,spec=""longrun"",dumvar=NULL)
vecm.var &lt;- vec2var(vecm,r=2)    
</code></pre>

<p>Now what I would like do is to predict ""dx"" into the future by varying the others. I am not sure if something like ""predict dx if u=30,cpi=15,bci=50,gdp=..."" in the next period would work. So what I have in mind is something along the lines of: increase ""u"" by 15% in the next period (which would obviously impact on all the other variables as well, including ""dx"") and predict the impact into the future.</p>

<p>Also, I am not sure if the ""vec2var"" step is necessary, so please ignore it if you think it is redundant.</p>

<p>Thanks<br>
Karl</p>
"
1769365,78912,2009-11-20T09:36:18Z,11,how to remove partial duplicates from a data frame?,"<p>Data I'm importing describes numeric measurements taken at various locations for more or less evenly spread timestamps.  sometimes this ""evenly spread"" is not really true and I have to discard some of the values, it's not that important which one, as long as I have one value for each timestamp for each location.  </p>

<p>what I do with the data?  I add it to a <code>result</code> data.frame.  There I have a <code>timestamp</code> column and the values in the timestamp column, they are definitely evenly spaced according to the <code>step</code>.</p>

<pre><code>timestamps &lt;- ceiling(as.numeric((timestamps-epoch)*24*60/step))*step*60 + epoch
result[result$timestamp %in% timestamps, columnName] &lt;- values
</code></pre>

<hr>

<p>This does NOT work when I have timestamps that fall in the same time step.  This is an example:</p>

<pre><code>&gt; data.frame(ts=timestamps, v=values)
                   ts         v
1 2009-09-30 10:00:00 -2.081609
2 2009-09-30 10:04:18 -2.079778
3 2009-09-30 10:07:47 -2.113531
4 2009-09-30 10:09:01 -2.124716
5 2009-09-30 10:15:00 -2.102117
6 2009-09-30 10:27:56 -2.093542
7 2009-09-30 10:30:00 -2.092626
8 2009-09-30 10:45:00 -2.086339
9 2009-09-30 11:00:00 -2.080144
&gt; data.frame(ts=ceiling(as.numeric((timestamps-epoch)*24*60/step))*step*60+epoch,
+ v=values)
                   ts         v
1 2009-09-30 10:00:00 -2.081609
2 2009-09-30 10:15:00 -2.079778
3 2009-09-30 10:15:00 -2.113531
4 2009-09-30 10:15:00 -2.124716
5 2009-09-30 10:15:00 -2.102117
6 2009-09-30 10:30:00 -2.093542
7 2009-09-30 10:30:00 -2.092626
8 2009-09-30 10:45:00 -2.086339
9 2009-09-30 11:00:00 -2.080144
</code></pre>

<p>in Python I would (mis)use a dictionary to achieve what I need:</p>

<pre><code>dict(zip(timestamps, values)).items()
</code></pre>

<p>returns a list of pairs where the first coordinate is unique.</p>

<p>in R I don't know how to do it in a compact and efficient way.</p>
"
1770787,141789,2009-11-20T14:29:55Z,8,R: access field values,"<p>I would like to know how I can access the individual fields contained in an R object. Or, more precisely, how to get R to tell me how.</p>

<p>For example, if I run the following code:</p>

<pre><code>dx.ct &lt;- ur.df(dat1[,'dx'], lags=3, type='trend')
summary(dx.ct)
</code></pre>

<p>then I get this output:</p>

<pre><code>############################################### 
# Augmented Dickey-Fuller Test Unit Root Test # 
############################################### 

Test regression trend 


Call:
lm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.46876 -0.24506  0.02420  0.15752  0.66688 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)  
(Intercept)  1.099231   0.561377   1.958   0.0606 .
z.lag.1     -0.239438   0.141093  -1.697   0.1012  
tt          -0.019831   0.007799  -2.543   0.0170 *
z.diff.lag1 -0.306326   0.193001  -1.587   0.1241  
z.diff.lag2 -0.214229   0.186135  -1.151   0.2599  
z.diff.lag3 -0.223433   0.179040  -1.248   0.2228  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 

Residual standard error: 0.3131 on 27 degrees of freedom
Multiple R-squared: 0.3326,     Adjusted R-squared: 0.209 
F-statistic: 2.691 on 5 and 27 DF,  p-value: 0.04244 


Value of test-statistic is: -1.697 2.4118 3.2358 

Critical values for test statistics: 
      1pct  5pct 10pct
tau3 -4.15 -3.50 -3.18
phi2  7.02  5.13  4.31
phi3  9.31  6.73  5.61
</code></pre>

<p>So, I know that I should be able to access all of the values above individually, I don't know how to point to them. Is there some way to ask R to show me how they are stored?</p>

<p>I am thinking along the lines of:</p>

<pre><code>showobjects(summary(dx.ct))
</code></pre>

<p>And then it outputs</p>

<pre><code>$formula
$residuals
$coefficients
etc.
</code></pre>

<p>and then I can do</p>

<pre><code>showobjects(summary(dx.ct)$residuals)
</code></pre>

<p>which then outputs</p>

<pre><code>$min
$1Q
$median
etc.
</code></pre>

<p>Thanks<br>
Karl</p>
"
1772964,177390,2009-11-20T20:11:34Z,1,Growing matrices in R from NULL,"<p>What is the problem with initializing a matrix object to <code>NULL</code> and then growing it with <code>cbind()</code> and <code>rbind()</code>?
In case the number of rows and columns are not known a priori, is it not necessary to grow from <code>NULL</code>?</p>

<p>Edit: My question was prompted by the need to understand memory efficient ways of writing R code. The matrix context is more general and I'm probably looking for suggestions about efficient ways to handle other data objects as well.
Apologize for being too abstract/generic, but I did not really have a specific problem in mind.</p>
"
1773366,215811,2009-11-20T21:31:12Z,15,An NA in subsetting a data.frame does something unexpected,"<p>Consider the following code.  When you don't explicitly test for <code>NA</code> in your condition, that code will fail at some later date then your data changes.</p>

<pre><code>&gt;   # A toy example
&gt;   a &lt;- as.data.frame(cbind(col1=c(1,2,3,4),col2=c(2,NA,2,3),col3=c(1,2,3,4),col4=c(4,3,2,1)))
&gt;   a
  col1 col2 col3 col4
1    1    2    1    4
2    2   NA    2    3
3    3    2    3    2
4    4    3    4    1
&gt;   
&gt;   # Bummer, there's an NA in my condition
&gt;   a$col2==2
[1]  TRUE    NA  TRUE FALSE
&gt; 
&gt;   # Why is this a good thing to do?
&gt;   # It NA'd the whole row, and kept it
&gt;   a[a$col2==2,]
   col1 col2 col3 col4
1     1    2    1    4
NA   NA   NA   NA   NA
3     3    2    3    2
&gt;   
&gt;   # Yes, this is the right way to do it
&gt;   a[!is.na(a$col2) &amp; a$col2==2,]
  col1 col2 col3 col4
1    1    2    1    4
3    3    2    3    2
&gt;     
&gt;   # Subset seems designed to avoid this problem
&gt;   subset(a, col2 == 2)
  col1 col2 col3 col4
1    1    2    1    4
3    3    2    3    2
</code></pre>

<p>Can someone explain why the behavior you get without the <code>is.na</code> check would ever be good or useful?</p>
"
1774112,200303,2009-11-21T00:51:12Z,0,Eclipse 3.5 / Statet / R Console not working on Ubuntu linux,"<p>I had Eclipse 3.4 working nicely with the R Console over rJava. I want to get Sweave working in Eclipse, but need Eclipse 3.5 / statet 0.8 to do it.</p>

<p>When I try to start the rJava Console the JVM starts, but no feedback comes back to the console in Eclipse.</p>

<p>JVM process below - any help gratefully received.</p>

<p>Thanks, Dave</p>

<pre><code>dave     23183 22325  0 Nov20 pts/0    00:00:52 /home/dave/dev/app/jdk1.6.0_18/bin/java -Djava.security.policy=jar:file:/home/dave/dev/app/eclipse-3.5/plugins/de.walware.statet.r.core_0.8.0.b200909221530sw.jar!/localhost.policy -Djava.rmi.server.hostname=127.0.0.1 -Djava.rmi.server.codebase=file:///home/dave/dev/app/eclipse-3.5/plugins/de.walware.rj.server_0.3.0.b200909221530sw.jar -Xss8192k -Dfile.encoding=UTF-8 -classpath /home/dave/dev/app/eclipse-3.5/plugins/de.walware.rj.server_0.3.0.b200909221530sw.jar:/home/dave/dev/app/eclipse-3.5/plugins/de.walware.rj.data_0.3.0.b200909221530sw.jar:/home/dave/dev/app/eclipse-3.5/plugins/org.eclipse.swt_3.5.1.v3555a.jar:/home/dave/dev/app/eclipse-3.5/plugins/org.eclipse.swt.gtk.linux.x86_3.5.1.v3555a.jar de.walware.rj.server.RMIServerControl start ///rjs-local-1258679148742 -auth=none -plugins=awt,
</code></pre>
"
1774559,177541,2009-11-21T04:53:44Z,0,Getting R to store the working directory for every session,"<p>I asked this on Super User, but someone suggested that I take it here because there are many more R experts.</p>

The question:

<p>I have to keep navigating to my directory when I go to File > Change dir..., which is particularly annoying.</p>

<p>Does anyone know how to make R remember the previously used directory?</p>
"
1776014,66549,2009-11-21T16:53:30Z,31,Importing Functions into Current Namespace,"<p>Let's say I have an R source file comprised of some functions, doesn't matter what they are, e.g.,</p>

<pre><code>fnx = function(x){(x - mean(x))/sd(x)}
</code></pre>

<p>I would like to be able to access them in my current R session (without typing them in obviously). It would be nice if library(""/path/to/file/my_fn_lib1.r"") worked, as ""import"" works in Python, but it doesn't. One obvious solution is to create an R Package, but i want to avoid that overhead just to import a few functions.</p>
"
1777351,216298,2009-11-22T00:43:01Z,3,how do tell if its better to standardize your data matrix first when you do principal component analysis in R?,"<p>Im trying to do principal component analysis in R . There is 2 ways of doing it , I believe. 
One is doing  principal component analysis right away the other way is  standardizing the matrix first  using s = scale(m)and then apply principal component analysis.<br>
How  do I tell what result is better ? What values in particular should i look at . I already managed to find the eigenvalues and eigenvectors , the proportion of  variance for each eigenvector using both methods. </p>

<p>I noticed that the proportion of the variance for the first  pca without standardizing had a larger  value . Is there a meaning to it ? Isnt this always the case?</p>

<p>At last , if I am  supposed to predict a variable ie weight should I drop the variable ie weight from my data matrix when I do principal component analysis ?</p>
"
1779916,216611,2009-11-22T20:36:44Z,0,Specific date format conversion problems in R,"<p>Basically I want to know why <code>as.Date(200322,format=""%Y%W"")</code> gives me <code>NA</code>. While we are at it, I would appreciate any advice on a data structure for repeated cross-section (aka pseudo-panel) in R.
I did get <code>aggregate()</code> to (sort of) work, but it is not flexible enough - it misses data on columns when I omit the missed values, for example.
Specifically, I have a survey that is repeated weekly for a couple of years with a bunch of similar questions answers to which I would like to combine, average, condition and plot in both dimensions. Getting the date conversion right should presumably help me towards my goal with zoo package or something similar.</p>

<p>Any input is appreciated.</p>

<p>Update: thanks for string suggestion, but as you can see in your own example, <code>%W</code> part doesn't work - it only identifies the year while setting the current day while I need to set a specific week (and leave the day blank).</p>
"
1782704,78912,2009-11-23T11:57:32Z,9,propagating data within a vector,"<p>I'm learning R and I'm curious...  I need a function that does this:</p>

<pre><code>&gt; fillInTheBlanks(c(1, NA, NA, 2, 3, NA, 4))
[1] 1 1 1 2 3 3 4
&gt; fillInTheBlanks(c(1, 2, 3, 4))
[1] 1 2 3 4
</code></pre>

<p>and I produced this one...  but I suspect there's a more R way to do this.</p>

<pre><code>fillInTheBlanks &lt;- function(v) {
  ## replace each NA with the latest preceding available value

  orig &lt;- v
  result &lt;- v
  for(i in 1:length(v)) {
    value &lt;- v[i]
    if (!is.na(value))
      result[i:length(v)] &lt;- value
  }
  return(result)
}
</code></pre>
"
1785118,217242,2009-11-23T18:42:48Z,6,Loess Fit and Resulting Equation,"<p>I'm a developer up in Portland, OR. I'm wondering if anyone can assist:</p>

<p>I'm working on Loess fit models using R, once I have the fit
accomplished, I'm looking to back-out the equation of the
fitted non-linear curve, wondering if there is a way to
determine this equation in R? I've been looking but can't find
any literature. For me, the graph of the function is great, but
without the equation of the graph, I'm kinda dead in the water.</p>
"
1785320,197321,2009-11-23T19:13:26Z,8,Calculating percent of row total with plyr,"<p>I am currently using <code>cast</code> on a melted table to calculate the total of each value at the combination of ID variables ID1 (row names) and ID2 (column headers), along with grand totals for each row using <code>margins=""grand_col""</code>. </p>

<p><code>c &lt;- cast(m, ID1 ~ ID2, sum, margins=""grand_col"")</code></p>

<pre><code>  ID1      ID2a  ID2b     ID2c     ID2d   ID2e    (all)
1  ID1a  6459695  885473  648019  453613 1777308 10224108
2  ID1b  7263529 1411355  587785  612730 2458672 12334071
3  ID1c  7740364 1253524  682977  886897 3559283 14123045
</code></pre>

<p>So far, so R-like.</p>

<p>Then I divide each cell by its row total to get a percentage of the total. </p>

<pre><code>c[,2:6]&lt;-c[,2:6] / c[,7]
</code></pre>

<p>This looks kludgy. Is there something I should be doing in <code>cast</code> or maybe in <code>plyr</code> to handle the percent of margin calculation in the first command? </p>

<p>Thanks,
Matt</p>
"
1785737,171659,2009-11-23T20:31:27Z,4,Determine which function is called by a generic function,"<p>I would like to know how to quickly find the specific function called by a generic function for a specific object. Example :</p>

<pre><code>library(spatial)
data(redwood)
K &lt;- Kest(redwood)
plot(K)
</code></pre>

<p>This is not an usual plot, it's a plot build for a <code>Kest()</code> object. So to investigate in order to find the function used, I do :</p>

<pre><code>class(K)
</code></pre>

<p>I get </p>

<blockquote>
  <p>""fv""         ""data.frame""</p>
</blockquote>

<p>I guess it is plot.fv</p>

<pre><code>?plot.fv
</code></pre>

<p>Yey ! But I'm sure there a more efficient way than guessing. Anyone ?</p>
"
1786667,170408,2009-11-23T23:01:07Z,0,Length doesn't work in by() aggregation?,"<p>I have some survey data that I want to describe by political party and state. </p>

<p>I'm having some trouble with the by() aggregation command. It works with lots of functions, but just not length(). Eg:</p>

<pre><code>by(x, list(party=nn$info$party,state=nn$info$st),mean)
</code></pre>

<p>works fine but not</p>

<pre><code>by(x, list(party=nn$info$party,state=nn$info$st),length)
</code></pre>

<p>Which returns an array filled not with the count of the data I'm looking for, but just a series of 1's. This is what it looks like for Alabama:</p>

<pre><code>party: D
state: AL
[1] 1
--------------------------------------------------------------------------- 
party: I
state: AL
[1] 1
--------------------------------------------------------------------------- 
party: R
state: AL
[1] 1
--------------------------------------------------------------------------- 
</code></pre>

<p>Very mystifying. Any ideas?</p>
"
1787578,205459,2009-11-24T03:24:21Z,6,problem with legend while plotting data from two data.frame,"<p>I'm having a little trouble with getting ggplot2 to work as I want. Basically, I'd like to compare actual observations vs. approximated by putting them in one single plot. For example,</p>

<pre><code>&gt; library(ggplot2)
&gt; df.actual &lt;- data.frame(x = 1:100, y = (1:100) * 2)
&gt; df.approx &lt;- data.frame(x = 1:150, y = (1:150) * 2 + 5  + rnorm(150, mean = 3) )
&gt; ggplot() + geom_point(aes(x, y), data = df.actual) + geom_line(aes(x,y), data = df.approx)
</code></pre>

<p>My problem is that I can't display a legend. I read somewhere that ggplot2's legend is not very flexible(?). Ideally, a legend with </p>

<ul>
<li>title = 'Type'</li>
<li>key: a black filled point, and a black line</li>
<li>key label: 'Actual', 'Approximate'</li>
<li>legend.position = 'topright'</li>
</ul>

<p>Thanks.</p>
"
1788779,30911,2009-11-24T08:58:44Z,22,View the source of an R package,"<p>Is there an easy way to view the source of an R package (or a method in a package), from within the interactive environment?</p>
"
1791164,209467,2009-11-24T16:22:52Z,2,Fast assessment of corrupted Affymetrix CEL files,"<p>I'm trying to normalize a big amount of Affymetrix CEL files using R. However, some of them appear to be truncated, so when reading them i get the error</p>

<pre><code>Cel file xxx does not seem to have the correct dimensions
</code></pre>

<p>And the normalization stops. Manually removing the corrupted files and restart every time will take very long. Do you know if there is a fast way (in R or with a tool) to detect corrupted files?</p>

<p>PS I'm 99.99% sure I'm normalizing together CELs from the same platform, it's really just truncated files :-)</p>
"
1794318,168139,2009-11-25T02:41:16Z,4,RGoogleDocs and now RGoogleData,"<p><a href=""http://www.omegahat.org/RGoogleDocs/"" rel=""nofollow noreferrer"">RGoogleDocs</a> is fantastic. It allows one to store data on Google and read it in in real time to R. I tried to install it on a computer the other day and lo and behold all I could find was RGoogleData in RForge. What is the relationship between the two packages? I tried to google search RGoogleData and RGoogleDocs in the same search and found nothing. Duncan Temple Lang wrote RGoogleDocs and it appears that Adrian A. Dragulescu wrote RGoogleData. </p>

<p>I could have sworn that a windows binary of RGoogleDocs had been posted in omegahat by Duncan Temple Lang but alas in the past couple of months I no longer see omegahat on the select repository option list from RGUI. Instead RForge is now on that list. What is the relationship between omegahat and RForge?</p>
"
1797712,184010,2009-11-25T15:30:42Z,3,Error when generating pdf using script in R,"<p>I'm using R to loop through the columns of a data frame and make a graph of the resulting analysis. I don't get any errors when the script runs, but it generates a pdf that cannot be opened.</p>

<p>If I run the content of the script, it works fine. I wondered if there is a problem with how quickly it is looping through, so I tried to force it to pause. This did not seem to make a difference. I'm interested in any suggestions that people have, and I'm also quite new to R so suggestions as to how I can improve the approach are welcome too. Thanks.</p>

<pre><code>for (i in 2:22) {

  # Organise data
  pop_den_z = subset(pop_den, pop_den[i] != ""0"")  # Remove zeros
  y = pop_den_z[,i]        # Get y col
  x = pop_den_z[,1]        # get x col
  y = log(y)               # Log transform

  # Regression
  lm.0 = lm(formula = y ~ x)                # make linear model
  inter = summary(lm.0)$coefficients[1,1]   # Get intercept
  slop = summary(lm.0)$coefficients[2,1]    # Get slope

  # Write to File
  a = c(i, inter, slop)
  write(a, file = ""C:/pop_den_coef.txt"", ncolumns = 3, append = TRUE, sep = "","")

  ## Setup pdf
  string = paste(""C:/LEED/results/Images/R_graphs/Pop_den"", paste(i-2), ""City.pdf"")
  pdf(string, height = 6, width = 9)

  p &lt;- qplot(
    x, y,
    xlab = ""Radius [km]"",
    ylab = ""Population Density [log(people/km)]"",
    xlim = x_range,
    main = ""Analysis of Cities""
  )

  # geom_abline(intercept,slope)
  p + geom_abline(intercept = inter, slope = slop, colour = ""red"", size = 1)

  Sys.sleep(5)

  ### close the PDF file
  dev.off()
}
</code></pre>
"
1801064,219059,2009-11-26T01:20:46Z,22,How to separate two  plots in R?,"<p>Whenever I run this code , the first plot would simply overwrite the previous one. Isnt there a way in R to separate to get two plots ? </p>

<pre><code>plot(pc)
title(main='abc',xlab='xx',ylab='yy')

plot(pcs)
title(main='sdf',xlab='sdf',ylab='xcv')
</code></pre>
"
1801487,219059,2009-11-26T04:07:54Z,3,include error terms in linear regression model with R,"<p>I was wondering if there is a way to include error terms for a linear regression model like </p>

<p>r = lm(y ~ x1+x2) ? </p>
"
1803627,78912,2009-11-26T13:19:00Z,6,understanding dates/times (POSIXc and POSIXct) in R,"<p>I'm reading a table and it contains strings that describe timestamps.  I just want to convert from string to a built-in datetime type...</p>

<pre><code>R&gt; Q &lt;- read.table(textConnection('
               tsstring
1 ""2009-09-30 10:00:00""
2 ""2009-09-30 10:15:00""
3 ""2009-09-30 10:35:00""
4 ""2009-09-30 10:45:00""
5 ""2009-09-30 11:00:00""
'), as.is=TRUE, header=TRUE)
R&gt; ts &lt;- strptime(Q$tsstring, ""%Y-%m-%d %H:%M:%S"", tz=""UTC"")
</code></pre>

<p>if I try to store the datetime column into the data.frame, I get a curious error:</p>

<pre><code>R&gt; Q$ts &lt;- ts
Error in `$&lt;-.data.frame`(`*tmp*`, ""ts"", value = list(sec = c(0, 0, 0,  : 
  replacement has 9 rows, data has 5
</code></pre>

<p>but if I go through a numeric representation held in the data.frame, it works...</p>

<pre><code>R&gt; EPOCH &lt;- strptime(""1970-01-01 00:00:00"", ""%Y-%m-%d %H:%M:%S"", tz=""UTC"")
R&gt; Q$minutes &lt;- as.numeric(difftime(ts, EPOCH, tz=""UTC""), units=""mins"")
R&gt; Q$ts &lt;- EPOCH + 60*Q$minutes
</code></pre>

<p>any help in understanding the situation?</p>
"
1805149,219059,2009-11-26T18:47:50Z,4,How to fit a linear regression model with two principal components in R?,"<p>Let's say I have a data matrix d </p>

<pre><code>pc = prcomp(d)

# pc1 and pc2 are the principal components  
pc1 = pc$rotation[,1] 
pc2 = pc$rotation[,2]
</code></pre>

<p>Then this should fit the linear regression model right? </p>

<pre><code>r = lm(y ~ pc1+pc2)
</code></pre>

<p>But then I get this error : </p>

<pre><code>Errormodel.frame.default(formula = y ~ pc1+pc2, drop.unused.levels = TRUE) : 
   unequal dimensions('pc1')
</code></pre>

<p>I guess there a packages out there who do this automatically, but this should work too? </p>
"
1809518,220120,2009-11-27T16:01:34Z,6,Getting the contents of a library interactively in R,"<p>Is there an equivalent of dir function (python) in R?</p>

<p>When I load a library in R like -</p>

<blockquote>
  <p>library(vrtest)</p>
</blockquote>

<p>I want to know all the functions that are in that library.</p>

<p>In Python, dir(vrtest) would be a list of all attributes of vrtest.</p>

<p>I guess in general, I am looking for the best way to get help on R while running it in ESS on linux. I see all these man pages for the packages I have installed, but I am not sure how I can access them.</p>

<p>Thanks</p>
"
1809525,220124,2009-11-27T16:03:20Z,1,Very simple bar graph,"<p>First I will have to apologise for my ignorance as I'm sure this is a very simple question but I am very new to R. My question is that I have a data frame that looks like this;</p>

<pre><code>countrydes       Insured

USA               4500
CANADA            4500 
USA               7500
CANADA            7600
</code></pre>

<p>All I want to do is aggregate the sum of the insured value by country and produce a bar graph e.g.</p>

<pre><code>countrydes        Insured 

USA                12000       
Canada             12100
</code></pre>

<p>Many thanks.</p>
"
1810650,77298,2009-11-27T21:14:42Z,3,How do I construct a new centrality measure?,"<p>I want to construct a new centrality measure using <code>igraph</code>, preferably in <code>R</code>. </p>

<p>How would I begin this? </p>

<p>For example, would I be better adding to the <code>igraph C library</code> or the <code>R interface</code>?</p>
"
1810662,219059,2009-11-27T21:19:07Z,-1,How to separate linear regression plots in R?,"<p>For a linear model with 2 variables </p>

<pre><code>r = lm(y ~ x1+x2)
</code></pre>

<p>When I run  <code>plot(r)</code> , I get a bunch of plots such as residuals vs fitted values and so on , but I can only look at one of them at a time . </p>

<p>Isn't there a way to separate them ? </p>
"
1811651,219059,2009-11-28T05:15:25Z,2,Factor Analysis in R,"<p>I'm trying to get a better understanding on FA, hope you can take a look at this, my biggest problem is how to interpret FA model in R.</p>

<p>My results look like this:
What values in my results should I be looking at and what is a good indication of FA analysis?</p>

<pre><code>Call:
factanal(x = m2, factors = 2)

Uniquenesses:
v1 v2 v3 v4 v5 v6 v7 v8 v9 v10 v11 v12
0.005 0.324 0.344 0.092 0.084 0.128 0.271 0.272 0.398 0.384 0.540 0.472

Loadings:
Factor1 Factor2
v1 0.847 0.527
v2 0.818
v3 0.733 0.344
v4 0.938 0.169
v5 0.949 0.125
v6 0.825 0.437
v7 0.701 0.488
v8 0.646 0.557
v9 0.467 0.619
v10 0.665 0.417
v11 0.525 0.429
v12 0.581 0.436

Factor1 Factor2
SS loadings 5.905 2.780
Proportion Var 0.492 0.232
Cumulative Var 0.492 0.724

Test of the hypothesis that 2 factors are sufficient.
The chi square statistic is 410.82 on 43 degrees of freedom.
The p-value is 1.59e-61
</code></pre>
"
1812702,66549,2009-11-28T14:59:25Z,4,"Finding What You Need in R: focused searching within R and all (3,500+) CRAN Packages","<p>Often in R, there are a dozen functions scattered across as many packages--all of which have the same purpose but of course differ in accuracy, performance, documentation, theoretical rigor, and so on.</p>

<p>How do you locate these--from within R and even from among the CRAN Packages which you have not installed?</p>

<p>So for instance: the generic <strong><em>plot</em></strong> function. Setting secondary ticks is much easier using a function <strong>outside</strong> of the base package:</p>

<pre><code>minor.tick(nx=n, ny=n, tick.ratio=n)
</code></pre>

<p>Of course <em>plot</em> is in R core, but <em>minor.tick</em> is not, it's actually in <em>Hmisc</em>. </p>

<p>Of course, that doesn't show up in the documentation for <em>plot</em>, nor should you expect it to. </p>

<p>Another example: data-input arguments to <em>plot</em> can be supplied by an object returned from the function <em>hexbin</em>, again, this function is from a library <em>outside</em> of R core.</p>

<p>What would be great obviously is a programmatic way to gather these function arguments from the various libraries and put them in a single namespace?</p>

<p>*edit: (trying to re-state my example just above more clearly:) the arguments to <em>plot</em> supplied in R core, e.g., setting the axis tick frequency are xaxp/yaxp; however, one can also set a/t/f via a function outside of the base package, again, as in the minor.tick function from the Hmisc package--but you wouldn't know that just from looking at the plot method signature. Is there a meta function in R for this?*</p>

<p>So far, as i come across them, i've been manually gathering them, each set gathered in a single <em>TextMate</em> <em>snippet</em> (along with the attendant library imports).  This isn't that difficult or time consuming, but i can only update my snippet as i find out about these additional arguments/parameters. Is there a canonical R way to do this, or at least an easier way?</p>

<p>Just in case that wasn't clear, i am not talking about the case where multiple packages provide functions directed to the same statistic or view (e.g., 'boxplot' in the base package; 'boxplot.matrix' in gplots; and 'bplots' in Rlab).  What i am talking is the case in which the function name is the same across two or more packages.</p>
"
1813550,220602,2009-11-28T19:38:43Z,20,count of entries in data frame in R,"<p>I'm looking to get a count for the following data frame:</p>

<pre><code>&gt; Santa
   Believe Age Gender Presents Behaviour
1    FALSE   9   male       25   naughty
2     TRUE   5   male       20      nice
3     TRUE   4 female       30      nice
4     TRUE   4   male       34   naughty
</code></pre>

<p>of the number of children who believe. What command would I use to get this?</p>

<p>(The actual data frame is much bigger. I've just given you the first four rows...)</p>

<p>Thanks!</p>
"
1813700,220626,2009-11-28T20:25:48Z,0,How to show all the sample principal component plots in R?,"<p>I noticed something in R, say <code>pc</code> is the result of applying PCA to a data matrix and 
<code>pc$x</code> is my sample principal component matrix . </p>

<p>When try <code>plot(pc$x)</code>, it will only plot the first principal component (<code>pc1</code>) against the second (<code>pc2</code>), but I actually have more than 2 principal components. How do I show all of them? </p>
"
1815606,60628,2009-11-29T13:58:32Z,159,Rscript: Determine path of the executing script,"<p>I have a script called <code>foo.R</code> that includes another script <code>other.R</code>, which is in the same directory:</p>

<pre><code>#!/usr/bin/env Rscript
print(""Hello"")
source(""other.R"")
</code></pre>

<p>But I want <code>R</code> to find that <code>other.R</code> no matter what the current working directory. </p>

<p>In other words, <code>foo.R</code> needs to know its own path. How can I do that?</p>
"
1816200,170792,2009-11-29T17:54:21Z,1,chisq.test doesn't print results when in a loop,"<p>I don't think I need to explain exactly what the code does. The point is that while performing the chisq.test outside the loop, I get a result like this (expected):</p>

<pre><code>        Chi-squared test for given probabilities

data:  observed 
X-squared = 185912, df = 5, p-value &lt; 2.2e-16
</code></pre>

<p>but when I try to do the test in a loop, the expected result does not appear </p>

<pre><code>total &lt;- dim(crs$dataset_init)[1]
expected.fr &lt;- cl.popul / total

for (i in 1:dim(cl.vs.Onerall)[1] ) {
        if (cl.vs.Onerall[i,1] &gt; 0) {
             observed &lt;- cl.vs.Onerall[i,2:(clust_no + 1)]

             print(rownames(cl.vs.Onerall)[i])
             chisq.test(observed, p=expected.fr)
             print(""------------------------------"")
    }
}
</code></pre>

<p>Any ideas would be greatly appreciated!</p>
"
1816238,198401,2009-11-29T18:07:09Z,8,How to turn off auto replacement in Emacs Speaks Statistics for R,"<p>In <code>Emacs Speaks Statistics</code> for <code>R</code>, how can the auto replacement of <code>_</code> with <code>&lt;-</code> be turned off?</p>
"
1816480,184010,2009-11-29T19:16:57Z,4,Generating names iteratively in R for storing plots,"<p>I'm using R to loop through a data frame, perform a calculation and to make a plot.</p>

<pre><code>for(i in 2 : 15){
# get data
dataframe[,i]  

# do analysis

# make plot
a &lt;- plot()
}
</code></pre>

<p>Is there a way that I can make the plot object name 'a', using the value of 'i'? For example, a + ""i"" &lt;- plot(). Then I want to add that to a vector so I have a series of plots that I can then use at a later stage when I want to make a pdf. Or perhaps there is another way of storing this.</p>

<p>I'm familiar with the paste() function but I haven't figured out how to define an object using it.</p>
"
1816719,170352,2009-11-29T20:48:40Z,11,ggplot2 Scatter Plot Labels,"<p>I'm trying to use ggplot2 to create and label a scatterplot. The variables that I am plotting are both scaled such that the horizontal and the vertical axis are plotted in units of standard deviation (1,2,3,4,...ect from the mean). What I would like to be able to do is label ONLY those elements that are beyond a certain limit of standard deviations from the mean. Ideally, this labeling would be based off of another column of data. </p>

<p>Is there a way to do this? </p>

<p>I've looked through the online manual, but I haven't been able to find anything about defining labels for plotted data. </p>

<p>Help is appreciated! </p>

<p>Thanks!</p>

<p>BEB</p>
"
1817305,162832,2009-11-30T00:32:40Z,0,from absolute numbers to proportion in two level data (R! SAC? plyr?),"<p>I have data nested in to levels:</p>

<pre><code>L1 L2   x1 x2 x3 x4
A  This 20 14 12 15
A  That 11 NA 8  16
A  Bat  Na 22 13  9
B  This 10  9 11  6
B  That 3   3  1 NA
B  Bat  4  10  2  8
</code></pre>

<p>Now I want something simply - and I feel I have been able to do this just last month. But something has gone missing in my head: I want percentages (ignoring NA), summing to 100 for each variable in L1</p>

<pre><code>L1 L2   x1  x2   x3   x4
A  This 65% 39%  36%  38%
A  That 35%  0%  24%  40%
A  Bat   0% 61%  40%  22%
</code></pre>

<p>I can get the totals I need with</p>

<pre><code>cast(L1~variable, data=melt(d, na.rm=T),sum)
</code></pre>

<p>But I guess it should be possible to cook up a function that gives me what I want?
I tried various approaches with cast and plyr... But it seams xmas has already brought to many beers to my frail brain.</p>

<p>Any help will be appreciated - as will any refrain from a downvote.</p>

<p>Thanx</p>

<p>this is my data:</p>

<pre><code>d &lt;- structure(list(level1 = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 
2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 
6L, 6L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 10L, 10L, 10L, 10L, 
11L, 11L, 11L, 11L, 11L, 11L, 9L, 9L, 9L, 9L, 9L, 12L, 12L, 12L, 
12L, 13L, 13L, 13L, 13L, 13L, 13L, 14L, 14L, 14L, 14L, 14L, 14L, 
15L, 15L, 15L, 15L, 15L, 16L, 16L, 16L, 16L, 16L, 16L, 17L, 17L, 
17L, 17L, 17L, 18L, 18L, 18L, 18L, 18L, 18L, 19L, 19L, 19L, 19L, 
19L, 19L), .Label = c(""a"", ""b"", ""c"", ""d"", ""e"", ""f"", ""g"", ""h"", 
""i"", ""j"", ""k"", ""l"", ""m"", ""n"", ""o"", ""p"", ""q"", ""r"", ""s""), class = ""factor""), 
level2 = structure(c(6L, 2L, 1L, 3L, 5L, 6L, 1L, 3L, 5L, 
6L, 1L, 3L, 5L, 6L, 5L, 6L, 1L, 3L, 5L, 4L, 6L, 2L, 1L, 3L, 
5L, 6L, 1L, 5L, 4L, 6L, 2L, 1L, 3L, 5L, 6L, 1L, 3L, 5L, 6L, 
2L, 1L, 3L, 5L, 4L, 6L, 2L, 1L, 3L, 5L, 6L, 1L, 3L, 5L, 6L, 
2L, 1L, 3L, 5L, 4L, 6L, 2L, 1L, 3L, 5L, 4L, 6L, 2L, 1L, 3L, 
5L, 6L, 2L, 1L, 3L, 5L, 4L, 6L, 2L, 1L, 3L, 5L, 6L, 2L, 1L, 
3L, 5L, 4L, 6L, 2L, 1L, 3L, 5L, 4L), .Label = c(""This"", ""That"", 
""Phat"", ""Bat"", ""Man"", ""Hat""), class = ""factor""), X2002 = c(28L, 
9L, 17L, 8L, 95L, 18L, NA, NA, 36L, 40L, 15L, 10L, 71L, NA, 
14L, 25L, 18L, NA, 56L, 5L, 29L, 5L, 13L, 8L, 65L, 23L, 8L, 
34L, NA, 14L, 5L, 5L, NA, 51L, 18L, NA, 5L, 56L, 30L, 8L, 
9L, 11L, 77L, 5L, 53L, 12L, 16L, 13L, 114L, 30L, 8L, NA, 
52L, 38L, NA, 12L, 5L, 87L, 5L, 35L, NA, 10L, 6L, 92L, 10L, 
41L, NA, 22L, 8L, 115L, 27L, 6L, 9L, NA, 47L, 9L, 29L, 6L, 
11L, NA, 56L, 38L, 7L, 10L, NA, 93L, 6L, 22L, 9L, 9L, NA, 
59L, 5L), X2003 = c(32L, NA, 16L, 9L, 76L, 10L, NA, 5L, 24L, 
22L, 12L, 9L, 63L, 12L, 9L, 36L, 9L, 6L, 83L, 5L, 35L, NA, 
12L, 8L, 82L, 19L, 5L, 53L, 5L, 10L, NA, 7L, NA, 35L, 15L, 
6L, 6L, 40L, 30L, NA, 10L, 8L, 85L, 9L, 46L, NA, 14L, 9L, 
106L, 24L, 6L, 7L, 56L, 33L, NA, 12L, 9L, 106L, NA, 37L, 
7L, 11L, 8L, 79L, 5L, 54L, 5L, 10L, 6L, 100L, 25L, 9L, 5L, 
6L, 49L, NA, 31L, NA, 13L, 10L, 79L, 46L, NA, 14L, NA, 82L, 
5L, 21L, 7L, 11L, NA, 69L, NA), X2004 = c(35L, 6L, 13L, 8L, 
82L, 12L, 5L, NA, 35L, 34L, 5L, 6L, 75L, 9L, 9L, 40L, 13L, 
9L, 70L, NA, 41L, NA, 17L, 10L, 83L, 10L, 6L, 40L, NA, 18L, 
NA, 6L, NA, 34L, 10L, NA, NA, 45L, 38L, 6L, 11L, NA, 74L, 
NA, 45L, 5L, 12L, 9L, 131L, 34L, NA, NA, 64L, 28L, 5L, NA, 
NA, 93L, NA, 32L, NA, 9L, 11L, 99L, NA, 40L, NA, 18L, 8L, 
104L, 14L, NA, 13L, 6L, 67L, NA, 23L, NA, 6L, 8L, 85L, 49L, 
NA, 19L, 7L, 102L, NA, 28L, 5L, 7L, 7L, 74L, NA), X2005 = c(36L, 
NA, 20L, 10L, 93L, 22L, NA, NA, 35L, 38L, 13L, 9L, 99L, NA, 
14L, 48L, 17L, 7L, 70L, NA, 35L, NA, 13L, 9L, 103L, 16L, 
5L, 49L, NA, 12L, NA, 5L, 8L, 51L, 15L, 7L, 5L, 45L, 40L, 
NA, 12L, 5L, 102L, NA, 40L, NA, 21L, 16L, 141L, 25L, 9L, 
10L, 70L, 41L, NA, 10L, NA, 111L, NA, 37L, NA, 10L, 9L, 124L, 
NA, 37L, NA, 12L, 12L, 124L, 32L, NA, 16L, 6L, 45L, NA, 33L, 
NA, 8L, NA, 101L, 51L, NA, 19L, 5L, 117L, NA, 17L, NA, 11L, 
5L, 73L, NA), X2006 = c(38L, NA, 22L, 13L, 103L, 15L, NA, 
7L, 44L, 39L, 11L, 6L, 95L, NA, 15L, 53L, 16L, 9L, 89L, NA, 
41L, NA, 12L, 13L, 87L, 30L, 6L, 43L, NA, 14L, NA, 6L, 5L, 
50L, 19L, 5L, NA, 63L, 23L, NA, 6L, NA, 75L, NA, 38L, NA, 
12L, 19L, 142L, 32L, 7L, 7L, 64L, 49L, NA, 13L, 12L, 114L, 
NA, 48L, NA, 23L, 5L, 136L, NA, 52L, NA, 15L, 16L, 127L, 
24L, NA, 6L, NA, 57L, NA, 32L, NA, NA, 13L, 96L, 20L, NA, 
10L, 21L, 102L, NA, 31L, NA, 5L, 12L, 93L, NA)), .Names = c(""level1"", 
""level2"", ""X2002"", ""X2003"", ""X2004"", ""X2005"", ""X2006""), row.names = c(NA, 
-93L), class = ""data.frame"")
</code></pre>
"
1819418,209467,2009-11-30T12:06:29Z,3,R error allocMatrix,"<p>HI all,</p>

<p>I was trying to load a certain amount of Affymetrix CEL files, with the standard BioConductor command (R 2.8.1 on 64 bit linux, 72 GB of RAM)</p>

<pre><code>abatch&lt;-ReadAffy()
</code></pre>

<p>But I keep getting this message:</p>

<pre><code>Error in read.affybatch(filenames = l$filenames, phenoData = l$phenoData,  : 
  allocMatrix: too many elements specified
</code></pre>

<p>What's the general meaning of this allocMatrix error? Is there some way to increase its maximum size?</p>

<p>Thank you</p>
"
1820590,184010,2009-11-30T15:45:46Z,8,Storing plot objects in a list,"<p>I asked <a href=""https://stackoverflow.com/questions/1816480/generating-names-iteratively-in-r-for-storing-plots"">this</a> question yesterday about storing a plot within an object. I tried implementing the first approach (aware that I did not specify that I was using <code>qplot()</code> in my original question) and noticed that it did not work as expected.</p>

<pre><code>library(ggplot2)               # add ggplot2

string = ""C:/example.pdf""      # Setup pdf
pdf(string,height=6,width=9)

x_range &lt;- range(1,50)         # Specify Range

# Create a list to hold the plot objects.
pltList &lt;- list()
pltList[]

for(i in 1 : 16){

# Organise data 
y = (1:50) * i * 1000                       # Get y col
x = (1:50)                                  # get x col
y = log(y)                                  # Use natural log

# Regression
lm.0 = lm(formula = y ~ x)                  # make linear model
inter = summary(lm.0)$coefficients[1,1]     # Get intercept
slop = summary(lm.0)$coefficients[2,1]      # Get slope

# Make plot name
pltName &lt;- paste( 'a', i, sep = '' )

# make plot object    
p &lt;- qplot(
    x, y,   
    xlab = ""Radius [km]"", 
    ylab = ""Services [log]"",
    xlim = x_range,
    main = paste(""Sample"",i)
) + geom_abline(intercept = inter, slope = slop, colour = ""red"", size = 1)        

print(p)     

pltList[[pltName]] = p       
}

# close the PDF file
dev.off() 
</code></pre>

<p>I have used sample numbers in this case so the code runs if it is just copied. I did spend a few hours puzzling over this but I cannot figure out what is going wrong. It writes the first set of pdfs without problem, so I have 16 pdfs with the correct plots.</p>

<p>Then when I use this piece of code:</p>

<pre><code>string = ""C:/test_tabloid.pdf""
pdf(string, height = 11, width = 17)

grid.newpage()
pushViewport( viewport( layout = grid.layout(3, 3) ) )

vplayout &lt;- function(x, y){viewport(layout.pos.row = x, layout.pos.col = y)}

counter = 1

# Page 1
for (i in 1:3){    
    for (j in 1:3){     
         pltName &lt;- paste( 'a', counter, sep = '' )   
         print( pltList[[pltName]], vp = vplayout(i,j) )
         counter = counter + 1
     }
 }

 dev.off()
</code></pre>

<p>the result I get is the last linear model line (<code>abline</code>) on every graph, but the data does not change. When I check my list of plots, it seems that all of them become overwritten by the most recent plot (with the exception of the <code>abline</code> object).</p>

<p>A less important secondary question was how to generate a muli-page pdf with several plots on each page, but the main goal of my code was to store the plots in a list that I could access at a later date.</p>
"
1823681,NA,2009-12-01T02:45:33Z,0,Problems with Newton's Method for finding coefficient and Hessian,"<p>I am trying to write a function that uses Newton's method <code>(coefficients+(inverse hessian)*gradient)</code> to iteratively find the coefficients for a loglinear model. </p>

<p>I am using the following code:</p>

<pre><code> ##reading in the data
    dat&lt;-read.csv('hw8.csv')
    summary(dat)
    # data file containing yi and xi
    attach(dat)
    ##Creating column of x's
    x&lt;-cbind(1,xi)

    mle&lt;-function(c){
     gi&lt;- 1-yi*exp(c[1]+c[2]*xi)
     hi&lt;- gi-1
     H&lt;- -1*(t(x)%*%hi%*%x)
     g&lt;-t(x)%*%gi
     c&lt;-c+solve(H)%*%g
      return(c)
    }

    optim(c(0,1),mle,hessian=TRUE)
</code></pre>

<p>When I run the code, I get the following error:</p>

<pre><code>Error in t(x) %*% hi %*% x : non-conformable arguments
RMate stopped at line 29
</code></pre>

<p>Given that the formula is drawn from Bill Greene's problem set, I don't think it is a formula problem. I think I am doing something wrong in passing my function.</p>

<p>How can I fix this?<br>
Any help with this function would be much appreciated.</p>
"
1826519,78912,2009-12-01T14:27:23Z,151,How to assign from a function which returns more than one value?,"<p>Still trying to get into the R logic...  what is the ""best"" way to unpack (on LHS) the results from a function returning multiple values?</p>

<p>I can't do this apparently:</p>

<pre><code>R&gt; functionReturningTwoValues &lt;- function() { return(c(1, 2)) }
R&gt; functionReturningTwoValues()
[1] 1 2
R&gt; a, b &lt;- functionReturningTwoValues()
Error: unexpected ',' in ""a,""
R&gt; c(a, b) &lt;- functionReturningTwoValues()
Error in c(a, b) &lt;- functionReturningTwoValues() : object 'a' not found
</code></pre>

<p>must I really do the following?</p>

<pre><code>R&gt; r &lt;- functionReturningTwoValues()
R&gt; a &lt;- r[1]; b &lt;- r[2]
</code></pre>

<p>or would the R programmer write something more like this:</p>

<pre><code>R&gt; functionReturningTwoValues &lt;- function() {return(list(first=1, second=2))}
R&gt; r &lt;- functionReturningTwoValues()
R&gt; r$first
[1] 1
R&gt; r$second
[1] 2
</code></pre>

<p>--- edited to answer Shane's questions ---</p>

<p>I don't really need giving names to the result value parts.  I am applying one aggregate function to the first component and an other to the second component (<code>min</code> and <code>max</code>.  if it was the same function for both components I would not need splitting them).  </p>
"
1828742,147537,2009-12-01T20:35:33Z,114,rotating axis labels in R,"<p>In R, how do I make a (bar)plot's y axis labels parallel to the X axis instead of parallel to the Y axis?</p>
"
1829429,163053,2009-12-01T22:35:50Z,21,Index value for matrix in R?,"<p>Is there a function to get an index (row number and column number) for a matrix?  </p>

<p>Suppose that I have a simple matrix:</p>

<pre><code>a &lt;- matrix(1:50, nrow=5)
</code></pre>

<p>Is there an easy way to get back something like c(3, 5) for the number ""23"", for instance?  In this case, saying <code>which(a==23)</code> just returns 23.  </p>

<p>This seems to work but I'm sure that there's a better way:</p>

<pre><code>matrix.index &lt;- function(a, value) {
  idx &lt;- which(data.frame(a)==value)
  col.num &lt;- ceiling(idx/nrow(a))
  row.num &lt;- idx - (col.num-1) * nrow(a)
  return(c(row.num, col.num))
}
&gt; matrix.index(a, 23)
[1] 3 5
&gt; matrix.index(a, 50)
[1]  5 10
</code></pre>
"
1831245,84458,2009-12-02T07:42:55Z,3,Vertical gridlines in ggplot with discrete x-axis,"<p>I have the following setup:</p>

<pre><code>emp &lt;- structure(list(s = structure(c(1L, 2L, 2L, 2L, 7L, 7L, 3L, 4L, 4L, 4L, 4L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 10L, 5L, 5L, 6L), .Label = c(""8"", ""24"", ""31"", ""78"", ""135"", ""142"", ""30"", ""98"", ""117"", ""123""), class = ""factor"", scores = structure(c(1, 2, 14, 3, 5, 17, 18, 20, 11, 13), .Dim = 10L, .Dimnames = list(c(""8"", ""24"", ""30"", ""31"", ""78"", ""98"", ""117"", ""123"", ""135"", ""142"")))), t = structure(c(6L, 1L, 2L, 4L, 7L, 9L, 3L, 1L,  2L, 4L, 5L, 8L, 9L, 10L, 7L, 8L, 9L, 11L, 9L, 1L, 4L, 1L), .Label = c(""8"", ""24"", ""40"", ""78"", ""135"", ""142"", ""30"", ""98"", ""117"", ""119"", ""123"" ), class = ""factor"", scores = structure(c(1, 2, 14, 4, 5, 17, 18, 19, 20, 11, 13), .Dim = 11L, .Dimnames = list(c(""8"", ""24"", ""30"", ""40"", ""78"", ""98"", ""117"", ""119"", ""123"", ""135"", ""142"")))), V1 = c(3L, 1L, 9L, 4L, 1L, 107L, 2L, 5L, 3L, 1L, 2L, 1L,  6L, 14L, 20L, 1L, 4L, 1L, 2L, 3L, 2L, 2L)), .Names = c(""s"", ""t"", ""V1""), row.names = c(NA, -22L), class = ""data.frame"")
o &lt;- c(8L, 24L, 31L, 40L, 78L, 80L, 85L, 94L, 104L, 113L, 135L, 136L, 142L, 30L, 54L, 91L, 98L, 117L, 119L, 123L, 9L, 34L, 97L, 126L,  140L, 13L, 75L, 92L, 134L, 138L, 141L, 6L, 12L, 22L, 44L, 48L, 51L, 57L, 64L, 79L, 84L, 88L, 93L, 100L, 115L, 124L, 129L, 132L,  143L, 144L, 2L, 10L, 14L, 15L, 16L, 17L, 19L, 35L, 39L, 41L, 50L, 52L, 53L, 58L, 61L, 66L, 67L, 68L, 71L, 72L, 73L, 76L, 96L, 99L, 101L, 106L, 109L, 114L, 121L, 127L, 128L, 131L, 137L, 145L, 146L, 148L, 150L, 4L, 18L, 23L, 28L, 29L, 32L, 37L, 38L, 65L, 82L, 90L, 102L, 105L, 107L, 111L, 122L, 130L, 133L, 139L, 147L, 3L, 5L, 7L, 11L, 21L, 27L, 33L, 43L, 45L, 46L, 47L, 49L, 55L, 56L, 59L, 60L, 62L, 63L, 69L, 70L, 77L, 83L, 87L, 89L, 103L, 108L, 112L, 116L, 118L, 120L, 125L, 149L, 151L, 1L, 20L, 25L, 26L, 36L, 42L, 74L, 81L, 86L, 95L, 110L)

emp$s &lt;- reorder(factor(emp$s),match(emp$s,o))
emp$t &lt;- reorder(factor(emp$t),match(emp$t,o))
qq &lt;- ggplot(emp,aes(x=s,y=t))
qq + geom_tile(aes(fill=log(V1)))+theme_bw()+
scale_fill_gradient(low=""white"",high=""black"")+
opts(axis.text.x=theme_text(angle=-90, hjust=0, size=5),
     axis.text.y=theme_text(vjust=0, size=5),
     panel.grid.minor = theme_blank(),
     panel.grid.major = theme_blank())
</code></pre>

<p>This produces the following:</p>

<p><a href=""http://i46.tinypic.com/292n3ao.png"" rel=""nofollow noreferrer"">alt text http://i46.tinypic.com/292n3ao.png</a></p>

<p>I would like to include a vertical line just after 142 and before 30.  (Note, I need to keep these values as a factor.) I've been considering two options: </p>

<ul>
<li>vline: I only am able to put the line on 142 and on 30, but not between them.</li>
<li>grid stuff: I feel like the ideal solution is to introduce a grid.major or something.</li>
</ul>

<p>Any ideas?</p>
"
1832761,78912,2009-12-02T13:01:00Z,4,how to vectorize with xml data?,"<p>let's say, I have this xml file:</p>

<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8"" ?&gt;
&lt;TimeSeries&gt;
  &lt;timeZone&gt;1.0&lt;/timeZone&gt;
  &lt;series&gt;
    &lt;header/&gt;
    &lt;event date=""2009-09-30"" time=""10:00:00"" value=""0.0"" flag=""2""&gt;&lt;/event&gt;
    &lt;event date=""2009-09-30"" time=""10:15:00"" value=""0.0"" flag=""2""&gt;&lt;/event&gt;
    &lt;event date=""2009-09-30"" time=""10:30:00"" value=""0.0"" flag=""2""&gt;&lt;/event&gt;
    &lt;event date=""2009-09-30"" time=""10:45:00"" value=""0.0"" flag=""2""&gt;&lt;/event&gt;
    &lt;event date=""2009-09-30"" time=""11:00:00"" value=""0.0"" flag=""2""&gt;&lt;/event&gt;
    &lt;event date=""2009-09-30"" time=""11:15:00"" value=""0.0"" flag=""2""&gt;&lt;/event&gt;
  &lt;/series&gt;
  &lt;series&gt;
    &lt;header/&gt;
    &lt;event date=""2009-09-30"" time=""08:00:00"" value=""1.0"" flag=""2""&gt;&lt;/event&gt;
    &lt;event date=""2009-09-30"" time=""08:15:00"" value=""2.6"" flag=""2""&gt;&lt;/event&gt;
    &lt;event date=""2009-09-30"" time=""09:00:00"" value=""6.3"" flag=""2""&gt;&lt;/event&gt;
    &lt;event date=""2009-09-30"" time=""09:15:00"" value=""4.4"" flag=""2""&gt;&lt;/event&gt;
    &lt;event date=""2009-09-30"" time=""09:30:00"" value=""3.9"" flag=""2""&gt;&lt;/event&gt;
    &lt;event date=""2009-09-30"" time=""09:45:00"" value=""2.0"" flag=""2""&gt;&lt;/event&gt;
    &lt;event date=""2009-09-30"" time=""10:00:00"" value=""1.7"" flag=""2""&gt;&lt;/event&gt;
    &lt;event date=""2009-09-30"" time=""10:15:00"" value=""2.3"" flag=""2""&gt;&lt;/event&gt;
    &lt;event date=""2009-09-30"" time=""10:30:00"" value=""2.0"" flag=""2""&gt;&lt;/event&gt;
  &lt;/series&gt;
  &lt;series&gt;
    &lt;header/&gt;
    &lt;event date=""2009-09-30"" time=""10:00:00"" value=""0.0"" flag=""2""&gt;&lt;/event&gt;
    &lt;event date=""2009-09-30"" time=""10:15:00"" value=""0.0"" flag=""2""&gt;&lt;/event&gt;
    &lt;event date=""2009-09-30"" time=""10:30:00"" value=""0.0"" flag=""2""&gt;&lt;/event&gt;
    &lt;event date=""2009-09-30"" time=""10:45:00"" value=""0.0"" flag=""2""&gt;&lt;/event&gt;
    &lt;event date=""2009-09-30"" time=""11:00:00"" value=""0.0"" flag=""2""&gt;&lt;/event&gt;
  &lt;/series&gt;
&lt;/TimeSeries&gt;
</code></pre>

<p>and let's say I want to do something with its series elements and that I would like to put in practice the advice 'vectorize the vectorizable'...  I import the XML library and do the following:</p>

<pre><code>R&gt; library(""XML"")
R&gt; doc &lt;- xmlTreeParse('/home/mario/Desktop/sample.xml')
R&gt; TimeSeriesNode &lt;- xmlRoot(doc)
R&gt; seriesNodes &lt;- xmlElementsByTagName(TimeSeriesNode, ""series"")
R&gt; length(seriesNodes)
[1] 3
R&gt; (function(x){length(xmlElementsByTagName(x[['series']], 'event'))}
+ )(seriesNodes)
[1] 6
R&gt; 
</code></pre>

<p>and I don't understand why I should only get the result of applying the function to the first element: I had expected three values, just as the length of seriesNodes, something like this:</p>

<pre><code>R&gt; mapply(length, seriesNodes)
series series series 
     7     10      6 
</code></pre>

<p>oops!  I already came with the answer: ""use <code>mapply</code>"":</p>

<pre><code>R&gt; mapply(function(x){length(xmlElementsByTagName(x, 'event'))}, seriesNodes)
series series series 
     6      9      5 
</code></pre>

<p>but then I see the following problem: the R-inferno tells me that I'm ""loop-hiding"", not ""vectorizing""!  can I avoid looping at all?  ...</p>
"
1833622,134830,2009-12-02T15:27:59Z,0,Assigning values from if-else blocks (how does it work?),"<p>I <a href=""https://stackoverflow.com/questions/1295955/what-is-the-most-useful-r-trick/1826778#1826778"">recently discovered</a> that you can conditionally assign a value with an if-else block.</p>

<pre><code>y &lt;- if(condition) 1 else 2
</code></pre>

<p>I realise that the use case for this is limited: if you have vectorised code, you would use the <code>ifelse</code> function instead.  There is a performance benefit: <code>if-else</code> runs about 35x faster than <code>ifelse</code> in the scalar case on my machine (though you need to call it millions of times to notice much of a difference).</p>

<p>What is bugging me is that I can't work out why this code works&mdash;I was amazed that it doesn't just throw an error.</p>

<p>Another example suggests that if blocks behave like functions&mdash;they automatically return the last value in the block (though you can't use a <code>return</code> statement in them).</p>

<pre><code>y &lt;- if(TRUE) 
{
   y &lt;- 3
   4
}    # y is 4
</code></pre>

<p>Based on this, I guessed that maybe another environment was created when you entered an if block, but this doesn't seem to be the case.</p>

<pre><code>if(TRUE) sys.frames()    # NULL
</code></pre>

<p>Can anyone tell me what is happening under the hood, please?</p>
"
1834833,143813,2009-12-02T18:23:20Z,3,automatic R wrapper generation for java methods,"<p>I am trying to use a <code>Java package</code> from <code>R</code>.  </p>

<p><code>RJava</code> provides a way to call <code>Java</code> from <code>R</code>, but wrapping all the methods is impractical. </p>

<p>Does anyone know of a script that generates wrappers for a package (say, by processing the relevant javadoc)?</p>
"
1837968,148389,2009-12-03T06:06:03Z,56,How to tell what is in one vector and not another?,"<p>In matlab there is a way to find the values in one vector but not in the other.</p>

<p>for example:</p>

<pre><code>x &lt;- c(1,2,3,4)
y &lt;- c(2,3,4)
</code></pre>

<p>is there any function that would tell me that the value in <code>x</code> that's not in <code>y</code> is 1?</p>
"
1840024,78912,2009-12-03T14:01:23Z,1,double threshold (on/off) with or without a for,"<p>the function I am writing specifies the behaviour of a physical switch: it should be turned ON if a value goes above an upper threshold and can go again OFF if it goes under the lower threshold.  a similar logic would describe a normal thermostat in a household oven.  obviously I want it to work on vectors, that's the whole point!</p>

<p>so if I have the data</p>

<pre><code>S &lt;- c(50, 100, 150, 180, 210, 200, 190, 182, 175, 185, 195, 205)
</code></pre>

<p>my function tells if the oven temperature is all right.  the logical inverse of ""switch the oven on"".</p>

<pre><code>R&gt; thresholdOnOff(S, 180, 200)
 [1] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE
</code></pre>

<p>the question is about programming style: I first tried to write it with an 'apply' function in it but I had forgotten to take environments into account...  so I wrote a working version with a 'for' loop - which I didn't like, then remembered about the environments and I'm not sure about the two versions:</p>

<pre><code>thresholdOnOff &lt;- local( {
  ## following the R inferno
  f &lt;- function(series, lower, upper, initialValue=FALSE) {
    status &lt;&lt;- initialValue

    switchOnOff &lt;- function(x) {
      if(x &gt; upper)
        status &lt;&lt;- TRUE
      if(x &lt; lower)
        status &lt;&lt;- FALSE
      return(status)
    }

    sapply(series, switchOnOff)
  }
} )


thresholdOnOff &lt;- function(series, lower, upper, initialValue=FALSE) {
  ## just guessing and reading from the documentation
  status &lt;- initialValue

  switchOnOff &lt;- function(x) {
    if(x &gt; upper)
      assign('status', TRUE, inherits=TRUE)
    if(x &lt; lower)
      assign('status', FALSE, inherits=TRUE)
    return(status)
  }

  sapply(series, switchOnOff)
}
</code></pre>
"
1842736,142477,2009-12-03T20:35:02Z,1,converting an ftable to a matrix,"<p>Take for example the following ftable</p>

<pre><code>height &lt;- c(rep('short', 7), rep('tall', 3))
girth &lt;- c(rep('narrow', 4), rep('wide', 6))
measurement &lt;- rnorm(10)
foo &lt;- data.frame(height=height, girth=girth, measurement=measurement)
ftable.result &lt;- ftable(foo$height, foo$girth)
</code></pre>

<p>I'd like to convert the above <code>ftable.result</code> into a matrix with row names and column names.  Is there an efficient way of doing this?  <code>as.matrix()</code> doesn't exactly work, since it won't attach the row names and column names for you.</p>

<p>You could do the following</p>

<pre><code>ftable.matrix &lt;- ftable.result
class(ftable.matrix) &lt;- 'matrix'

rownames(ftable.matrix) &lt;- unlist(attr(ftable.result, 'row.vars'))
colnames(ftable.matrix) &lt;- unlist(attr(ftable.result, 'col.vars'))
</code></pre>

<p>However, it seems a bit heavy-handed.   Is there a more efficient way of doing this?</p>
"
1844829,55362,2009-12-04T04:18:46Z,8,How can I read and parse the contents of a webpage in R,"<p>I'd like to read the contents of a URL (e.q., <a href=""http://www.haaretz.com/"" rel=""noreferrer"">http://www.haaretz.com/</a>) in R. I am wondering how I can do it</p>
"
1848331,76235,2009-12-04T17:04:01Z,3,What's a robust method in R for importing from and exporting data to Excel?,"<p>I've used RODBC for some time to import Excel spreadsheets with mostly good results. However I have had no luck writing to an Excel spreadsheet. Also are there favorable differences using the xlsx format with Excel2007? </p>
"
1853703,184010,2009-12-05T22:38:22Z,9,Plotting functions on top of datapoints in R,"<p>Is there a way of overlaying a mathematical function on top of data using ggplot?</p>

<pre><code>## add ggplot2
library(ggplot2)

# function
eq = function(x){x*x}

# Data                     
x = (1:50)     
y = eq(x)                                                               

# Make plot object    
p = qplot(    
x, y,   
xlab = ""X-axis"", 
ylab = ""Y-axis"",
) 

# Plot Equation     
c = curve(eq)  

# Combine data and function
p + c #?
</code></pre>

<p>In this case my data is generated using the function, but I want to understand how to use <code>curve()</code> with ggplot.</p>
"
1857747,226097,2009-12-07T04:06:06Z,1,R + user defined function,"<p>I have a situation in which I have to give a formula as input to the <code>nls()</code> function.
I have data which is between time and variance. For example:</p>

<pre><code>Time Variance
1     0.15
2     0.23
3     0.67
4     0.85
</code></pre>

<p>Now I am using the formula <em>Vt = ((1-e^kt)/kt)) (q^2)/2k</em>, where <em>Vt</em> is the variance at time <em>t</em>. I have the two variables <em>(k,q)</em> in the above equation. I have to determine <em>k(hat)</em> and <em>q(hat)</em>. Can I define the above formula as a user-defined formula and give it as an argument to the <code>nls()</code> function?</p>
"
1858280,177541,2009-12-07T06:47:17Z,2,Change specific column values in R,"<p>I have a table where there are ""NA""s littered all over the place in one column in particular. I want to replace every instance of ""NA"" with something else -- say, the number 1. </p>

<p>How should I do that?</p>
"
1860913,3514,2009-12-07T15:59:49Z,10,R performance with data reshaping,"<p>I am trying to reshape a data frame in R and it seems to have problems using the recommended ways of doing so. The data frame has the following structure:</p>

<pre><code>ID                     DATE1             DATE2            VALTYPE        VALUE
'abcd1233'         2009-11-12        2009-12-23           'TYPE1'        123.45
...
</code></pre>

<p><code>VALTYPE</code> is a string and is a factor with only 2 values (say <code>TYPE1</code> and <code>TYPE2</code>). I need to transform it into the following data frame (""wide"" transpose) based on common ID and DATEs:</p>

<pre><code>ID                     DATE1             DATE2            VALUE.TYPE1  VALUE.TYPE2
'abcd1233'             2009-11-12        2009-12-23       123.45           NA
...
</code></pre>

<p>The data frame has more than 4,500,000 observations (although about 70% of <code>VALUE</code>s are <code>NA</code>). The machine is an Intel-based Linux workstation with 4Gb of RAM. Loading the data (from a compressed Rdata file) into a fresh R process makes it grow to about 250Mb which clearly leaves a lot of space for reshaping.</p>

<p>These are my experiences so far:</p>

<ul>
<li><p>Using vanilla <code>reshape()</code> method:</p>

<p>tbl2 &lt;- reshape(tbl, direction = ""wide"", idvar = c(""ID"", ""DATE1"", ""DATE2""), 
                timevar = ""VALTYPE"");</p></li>
</ul>

<p>RESULT: <code>Error: cannot allocate vector of size 4.8 Gb</code></p>

<ul>
<li><p>Using <code>cast()</code> method of <code>reshape</code> package:</p>

<p>tbl2 &lt;- cast(tbl, ID + DATE1 + DATE2 ~ VALTYPE);</p></li>
</ul>

<p>RESULT: R process consumes all RAM with no end in sight. Had to kill the process eventually.</p>

<ul>
<li><p>Using <code>by()</code> and <code>merge()</code>:</p>

<p>sp &lt;- by(tbl[c(1,2,3,5)], tbl$VALTYPE, function(x) x);
tbl &lt;- merge(sp[[""TYPE1""]], sp[[""TYPE2""]], 
       by = c(""ID"", ""DATE1"", ""DATE2""), all = TRUE, sort = TRUE);</p></li>
</ul>

<p>RESULT: works fine, although this is not very elegant and foolproof (i.e. it will break if more types are added).</p>

<p>To add insult to injury, the operation in question can be trivially achieved in about 3 lines of AWK or Perl (and with hardly any RAM used). So the question is: what is a better way to do this operation in R using recommended methods without consuming all available RAM?</p>
"
1861160,78912,2009-12-07T16:35:56Z,0,working with sequences of different length,"<p>a function I wrote extracts timestamps from a XML document.  Timestamps are coupled to events, which are repeated elements of the series element.</p>

<p>series elements have a variable amount of events, so my function returns a data.frame (if the series have the same length).  in general it returns a more generic list and I want it to work with matrices as well.  I was pointed out (Thanks Eduardo) that 'list' is the generic type, but I still have trouble with functions that work on generic lists but not with more specific types, like data.frame or matrix.</p>

<p>what I need to do with the data at the moment is to see what is the most common distance between timestamps (I expect it to appear (much) more often than 50% of the times), I have written and rewritten a function doing this:</p>

<pre><code>R&gt; mostCommonStep( list(a=cumsum(c(1,3,3,2,3,3,4,3,2,3,3)), b=cumsum(c(2,3,2,3))) )
[1] 3
R&gt; mostCommonStep( data.frame(a=c(2,4,6,8,12,14,18), b=c(12,14,16,18,22,24,28)) )
[1] 2
R&gt; mostCommonStep( matrix(c(2,4,6,8,12,14,18, 12,14,16,18,22,24,28), 7, 2) )
[1] 2
</code></pre>

<p>but I would like to see a more ""R"" conformant version</p>
"
1866816,101419,2009-12-08T12:59:42Z,0,Auto fit labels in R boxplot,"<p>We are currently using <code>R</code> to automatically generate various kinds of <code>boxplots</code>. </p>

<p>The problem we have is that the length of our labels varies considerably between different plots and classes in one plot.</p>

<p>Is there a way to automatically adjust the plot so that all the labels will fit it nicely? </p>

<p>Specifying a worst case <code>mar</code> isn't feasible because in some plots the labels are considerably shorter than in others.</p>
"
1867139,209467,2009-12-08T13:58:05Z,3,Read text file in R and convert it to a character object,"<p>I'm reading a text file like this in R 2.10.0</p>

<pre><code>248585_at   250887_at   245638_s_at AFFX-BioC-5_at
248585_at   250887_at   264488_s_at 245638_s_at AFFX-BioC-5_at  AFFX-BioC-3_at  AFFX-BioDn-5_at
248585_at   250887_at
</code></pre>

<p>Using the command
    clusters&lt;-read.delim(""test"",sep=""\t"",fill=TRUE,header=FALSE)</p>

<p>Now, I must pass every row in this file to a BioConductor function that takes only character vectors as input.
MY problem is that using ""as.character"" on this ""clusters"" object turns everything into numeric strings.</p>

<pre><code>&gt; clusters[1,]
         V1        V2          V3             V4 V5 V6 V7
1 248585_at 250887_at 245638_s_at AFFX-BioC-5_at         
</code></pre>

<p>But </p>

<pre><code>&gt; as.character(clusters[1,])
[1] ""1"" ""1"" ""2"" ""3"" ""1"" ""1"" ""1""
</code></pre>

<p>Is there any way to keep the original names and put them into a character vector?</p>

<p>Maybe it helps: my ""clusters"" object given by the ""read.delim"" file belongs to the ""list"" type.</p>

<p>Thanks a lot :-)</p>

<p>Federico</p>
"
1867647,227212,2009-12-08T15:19:02Z,1,multiple transform on df with plyr,"<p>I have a df and I want to do multiple transform on it with plyr:</p>

<pre><code>idplot / idtree / species /  condition / dbh_cm / h_m / hblc_m


CalcG &lt;- function (df) transform(df, g_m2 = pi * (dbh_cm^2)/40000)

CalcHD &lt;- function (df) transform(df, hd = h_m / dbh_cm)
</code></pre>

<p>...</p>

<p>Can be done in one function?
Many thanks.</p>
"
1872982,84952,2009-12-09T10:26:34Z,6,R function that returns a string literal,"<p>I have a vector: <code>c(1,2,3)</code></p>

<p>Calling <code>print()</code> on this value gives <code>[1] 1 2 3</code></p>

<p>Is there a function that takes a vector and gives the string <code>c(1,2,3)</code>?</p>
"
1874443,209467,2009-12-09T14:59:48Z,27,Import data into R with an unknown number of columns?,"<p>I'm trying to read a text file with different row lengths:</p>

<pre><code>1
1   2
1   2   3
1   2   3   4
1   2   3   4   5
1   2   3   4   5   6
1   2   3   4   5   6   7
1   2   3   4   5   6   7   8
</code></pre>

<p>To overcome this problem, I'm using the argument fill=TRUE in read.table, so:</p>

<pre><code>data&lt;-read.table(""test"",sep=""\t"",fill=TRUE)
</code></pre>

<p>Unfortunately, to assess the maximum row length, read.table reads only the first 5 lines of the file, and generates an object looking like this:</p>

<pre><code>data
   V1 V2 V3 V4 V5
1   1 NA NA NA NA
2   1  2 NA NA NA
3   1  2  3 NA NA
4   1  2  3  4 NA
5   1  2  3  4  5
6   1  2  3  4  5
7   6 NA NA NA NA
8   1  2  3  4  5
9   6  7 NA NA NA
10  1  2  3  4  5
11  6  7  8 NA NA
</code></pre>

<p>Is there a way to force read.table to scroll over the whole file to assess the maximum row length?
I know a possible solution would be to provide the column number, like:</p>

<pre><code>data&lt;-read.table(""test"",sep=""\t"",fill=TRUE,col.names=c(1:8))
</code></pre>

<p>But since I have a lot of files, I wanted to assess this automatically within R. Any suggestion? :-)</p>

<hr>

<p>EDIT: the original file doesn't contain progressive numbers, so this is not a solution:</p>

<pre><code>data1&lt;-read.table(""test"",sep=""\t"",fill=TRUE)
data2&lt;-read.table(""test"",sep=""\t"",fill=TRUE,col.names=c(1:max(data1))
</code></pre>
"
1875192,84952,2009-12-09T16:47:08Z,7,Plot multiple sets of points in R,"<p>I have multiple sets of xy pairs that I want to plot.  I want each set of xy pairs to be connected by a line.  In other words the goal is to have multiple experimental instances each approximated by a line plotted on one plot.  Also how would I colour the lines differently?</p>

<p>The plot function does what I want, but takes on one set of xy pairs:
<code>plot(x, y, ...)</code></p>

<p>Can this function be made to take multiple sets or is there another function for that?</p>
"
1875795,197321,2009-12-09T18:21:38Z,21,Best practices for storing and using data frames too large for memory?,"<p>I'm working with a large data frame, and have run up against RAM limits. At this point, I probably need to work with a serialized version on the disk. There are <a href=""http://cran.r-project.org/web/views/HighPerformanceComputing.html"" rel=""nofollow noreferrer"">a few packages</a> to support out-of-memory operations, but I'm not sure which one will suit my needs. I'd prefer to keep everything in data frames, so the <code>ff</code> package looks encouraging, but there are still compatibility problems that I can't work around.</p>

<p>What's the first tool to reach for when you realize that your data has reached out-of-memory scale?</p>
"
1876085,228220,2009-12-09T19:03:29Z,1,Patterns for reshape in R,"<p>I have a dataframe that I want to reshape; my reshape code:</p>

<pre><code>matchedlong &lt;- reshape(matched, direction = 'long',
                       varying = c(29:33, 36:3943),
                       v.names = c(""Math34"", ""TFCIn""),
                       times = 2006:2009, idvar = ""schoolnum"")
</code></pre>

<p>in <code>matched</code> columns 36 to 39 are logical (<code>TRUE</code> <code>FALSE</code>) but in <code>matchedlong</code> they have turned into numbers somehow .... No clear pattern to the numbers. </p>

<p>what is causing this?</p>

<p>Sample data:</p>

<pre><code>example.data &lt;- structure(list(Grade_Range_2008 = structure(c(14L, 14L, 40L,
40L, 36L, 13L), .Label = c(""3-5, UE"", ""4-5, UE"", ""4-8, UE, US"",
""5-10, UE, US"", ""5-8, 10, UE, US"", ""5-8, UE, US"", ""5-9, UE, US"",
""6-11, US"", ""6-12, UE, US"", ""6-7, UE, US"", ""6-8, 10, UE, US"",
""6-8, UE"", ""6-8, UE, US"", ""6-9, UE, US"", ""6, UE"", ""7-10, US"",
""7-8, US"", ""8-Jun"", ""8-May"", ""K-3"", ""K-3, UE"", ""K-4, UE"", ""K-5"",
""K-5, UE"", ""K-6, UE"", ""K-8"", ""K-8, UE"", ""K-8, UE, US"", ""K, 2-5, UE"",
""N/A"", ""PK-3, UE"", ""PK-4, UE"", ""PK-5, 10, UE"", ""PK-5, 7-9, UE, US"",
""PK-5, 8, UE"", ""PK-5, UE"", ""PK-6, 10, UE"", ""PK-6, UE"", ""PK-8, UE"",
""PK-8, UE, US""), class = ""factor""), X__of_Yrs_in_school = c(0L,
0L, 0L, 0L, 0L, 0L), Total_Enrollment_2008 = c(348L, 444L, 636L,
495L, 319L, 410L), Free_Lunch_pct_2008 = c(75L, 89L, 94L, 89L,
89L, 91L), Reduced_Lunch_pct_2008 = c(6L, 6L, 3L, 4L, 5L, 4L),
    Stability_pct_2008 = c(89L, 93L, 100L, 98L, 92L, 81L),
Limited_Eng__Prof__pct_2008 = c(8L,
    20L, 8L, 10L, 19L, 19L), Am__Ind_pct_2008 = c(1L, 2L, 0L,
    2L, 0L, 2L), Black_pct_2008 = c(41L, 39L, 28L, 33L, 32L,
    38L), Hispanic_pct_2008 = c(55L, 59L, 70L, 61L, 65L, 57L),
    Asian_pct_2008 = c(2L, 1L, 0L, 2L, 1L, 1L), White_pct_2008 = c(2L,
    0L, 1L, 2L, 1L, 2L), Multi_pct_2008 = c(0L, 0L, 0L, 0L, 0L,
    0L), w_o_Valid_Cert__N_2008 = c(4L, 0L, 1L, 0L, 1L, 1L),
    w_o_Valid_Cert__pct_2008 = c(11L, 0L, 2L, 0L, 3L, 5L),
Teaching_Out_of_Certification_N_ = c(7L,
    7L, 2L, 13L, 3L, 4L), Teaching_Out_of_Certification_pc = c(20L,
    15L, 4L, 25L, 9L, 18L), X_3_yrs__Exp_N_2008 = c(12L, 13L,
    5L, 12L, 5L, 5L), X_3_yrs__Exp_pct_2008 = c(34L, 28L, 11L,
    24L, 15L, 23L), Masters_Plus_N_2008 = c(6L, 11L, 15L, 10L,
    16L, 8L), Masters_Plus___2008 = c(17L, 23L, 32L, 20L, 47L,
    36L), Core_Classes_N_2008 = c(78L, 142L, 49L, 91L, 22L, 49L
    ), Core_Not_Taught_by_HQ_Teachers_p = c(23L, 6L, 2L, 24L,
    9L, 20L), Number_of_Classes_N_2008 = c(93L, 193L, 56L, 119L,
    33L, 68L), Clases_Not_taught_by_App__Cert__ = c(18L, 18L,
    2L, 37L, 3L, 13L), Clases_Not_taught_by_App__Cert_0 = c(19L,
    9L, 4L, 31L, 9L, 19L), Turnover_Rate_of_Teachers_with__ = c(31L,
    56L, 20L, 32L, 0L, 50L), Turnover_Rate_all_Teachers_pct_2 = c(42L,
    29L, 17L, 30L, 14L, 49L), Math_Level_3_4_pct_2006 = c(5.1,
    16.4, 58.2, 34.4, 48.9, 12.4), Math_Level_3_4_pct_2007 = c(15.2,
    22.1, 65.7, 29.9, 70.5, 22.6), Math_Level_3_4_pct_2008 = c(29.9,
    43.2, 69.8, 41.2, 78.9, 38.5), Math_Level_3_4_pct_2009 = c(50.7,
    49.7, 80.7, 47.1, 83.9, 51.6), Att__pct_2005 = c(0.83, 0.86,
    0.89, 0.9, 0.89, 0.87), Susp__pct_2005 = c(6L, 15L, 1L, 4L,
    0L, 3L), schoolnum = c(4013, 4045, 4096, 4101, 4102, 4117
    ), In_2006 = c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE),
    In_2007 = c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE), In_2008 = c(FALSE,
    FALSE, FALSE, FALSE, FALSE, FALSE), In_2009 = c(FALSE, FALSE,
    FALSE, FALSE, FALSE, FALSE), weights = c(1, 1, 1, 1, 1, 1
    )), .Names = c(""Grade_Range_2008"", ""X__of_Yrs_in_school"",
""Total_Enrollment_2008"", ""Free_Lunch_pct_2008"", ""Reduced_Lunch_pct_2008"",
""Stability_pct_2008"", ""Limited_Eng__Prof__pct_2008"", ""Am__Ind_pct_2008"",
""Black_pct_2008"", ""Hispanic_pct_2008"", ""Asian_pct_2008"", ""White_pct_2008"",
""Multi_pct_2008"", ""w_o_Valid_Cert__N_2008"", ""w_o_Valid_Cert__pct_2008"",
""Teaching_Out_of_Certification_N_"", ""Teaching_Out_of_Certification_pc"",
""X_3_yrs__Exp_N_2008"", ""X_3_yrs__Exp_pct_2008"", ""Masters_Plus_N_2008"",
""Masters_Plus___2008"", ""Core_Classes_N_2008"",
""Core_Not_Taught_by_HQ_Teachers_p"",
""Number_of_Classes_N_2008"", ""Clases_Not_taught_by_App__Cert__"",
""Clases_Not_taught_by_App__Cert_0"", ""Turnover_Rate_of_Teachers_with__"",
""Turnover_Rate_all_Teachers_pct_2"", ""Math_Level_3_4_pct_2006"",
""Math_Level_3_4_pct_2007"", ""Math_Level_3_4_pct_2008"",
""Math_Level_3_4_pct_2009"",
""Att__pct_2005"", ""Susp__pct_2005"", ""schoolnum"", ""In_2006"", ""In_2007"",
""In_2008"", ""In_2009"", ""weights""), row.names = c(1L, 4L, 7L, 8L,
11L, 12L), class = ""data.frame"")
</code></pre>
"
1879843,78912,2009-12-10T09:36:43Z,4,distributing R package containing unit tests,"<p>so I decided I would put my few R functions into a package and I'm reading/learning <a href=""http://cran.r-project.org/doc/manuals/R-exts.pdf"" rel=""nofollow noreferrer"">Writing R Extension</a>.</p>

<p>it obviously complains about an amount of things I'm not doing right.</p>

<p>after enough googling, I'm firing a few questions here, this one is about testing style: I am using <a href=""http://cran.r-project.org/web/packages/RUnit/vignettes/RUnit.pdf"" rel=""nofollow noreferrer"">RUnit</a> and I like having tests as close possible to the code being tested.  this way I won't forget about the tests and I use the tests as part of the technical documentation.  </p>

<p>for example:</p>

<pre><code>fillInTheBlanks &lt;- function(S) {
  ## NA in S are replaced with observed values

  ## accepts a vector possibly holding NA values and returns a vector
  ## where all observed values are carried forward and the first is
  ## carried backward.  cfr na.locf from zoo library.
  L &lt;- !is.na(S)
  c(S[L][1], S[L])[1 + cumsum(L)]
}

test.fillInTheBlanks &lt;- function() {
  checkEquals(fillInTheBlanks(c(1, NA, NA, 2, 3, NA, 4)), c(1, 1, 1, 2, 3, 3, 4))
  checkEquals(fillInTheBlanks(c(1, 2, 3, 4)), c(1, 2, 3, 4))
  checkEquals(fillInTheBlanks(c(NA, NA, 2, 3, NA, 4)), c(2, 2, 2, 3, 3, 4))
}
</code></pre>

<p>but <code>R CMD check</code> issues NOTE lines, like this one:</p>

<pre><code>test.fillInTheBlanks: no visible global function definition for
  ‘checkEquals’
</code></pre>

<p>and it complains about me not documenting the test functions.</p>

<p>I don't really want to add documentation for the test functions and I definitely would prefer not having to add a dependency to the RUnit package.</p>

<p>how do you think I should look at this issue?</p>
"
1879933,78912,2009-12-10T09:53:43Z,0,R CMD check complains about unexpected files in man,"<p>this sounds like a silly problem: I'm putting my R code into a package and <code>R CMD check src</code> complains about the .Rd~ backup files being produced by Emacs.  </p>

<pre><code>* checking package subdirectories ... WARNING
Subdirectory 'man' contains invalid file names:
  read.PI.Rd~ write.PI.Rd~
</code></pre>

<p>the documentation says: »In addition [...] files [...]  with base names [...] ending in ‘~’, ‘.bak’ or ‘.swp’, are excluded by default.« (page 18).  but then why the warning?</p>
"
1885264,280,2009-12-11T01:18:47Z,2,Combining 3D/2D plots,"<p>I'm trying to make a visualization that looks like this <a href=""http://www.gradient-da.com/img/temperature%20surface%20plot%20470x406.JPG"" rel=""nofollow noreferrer"">http://www.gradient-da.com/img/temperature%20surface%20plot%20470x406.JPG http://www.gradient-da.com/img/temperature%20surface%20plot%20470x406.JPG</a>.</p>

<p>The idea is to have a 3D surface plot overlapping a 2d representation of a surface.</p>

<p>I can build arbitrary surfaces/polygon shapes (as in <a href=""http://addictedtor.free.fr/graphiques/graphcode.php?graph=135"" rel=""nofollow noreferrer"">http://addictedtor.free.fr/graphiques/graphcode.php?graph=135</a> ) and I can make the respective 2D plot. What I don't seem to be able to figure out is the way to put them together in a nice way (like the one shown in the jpg above).</p>

<p>I've tried googling for the answer, but I wasn't able to find anything similar done in R.
Any help would be greatly appreciated!</p>

<p>EDIT: The 2D portion is not a projection of the 2D one. I chose this specific picture to illustrate this. For example</p>

<ol>
<li>Here the 2D portion is the image of the circuit and on the 3D portion is the temperature).</li>
<li>In 2D you can have the map of a city and in 3D the traffic</li>
<li>etc...</li>
</ol>

<p>Best,</p>

<p>Bruno</p>
"
1886264,229420,2009-12-11T06:49:02Z,1,Avoiding loops in R,"<p>I have decided to learn R. I am trying to get a sense of how to write ""R style"" functions and to avoid looping. Here is a sample situation:</p>

<p>Given a vector <code>a</code>, I would like to compute a vector <code>b</code> whose elements <code>b[i]</code> (the vector index begins at 1) are defined as follows:</p>

<pre><code>1 &lt;= i &lt;= 4:
b[i] = NaN

5 &lt;= i &lt;= length(a):
b[i] = mean(a[i-4] to a[i])
</code></pre>

<p>Essentially, if we pretend 'a' is a list of speeds where the first entry is at time = 0, the second at time = 1 second, the third at time = 2 seconds... I would like to obtain a corresponding vector describing the average speed over the past 5 seconds.</p>

<p>E.g.:
If <code>a is (1,1,1,1,1,4,6,3,6,8,9)</code> then <code>b</code> should be <code>(NaN, NaN, NaN, NaN, 1, 1.6, 2.6, 3, 4, 5.4, 6.4)</code></p>

<p>I could do this using a loop, but I feel that doing so would not be in ""R style"".</p>

<p>Thank you,</p>

<p>Tungata</p>
"
1886571,78912,2009-12-11T08:14:19Z,3,making the subversion revision number visible in my R scripts,"<p>I'm putting this thing in my source(s)...  (right, for now it's just one, plus the test scripts).</p>

<pre><code>REVISION = (function(x) substring(x, first=7, last=nchar(x)-2))(""$Rev: 8727 $"")
</code></pre>

<p>but how do ""real"" R programmers do?  </p>
"
1886644,55362,2009-12-11T08:35:43Z,5,How to point to a directory in an R package?,"<p>I am making my first attempts to write a R package. I am loading one csv file from hard drive and I am hoping to bundle up my R codes and my csv files into one package later.</p>

<p>My question is how can I load my csv file when my pakage is generated, I mean right now my file address is something like c:\R\mydirectory....\myfile.csv but after I sent it to someone else how can I have a relative address to that file?</p>

<p>Feel free to correct this question if it is not clear to others!</p>
"
1886808,85514,2009-12-11T09:20:06Z,4,"How to format axes in R, year and months","<p>I have the following dataset</p>

<pre><code>1890 mar 0.4
1890 apr 0.8
1890 may 1.0
...
1989 jan 0.2
1989 feb 0.4
1989 mar 0.5
</code></pre>

<p>How can I make a line plot in <a href=""http://www.r-project.org/"" rel=""nofollow noreferrer"">R</a> with on the x-axis the year, displayed every 5 years?</p>

<p>My problem is not so much making the plot, but getting to display only the years I want, and place them on the beginning of that year. So I don't want a tick on April but on January.</p>
"
1887195,84952,2009-12-11T10:32:23Z,1,Unexpected value for length of a vector in R,"<p>I have the character vector below</p>

<pre><code>a = c(""2009-07-31 18:00:33"", ""2009-07-31 18:00:38"", ""2009-07-31 18:00:43"",  ""2009-07-31 18:00:49"", ""2009-08-01 01:58:49"", ""2009-08-01 01:53:16"",  ""2009-08-01 08:04:13"", ""2009-08-01 16:16:13"")
</code></pre>

<p>I want to convert this to time objects so I do this:</p>

<pre><code>b = strptime(a, ""%Y-%m-%d %H:%M:%S"")
</code></pre>

<p>Why do a and b have different lengths?</p>

<pre><code>&gt; length(a)
[1] 8
&gt; length(b)
[1] 9
</code></pre>
"
1888151,78912,2009-12-11T13:42:24Z,0,getting the highest subversion revision in my `R CMD build` filename,"<p>a question following  <a href=""https://stackoverflow.com/questions/1886571"">making-the-subversion-revision-number-visible-in-my-r-scripts</a></p>

<p><code>R CMD build PKG</code> creates a file named as Package_Version.tar.gz according to the fields in <code>DESCRIPTION</code>.  </p>

<p>not only isn't the strictly sequential numbering coming from svn very practical here, but its <code>$REV: number $</code> format does not respect the <code>number.number-number</code> structure expected after <code>Version:</code>.  </p>

<p>I think I would want to use the subversion revision number as the third ""coordinate"" of the package version.  the first and second coordinates would be raised by hand at major changes.</p>

<p>but how do you ""normally"" do?</p>

<hr>

<p>One could write a bash/grep/awk script that gets the highest Rev out of the sources, that wouldn't a problem.  But, is <code>configure</code> run before <code>R CMD build</code>?  In this case one could build the DESCRIPTION file (kept out of source control) from a template file and this highest Rev number.</p>

<p>My question is about common practice.</p>

<hr>

<p>the ""optimal"" answer would allow me to place a package on r-forge and have the automated scripts run there update the third coordinate of the <code>Version:</code> field from the latest files committed in the <code>R</code> subdir.</p>

<p>a ""good enough"" answer would work locally and I have it already, but am not using it any more because I otherwise get used to things that are generally unavailable.</p>

<p>since it's about practices, I'll add my current practice as possible answer.  it is not automated but I find it clear and (almost) acceptable.</p>
"
1890215,105132,2009-12-11T19:06:55Z,61,Getting R plots into LaTeX?,"<p>I'm a newbie to both R and LaTeX and have just recently found how to plot a standard time series graph using R and save it as a png image. What I'm worried about is that saving it as an image and then embedding it into LaTeX is going to scale it and make it look ugly.</p>

<p>Is there a way to make R's <code>plot()</code> function output a vector graphic and embed that into LaTeX? I'm a total beginner in both so please be gentle :) Code snippets are highly appreciated!</p>
"
1893257,85514,2009-12-12T12:23:51Z,1,How to create a sensible Hilbert Spectrum plot with R (computing environment),"<p>I am using the <a href=""http://cran.r-project.org/web/packages/EMD/EMD.pdf"" rel=""nofollow noreferrer"">EMD</a> package for R. This package has a spectrogram function for displaying a Hilbert Spectrum (calculated with hilbertspec). The output however, is really vague and black-white.</p>

<p>This function does not seem to have an option for outputting color images. How can I get the spectrum displayed clearly and if possible in color.</p>
"
1894190,162832,2009-12-12T17:52:04Z,4,basic SNA in R? - How to load network data,"<p>A few years back I used UCINET for some social network analysis. Theese days I'd like to use SNA again - but this time I prefer a unified analysis framework - which for me is R.</p>

<p>I have looked at the sna and statnet documentation but am a bit overwhelmed.</p>

<p>What I'd like to do: First: Load an bipartite/incidence matrix pulled directly from e.g. a websurvey (often valued). Convert this matrix to two adjacency matrix' (affiliatoin by affiliation and cases by cases). It could also be a directed, valued cases by cases matrix.</p>

<p>Second: Load a file (also from e.g. websurvey data) of vertice attributes.</p>

<p>Third: Then plot the graph with e.g. vertice size according to some centrality measure, colored and labeled by some vertice attributes, with only edges with value over a certain threshold being drawn.</p>

<p>This is a mini incidence matrix: </p>

<pre><code>data &lt;- structure(list(this = c(0, 1, 0, 1, 1, 2, 0, 1, 3), 
 that = c(1, 1, 3, 0, 0, 0, 2, 1, 0), 
 phat = c(0, 0, 2, 1, 0, 0, 1, 2, 0)), 
 .Names = c(""this"", ""that"", ""phat""), 
 row.names = c(""a"", ""b"", ""c"", ""d"", ""e"", ""f"", ""g"", ""h"", ""i""), 
 class = ""data.frame"")
</code></pre>

<p>with som attribute data:</p>

<pre><code>att &lt;-structure(list(sex = structure(c(1L, 1L, 2L, 2L, 1L, 2L, 1L, 
1L, 1L), .Label = c(""F"", ""M""), class = ""factor""), agegr = c(1L, 
1L, 3L, 1L, 3L, 1L, 1L, 3L, 1L), place = structure(c(1L, 2L, 
1L, 1L, 1L, 1L, 2L, 2L, 1L), .Label = c(""Lower"", ""Upper""), 
class = ""factor"")), .Names  = c(""sex"", 
""agegr"", ""place""), row.names = c(NA, -9L), class = ""data.frame"")
</code></pre>

<p>p.s. maybe SNA would be a good tag for this post? I just don't have the nescassary SO goodwill :-)</p>
"
1896419,205040,2009-12-13T12:53:44Z,56,"Plotting a 3D surface plot with contour map overlay, using R","<p>I have a 3-tuple data set (X,Y,Z points) that I want to plot using R.</p>

<p>I want to create a surface plot from the data, and superimpose a contour map on the surface plot, so as to create the impression of the contour map being the ""shadow"" or projection from the surface plot. The contour map is to appear below the surface plot.</p>

<p>My data set looks somewhat like this:</p>

<pre><code>Axis  |  Data Type
-------------------
X     |  Date value
Y     |  Float value
Z     |  Float value
</code></pre>

<p>How can I achieve this?</p>
"
1897704,25282,2009-12-13T20:55:01Z,22,Angle between two vectors in R,"<p>What the most efficient way in the programming language <a href=""http://www.r-project.org/"" rel=""nofollow noreferrer"">R</a> to calculate the angle between two vectors?</p>
"
1898101,55362,2009-12-13T22:55:23Z,15,qplot and anti-aliasing in R,"<p>I am using ggplot2 library and am working with the qplot command
I know I can save my output as an anti-aliased image file by using the following command after my qplot </p>

<pre><code>ggsave(file=""filename.png"")
</code></pre>

<p>But how about my LCD display? is there any way to see a plot on the monitor as anti-aliased grpah? </p>
"
1898815,178967,2009-12-14T03:54:14Z,0,rbind.zoo doesn't seem create consistent zoo object,"<p>I want to rbind.zoo two zoo object together.  When I was testing I came across the following issue(?)...</p>

<p>Note:  The below is an example, there is clearly no point to it apart from being illustrative.
I have an zoo object, call it, 'X'.  I want to break it into two parts and then rbind.zoo them together.  When I compare it to the original object then all.equal gives differences.</p>

<p>It appears that the '$class' attribute differs, but I can't see how or why.  Is I make these xts objects then the all.equal works as expected.</p>

<p>i.e. .....</p>

<pre><code>X.date &lt;- as.POSIXct(paste(""2003-"", rep(1:4, 4:1), 
                     ""-"", sample(1:28, 10, replace = TRUE), sep = """"))

X &lt;- zoo(matrix(rnorm(24), ncol = 2), X.date)

a &lt;- X[c(1:3), ]      # first 3 elements

b &lt;- X[c(4:6), ]      # second 3 elements

c &lt;- rbind.zoo(a, b)  # rbind into an object of 6 elements

d &lt;- X[c(1:6), ]      # all 6 elements

all.equal(c, d)       # are they equal?
</code></pre>

<p>~~~~</p>

<p>all.equal gives me the following difference:</p>

<p>""Attributes: &lt; Component 3: Attributes: &lt; Length mismatch: comparison on first 1 components > >""</p>
"
1899008,169947,2009-12-14T05:01:42Z,4,Weights from linear SVM model (in R)?,"<p>Using <code>kernlab</code> I've trained a model with code like the following:</p>

<pre><code>my.model &lt;- ksvm(result ~ f1+f2+f3, data=gold, kernel=""vanilladot"")
</code></pre>

<p>Since it's a linear model, I prefer at run-time to compute the scores as a simple weighted sum of the feature values rather than using the full SVM machinery.  How can I convert the model to something like this (some made-up weights here):</p>

<pre><code>&gt; c(.bias=-2.7, f1=0.35, f2=-0.24, f3=2.31)
.bias    f1    f2    f3 
-2.70  0.35 -0.24  2.31 
</code></pre>

<p>where <code>.bias</code> is the bias term and the rest are feature weights?</p>

<p>EDIT:</p>

<p>Here's some example data.</p>

<pre><code>gold &lt;- structure(list(result = c(-1, -1, -1, -1, -1, -1, -1, -1, -1, 
-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), f1 = c(0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 
1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1), f2 = c(13.4138113499447, 
13.2216999857095, 12.964145772169, 13.1975227965938, 13.1031520152764, 
13.59351759447, 13.1031520152764, 13.2700658838026, 12.964145772169, 
13.1975227965938, 12.964145772169, 13.59351759447, 13.59351759447, 
13.0897162110721, 13.364151238365, 12.9483051847806, 12.964145772169, 
12.964145772169, 12.964145772169, 12.9483051847806, 13.0937231331592, 
13.5362700880482, 13.3654209223623, 13.4356400945176, 13.59351759447, 
13.2659406408724, 13.4228886221088, 13.5103065354936, 13.5642812689161, 
13.3224757352068, 13.1779418771704, 13.5601730479315, 13.5457299603578, 
13.3729010596517, 13.4823595997866, 13.0965264603473, 13.2710281801434, 
13.4489887206797, 13.5132372154748, 13.5196188787197), f3 = c(0, 
1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 
0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0)), .Names = c(""result"", 
""f1"", ""f2"", ""f3""), class = ""data.frame"", row.names = c(NA, 40L
))
</code></pre>
"
1899243,141789,2009-12-14T06:27:47Z,6,GLM with autoregressive term to correct for serial correlation,"<p>I have a stationary time series to which I want to fit a linear model with an autoregressive term to correct for serial correlation, i.e. using the formula At = c1*Bt + c2*Ct + ut, where ut = r*ut-1 + et</p>

<p>(ut is an AR(1) term to correct for serial correlation in the error terms)</p>

<p>Does anyone know what to use in R to model this?</p>

<p>Thanks
Karl</p>
"
1905258,15050,2009-12-15T04:58:52Z,8,R code examples/best practices,"<p>I'm new to R and having a hard time piecing together information from various sources online related to what is considered a ""good"" practice with writing R code.  I've read basic guides but I've been having a hard time finding information that is definitely up to date.</p>

<ol>
<li>What are some examples of well written/documented S3 classes?</li>
<li>How about corresponding S4 classes?</li>
<li>What conventions do you use when commenting .R classes/functions?  Do you put all of your comments in both .Rd files and .R files?  Is synchronization of these files tiresome?</li>
</ol>
"
1907129,78912,2009-12-15T12:33:15Z,3,RUnit testing uninstalled package,"<p>I am following the hints to <a href=""https://stackoverflow.com/questions/1879843/distributing-r-package-containing-unit-tests"">this question</a>, but I'm impatient and I would like to run my tests more quickly, without having to wait for the 30+ checks that <code>R CMD check src</code> invokes  before <code>checking tests</code>.  </p>

<p>what I thought I could do was to add a <code>--standalone</code> option to the <code>doRUnit.R</code> suggested in <a href=""http://wiki.r-project.org/rwiki/doku.php?id=developers:runit"" rel=""nofollow noreferrer"">that R-wiki page</a> so that I could run the unit tests independently of <code>R CMD</code>.</p>

<p>I added these lines to the script:</p>

<pre><code>  opt &lt;- list(standalone=NULL)
  if(require(""getopt"", quietly=TRUE)) {
    ## path to unit tests may be given on command line, in which case
    ## we also want to move the cwd to this script
    opt &lt;- getopt(matrix(c('standalone', 's', 0, ""logical""),
                         ncol=4, byrow=TRUE))
    if(!is.null(opt$standalone)) {
      ## switch the cwd to the dir of this script
      args &lt;- commandArgs()
      script.name &lt;- substring(args[substring(args, 1, 7)==""--file=""], 8, 1000)
      if(!is.null(script.name))
        setwd(dirname(script.name))
    }
  }
</code></pre>

<p>with this change, the script finds the <code>test.*\.R</code> files, independently from the directory from which I invoke the script.</p>

<p>the remaining problem now is that the <code>doRUnit.R</code> script loads the <strong>installed</strong> library, it does not <code>source()</code> the files that compose the library.</p>

<p>assuming that I want to load each and every file in the <code>R</code> directory, how would I do that?</p>

<p>assuming you have a better testing schema (satisfying the requirements ""quick"", ""uninstalled""), what is it?</p>
"
1908010,30911,2009-12-15T14:58:56Z,24,What does the @ symbol mean in R?,"<p>In packages like marray and <a href=""http://bioinf.wehi.edu.au/limma/"" rel=""noreferrer"">limma</a>, when complex objects are loaded, they contain ""members variables"" that are accessed using the @ symbol. What does this mean and how does it differ from the $ symbol?</p>
"
1909357,135944,2009-12-15T18:18:11Z,2,losing stdout in R console on Mac OS X,"<p>I'm working on a big Sweave document/script on a Mac OS X system, R version 2.9.2. Under some circumstances, it appears as if Sweave is redirecting stdout, so that <code>x &lt;- 1; print(x)</code> gives nothing at all. (The console is still running, as <code>plot(x)</code> pops up a plot as normal.) So, two questions:</p>

<ol>
<li>How do I force stdout to go back to the console, and,</li>
<li>Why does Sweave do this, and how?</li>
</ol>
"
1915001,85514,2009-12-16T14:32:10Z,9,Highlighting specific values in R plot,"<p>In R (statistical computing environment) I would like on a generic plot, with time on the x-axis, highlight some specific years.</p>

<p>How can I bestly do this? My idea is for example a light yellow bar for the highlighted years, behind the plot of course.</p>

<p>The plot code I have now:</p>

<pre><code>pdf(""temperature_imfs_big_interm5.pdf"", width=6, height=8);
par(mfrow=c(temperature$bigEmdIm5$nimf+1,1), mar=c(2,1,2,1))
for(i in 1:temperature$bigEmdIm5$nimf) {
    plot(timeline$big, temperature$bigEmdIm5$imf[,i], type=""l"", xlab="""", ylab="""", ylim=range(temperature$bigEmdIm5$imf[,i]), axes=FALSE, main=paste(i, ""-th IMF"", sep=""""))#; abline(h=0)
  axis.POSIXct(side=1, at=tickpos$big)
}
plot(timeline$big, temperature$bigEmdIm5$residue, xlab="""", ylab="""", axes=FALSE, main=""residue"", type=""l"")
axis.POSIXct(side=1, at=tickpos$big)
dev.off();
</code></pre>

<p>Where temperature$bigEmdIm5 is the output of emperical mode decompostion. The data is in months, so I would like to higlight 01/1950 until 12/1950 for example.</p>
"
1923273,233979,2009-12-17T17:21:36Z,263,Counting the number of elements with the values of x in a vector,"<p>I have a vector of numbers:</p>

<pre><code>numbers &lt;- c(4,23,4,23,5,43,54,56,657,67,67,435,
         453,435,324,34,456,56,567,65,34,435)
</code></pre>

<p>How can I have R count the number of times a value <em>x</em> appears in the vector?</p>
"
1931742,487499,2009-12-19T02:28:01Z,1,Extracting subsets of data,"<p>this seems to be an easy task really, but being completely new to the world of programming, I have problems with the following task:
I have a huge file which has the following format:</p>

<pre><code>track type= wiggle name09
variableStep chrom=chr1
34 5 
36 7 
54 8 
variableStep chrom=chr2 
33 4 
35 2 
78 7 
this is text with the word random in it# this we need to remove
82 4 
88 6 
variableStep chrom=chr3 
78 5 
89 4 
56 7
</code></pre>

<p>now what I would like as an out put is just</p>

<p>one file called 1 
and containing only</p>

<pre><code>34 5
36 7
54 8

a second file called 2

33 4
35 2
78 7
82 4 
88 6

a third file

78 5
89 4
56 7
</code></pre>

<p>It would be great to get some help on this...
If any knows how to do it in R... that would be even better</p>
"
1934670,170352,2009-12-20T02:03:11Z,2,Conditional Column Creation,"<p>I have a data frame with two columns (data will not always be identical). </p>

<pre><code>1 1 
2 2 
3 3 
0 0 
-1 -1 
-2 -2 
-3 -3
</code></pre>

<p>What I would like to do is create another column for the top 10% of the column and the bottom 10% of the column to be used as labels for a scatter plot. </p>

<pre><code>1 1 
2 2 
3 3 1
0 0 
-1 -1  
-2 -2 
-3 -3 2
</code></pre>

<p>In addition, it needs to be able to select and label from either column the top/bottom 10% </p>

<p>Any ideas?</p>
"
1934751,235349,2009-12-20T03:30:43Z,8,Plot Histogram with Points Instead of Bars,"<p>Here is a question for R-users. I am interested in drawing a histogram with points stacked up, instead of a bar. For example if the data is (1,1,2,1,2,3,3,3,4,4), then I would like to see three points stacked up at 1, 2 points stacked up at 2 and so on. What is the best way to do this in R?</p>
"
1939098,170352,2009-12-21T09:27:53Z,4,Repositioning scatter plot labels in ggplot2,"<p>Is it possible to reposition the labels such that in sector (-x,y) the label is on the left and sector (+x,y) the label is on the right?</p>
"
1939492,170352,2009-12-21T11:09:07Z,0,Error in jpeg(a_paste_function) : too many open devices,"<p>I am trying to output about 250 plots from an r-script and I'm receiving a ""too many open devices"" error. Is there some setting that I can adjust to avoid this problem?</p>

<p>Here is an example of how I am creating the plots: </p>

<pre><code>for(x in 250) { 

plots &lt;- ggplot(data=dat, aes(x,y,lab=labels))
jpeg(a_paste_function)
print(plots)

} 
</code></pre>

<p>One thing I notice is that when I <code>write.table</code>, the files are ready right away, whereas I always have to close R for the jpegs to be ""printed"". Perhaps that is the real problem, the method in which I'm dumping the plots?</p>
"
1950608,13969,2009-12-23T03:50:58Z,1,"Given a time series for many unique IDs, I need the top 100 deltas for each period","<p>I have a time series of data in TSV like so:</p>

<pre><code>ID \t Date \t Value
-------------------------------
1234567 \t 2009-01-01T00:00:00.000Z \t 121
12131 \t 2009-06-01T00:00:00.000Z \t 151
12131 \t 2009-07-01T00:00:00.000Z \t 15153
...
</code></pre>

<p>It easily fits in RAM, but is too big for Excel.</p>

<p>There is one value per month per ID, but not all IDs have entries for all 12 months.</p>

<p>The data spans 12 months, but not all IDs have all 12 months.  I want to go through the data for each ID, and if there is an entry for the previous month, take the current month minus the previous month and store it in a new column to get a delta.  If there is no entry for the previous month, then return 0.  Then, for each month, I want the top 100 positive and negative of those deltas, along with the ID.</p>

<p>I'd like to do this in R, because it's hard in Excel and it keeps crashing.  I have R, Rattle, etc. installed and I've worked through basic examples, but ... the learning curve is steep.  I would really appreciate some help :)</p>
"
1951070,144157,2009-12-23T06:47:37Z,2,Strange error when building R packages for Windows,"<p>On one of my PCs, when I build any R package I get the following fatal error</p>

<pre><code>* checking for file 'forecast/DESCRIPTION' ... OK
* preparing 'forecast':
* checking DESCRIPTION meta-information ... OK
* cleaning src
* removing junk files
* checking for LF line-endings in source and make files
* checking for empty or unneeded directories
* building binary distribution
WARNING: some HTML links may not be found
Error in setwd(owd) : cannot change working directory
 ERROR
* installation failed
</code></pre>

<p>But the same packages compile fine on my other PC. I'm at a loss as to what's causing this. Has anyone else seen something similar?</p>

<p>Using Windows XP, R2.10.1, Rtools 2.10.</p>
"
1953256,142477,2009-12-23T14:56:47Z,0,creating a pdf in R that is vertically justified,"<p>Question:  how can you create a pdf where the output is vertically
justified, with for example, a one inch margin on top using <code>pdf()</code>.</p>

<p>For example in</p>

<pre><code>pdf(file='test.pdf', paper='letter', pagecentre=F)
### code for plot here ###
dev.off()
</code></pre>

<p>is there an option where it generate output that starts from the top of the
page rather than printing from the bottom of the page (which is what happens when <code>pagecentre=F</code>).  Or will this require
some adjustment of settings in <code>par()</code>?</p>
"
1955330,126353,2009-12-23T21:10:48Z,2,R and Daily Projects,"<p>I'm now reading some books of <strong><a href=""http://www.r-project.org/"" rel=""nofollow noreferrer"">R</a></strong>, but I want to know if I can use this language as I use Perl or Ruby. Things like:</p>

<ul>
<li>Image Processing</li>
<li>File Compression</li>
<li>Use APIs</li>
<li>Interact With Internet</li>
</ul>

<p>But it's usual and simple(as in Perl or Ruby) to do things like this?</p>

<p>PS: I liked this language very much, because of this I want to use it on my personal projects and spread it for my friends and at the internet.</p>
"
1956337,170352,2009-12-24T02:07:30Z,0,Inner sort with R - Once by numeric then by alpha,"<p>I have a data.frame, like this:</p>

<pre><code>nums&lt;-c(5,7,8,9,10,3,2,1)
text&lt;-c(""a"",""b"",""c"",""d"",""a 09"",""b 09"",""c 09"",""d 09"")
this &lt;- data.frame()
this &lt;- cbind(text,nums)

""a""   5 
""b""   7
""c""   8
""d""   9
""a 09"" 10
""b 09"" 3
""c 09"" 2
""d 09"" 1
</code></pre>

<p>a:d = data from 2010, a 09:d:09 = data from 2009. 
I'd like it to be sorted first by the numeric column from greatest to least and then by the string column. The only catch is that the string column has to show the 09' data underneath the 2010 data, like this: </p>

<pre><code>""d""   9
""d 09"" 1
""c""   8
""c 09"" 2
""b""   7
""b 09"" 3
""a""   5 
""a 09"" 10
</code></pre>
"
1960119,25282,2009-12-25T00:01:58Z,7,Importing data from an XML file into R,"<p>I want to import an XML file from polarpersonaltrainer.com that stores heartrate data into a R data.frame.
Is there a package that makes importing XML easy or do I have to write my own parser?</p>
"
1961109,126353,2009-12-25T12:36:16Z,1,R Ports For Mobile Devices,"<p>I'm learning <strong><a href=""http://r-project.org"" rel=""nofollow noreferrer"">R</a></strong> and like the language very much because of its flexibility, but I want to know:</p>

<ul>
<li>Are there any ports of <strong><a href=""http://r-project.org"" rel=""nofollow noreferrer"">R</a></strong> for mobile devices?</li>
<li>Where can I get them?</li>
</ul>
"
1961948,25282,2009-12-25T21:02:16Z,0,Turning a list of characters that contain numbers into integers in R,"<p>Is there a faster way in R to turn a list of characters like <code>c(""12313"",""21323"")</code> into an integer list like <code>c(12313, 21323)</code> other than writing a for loop myself?</p>
"
1962278,25282,2009-12-25T23:58:45Z,45,Dealing with timestamps in R,"<p>I have multiple lists of measurements. In each list have the timestramp formated as a string (""2009-12-24 21:00:07.0"") and I know that each measurement in the list is separated by 5 seconds.
I want to combine all data into a huge data.frame in R. Afterwards I want to be able to easily access the time difference of two measurements so I probably should convert data into something different than characters.</p>

<p>Which format should I use to store the times? Is there some time format in some package that I should use?</p>
"
1962954,162436,2009-12-26T08:54:20Z,7,maximum plot points in R?,"<p>I have come across a number of situations where I want to plot more points than I really ought to be -- the main holdup is that when I share my plots with people or embed them in papers, they occupy too much space.  It's very straightforward to randomly sample rows in a dataframe.</p>

<p>if I want a truly random sample for a point plot, it's easy to say:</p>

<pre><code>ggplot(x,y,data=myDf[sample(1:nrow(myDf),1000),])
</code></pre>

<p>However, I was wondering if there were more effective (ideally canned) ways to specify the number of plot points such that your actual data is accurately reflected in the plot.  So here is an example. 
Suppose I am plotting something like the CCDF of a heavy tailed distribution, e.g.</p>

<pre><code>ccdf &lt;- function(myList,density=FALSE)
{
  # generates the CCDF of a list or vector
  freqs = table(myList)
  X = rev(as.numeric(names(freqs)))
  Y =cumsum(rev(as.list(freqs)));
  data.frame(x=X,count=Y)
}
qplot(x,count,data=ccdf(rlnorm(10000,3,2.4)),log='xy')
</code></pre>

<p>This will produce a plot where the x &amp; y axis become increasingly dense. Here it would be ideal to have fewer samples plotted for large x or y values.</p>

<p>Does anybody have any tips or suggestions for dealing with similar issues?</p>

<p>Thanks,
-e</p>
"
1963492,25282,2009-12-26T14:21:11Z,35,Grid in an R plot,"<p>Is there a command to easily add a grid onto an R plot?</p>
"
1971323,199166,2009-12-28T20:13:58Z,22,Efficiency of operations on R data structures,"<p>I'm wondering if there's any documentation about the efficiency of operations in <code>R</code>, specifically those related to data manipulation. </p>

<p>For example:</p>

<ul>
<li>I imagine it's efficient to add columns to a data frame, because I'm guessing you're just adding an element to a linked list. </li>
<li>I imagine adding rows is slower because vectors are held in arrays at the <code>C level</code> and you have to allocate a new array of length <code>n+1</code> and copy all the elements over.</li>
</ul>

<p>The developers probably don't want to tie themselves to a particular implementation, but it would be nice to have something more solid than guesses to go on.</p>

<p>Also, I know the main <code>R</code> performance hint is to use vectored operations whenever possible as opposed to <code>loops</code>. </p>

<ul>
<li>what about the various flavors of <code>apply</code>? </li>
<li>are those just <code>hidden loops</code>? </li>
<li>what about <code>matrices</code> vs. <code>data frames</code>?</li>
</ul>
"
1971461,239788,2009-12-28T20:43:53Z,4,Generating a lagged time series cross sectional variable in R,"<p>I am a new R user.  I have a time series cross sectional dataset and, although I have found ways to lag time series data in R, I have not found a way to create lagged time-series cross sectional variables so that I can use them in my analysis. </p>
"
1973360,79358,2009-12-29T07:21:28Z,0,R accessing DB query results by column and row number,"<p>I am new to R language. I have successfully loaded a query's resultset into a variable. Now I want to access the resultset data by column name and row number. And I need to verify if it is Null (it is shown as &lt; NA > in result) then send a mail by bat file with PHP. My sample code is below.</p>

<pre><code>library(RODBC)
newconn = odbcConnect(""db"", uid=""uid"", pwd=""pwd"") 
new &lt;- sqlQuery(newconn,""SELECT COL1, COL2 FROM TABLE1;"", errors = TRUE, 1)
if(new$COL1[3] == ""&lt;NA&gt;""){
system(""sendmail.bat"")
}else{
print (""failed"")
}
</code></pre>

<p>Also I would like to compare a string result like below.</p>

<pre><code>if(new$COL2[10] == 'MYSTRING'){
print(""success"")
}
</code></pre>

<p>But I think I am using wrong syntax. Please help as I am not able to get the correct syntax for doing these comparisons. </p>
"
1974930,160794,2009-12-29T14:37:44Z,4,Memory Usage in Foreach Function,"<p>I was wondering if there is any way to get the foreach package in R to use a pre-allocated structure to put results. basically it involves lots of small linalg operations on very big data sets.</p>

<p>My non-foreach original code is something like</p>

<pre><code>results &lt;- rep(NA,m*l*[big.number])
dim(results) &lt;- c(m,l,[big.number])
for (i in 1:m){
    for (j in 1:l){
        results[i,j,] &lt;- function(j,i,data)
    }
}
</code></pre>

<p>I'd like to use foreach and doMC to parallelize this but test runs are really really slow and I think it's the continual data moving that rbind and c do.</p>
"
1974998,25282,2009-12-29T14:47:19Z,0,Optimising R function that adds a new column to a data.frame,"<p>I have a function that at the moment programmed in a functional model and either want to speed it up and maybe solve the problem more in the spirit of R.
I have a data.frame and want to add a column based on information that's where every entry depends on two rows.
At the moment it looks like the following:</p>

<pre><code>faultFinging &lt;- function(heartData){
    if(heartData$Pulse[[1]] == 0){
        Group &lt;- 0
    }
    else{
        Group &lt;- 1
    }
    for(i in seq(2, length(heartData$Pulse), 1)){
        if(heartData$Pulse[[i-1]] != 0 
            &amp;&amp; heartData$Pulse[[i]] != 0
            &amp;&amp; abs(heartData$Pulse[[i-1]] - heartData$Pulse[[i]])&lt;20){
            Group[[i]] &lt;- 1
        }
        else{
            if(heartData$Pulse[[i-1]] == 0 &amp;&amp; heartData$Pulse[[i]] != 0){
                Group[[i]] &lt;- 1
            }
            else{
                Group[[i]] &lt;- 0
            }
        }
    }
    Pulse&lt;-heartData$Pulse
    Time&lt;-heartData$Time
    return(data.frame(Time,Pulse,Group))
}
</code></pre>
"
1975110,125663,2009-12-29T15:07:14Z,17,Printing stack trace and continuing after error occurs in R,"<p>I'm writing some R code that calls other code that may fail. If it does, I want to print a stack trace (to track down what went wrong), then carry on regardless. However, the traceback() function only provides information about uncaught exceptions. I can get the result I want via a rather complex, natty construction involving tryCatch and dump.frames, but is there not an easier way of doing this?</p>
"
1976728,240395,2009-12-29T20:19:03Z,1,mca or various ca (multivariate analysis),"<p>I will make a analysis about some information of my company.</p>

<p>I thought making a <strong>ca</strong> to representate the association between two variables. I have 3 variables: Category, Tag, Valoration. My idea is to make 2 analysis, one to view the association between Category - Valorarion and a second analysis between Tag - Valoration.</p>

<p>But I think that this representation is possible with a mca.</p>

<p>What do you recomment me?</p>

<p>Thank You</p>
"
1978006,170352,2009-12-30T01:52:58Z,0,Data manipulation with R: Restructuring Data,"<p>I have a dataset that looks like this: </p>

<pre><code>a &lt;- data.frame(rep(1,5),1:5,1:5)
b &lt;- data.frame(rep(2,5),1:5,1:5)
colnames(a) &lt;- c(1,2,3)
colnames(b) &lt;- c(1,2,3)
c &lt;- rbind(a,b)

   1 2 3
1  1 1 1
2  1 2 2
3  1 3 3
4  1 4 4
5  1 5 5
6  2 1 1
7  2 2 2
8  2 3 3
9  2 4 4
10 2 5 5
</code></pre>

<p>but I want it to be restructured to this: </p>

<pre><code>    2_1 2_2 3_1 3_2
   1  1   1   1   1
   2  2   2   2   2 
   3  3   3   3   4
   4  4   4   4   4 
   5  5   5   5   5
</code></pre>
"
1982667,194742,2009-12-30T21:44:11Z,2,Standard error of the ARIMA constant,"<p>I am trying to manually calculate the standard error of the constant in an ARIMA model, if it is included. I have referred to Box and Jenkins (1994) text, specially Section 7.2, but my understanding is that the methods mentioned here calculates the variance-covariance matrix for the ARIMA parameters only, not the constant. Tried searching on the Internet, but couldn't find any theory. Software like Minitab, R etc. calculate this, so I was wondering what is the way? Can someone provide any pointer(s) on this topic?
Thanks. </p>
"
1995933,205459,2010-01-03T19:12:47Z,33,Number of months between two dates,"<p>Is there a standard/common method/formula to calculate the number of months between two dates in R?</p>

<p>I am looking for something that is similar to <a href=""http://www.mathworks.com/access/helpdesk/help/toolbox/finance/months.html"" rel=""noreferrer"">MathWorks months function</a></p>
"
2001441,103832,2010-01-04T19:01:21Z,0,Rscript: Define path file as argument,"<p>I try this command :</p>

<pre><code>Rscript ""/Users/test/Scripts/arg_test.R"" ""path_in=/Users/test/GR/web-app/Rproject/Inputs/Rmerge/Description.csv"" path_in2=""/Users/test/IdeaProjects/Rproject/Inputs/Rmerge/Template_Auto.csv""
</code></pre>

<p>but I have this error :
Error in parse(text = args[[i]]) : unexpected '/' in ""path_in=/""</p>

<p>Part of Rscript :</p>

<pre><code>args=(commandArgs(TRUE))

if(length(args)==0){
    print(""No arguments supplied."")
}else{
    for(i in 1:length(args)){
         eval(parse(text=args[[i]]))
    }
}


path_out = ""/Users/test/Rproject/Results/""

annotation = read.csv(paste(path_in, sep=""""))

modules = read.csv(paste(path_in2, sep=""""))

merge_output = merge(annotation, modules, by = ""Module"")
</code></pre>

<p>How can I define path_in as argument(args) ?</p>

<p>Thank you.</p>
"
2001625,202190,2010-01-04T19:34:24Z,0,where do I find the definition of class objects in spatstat,"<p>I would like to know what kind of information does an object of class Spatialpolygons has versus an object of class Polygons. </p>
"
2003465,182378,2010-01-05T00:59:55Z,2,Fastest numerical solution of a real cubic polynomial?,"<p>R question: Looking for the fastest way to NUMERICALLY solve a bunch of arbitrary cubics known to have real coeffs and three real roots. The polyroot function in R is reported to use Jenkins-Traub's algorithm 419 for complex polynomials, but for real polynomials the authors refer to their earlier work. What are the faster options for a real cubic, or more generally for a real polynomial? </p>
"
2003663,176995,2010-01-05T01:51:01Z,13,Import multiline SQL query to single string,"<p>In <a href=""http://en.wikipedia.org/wiki/R_language"" rel=""noreferrer"">R</a>, how can I import the contents of a multiline text file (containing SQL) to a single string? </p>

<p>The sql.txt file looks like this:</p>

<pre><code>SELECT TOP 100 
 setpoint, 
 tph 
FROM rates
</code></pre>

<p>I need to import that text file into an R string such that it looks like this:</p>

<pre><code>&gt; sqlString
[1] ""SELECT TOP 100 setpoint, tph FROM rates""
</code></pre>

<p>That's so that I can feed it to the RODBC like this</p>

<pre><code>&gt; library(RODBC)
&gt; myconn&lt;-odbcConnect(""RPM"")
&gt; results&lt;-sqlQuery(myconn,sqlString)
</code></pre>

<p>I've tried the readLines command as follows but it doesn't give the string format that RODBC needs.</p>

<pre><code>&gt; filecon&lt;-file(""sql.txt"",""r"")
&gt; sqlString&lt;-readLines(filecon, warn=FALSE)
&gt; sqlString
[1] ""SELECT TOP 100 ""                              ""\t[Reclaim Setpoint Mean (tph)] as setpoint, ""
[3] ""\t[Reclaim Rate Mean (tph)] as tphmean ""       ""FROM [Dampier_RC1P].[dbo].[Rates]""           
&gt; 
</code></pre>
"
2007464,197321,2010-01-05T16:33:26Z,0,Can I do margin calculations in ddply()?,"<p>The <code>cast()</code> function is great at calculating margins for aggregate values:</p>

<p><code>cast(df, IDx1+IDx2~IDy1, margins=c('IDx1','IDx2','grand_row'),c(min, mean, max))</code></p>

<p>The problem is that I need to weight my means using a second vector and a custom function. </p>

<p>Of course, <code>ddply()</code> lets me apply custom aggregation functions to my grouped records:</p>

<pre><code>ddply(d, IDx1+IDx2~IDy1 , function(x) 
c(
min(x$value),
MyFancyWeightedHarmonicMeanFunction(x$value,x$weight),
max(x$value)
)
)
</code></pre>

<p>...and this is awesome.</p>

<p>But what would really save the day is the ability to do both things at once, whether by calling the two-vector function in <code>cast()</code> or by faking somehow the <code>margins=()</code> variable in <code>ddply().</code></p>

<p>Is this possible?</p>
"
2010641,163053,2010-01-06T02:42:39Z,2,Calling R from S-Plus?,"<p>Does anyone have any suggestions for a good way to call R from S-Plus?  Ideally I would like to just pass code to R and get data back without having to write anything too elaborate to integrate them.  </p>

<p>I should add that I'm familiar with the <a href=""http://www.omegahat.org/RinS/"" rel=""nofollow noreferrer"">RinS</a> package on Omegahat, but I haven't used it.  I was under the impression that Insightful had made an effort to integrate the environments before Tibco took over.</p>

<p><em>Edit:</em> It turns out that RinS doesn't work on Windows.  I found that the easiest solution was to just use Rscript.  I can call this from S-Plus with the <code>system()</code> command.  For example, here's a simple script:</p>

<pre><code>#! Rscript --vanilla --default-packages=utils
args &lt;- commandArgs(TRUE)
print(args)
print(1:100)
Sys.sleep(2)
res &lt;- ""hello world""
class(res) &lt;- ""try-error""
if(inherits(res, ""try-error"")) q(status=1) else q()
</code></pre>

<p>And calling it from S-Plus:</p>

<pre><code>system(""rscript c://test.rscript 'some text'"")
</code></pre>

<p>Then I just store the results into a text file and import it into S-Plus after the script is run.  </p>
"
2018480,245292,2010-01-07T05:50:07Z,4,What is the equivalent of var_dump() in r?,"<p>I'm looking for a function to dump variables and objects, with human readable explanations of their data types.  For instance, in php <code>var_dump</code> does this.</p>

<pre><code>$foo = array();
$foo[] = 1;
$foo['moo'] = 2;

var_dump($foo);
</code></pre>

<p>Yields:</p>

<pre><code>array(2) {
  [0]=&gt;
  int(1)
  [""moo""]=&gt;
  int(2)
}
</code></pre>
"
2020790,148335,2010-01-07T14:00:35Z,10,R Script: Determine whether the script is run in the GUI or from command line,"<p>Is it possible to determine - from within the script - whether the script is running in the R-GUI (specifically R.app on OS X) or whether it has been called from Terminal/command line (i.e. <code>R --vanilla -f script.R</code>)? If so, how is this possible?</p>

<p>I'm asking because I have a script that can run parallelized (using the <code>doMC</code> library), which should not be used from the GUI. Sometimes I need to further process the data calculated in the script, so I'd like to call the script from the GUI on these occasions.</p>
"
2030895,170352,2010-01-08T21:31:14Z,0,Inner Sort with R - Once by Numeric then by Alpha (V2),"<p>I have asked this question before and received a solution, but my problem is somewhat varied from the original explanation </p>

<p>I have a data frame, like this: </p>

<pre><code>nums&lt;-c(5,7,8,9,10,3,2,1)
text&lt;-c(""Company a"",""Company b"",""Company c"",""Company d"",""Company a 09"",""Company b 09"",""Company c 09"",""Company d 09"")
this &lt;- data.frame()
this &lt;- cbind(text,nums)
</code></pre>

<p>""Company a:d"" = data from 2010, ""Company a 09:d:09"" = data from 2009. I'd like it to be sorted first by the numeric column from greatest to least and then by the string column. The only catch is that the string column has to show the 09' data underneath the 2010 data, like this: </p>

<pre><code>""Company d""   9
""Company d 09"" 1
""Company c""   8
""Company c 09"" 2
""Company b""   7
""Company b 09"" 3
""Company a""   5 
""Company a 09"" 10
</code></pre>

<p>There's been a few suggestions from <a href=""https://stackoverflow.com/questions/1956337/inner-sort-with-r-once-by-numeric-then-by-alpha"">this question</a>, but I can't replicate it for this, somewhat more complicated example. </p>

<p>I've uploaded some <a href=""http://www.bertelsen.ca/R/testdata.csv"" rel=""nofollow noreferrer"">test data</a>.</p>
"
2034255,60628,2010-01-09T17:40:22Z,2,"How to plot nice graph using few commands, separating drawing logic from layout?","<p>Is there a simple way to make a nice plot of the following data in R, without using many commands?</p>

<pre><code> Region1 Region2
2007 17 55
2008 26 43
2009 53 70
2010 96 58
</code></pre>

<p>I do know how to plot the data, but it uses too many commands and parameters, and the result still looks absolutely terrible (see <a href=""http://i50.tinypic.com/30nklfm.png"" rel=""nofollow noreferrer"">here</a>):</p>

<pre><code>&gt; test &lt;- read.table(""/tmp/data.txt"")
&gt; png(filename=""/tmp/test.png"", height=1000, width=750, bg=""white"", res=300)
&gt; plot(test$Region1, type=""b"", col=""blue"", ylim=c(0,100), lwd=3)
&gt; lines(test$Region2, type=""b"", col=""red"", lwd=3)
&gt; dev.off()
</code></pre>

<p>It took me a while to figure out all the commands, and I still have to get the x axis labels (2007, 2008, ...), using the <code>axis</code> command (but how do I access the <code>test</code> x axis labels?), etc. </p>

<p>In Keynote (or Powerpoint) I can just give it the same table (transposed) and it produces a nice graph from it (see <a href=""http://i45.tinypic.com/b3tw08.jpg"" rel=""nofollow noreferrer"">here</a>).</p>

<p>My question is really: Is there a higher-level command that draws such typical data nicely? Also, how can I separate the drawing logic (draw 2 lines from that specific data, etc.) from the layout (use specific colors and line types for the graph, etc.)? Ideally, I'd hope there were different libraries for different layouts of the graph, e.g. called <code>NiceKeynoteLayout</code>, which I just could use like this (or similar):</p>

<pre><code>&gt; d &lt;- read.table(""/tmp/data.txt"")
&gt; png &lt;- png(filename=""/tmp/test.png"", height=1000, width=750)
&gt; myLayout &lt;- loadPredefinedLayout(""NiceKeynoteLayout"")
&gt; coolplot(d, layout=myLayout, out=png)
</code></pre>
"
2036250,20426,2010-01-10T05:45:43Z,3,Grouping rows or columns of data in R,"<p>I'm trying to import some data into R and not having much luck grouping together rows of related data. </p>

<p>Example:
There a set of problems such as {A, B, C, D}. Each problem has two variables of interest which are being measured: ""x"" and ""y"". 
Each variable is analysed in terms of some simple statistics: min, max, mean, stddev.</p>

<p>So, my input data has the form:</p>

<pre><code>      Min  Max  Mean  StdDev
A
  x   3    10   6.6   2.1 
  y   2    5    3.2   1.7
B
  x   3    10   6.6   2.1 
  y   2    5    3.2   1.7
C
  x   3    10   6.6   2.1 
  y   2    5    3.2   1.7
D
  x   3    10   6.6   2.1 
  y   2    5    3.2   1.7
</code></pre>

<p>Is there any way to preserve the structure of this data in R?
A similar problem is creating groups of columns (flip the table by 90 degrees to the right for example).</p>
"
2039763,246211,2010-01-11T03:33:18Z,6,Dynamically create R graphics for webpage,"<p>I've spent a few weeks learning some R and I'm floored at just how slick and powerful it is. I'm using it to plot some data returned from an SQL query, and I'd like to be able to share those plots with others I work with through a web portal. </p>

<p>I realize I can create a cron job to run the R scripts on the webserver to create the plots daily to be viewed from the website as images. But is there any way I can set things up such that the images are created only when the user views the page? That way I could make a web interface that lets the user select date ranges, etc for the SQL query. (and then have R analyse the data and plot it)</p>

<p>Any advice?</p>
"
2040026,247810,2010-01-11T05:10:59Z,2,How to import data with line breaks from text file into R?,"<p>I have a text file that I'd like to import into <code>R</code>. Problem is, the file looks like this:</p>

<pre><code>x1,x2,x3,x4,x5,x6,x7,x8,x9,10,x11
   1953.00       7.40000       159565.       16.6680       8883.00    
   47.2000       26.7000       16.8000       37.7000       29.7000    
   19.4000    
   1954.00       7.80000       162391.       17.0290       8685.00    
   46.5000       22.7000       18.0000       36.8000       29.7000    
   20.0000
</code></pre>

<p>and so on.</p>

<p>I tried <code>&gt; data &lt;- read.table(""clipboard"", header=TRUE)</code> but that didn't work.</p>
"
2041120,247946,2010-01-11T10:19:07Z,2,Ordering Merged data frames,"<p>As a fairly new R programmer I seem to have run into a strange problem - probably my inexperience with R</p>

<p>After reading and merging successive files into a single data frame, I find that order does not sort the data as expected. </p>

<p>I have multiple references in each file but each file refers to measurement data obtained at a different time.</p>

<p>Here's the code</p>

<pre><code>library(reshape)
# Enter file name to Read &amp; Save data
FileName=readline(""Enter File name:\n"")
# Find first occurance of file
for ( round1 in 1 : 6) {
ReadFile=paste(round1,""C_"",FileName,""_Stats.csv"", sep="""")
if (file.exists(ReadFile))
break
}

x = data.frame(read.csv(ReadFile, header=TRUE),rnd=round1)
for ( round2 in (round1+1) : 6) {
#
ReadFile=paste(round2,""C_"",FileName,""_Stats.csv"", sep="""")
if (file.exists(ReadFile)) {
y = data.frame(read.csv(ReadFile, header=TRUE),rnd = round2)
    if (round2 == (round1 +1))
    z=data.frame(merge(x,y,all=TRUE))
    z=data.frame(merge(y,z,all=TRUE))
}
}
ordered = order(z$lab_id)

results = z[ordered,]

res = data.frame( lab=results[,""lab_id""],bw=results[,""ZBW""],wi=results[,""ZWI""],pf_zbw=0,pf_zwi=0,r = results[,""rnd""])


#
# Establish no of samples recorded
nsmpls = length(res[,c(""lab"")])

# Evaluate Z_scores for Between Lab Results
for ( i in 1 : nsmpls) {
if (res[i,""bw""] &gt; 3 | res[i,""bw""] &lt; -3)
res[i,""pf_zbw""]=1
}
# Evaluate Z_scores for Within Lab Results
for ( i in 1 : nsmpls) {
if (res[i,""wi""] &gt; 3 | res[i,""wi""] &lt; -3)
res[i,""pf_zwi""]=1
}

dd = melt(res, id=c(""lab"",""r""), ""pf_zbw"")
b = cast(dd, lab ~ r)
</code></pre>

<p>If anyone could see why the ordering only works for about 55 of 70 records and could steer me in the right direction I would be obliged</p>

<p>Thanks very much</p>
"
2043760,248275,2010-01-11T18:03:32Z,1,Using the 'available.packages' Function to Retrieve Emails,"<p>I am attempting to retrieve email addresses of contributing package authors and maintainers to the R-Project.  The function reads as follows:</p>

<pre><code>availpkgs &lt;- available.packages(contriburl = contrib.url(getOption(""repos""), type),
    method, fields = NULL, type = getOption(""pkgType""),
    filters = NULL)
</code></pre>

<p>I've attempted different character values in the <code>fields</code> parameter to retrieve Maintainer and Author info from the 'PACKAGES' files, but have not been had luck.  Does anyone know how I might approach this?  Thank you in advance for your time.</p>
"
2045706,103832,2010-01-11T23:29:16Z,1,Why my bash can't execute R script?,"<p>My script use an access to mysql to get command arguments to launch Rscript.
Its use is as follows : Rscript $RFILE $ARGUMENTS (RFILE corresponding to path to Rscript, and ARGUMENTS corresponding to path file used and agr).</p>

<p>I try, different way, but I still have errors, here a copy of my bash script :</p>

<pre><code>#!/usr/bin/env bash
# Execute R process
# -----------------
### Mysql Setup ###
USER=...
PASS=...
HOST=...
DB=...

# Get Job ID process
# Use to retrieve args in my DB
ID=$1

# Get script name
RFILE=$(mysql -u$USER -p$PASS -e ""SELECT script_name FROM JobProcess WHERE script_run_id=$ID;"" $DB)
SUBSTRING=""script_name""
RFILE=""${RFILE//$SUBSTRING}""

# Get script_args
ARGUMENTS=$(mysql -u$USER -p$PASS -e ""SELECT script_args FROM JobProcess WHERE script_run_id=$ID;"" $DB)
SUBSTRING2=""script_args""
ARGUMENTS=""${ARGUMENTS//$SUBSTRING2}""

RUN=""Rscript $RFILE $ARGUMENTS""

# Try Different execute process
Rscript $RFILE $ARGUMENTS
#eval ""$RUN""
#`Rscript $RFILE $ARGUMENTS`
#$RUN
</code></pre>

<p>I verified my command line (via echo), and if I made a copy-paste to my shell I can run my R script. But from my bash, I can't execute my script (but command line is good).</p>

<p>By using : Rscript $RFILE $ARGUMENTS, <code>Rscript $RFILE $ARGUMENTS</code> and $RUN, I have this error : </p>

<pre><code>Error in parse(text = args[[i]]) : 
  unexpected end of input in """"path_in='/Users/GR/web-app/Rproject/Inputs/Rscript/Gene-level""
Calls: eval -&gt; parse
Execution halted
</code></pre>

<p>By using : eval ""$RUN"", I have this error :</p>

<pre><code>/Users/GR/web-app/Rproject/Scripts/Rscript.sh: line 38: /Users/GR/web-app/Rproject/Scripts/arg_file_test.R: Permission denied
/Users/GR/web-app/Rproject/Scripts/Rscript.sh: line 44: path_in&lt;-""/Users/GR/web-app/Rproject/Inputs/Rscript/Gene-level Description for Modules.csv"": No such file or directory
</code></pre>

<p>If I try this in my shell script, all works fine :</p>

<pre><code>SCRIPT=""/Users/GR/web-app/Rproject/Scripts/arg_file_test.R""
FILE1=""path_in='/Users/GR/web-app/Rproject/Inputs/Rscript/Gene-level Description for Modules.csv'""
FILE2=""path_in2='/Users/GR/web-app/Rproject/Inputs/Rscript/Template_Auto.csv'""
FILES=""\""$FILE1\"" \""$FILE2\""""
ARG=""l=32 w=33""
RUN=""Rscript $SCRIPT $FILES $ARG""
</code></pre>

<p>Someone has an idea ?</p>

<p>Thanks</p>
"
2045837,15050,2010-01-12T00:03:34Z,2,How to save R plot image to database?,"<p>I'd like to save a plot image directly to the database.</p>

<p>Is the best way in R to do this:</p>

<ol>
<li>Write the plot image (png) to the filesystem</li>
<li>Read the file that was written</li>
<li>Send the file to the database via query (RODBC)</li>
</ol>

<p>Ideally I'd like to combine steps 1 and 2 above by simply write the png image to a binary connection.  Does R support this?</p>
"
2047487,248690,2010-01-12T07:55:31Z,1,Creating a new variable from a conditional operation on 3 old variables in R,"<p>I have a dataset in R, which contains the results of a rapid diagnostic test.  The test has a visible line if it is working properly (control line) and a visible line for each of the two parasite species it detects, if they are present in the patient sample.</p>

<p>The dataset contains a logical column for each test line, as follows:
(database is called RDTbase)</p>

<pre><code>   Control  Pf    Pv
1. TRUE     TRUE  FALSE
2. TRUE     FALSE TRUE
3. FALSE    FALSE FALSE
4. TRUE     TRUE  TRUE
5. TRUE     FALSE FALSE
</code></pre>

<p>I would like to add a new column which contains a single result for each rapid test.  The results are designated according to the different logical conditions met by the three lines.  For the example above the new column would look like this:</p>

<pre><code>Control  Pf     Pv     Result
1. TRUE  TRUE   FALSE  Pf
2. TRUE  FALSE  TRUE   Pv
3. FALSE FALSE  FALSE  Invalid
4. TRUE  TRUE   TRUE   Mixed
5. TRUE  FALSE  FALSE  Negative
</code></pre>

<p>I am able to create the new column, but it takes a lot of coding and I think there has to be a much simpler (and shorter) way to do this.</p>

<p>Here is my current (long) method:</p>

<pre><code>R.Pf &lt;- RDTbase[which(Control == ""TRUE"" &amp; Pf == ""TRUE"" &amp; Pv == ""FALSE""),]
R.Pv &lt;- RDTbase[which(Control == ""TRUE"" &amp; Pf == ""FALSE"" &amp; Pv == ""TRUE""),]
R.inv &lt;- RDTbase[which(Control == ""FALSE""),]
R.mix &lt;- RDTbase[which(Control == ""TRUE"" &amp; Pf == ""TRUE"" &amp; Pv == ""TRUE""),]
R.neg &lt;- RDTbase[which(Control == ""TRUE"" &amp; Pf == ""FALSE"" &amp; Pv == ""FALSE""),]

R.Pf$Result &lt;- c(""Pf"")
R.Pv$Result &lt;- c(""Pv"")
R.inv$Result &lt;- c(""Invalid"")
R.mix$Result &lt;- c(""Mixed"")
R.neg$Result &lt;- c(""Negative"")

RDTbase2 &lt;- rbind(R.Pf, R.Pv, R.inv, R.mix, R.neg)
</code></pre>

<p>Any ideas on how to simplify and shorten this code would be greatly appreciated, as I have to do this kind of thing to my databases alot.</p>

<p>Many thanks,
Amy</p>
"
2048304,74658,2010-01-12T10:49:24Z,9,Create Editable plots from R,"<p>I'm creating a series of plots in R (I'm using ggplot2, but that's not essential) and I want to be able to save my output so I can then edit it for furthur use, For instance, I might want to move legends about, or adjust colours etc.  I have seen that ggplot2 has a save command but that seems to produce pdf's or bitmaps, neither of which are particularly editable</p>

<p>How do other people do this ?  Any good ideas ?</p>

<p>Here's some sample code to produce a sample plot;</p>

<pre><code>library(ggplot2)
dataframe&lt;-data.frame(fac=factor(c(1:4)),data1=rnorm(400,100,sd=15))
dataframe$data2&lt;-dataframe$data1*c(0.25,0.5,0.75,1)
dataframe
testplot&lt;-qplot(x=fac, y=data2,data=dataframe, colour=fac, geom=c(""boxplot"", ""jitter""))
testplot
</code></pre>

<p>Thanks</p>

<p>Paul.</p>
"
2050610,144537,2010-01-12T16:46:36Z,16,Creating a facet_wrap plot with ggplot2 with different annotations in each plot,"<p>I am using ggplot2 to explore the result of some testing on an agent-based model.  The model can end in one of three rounds per realization, and as such I am interested in how player utilities differ in terms of what round the game ends and their relative position in 2D space.</p>

<p>All this is to say that I have generated a facet_wrap plot to show this for each round, but I would also like to annotate each plot with the cor(x,y) for the subset of data represented in each facet.  Is there a way to tell ggplot2 that I would like the annotation to use the subset of data generated by facet_wrap?  Here is the code I have so far, and what it is producing</p>

<pre><code>library(ggplot2)

# Load data
abm.data&lt;-read.csv(""ABM_results.csv"")

# Create new colun for area of Pareto set
attach(abm.data)
area&lt;-abs(((x3*(y2-y1))+(x2*(y1-y3))+(x1*(y3-y2)))/2)
abm.data&lt;-transform(abm.data,area=area)
detach(abm.data)

# Compare area of Pareto set with player utility
png(""area_p1.png"",res=100,pointsize=20,height=500,width=1600)
area.p1&lt;-ggplot(abm.data,aes(x=area))+geom_point(aes(y=U1_2,colour=""Player 1"",alpha=0.4))+facet_wrap(~round,ncol=3)+
    annotate(""text"",0.375,-1.25,label=paste(""rho="",round(cor(abm.data$area,abm.data$U1_2),2)), parse=TRUE)+
    scale_colour_manual(values=c(""Player 1""=""red""))
area.p1+xlab(""Area of Pareto Set"")+ylab(""Player Utility at Game End"")+
    opts(title=""Final Player 1 Utility by Pareto Set Size and Round Game Ends"",legend.position=""none"")
dev.off()
</code></pre>

<p><a href=""http://www.drewconway.com/zia/wp-content/uploads/2010/01/area_p1.png"">area_p1 http://www.drewconway.com/zia/wp-content/uploads/2010/01/area_p1.png</a></p>

<p>As you can see, there are two problems:</p>

<ol>
<li>The \rho value is of the full dataset, rather than the subsets by 'round'.  Is there a way to get the cor(x,y) to print based on only the data shown in each plot?</li>
<li>The annotation should read ""\rho=some_value"" but instead I get ""=(\rho,value);"" is there a way to fix this?  </li>
</ol>
"
2050790,66549,2010-01-12T17:08:50Z,262,How to Correctly Use Lists in R?,"<p>Brief background: Many (most?) contemporary programming languages in widespread use have at least a handful of ADTs [abstract data types] in common, in particular,</p>

<ul>
<li><p><strong>string</strong> (a sequence comprised of characters)</p></li>
<li><p><strong>list</strong> (an ordered collection of values), and</p></li>
<li><p><strong>map-based type</strong> (an unordered array that maps keys to values)</p></li>
</ul>

<p>In the R programming language, the first two are implemented as <code>character</code> and <code>vector</code>, respectively.</p>

<p>When I began learning R, two things were obvious almost from the start: <code>list</code> is the most important data type in R (because it is the parent class for the R <code>data.frame</code>), and second, I just couldn't understand how they worked, at least not well enough to use them correctly in my code.</p>

<p>For one thing, it seemed to me that R's <code>list</code> data type was a straightforward implementation of the map ADT (<code>dictionary</code> in Python, <code>NSMutableDictionary</code> in Objective C, <code>hash</code> in Perl and Ruby, <code>object literal</code> in Javascript, and so forth).</p>

<p>For instance, you create them just like you would a Python dictionary, by passing key-value pairs to a constructor (which in Python is <code>dict</code> not <code>list</code>):</p>

<pre><code>x = list(""ev1""=10, ""ev2""=15, ""rv""=""Group 1"")
</code></pre>

<p>And you access the items of an R List just like you would those of a Python dictionary, e.g., <code>x['ev1']</code>. Likewise, you can retrieve just the <em>'keys'</em> or just the <em>'values'</em> by: </p>

<pre><code>names(x)    # fetch just the 'keys' of an R list
# [1] ""ev1"" ""ev2"" ""rv""

unlist(x)   # fetch just the 'values' of an R list
#   ev1       ev2        rv 
#  ""10""      ""15"" ""Group 1"" 

x = list(""a""=6, ""b""=9, ""c""=3)  

sum(unlist(x))
# [1] 18
</code></pre>

<p>but R <code>list</code>s are also <strong><em>unlike</em></strong> other map-type ADTs (from among the languages I've learned anyway). My guess is that this is a consequence of the initial spec for S, i.e., an intention to design a data/statistics DSL [domain-specific language] from the ground-up. </p>

<p><em>three</em> significant differences between R <code>list</code>s and mapping types in other languages in widespread use (e.g,. Python, Perl, JavaScript):</p>

<p><em>first</em>, <code>list</code>s in R are an <em>ordered</em> collection, just like vectors, even though the values are keyed (ie, the keys can be any hashable value not just sequential integers). Nearly always, the mapping data type in other languages is <em>unordered</em>.</p>

<p><em>second</em>, <code>list</code>s can be returned from functions even though you never passed in a <code>list</code> when you called the function, and <em>even though</em> the function that returned the <code>list</code> doesn't contain an (explicit) <code>list</code> constructor (Of course, you can deal with this in practice by wrapping the returned result in a call to <code>unlist</code>):</p>

<pre><code>x = strsplit(LETTERS[1:10], """")     # passing in an object of type 'character'

class(x)                            # returns 'list', not a vector of length 2
# [1] list
</code></pre>

<p>A <em>third</em> peculiar feature of R's <code>list</code>s: it doesn't seem that they can be members of another ADT, and if you try to do that then the primary container is coerced to a <code>list</code>. E.g.,</p>

<pre><code>x = c(0.5, 0.8, 0.23, list(0.5, 0.2, 0.9), recursive=TRUE)

class(x)
# [1] list
</code></pre>

<p>my intention here is not to criticize the language or how it is documented; likewise, I'm not suggesting there is anything wrong with the <code>list</code> data structure or how it behaves. All I'm after is to correct is my understanding of how they work so I can correctly use them in my code. </p>

<p>Here are the sorts of things I'd like to better understand:</p>

<ul>
<li><p>What are the rules which determine when a function call will return a <code>list</code> (e.g., <code>strsplit</code> expression recited above)?</p></li>
<li><p>If I don't explicitly assign names to a <code>list</code> (e.g., <code>list(10,20,30,40)</code>) are the default names just sequential integers beginning with 1?  (I assume, but I am far from certain that the answer is yes, otherwise we wouldn't be able to coerce this type of <code>list</code> to a vector w/ a call to <code>unlist</code>.)</p></li>
<li><p>Why do these two different operators, <code>[]</code>, and <code>[[]]</code>, return the <em>same</em> result?</p>

<p><code>x = list(1, 2, 3, 4)</code></p>

<p>both expressions return ""1"":</p>

<p><code>x[1]</code></p>

<p><code>x[[1]]</code></p></li>
<li><p>why do these two expressions <strong>not</strong> return the same result?</p>

<p><code>x = list(1, 2, 3, 4)</code></p>

<p><code>x2 = list(1:4)</code></p></li>
</ul>

<p>Please don't point me to the R Documentation (<a href=""http://www.inside-r.org/r-doc/base/list"" rel=""nofollow noreferrer""><code>?list</code></a>, <a href=""http://cran.r-project.org/doc/manuals/r-devel/R-intro.html#Lists"" rel=""nofollow noreferrer""><code>R-intro</code></a>)--I have read it carefully and it does not help me answer the type of questions I recited just above.</p>

<p>(lastly, I recently learned of and began using an R Package (available on CRAN) called <a href=""http://mran.revolutionanalytics.com/packages/info/?hash"" rel=""nofollow noreferrer""><code>hash</code></a> which implements <em>conventional</em> map-type behavior via an S4 class; I can certainly recommend this Package.)</p>
"
2052174,249238,2010-01-12T20:38:24Z,1,Transform R dataframes using variables in loop,"<p>I am trying to replace values in a R dataframe by column. I would like to loop though a given list of columns of the dataframe and replace all ""Yes"" values by 1 and all the other values by 0.</p>

<p>I tried to do this using transform() and ifelse() functions with the something like this:</p>

<pre><code># List of selected Columns:
ColumnNames = c(""Frigori"", ""Microond"" , ""Arca"", ""Aspira"")

# Replace Values in dataframe
for(i in 1:length(ColumnNames)){
dataframe &lt;- transform(dataframe, ColumnNames[i] = ifelse(Columnames[i] == ""Yes"", 1, 0))
}
</code></pre>

<p>This piece of code works fine with explicit column names outside the loop, but with the array it will give me the following error:</p>

<pre><code>Error: unexpected '=' in:
""for(i in 1:length(Appliances)){
dataframe &lt;- transform(dataframe, ColumnNames[i] =""
</code></pre>

<p>I don't know what goes wrong here, but the problem has to be related with the variable substitution.</p>
"
2053397,95750,2010-01-12T23:56:19Z,21,long/bigint/decimal equivalent datatype in R,"<p>What datatype choices do we have to handle large numbers in R? By default, the size of an integer seems to be 32bit, so bigint numbers from sql server as well as any large numbers passed from python via rpy2 get mangled.</p>

<pre><code>&gt; 123456789123
[1] 123456789123
&gt; 1234567891234
[1] 1.234568e+12
</code></pre>

<p>When reading a bigint value of 123456789123456789 using RODBC, it comes back as 123456789123456784 (see the last digit), and the same number when deserialized via RJSONIO, comes back as -1395630315L (which seems like an additional bug/limitation of RJSONIO).</p>

<pre><code>&gt; fromJSON('[1234567891]')
[1] 1234567891
&gt; fromJSON('[12345678912]')
[1] -539222976
</code></pre>

<p>Actually, I do need to be able to handle large numbers coming from JSON, so with RJSONIO's limitation, I may not have a workaround except for finding a better JSON library (which seems like a non-option right now). I would like to hear what experts have to say on this as well as in general.</p>
"
2054772,234233,2010-01-13T06:01:26Z,1,Using outer() with predict(),"<p>I am trying to use the <strong>outer</strong> function with <strong>predict</strong> in some classification code in R.  For ease, we will assume in this post that we have two vectors named <strong>alpha</strong> and <strong>beta</strong> each containing ONLY 0 and 1. I am looking for a simple yet efficient way to pass all combinations of <strong>alpha</strong> and <strong>beta</strong> to <strong>predict</strong>.</p>

<p>I have constructed the code below to mimic the lda function from the MASS library, so rather than ""lda"", I am using ""classifier"". It is important to note that the prediction method within <strong>predict</strong> depends on an (<strong>alpha</strong>, <strong>beta</strong>) pair.</p>

<p>Of course, I could use a nested for loop to do this, but I am trying to avoid this method.</p>

<p>Here is what I would like to do ideally:</p>

<pre><code>alpha &lt;- seq(0, 1)
beta &lt;- seq(0, 1)
classifier.out &lt;- classifier(training.data, labels)
outer(X=alpha, Y=beta, FUN=""predict"", classifier.out, validation.data)
</code></pre>

<p>This is a problem because <strong>alpha</strong> and <strong>beta</strong> are not the first two parameters in <strong>predict</strong>.</p>

<p>So, in order to get around this, I changed the last line to</p>

<pre><code>outer(X=alpha, Y=beta, FUN=""predict"", object=classifier.out, data=validation.data)
</code></pre>

<p>Note that my validation data has 40 observations, and also that there are 4 possible pairs of <strong>alpha</strong> and <strong>beta</strong>. I get an error though saying</p>

<pre><code>dims [product 4] do not match the length of object [40]
</code></pre>

<p>I have tried a few other things, some of which work but are far from simple. Any suggestions?</p>
"
2055677,249670,2010-01-13T09:42:16Z,0,Pipe R commands and results from within a for loop to a file,"<p>We want to log the commands and results of a R script into a text report file. The pipe into the text file works well with <code>sink()</code>, but not within a for loop.</p>

<p>The script is called with</p>

<pre><code>source(""myscript.r"",echo=TRUE)
</code></pre>

<p>We need the loop to extract all rows of a <code>data.frame</code> consecutively into a vector and do some vector based analysis with each vector.
Here's a short example:</p>

<pre><code>#pipe output to file
sink(""myfile.txt"",append=TRUE,split=TRUE)
#some data
c1&lt;-rnorm(10,mean=90,sd=10) 
c2&lt;-rnorm(10,mean=75,sd=8)
c3&lt;-rnorm(10,mean=98,sd=12)
#data in a data.frame
cData&lt;-data.frame(c1,c2,c3)
#print data.frame
cData  
#loop over frame 
for (i in 1:ncol(cData))  
{
  #extract vector
  x&lt;-cData[,i]
  #do something with vector
  n = length(x)
  #... more code
  #print result
  print(n)    
}
#close output
sink()
</code></pre>

<p>I tried it with <code>sink()</code> and <code>txtStart()</code> but <code>sink()</code> truncates the commands and puts results after the loop, <code>txtStart()</code> seems to repeat the commands but not the results. </p>

<p>I looked also at brew, but I just need a text file, nothing formatted.</p>
"
2055947,236703,2010-01-13T10:30:02Z,-3,Information criterions in exp smoothing models,"<p>What are the numbers of parameters to be penalized for when using information criterions(BIC or AIC or..) for selecting the best models? Let's say that we have 3 models: 1. Simple exponential smoothing 2. Holt's method(level+trend) 3. Holt Winters(L+T+S), where we have monthly seasonality. How many parameters for penalization does have each model?</p>
"
2061897,155406,2010-01-14T03:03:22Z,72,Parse JSON with R,"<p>I am fairly new to R, but the more use it, the more I see how powerful it really is over SAS or SPSS.  Just one of the major benefits, as I see them, is the ability to get and analyze data from the web.  I imagine this is possible (and maybe even straightforward), but I am looking to parse JSON data that is publicly available on the web.  I am not programmer by any stretch, so any help and instruction you can provide will be greatly appreciated.  Even if you point me to a basic working example, I probably can work through it.</p>
"
2062194,15050,2010-01-14T04:37:07Z,5,Create lm object from data/coefficients,"<p>Does anyone know of a function that can create an lm object given a dataset and coefficients?</p>

<p>I'm interested in this because I started playing with Bayesian model averaging (BMA) and I'd like to be able to create an lm object out of the results of bicreg.  I'd like to have access to all of the nice generic lm functions like diagnostic plotting, predict, cv.lm etc.</p>

<p>If you are pretty sure such a function doesn't exist that's also very helpful to know!</p>

<pre><code>library(BMA)
mtcars_y &lt;- mtcars[, 1] #mpg
mtcars_x &lt;- as.matrix(mtcars[,-1])
res &lt;- bicreg(mtcars_x, mtcars_y)

summary(res)
res$postmean # bma coefficients

# The approximate form of the function
# I'm looking for
lmObject &lt;- magicFunction(data=mtcars, coefficients=res$postmean)
</code></pre>
"
2063821,203420,2010-01-14T11:52:36Z,16,Do I always have to use data frames in ggplot2,"<p>I'm running a monte-carlo simulation and the output is in the form:</p>

<pre><code>&gt; d = data.frame(iter=seq(1, 2), k1 = c(0.2, 0.6), k2=c(0.3, 0.4))
&gt; d
iter  k1   k2
1     0.2  0.3
2     0.6  0.4
</code></pre>

<p>The plots I want to generate are:</p>

<pre><code>plot(d$iter, d$k1)
plot(density(d$k1))
</code></pre>

<p>I know how to do equivalent plots using ggplot2,  convert to data frame</p>

<pre><code>new_d = data.frame(iter=rep(d$iter, 2), 
                   k = c(d$k1, d$k2), 
                   label = rep(c('k1', 'k2'), each=2))
</code></pre>

<p>then plotting is easy. However the number of iterations can be very large and the number of k's can also be large. This means messing about with a very large data frame.</p>

<p>Is there anyway I can avoid creating this new data frame?</p>

<p>Thanks</p>
"
2067098,184403,2010-01-14T19:49:38Z,32,How to transform XML data into a data.frame?,"<p>I'm trying to learn R's <code>XML</code> package. I'm trying to create a data.frame from books.xml sample xml data file. Here's what I get:</p>

<pre><code>library(XML)
books &lt;- ""http://www.w3schools.com/XQuery/books.xml""
doc &lt;- xmlTreeParse(books, useInternalNodes = TRUE)
doc
xpathApply(doc, ""//book"", function(x) do.call(paste, as.list(xmlValue(x))))
xpathSApply(doc, ""//book"", function(x) strsplit(xmlValue(x), "" ""))
xpathSApply(doc, ""//book/child::*"", xmlValue)
</code></pre>

<p>Each of these xpathSApply's don't get me even close to my intention. How should one proceed toward a well formed data.frame?</p>
"
2069836,215244,2010-01-15T06:23:33Z,15,reading and plotting an esri shape file in R,"<p>I'm having difficulties reading in a .shp (esri shape file) into R. I have tried several options in R, and tried to convert the shape file in ArcMap to something that correctly reads in the shape file but nothing worked yet. (In ArcMap I corrected the geometry, converted from single to multipolygon, etc which was probably not necessary or relevant)</p>

<p>It probably has something to with the fact that my shape file contains 'regions' (multi-polygons) instead of 'polygons'... </p>

<p>How can I read that type of shape file correctly in R for plotting? (it looks like a normal shape in ArcMap)</p>

<p>In ArcMap the shape file looks like this:
<a href=""http://bfast.r-forge.r-project.org/arcmapshape.jpg"" rel=""noreferrer"">http://bfast.r-forge.r-project.org/arcmapshape.jpg</a></p>

<p>(shows a shape file with polygons within other polygons)</p>

<p>In R it looks like this:
<img src=""https://i.stack.imgur.com/jRwBp.jpg"" alt=""enter image description here""></p>

<p>(shows a shape file where some polygons are wrongly filled)</p>

<p>I used the following code in R:</p>

<pre><code>require(maptools)
require(rgdal)

newproj &lt;- ""+proj=utm +zone=55 +south +ellps=GRS80 +units=m""
shape&lt;- readShapeSpatial(pdir, proj4string = CRS(newproj),repair=TRUE,force_ring=T,verbose=TRUE) # without any errors
plot(shape, col=""gray"",border=""blue"", axes=TRUE)

# via rgdal
folder &lt;- c(""spatial"")
lyr &lt;- c(""clipped_forest_mga"")
shp &lt;- readOGR(dsn=folder,layer=lyr)
plot(shp, col=""gray"",border=""blue"", axes=TRUE)
</code></pre>

<p>Both plot() commands give the same R result. No errors occur. only the following message</p>

<pre><code>OGR data source with driver: ESRI Shapefile 
Source: ""P:/Victoria_DSE/BFAST_spatial/vector/PLM_excl_fire03_09_GDA94LL/mgaz94z55/clipped_EG"", layer: ""clipped_forest_mga""
with 1 features and 4 fields
Feature type: wkbMultiPolygon with 2 dimensions
</code></pre>

<p>How can this be solved?</p>
"
2073000,251681,2010-01-15T16:12:33Z,1,"2 questions: 1) long 2 wide data in R, 2) followup re: rattle","<p>1) long to wide question:</p>

<p>I have a dataset with 3 columns:
person, event, frequency.
If the frequency is zero, the row is not in the table. Is there a simple way using basic R functions or libraries to convert this table to wide format, with one row per person and one column per event with the frequency as the value in table. </p>

<p>2) rattle question: </p>

<p>On a related note, is this even necessary for Rattle to understand as an input?</p>

<p>I am trying to import some data into R to explore some of Rattle's machine learning algorithms.</p>

<p>Thanks!
Patrick McCann</p>
"
2074606,37751,2010-01-15T20:36:04Z,30,doing a plyr operation on every row of a data frame in R,"<p>I like the plyr syntax. Any time I have to use one of the *apply() commands I end up kicking the dog and going on a 3 day bender. So for the sake of my dog and my liver, what's concise syntax for doing a ddply operation on every row of a data frame?</p>

<p>Here's an example that works well for a simple case:</p>

<pre><code>x &lt;- rnorm(10)
y &lt;- rnorm(10)
df &lt;- data.frame(x,y)
ddply(df,names(df) ,function(df) max(df$x,df$y))
</code></pre>

<p>that works fine and gives me what I want. But if things get more complex this causes plyr to get funky (and not like Bootsy Collins) because plyr is chewing on making ""levels"" out of all those floating point values</p>

<pre><code>x &lt;- rnorm(1000)
y &lt;- rnorm(1000)
z &lt;- rnorm(1000)
myLetters &lt;- sample(letters, 1000, replace=T)
df &lt;- data.frame(x,y, z, myLetters)
ddply(df,names(df) ,function(df) max(df$x,df$y))
</code></pre>

<p>on my box this chews for a few minutes and then returns:</p>

<pre><code>Error: memory exhausted (limit reached?)
In addition: Warning messages:
1: In paste(rep(l, each = ll), rep(lvs, length(l)), sep = sep) :
  Reached total allocation of 1535Mb: see help(memory.size)
2: In paste(rep(l, each = ll), rep(lvs, length(l)), sep = sep) :
  Reached total allocation of 1535Mb: see help(memory.size)
</code></pre>

<p>I think I am totally abusing plyr and I am not saying this is a bug in plyr, but rather abusive behavior by me (liver and dog notwithstanding).</p>

<p>So in short, is there syntax shortcut for using ddply to operate on every row as a substitute for <code>apply(X, 1, ...)</code>?</p>

<p>The workaround I've been using is to create a ""key"" that gives a unique value for every row and then I can join back to it. </p>

<pre><code> x &lt;- rnorm(1000)
 y &lt;- rnorm(1000)
 z &lt;- rnorm(1000)
 myLetters &lt;- sample(letters, 1000, replace=T)
 df &lt;- data.frame(x,y, z, myLetters)
  #make the key
 df$myKey &lt;- 1:nrow(df)
 myOut &lt;- merge(df, ddply(df,""myKey"" ,function(df) max(df$x,df$y)))
  #knock out the key
 myOut$myKey &lt;- NULL
</code></pre>

<p>But I keep thinking that ""There Has to Be a Better Way""</p>

<p>Thanks! </p>
"
2075327,169947,2010-01-15T23:02:58Z,6,Getting more info from Rprof(),"<p>I've been trying to dig into what the time-hogs are in some R code I've written, so I'm using <code>Rprof</code>.  The output isn't yet very helpful though:</p>

<pre><code>&gt; summaryRprof()
$by.self
                      self.time self.pct total.time total.pct
""$&lt;-.data.frame""           2.38     23.2       2.38      23.2
""FUN""                      2.04     19.9      10.20      99.6
""[.data.frame""             1.74     17.0       5.54      54.1
""[.factor""                 1.42     13.9       2.90      28.3
...
</code></pre>

<p>Is there some way to dig deeper and find out which specific invocations of <code>$&lt;-.data.frame</code>, and <code>FUN</code> (which is probably from <code>by()</code>), etc. are actually the culprits?  Or will I need to refactor the code and make smaller functional chunks in order to get more fine-grained results?</p>

<p>The only reason I'm resisting refactoring is that I'd have to pass data structures into the functions, and all the passing is by value, so that seems like a step in the wrong direction.</p>

<p>Thanks.</p>
"
2076450,176995,2010-01-16T06:40:54Z,2,R ggplot2 question - working with factors,"<p>I've got a dataset that looks like this...</p>

<blockquote>
<pre><code>mine tonnes week
AA   112    41
AA   114    41
AA   119    41
BB   108    41 
BB   112    41
AA   110    42
AA   109    42
AA   102    43
AA   101    43
</code></pre>
</blockquote>

<p>And I want to create a boxplot in ggplot2 to show the distribution of tonnes for each week. But I only want results from mine AA.</p>

<p>I thought it would work like this....</p>

<pre><code>qplot(factor(week), tonnes[mine == ""AA""], data = sql_results, geom = ""boxplot"")
</code></pre>

<p>But instead, I get this error.</p>

<pre><code>Error in data.frame(x = c(13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,  :

  arguments imply differing number of rows: 423100, 109436
</code></pre>

<p>It's probably dead simple, but I'm not having much luck figuring the right way to do this.</p>
"
2078468,213185,2010-01-16T18:32:07Z,6,Plotting shapefiles on top of Google map tiles,"<p>I have some shapefiles I want to plot over Google Maps tiles. What's the most efficient way to do this? One path might be to use the pkg RgoogleMaps, however, it is still unclear to me how to do this. I assume using PlotonStaticMap with some combination of reformatting the shapefile data</p>
"
2078946,168139,2010-01-16T21:19:36Z,1,Parallel gsub: how does one remove a different string in each element of a vector,"<p>I have a guest list that has a last name in one column and then in another column I have the first names or the full names (first space last) of each person in the family. I am wanting to get the other column to just have the first names. </p>

<pre><code>gsub(guest.w$Last.Name,"""",guest.w$Party.Name.s.)
</code></pre>

<p>That would work perfectly if I just had one row but how do it do it for each row in the dataframe. Do I have to write a for loop? Is there a way to do it in parallel similarly to the way pmax() relates to max().</p>

<p>My problem is similar in a way to a <a href=""https://stackoverflow.com/questions/1355355/how-to-avoid-a-loop-in-r-selecting-items-from-a-list"">previously asked question by JD Long</a> but that question was a piece of cake compared to mine. </p>

<h2>Example</h2>

<p>:</p>

<p>Smith;  Joe Smith, Kevin Smith, Jane Smith<br>
Alter; Robert Alter, Mary Alter, Ronald Alter  </p>

<p>Becomes</p>

<p>Smith; Joe, Kevin, Jane<br>
Alter; Robert, Mary, Ronald  </p>
"
2079772,220120,2010-01-17T02:33:42Z,3,Generating means from a bivariate gaussian distribution,"<p>I am reading Elements of Statistical Learning <a href=""http://www-stat.stanford.edu/~tibs/ElemStatLearn/"" rel=""nofollow noreferrer"">ESLII</a> and in chapter 2, they have a gaussian mixture data set to illustrate some learning algorithms. To generate this data set, they first generate 10 means from a bivariate gaussian distribution N((1,0)', I). I am not sure what they mean?</p>

<p>How can you generate 10 means from a bivariate distribution having mean(1,0)?</p>
"
2079784,168139,2010-01-17T02:43:35Z,7,Generating a vector of the number of items in each list item,"<p>I have a list containing 98 items. But each item contains 0, 1, 2, 3, 4 or 5 character strings.</p>

<p>I know how to get the length of the list and in fact <a href=""https://stackoverflow.com/questions/1740524/r-count-number-of-objects-in-list"">someone has asked the question before</a> and got voted down for presumably asking such an easy question.</p>

<p>But I want a vector that is 98 elements long with each element being an integer from 0 to 5 telling me how many character strings there are in each list item.
I was expecting the following to work but it did not.</p>

<pre><code>lapply(name.of.list,length())
</code></pre>

<p>From my question you will see that I do not really know the nomeclature of lists and items. Feel free to straighten me out.</p>
"
2080774,170792,2010-01-17T11:18:12Z,14,Generating interaction variables in R dataframes,"<p>Is there a way - other than a for loop - to generate new variables in an R dataframe, which will be all the possible 2-way interactions between the existing ones?
i.e. supposing a dataframe with three numeric variables V1, V2, V3, I would like to generate the following new variables:</p>

<pre><code>Inter.V1V2 (= V1 * V2) 
Inter.V1V3 (= V1 * V3)
Inter.V2V3 (= V2 * V3)
</code></pre>

<p>Example using for loop :</p>

<pre><code>x &lt;- read.table(textConnection('
   V1 V2 V3 V4
1  9   25   18
2  5   20   10
3  4   30   12
4  4   34   16'
), header=TRUE)

dim.init &lt;- dim(x)[2]
for (i in 1: (dim.init - 1) ) {
        for (j in (i + 1) : (dim.init) ) {
                x[dim(x)[2] + 1]    &lt;- x[i] * x[j]
                names(x)[dim(x)[2]] &lt;- paste(""Inter.V"",i,""V"",j,sep="""")

        }
}
</code></pre>
"
2082553,235349,2010-01-17T20:43:54Z,1,Using ggplot2 and rpanel together,"<p>Has anybody used ggplot2 along with rpanel to produce interactive plots. Here is a piece of code that I adapted from rpanel to plot a Poisson distribution and have a slider to change the parameter value.</p>

<p>However, the plot changes too slowly as I change the parameters using the slider. When I change the plot function to use Lattice, it is much faster. Is this a limitation of ggplot2 in terms of speed? Is there a way to overcome this?</p>

<pre><code>poisson.draw = function(panel) {
  with(panel, {
     x = seq(0,n, by = 1)
     library(ggplot2)
     y = dpois(x, lambda)
     d = data.frame(cbind(x,y))
     p1 = ggplot(d, aes(x,y)) + geom_point()
     print(p1)
  })
  panel
}
panel &lt;- rp.control(""Poisson distribution"", n = 30, lambda = 3, 
  ylim = 0.5)
rp.slider(panel, lambda, 1, 30, poisson.draw)
</code></pre>
"
2083333,55362,2010-01-18T00:57:28Z,0,cURL for webpage login,"<p>I want to submit my submissions to <a href=""http://analyticsx.com/"" rel=""nofollow noreferrer"">this competition</a> automatically from my code. I need to log-in on <a href=""http://analyticsx.com/analyticsx/Login"" rel=""nofollow noreferrer"">this page</a> and then submit a file on <a href=""http://analyticsx.com/analyticsx/Controller?REQUEST_COMMAND=User&amp;REQUEST_SUB_COMMAND=SubmitPred"" rel=""nofollow noreferrer"">this page</a>. I'd like to use cURL since it integrates with both of the languages that I am using (R and Python). </p>

<p>I am just wondering if this procedure is possible in cURL? and my another question is if I can use cURL inside MS Excel?</p>
"
2084192,252954,2010-01-18T06:10:36Z,2,How do I get a predictions list from running svm in e1071 package,"<p>Q1: 
I have been trying to get the AUC value for a classification problem and have been trying to use e1071 and ROCR packages in R for this. ROCR has a nice example ""ROCR.simple"" which has prediction values and label values.</p>

<pre><code>library(ROCR)
data(ROCR.simple)
pred&lt;-prediction(ROCR.simpe$predictions, ROCR.simple$labels)
auc&lt;-performance(pred,""auc"")
</code></pre>

<p>This gives the AUC value, no problem.
MY PROBLEM is: How do I get the type of data given by <code>ROCR.simple$predictions</code> in the above example?
I run my analysis like</p>

<pre><code>library(e1071)
data(iris)
y&lt;-Species
x&lt;-iris[,1:2]
model&lt;-svm(x,y)
pred&lt;-predict(model,x)
</code></pre>

<p>Upto here I'm ok. 
Then how do I get the kind of predictions that <code>ROCR.simpe$predictions</code> give?</p>

<p>Q2:</p>

<p>there is a nice example involving <code>ROCR.xvals</code>. This is a problem with 10 cross validations.</p>

<p>They run</p>

<pre><code>pred&lt;-prediction(ROCR.xval$predictions,ROCR.xval$labels)
auc&lt;-performance(pred,""auc"")
</code></pre>

<p>This gives results for all 10 cross validations.</p>

<p>My problem is:</p>

<p>How do I use </p>

<pre><code>model&lt;-svm(x,y,cross=10)     # where x and y are as given in Q1
</code></pre>

<p>and get all 10 results of predictions and labels into a list as given in <code>ROCR.xvals</code>?</p>
"
2087735,170792,2010-01-18T17:03:53Z,3,Most representative instance of a cluster,"<p>After performing a cluster analysis to my dataset (a dataframe named <em>data.matrix</em>), I added a new column, named <em>cluster</em>, at the end (col 27) containing the cluster name that each instance belongs to.</p>

<p>What I want now, is a representative instance from each cluster. I tried to find the instance having the smallest euclidean distance from the cluster's centroid (and repeat the procedure for each one of my clusters)</p>

<p>This is what I did. Can you think of other -perhaps more elegant- ways? (assume numeric columns with no nulls). </p>

<pre><code>clusters &lt;- levels(data.matrix$cluster)
cluster_col = c(27)

for (j in 1:length(clusters)) {
    # get the subset for cluster j
    data = data.matrix[data.matrix$cluster == clusters[j],]

    # remove the cluster column
    data &lt;- data[,-cluster_col]

    # calculate the centroid
    cent &lt;- mean(data)

    # copy data to data.matrix_cl, attaching a distance column at the end
    data.matrix_cl &lt;- cbind(data, dist = apply(data, 1, function(x) {sqrt(sum((x - cent)^2))}))

    # get instances with min distance
    candidates &lt;- data.matrix_cl[data.matrix_cl$dist == min(data.matrix_cl$dist),]

    # print their rownames
    print(paste(""Candidates for cluster "",j))
    print(rownames(candidates))
}
</code></pre>
"
2095215,143383,2010-01-19T16:53:27Z,2,Buffer-local variables with Emacs and Sweave,"<p>I'm using Emacs 23.1 with ESS 5.4 to edit an Sweave file.  I'd like to turn off the default AUCTeX indentation behavior in the buffer (to avoid annoyances with code chunks contained in itemized lists), so at the top of the file I have <code>% -*- LaTeX-indent-level: 0; LaTeX-item-indent: 0; -*-</code>.  When I open the buffer and run <code>C-h v LaTeX-indent-level</code>, I get what I wanted:</p>

<pre><code>LaTeX-indent-level is a variable defined in `latex.el'.
Its value is 0
Local in buffer test.Rnw; global value is 2

  This variable is a file local variable.
</code></pre>

<p>However, after I edit a code chunk, it returns to the default behavior. <code>C-h v LaTeX-indent-level</code> now yields:</p>

<pre><code>LaTeX-indent-level is a variable defined in `latex.el'.
Its value is 2
</code></pre>

<p>I tried the fix suggested in <a href=""http://www.cs.tufts.edu/~nr/noweb/FAQ.html#toc6"" rel=""nofollow noreferrer"">the noweb-mode FAQ</a>, which suggests adding</p>

<pre><code>(add-hook 'noweb-select-mode-hook
              '(lambda () (hack-local-variables-prop-line)))
</code></pre>

<p>to my .emacs.  The behavior described above persisted when I did this.</p>

<p>Is there any way I can get buffer-local variables to work in this situation?  I would prefer not to have to change my .emacs to set <code>LaTeX-indent-level</code> to 0 in all Sweave/noweb buffers.</p>
"
2096473,37751,2010-01-19T19:35:52Z,26,R: determine if a script is running in Windows or Linux,"<p>Is there a simple way to programmatically determine if an R script is being executed in Windows vs. Linux?</p>
"
2098368,5222,2010-01-20T01:00:37Z,169,How do I concatenate a vector of strings/character in R?,"<p>If I have a vector of type character in R, how can I concatenate the values into string? Here's how I would do it with paste():</p>

<pre><code>sdata = c('a', 'b', 'c')
paste(sdata[1], sdata[2], sdata[3], sep='')
</code></pre>

<p>yielding ""abc"".  But of course, that only works if I know the length of sdata ahead of time.</p>
"
2102017,209467,2010-01-20T14:29:28Z,7,Multi-panel titles in R,"<p>I have an ultra short question about R</p>

<p>My aim is to assign a common title to a multi-panel plot generated using par, e.g.</p>

<pre><code>par(mfrow=c(1,2))
plot(rnorm(1000))
plot(rnorm(1000))
</code></pre>

<p>So, something like ""main"" for the plot function, but extended to both plots. Is there a canonical way to do this?</p>

<p>Thanks for any answer :-)</p>
"
2103152,220120,2010-01-20T16:45:27Z,5,What is the equivalents of matlab's pcolor in R?,"<p>I have a 16x16 matrix of grayscale values representing handwriting digits. Is there a plot in R that I can use to visualize it?</p>

<p>Matlab has pcolor, I am looking for something along those lines.
<a href=""http://www.mathworks.com/access/helpdesk/help/techdoc/ref/pcolor.html"" rel=""nofollow noreferrer"">pcolor</a></p>
"
2104483,12874,2010-01-20T19:57:56Z,14,How to read.table() multiple files into a single table in R?,"<p>I have filenames named <code>&lt;InputData&gt;.&lt;TestName&gt;.csv</code> and I'd like to make graphs for each test.  The best way I can see to do this is to make one R table for each TestName.  Each test produces the same columns of data, so I'd like to pull in all the data for each test into an R datatable with an extra column for the inputdata.  </p>

<p>I'd like to do:</p>

<pre><code>read.tables(c(""B217.SE.csv"", ""C10.SE.csv""), sep="","")
</code></pre>

<p>produces (for example):</p>

<pre><code>       Filename  col1   col2
1   B217.SE.csv     1      2
2   B217.SE.csv     2      4
3   C10.SE.csv      3      1
4   C10.SE.csv      4      5
</code></pre>

<p>What's the right way to do this?  Some existing function I don't know about?  Writing it out in the R language using a for loop?</p>
"
2107665,246211,2010-01-21T07:53:48Z,6,R ggplot2 - no background or grid lines in plot with RGui,"<p>I'm having a strange problem with the output window in RGui (under Win XP). I should see a plot like the one below...</p>

<p><a href=""http://img402.imageshack.us/img402/7483/ss20100121153931.png"">alt text http://img402.imageshack.us/img402/7483/ss20100121153931.png</a></p>

<p>... when I run this script:</p>

<pre><code>library(ggplot2)
x &lt;- rnorm(100,0,1)
y &lt;- rnorm(100,0,1)
z &lt;- data.frame(x,y) 
g &lt;- ggplot(z, aes(x,y)) + geom_point() + theme_gray()
</code></pre>

<p>Instead, in the plot window it shows a white background and white grid lines, like below.</p>

<p><strong>R Plot Window</strong></p>

<p><a href=""http://img192.imageshack.us/img192/5349/ss20100121160230.png"">alt text http://img192.imageshack.us/img192/5349/ss20100121160230.png</a></p>

<p>When I export the plot to .png and I ""preview"" it in windows explorer - it doesn't show a background or grid lines. </p>

<p><strong>Png in Windows</strong></p>

<p><a href=""http://img192.imageshack.us/img192/5349/ss20100121160230.png"">alt text http://img192.imageshack.us/img192/5349/ss20100121160230.png</a></p>

<p><strong>Same Png in Gimp</strong></p>

<p><a href=""http://img402.imageshack.us/img402/7483/ss20100121153931.png"">alt text http://img402.imageshack.us/img402/7483/ss20100121153931.png</a></p>

<p><strong>Same Png uploaded to image hosting</strong></p>

<p><a href=""http://img402.imageshack.us/img402/7483/ss20100121153931.png"">alt text http://img402.imageshack.us/img402/7483/ss20100121153931.png</a></p>

<p>Any ideas about what's going on? How can I get the plot to display correctly in RGui?</p>
"
2108174,900119,2010-01-21T09:42:44Z,1,change look-and-feel of plot to resemble hist,"<p>I used the information from this post to create a histogram with logarithmic scale:
<a href=""https://stackoverflow.com/questions/1245273/histogram-with-logarithmic-scale"">Histogram with Logarithmic Scale</a></p>

<p>However, the output from plot looks nothing like the output from hist. Does anyone know how to configure the output from plot to resemble the output from hist? Thanks for the help.</p>
"
2108484,246211,2010-01-21T10:40:23Z,8,R ggplot2 facet_grid question,"<p>I have a ggplot2 plot that looks like this:</p>

<p><a href=""http://img69.imageshack.us/img69/9704/plot.png"" rel=""noreferrer"">alt text http://img69.imageshack.us/img69/9704/plot.png</a></p>

<p>from the following R code:</p>

<pre><code>ggplot(newdata, aes(benefit, cost, colour = factor(opt), shape = factor(roster)))

+ facet_grid(. ~ location)
</code></pre>

<p>It's exactly what I need, except that the graph is too wide to be clearly read. </p>

<p>I'd like to be able to take the four rightmost locations and place them under the four leftmost, such that the scatter plots are ordered like this.</p>

<blockquote>
<pre><code>Adelaide   Brisbane   Cairns      Canberra

Darwin     Hobart     Melbourne   Sydney
</code></pre>
</blockquote>

<p>Can I do this with facet_grid()? Or should I just create two plots and line them up in GIMP?</p>

<p>The documentation on <a href=""http://had.co.nz/ggplot2/facet_grid.htmltwo"" rel=""noreferrer"">facet_grid()</a> doesn't seem to indicate that it's possible.</p>

<p>Thanks for the help :-)</p>
"
2113855,216064,2010-01-21T23:39:05Z,3,"substitute, eval, bquote, do.call ... some guidance for substituting expressions","<p>I would like to program a time series class. The idea is that I instantiate an object with an expression and some other time series objects, for instance</p>

<p>(two time series)  </p>

<pre><code>x &lt;- ts(rnorm(10), frequency = 4, start = c(1959, 2))  
y &lt;- ts(rnorm(10), frequency = 4, start = c(1959, 2))  
</code></pre>

<p>(a time series, defined to be the sum of x and y)  </p>

<pre><code>z &lt;- exprTs(""x+y"", parents=list(x=x, y=y)) 
</code></pre>

<p>(get some part of the series)  </p>

<pre><code>window(z, start=1960, end=1960.75)
</code></pre>

<p>The problem is, how can I evaluate the expression? I tried the following:</p>

<pre><code>#(constructor for class)  
exprTs &lt;- function(expr, parents) {  
  res = list(expr=expr, parents=parents)  
  class(res) &lt;- ""exprTs""  
  res  
}  

#(window method)  
window.exprTs &lt;- function(z, ...) {  
  eval(substitute(z$expr, lapply(z$parents, window, ...)))  
  #do.call(z$expr, lapply(z$parents, window, ...))  
}  
</code></pre>

<p>I can not get the window method to work.</p>

<p>If you could guide me to how to use substitute, eval, do.call appropriately, that would be very helpful.</p>
"
2118698,170352,2010-01-22T16:25:35Z,3,"Numeric Column in data.frame returning ""num"" with str() but not is.numeric()","<p>I have a data.frame, d1, that has 7 columns, the 5th through 7th column are supposed to be numeric: </p>

<pre><code>str(d1[5])
'data.frame':   871 obs. of  1 variable:
 $ Latest.Assets..Mns.: num  14008 1483 11524 1081 2742 ... 

is.numeric(d1[5])
[1] FALSE

as.numeric(d1[5])
Error: (list) object cannot be coerced to type 'double'
</code></pre>

<p>How can this be? If str identifies it as numeric, how can it not be numeric? I'm importing from CSV. </p>
"
2118929,170352,2010-01-22T16:58:18Z,2,Error Messages in R after a for loop,"<p>This is a bit of a shot in the dark, but I have a script that does exactly what I expect it to do, yet, at the very end of the script I get an error like this: </p>

<pre><code>Error in `[&lt;-.data.frame`(`*tmp*`, ""label"", value = c(1L, 0L)) : 
  replacement has 2 rows, data has 0
</code></pre>

<p>In terms of an answer, I'm looking for general suggestions on how to track errors like this in R, best practices for using loops and double checking that they ""made it through"". </p>

<p>Any thoughts, suggestions, or past experiences that could relegate or inform an error message like this? </p>
"
2119750,12874,2010-01-22T19:07:17Z,5,Add subgroup labels to a jitter plot in ggplot2,"<p>I have a nearly-boxplot like jitter-plot:</p>

<pre><code>dt &lt;- rbind(se,cb,cb.se)
qplot(ds, size, data=dt, geom=""jitter"", colour=root, facets = test ~ .)
</code></pre>

<p><a href=""http://i50.tinypic.com/1zbfjih.png"">plot http://i50.tinypic.com/1zbfjih.png</a></p>

<p>I'd love to put a summary label for each group in the middle of the plot - for example the size totals here:</p>

<pre><code> aggregate(list(size=dt$size), list(dt$ds, dt$test), sum)

   Group.1  Group.2   size
1     b217       se   9847
2      c10       se  97296
3     c613       se  21633
4       c7       se 207540
...
</code></pre>

<p>I've tried using <code>+ geom_text(aes(x=ds, y=128, label=sum(size)), size=2)</code> to add labels, but I get the same label on each position - how can I get the sum of just that section of data?</p>

<p><strong>Edit:</strong>
Here's where I'm at now - maybe I'm just going in the wrong direction</p>

<pre><code>data &lt;- rbind(se,cb,cb.se)
labels &lt;-ddply(data, c(""ds"", ""test""), function(df) sum(df$size))
ggplot(data=data, aes(x=ds)) +
  geom_jitter(aes(y=size, colour=root)) +
  geom_text(data=labels, aes(x=ds, y=600, label=V1), size=3) +
  facet_wrap(test ~ .)
</code></pre>

<p>This code doesn't work - I get an <code>undefined columns selected</code> error... somewhere.  Maybe it's because of the multiple <code>data=</code> sections?  </p>
"
2121484,404,2010-01-23T00:30:05Z,1,How can I smooth an array in R?,"<p>I have a 2-D array in R which represents value data for a grid of rows and columns.  It looks like this:</p>

<pre><code>     [,1] [,2] [,3] [,4]
[1,]    1    1    2    1
[2,]    1    5    6    3
[3,]    2    3    2    1
[4,]    1    1    1    1
</code></pre>

<p>I want to ""smooth"" these values.  At this proof-of-concept point, I am fine with using any popular smoothing function.  I am currently attempting to use the <code>smooth.spline</code> function:</p>

<pre><code>smooth.spline(x, y = NULL, w = NULL, df, spar = NULL,
              cv = FALSE, all.knots = FALSE, nknots = NULL,
              keep.data = TRUE, df.offset = 0, penalty = 1,
              control.spar = list())
</code></pre>

<p>by (naively) calling</p>

<pre><code>smoothed &lt;- smooth.spline(myarray)
</code></pre>

<p>When I run this, I get this error:</p>

<blockquote>
  <p>Error in smooth.spline(a) : need at least four unique 'x' values</p>
</blockquote>

<p>My array has four or more unique values in each dimension, so I am thinking that I do not know how to properly format the input data.  Can someone give me some pointers to this kind of thing?  The examples for <code>smooth</code>-like functions seem to work with single-dimension vectors, and I can't seem to extrapolate to the 2-D world.  I am an R novice, so please feel free to correct my misuse of terms here!</p>
"
2123195,256662,2010-01-23T12:59:26Z,0,What's the best way to map the link connection between blogs?,"<p>I wish to perform a social network analysis on a bunch of blogs, plotting who is linking to who (not just by their blogroll but also inside their posts). What software can perform such crawling/data-collecting/mapping ?</p>

<p>Thanks!</p>
"
2123968,198401,2010-01-23T17:21:25Z,10,R array manipulation,"<p>In python lists can be sliced like this <code>x[4:-1]</code> to get from the fourth to the last element.</p>

<p>In R something similar can be accomplished for vectors with <code>x[4:length(x)]</code> and for multidimensional arrays with something like <code>x[,,,,4:dim(x)[5],,,]</code>.  Is this more elegant syntax for array slicing for a particular dimension from an element in the middle to the last element?</p>

<p>Thanks    </p>
"
2125231,170352,2010-01-23T23:39:35Z,10,Subsetting in R using OR condition with strings,"<p>I have a data frame with about 40 columns, the second column, data[2] contains the name of the company that the rest of the row data describes. However, the names of the companies are different depending on the year (trailing 09 for 2009 data, nothing for 2010). </p>

<p>I would like to be able to subset the data such that I can pull in both years at once. Here is an example of what I'm trying to do...</p>

<pre><code>subset(data, data[2] == ""Company Name 09"" | ""Company Name"", drop = T) 
</code></pre>

<p>Essentially, I'm having difficulty using the OR operator within the subset function. </p>

<p>However, I have tried other alternatives:</p>

<pre><code>subset(data, data[[2]] == grep(""Company Name"", data[[2]]))
</code></pre>

<p>Perhaps there's an easier way to do it using a string function? </p>

<p>Any thoughts would be appreicated.</p>
"
2126124,257700,2010-01-24T05:57:33Z,1,I can't print the mean value of survfit(...),"<p>I used the data, aml in survival package in R and computed a survival function by
""survfit"". Since the result of survfit doesn't show the mean value,
I used the following code to print the mean:</p>

<pre><code>&gt; print(survfit(Surv(aml1$time,aml1$status)~1),show.rmean=T)
</code></pre>

<p>(the data I used is, <code>aml1 &lt;-aml[aml$x=""Maintained"",]</code>)</p>

<p>The code above worked in my friend pc, but not mine.
So, I thought about downloading  some extra package to use <code>print(...show.rmean=T)</code>.
But, ""print"" is basic, so I don't need anything to run  print.
Then why I can't get the mean value?</p>
"
2127926,98080,2010-01-24T17:09:28Z,6,How do I highlight an observation's bin in a histogram in R,"<p>I want to create a histogram from a number of observations (i.e. d &lt;- c(1,2.1,3.4,4.5) ) and then highlight the bin that a particular observation falls in, such that I have an output that looks like this:
<a href=""http://img686.imageshack.us/img686/5061/observationhist.png"">alt text http://img686.imageshack.us/img686/5061/observationhist.png</a></p>

<p>how do I do this in R?</p>
"
2129952,144278,2010-01-25T02:52:33Z,45,Creating a Plot Window of a Particular Size,"<p>How can I create a new on-screen R plot window with a particular width and height (in pixels, etc.)?</p>
"
2134972,243588,2010-01-25T19:26:49Z,1,How to split a chron date & time object in zoo for aggregation,"<p>I have imported data with a five minute interval into a zoo object, where the index is a chron with both date and time:</p>

<pre>
> d
(09/09/09 16:45:10)  13.2  5.8
(09/09/09 16:50:10)   8.3  0.7
(09/09/09 16:55:10)   4.7  0.7
(09/09/09 17:00:10)   6.6  0.7
(09/09/09 17:05:10)   4.6  0.7
</pre>

<p>I am trying to aggregate by quarter hour intervals.</p>

<p>I found way to do so by converting back to a string, but the output is no longer a zoo.</p>

<pre>
> r =data.frame(aggregate(d,trunc(chron(times=substr(as.character(index(d)),11,18)),""00:15:00""), mean)
> r
00:00:00   0.5644444
00:15:00   0.5400000
00:30:00   0.5488889
00:45:00   0.6155556
01:00:00   0.3422222
</pre>

<p>While I can plot this, I was trying to do this natively. I found that aggregate with zoo could do day and hour, but I could not subdivide the hour.</p>
"
2139703,170792,2010-01-26T13:44:01Z,2,"FA: Choosing Rotation matrix, based on ""Simple Structure Criteria""","<p>One of the most important issues in using factor analysis is its interpretation. Factor analysis often uses factor rotation to enhance its interpretation. After a satisfactory rotation, the rotated factor loading matrix <strong>L'</strong> will have the same ability to represent the correlation matrix and it can be used as the factor loading matrix, instead of the unrotated matrix <strong>L</strong>.</p>

<p>The purpose of rotation is to make the rotated factor loading matrix have some desirable properties. One of the methods used is to rotate the factor loading matrix such that the rotated matrix will have a <strong>simple structure</strong>.</p>

<p>L. L. Thurstone introduced the Principle of Simple Structure, as a general guide for factor rotation:</p>

<h2>Simple Structure Criteria:</h2>

<ol>
<li>Each row of the factor matrix should contain at least one zero</li>
<li>If there are m common factors, each column of the factor matrix should have at least m zeros</li>
<li>For every pair of columns in the factor matrix, there should be several variables for which entries approach zero in the one column but not in the other</li>
<li>For every pair of columns in the factor matrix, a large proportion of the variables should have entries approaching zero in both columns when there are four or more factors</li>
<li>For every pair of columns in the factor matrix, there should be only a small number of variables with nonzero entries in both columns</li>
</ol>

<p>The ideal simple structure is such that:</p>

<ol>
<li>each item has a high, or meaningful, loading on one factor only and</li>
<li>each factor have high, or meaningful, loadings for only some of the items.</li>
</ol>

<p>The problem is that, trying several combinations of rotation methods along with the parameters that each one accepts (especially for oblique ones), the number of candidate matrices increases and it is very difficult to see which one better meets the above criteria.</p>

<p>When I first faced that problem I realized that I was unable to select the best match by merely 'looking' at them, and that I needed an algorithm to help me decide. Under the stress of project's deadlines, the most I could do was to write the following code in MATLAB, which accepts one rotation matrix at a time and returns (under some assumptions) whether each criterion is met or not.
A new version (If I would ever tried to upgrade it) would accept a 3d matrix (a set of 2d matrices) as an argument, and the algorithm should return the one that better fits the above criteria.</p>

<p>I am just asking for your opinions (I also think that there's been criticism over the usefulness of the method by itself) and perhaps better approaches to the rotation matrix selection problem. If someone wants to provide some code, I would prefer R or MATLAB. </p>

<p>P.S. The above <a href=""http://books.google.gr/books?id=5Jyaa2LQWbQC&amp;pg=PA132&amp;lpg=PA132&amp;dq=%22The+criteria+of+simple+structure+was+originally+proposed%22&amp;source=bl&amp;ots=OXsCeU0Nzi&amp;sig=qfiLMUyXsgwPunWBgNdSEeBNm34&amp;hl=el&amp;ei=huZeS5nkApTE4gaC67HsCw&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=1&amp;ved=0CAcQ6AEwAA#v=onepage&amp;q=%22The%20criteria%20of%20simple%20structure%20was%20originally%20proposed%22&amp;f=false"" rel=""nofollow noreferrer"">Simple Structure Criteria formulation</a> can be found in the book <em>""Making Sense of Factor Analysis""</em> by PETT, M., LACKEY, N., SULLIVAN, J.</p>

<p>P.S.2 (from the same book): <em>""A test of successful factor analysis is the extent to which it can reproduce the original corr matrix. If you also used oblique solutions, among all select the one that generated the greatest number of highest and lowest factor loadings.""</em> 
This sounds like another constraint that the algorithm could use.</p>

<pre><code>function [] = simple_structure_criteria (my_pattern_table)
%Simple Structure Criteria
%Making Sense of Factor Analysis, page 132

disp(' ');
disp('Simple Structure Criteria (Thurstone):');
disp('1. Each row of the factor matrix should contain at least one zero');
disp( '2. If there are m common factors, each column of the factor matrix should have at least m zeros');
disp( '3. For every pair of columns in the factor matrix, there should be several variables for which entries approach zero in the one column but not in the other');
disp( '4. For every pair of columns in the factor matrix, a large proportion of the variables should have entries approaching zero in both columns when there are four or more factors');
disp( '5. For every pair of columns in the factor matrix, there should be only a small number of variables with nonzero entries in both columns');
disp(' ');
disp( '(additional by Pedhazur and Schmelkin) The ideal simple structure is such that:');
disp( '6. Each item has a high, or meaningful, loading on one factor only and');
disp( '7. Each factor have high, or meaningful, loadings for only some of the items.');

disp('')
disp('Start checking...')

%test matrix
%ct=[76,78,16,7;19,29,10,13;2,6,7,8];
%test it by giving: simple_structure_criteria (ct)

ct=abs(my_pattern_table);

items=size(ct,1);
factors=size(ct,2);
my_zero = 0.1;
approach_zero = 0.2;
several = floor(items / 3);
small_number = ceil(items / 4);
large_proportion = 0.30;
meaningful = 0.4;
some_bottom = 2;
some_top = floor(items / 2);

% CRITERION 1
disp(' ');
disp('CRITERION 1');
for i = 1 : 1 : items
    count = 0;
    for j = 1 : 1 : factors
        if (ct(i,j) &lt; my_zero)
            count = count + 1;
            break
        end
    end
    if (count == 0)
        disp(['Criterion 1 is NOT MET for item ' num2str(i)])
    end
end


% CRITERION 2
disp(' ');
disp('CRITERION 2');
for j = 1 : 1 : factors 
    m=0;
    for i = 1 : 1 : items
        if (ct(i,j) &lt; my_zero)
            m = m + 1;
        end
    end
    if (m &lt; factors)
        disp(['Criterion 2 is NOT MET for factor ' num2str(j) '. m = ' num2str(m)]);
    end
end

% CRITERION 3
disp(' ');
disp('CRITERION 3');
for c1 = 1 : 1 : factors - 1
    for c2 = c1 + 1 : 1 : factors
        test_several = 0;
        for i = 1 : 1 : items
            if ( (ct(i,c1)&gt;my_zero &amp;&amp; ct(i,c2)&lt;my_zero) || (ct(i,c1)&lt;my_zero &amp;&amp; ct(i,c2)&gt;my_zero) ) % approach zero in one but not in the other
                test_several = test_several + 1;
            end
        end
        disp(['several = ' num2str(test_several) ' for factors ' num2str(c1) ' and ' num2str(c2)]);
        if (test_several &lt; several)
            disp(['Criterion 3 is NOT MET for factors ' num2str(c1) ' and ' num2str(c2)]);
        end
    end
end

% CRITERION 4
disp(' ');
disp('CRITERION 4');
if (factors &gt; 3)
    for c1 = 1 : 1 : factors - 1
        for c2 = c1 + 1 : 1 : factors
            test_several = 0;
            for i = 1 : 1 : items
                if (ct(i,c1)&lt;approach_zero &amp;&amp; ct(i,c2)&lt;approach_zero) % approach zero in both
                    test_several = test_several + 1;
                end
            end
            disp(['large proportion = ' num2str((test_several / items)*100) '% for factors ' num2str(c1) ' and ' num2str(c2)]);
            if ((test_several / items) &lt; large_proportion)
                pr = sprintf('%4.2g',  (test_several / items) * 100 );
                disp(['Criterion 4 is NOT MET for factors ' num2str(c1) ' and ' num2str(c2) '. Proportion is ' pr '%']);
            end
        end
    end
end

% CRITERION 5
disp(' ');
disp('CRITERION 5');
for c1 = 1 : 1 : factors - 1
    for c2 = c1 + 1 : 1 : factors
        test_number = 0;
        for i = 1 : 1 : items
            if (ct(i,c1)&gt;approach_zero &amp;&amp; ct(i,c2)&gt;approach_zero) % approach zero in both
                test_number = test_number + 1;
            end
        end
        disp(['small number = ' num2str(test_number) ' for factors ' num2str(c1) ' and ' num2str(c2)]);
        if (test_number &gt; small_number)
            disp(['Criterion 5 is NOT MET for factors ' num2str(c1) ' and ' num2str(c2)]);
        end
    end
end

% CRITERION 6
disp(' ');
disp('CRITERION 6');
for i = 1 : 1 : items
    count = 0;
    for j = 1 : 1 : factors
        if (ct(i,j) &gt; meaningful)
            count = count + 1;
        end
    end
    if (count == 0 || count &gt; 1)
        disp(['Criterion 6 is NOT MET for item ' num2str(i)])
    end
end

% CRITERION 7
disp(' ');
disp('CRITERION 7');
for j = 1 : 1 : factors 
    m=0;
    for i = 1 : 1 : items
        if (ct(i,j) &gt; meaningful)
            m = m + 1;
        end
    end
    disp(['some items = ' num2str(m) ' for factor ' num2str(j)]);
    if (m &lt; some_bottom || m &gt; some_top)
        disp(['Criterion 7 is NOT MET for factor ' num2str(j)]);
    end
end
disp('')
disp('Checking completed.')
return
</code></pre>
"
2140540,900119,2010-01-26T15:57:50Z,2,SQLite and R interaction,"<p>I'm using the SQlite package to interface with a database from R. However, I'm running into the issue that the results from exactly the same query are different when I run it in R or from the command-line interface. 
For instance, the minimum value in a column is 0, but R somehow gives the result -2147332296. As I just copy-n-paste the query, I don't think the problem is in the query. The only thing I can think of is that there might be a problem with conversion between datatypes. The maximum value in that same column is 147031553000 and the type of the column is ""integer"". Perhaps this value is too big for the datatype which R uses and this results in the negative value?</p>

<p>However, there is one more problem. For the same query, R reports less results than when I run the query in the command-line interface. Does anyone here have an idea as to why things might be going wrong?</p>
"
2140972,189035,2010-01-26T16:51:39Z,3,Can we have more error (messages)?,"<p>Is there a way, in R, to pop up an error message if a function uses a variable
not declared in the body of the function: i.e, i want someone to flag this type of functions</p>

<pre><code>aha&lt;-function(p){
  return(p+n)
}
</code></pre>

<p>see; if there happens to be a ""n"" variable lying somewhere, aha(p=2) will give me an ""answer"" since R will just take ""n"" from that mysterious place called the ""environment""</p>
"
2144968,84458,2010-01-27T06:25:36Z,10,Monitoring Progress/Debugging Parallel R Scripts,"<p>Among the choices I have for quickly parallelizing simple code (<a href=""http://cran.revolution-computing.com/web/packages/snowfall/index.html"" rel=""noreferrer"">snowfall</a>, <a href=""http://cran.revolution-computing.com/web/packages/foreach/index.html"" rel=""noreferrer"">foreach</a>, and <a href=""http://cran.revolution-computing.com/web/views/HighPerformanceComputing.html"" rel=""noreferrer"">so on</a>), what are my options for showing the progress of all the slave processes?  Do any of the offerings excel in this regard?</p>

<p>I've seen that snowfall 1.70 has <code>sfCat()</code>, but it doesn't seem to cat output to the master R session.  </p>
"
2147084,900119,2010-01-27T13:22:55Z,6,add labels to lattice barchart,"<p>I would like to place the value for each bar in barchart (lattice) at the top of each bar. However, I cannot find any option with which I can achieve this. I can only find options for the axis.</p>
"
2150138,220120,2010-01-27T20:48:38Z,61,How to parse milliseconds?,"<p>How do I use <code>strptime</code> or any other functions to parse time stamps with milliseconds in R?</p>

<pre><code>time[1]
# [1] ""2010-01-15 13:55:23.975""
strptime(time[1], format=""%Y-%m-%d %H:%M:%S.%f"")
# [1] NA
strptime(time[1], format=""%Y-%m-%d %H:%M:%S"")
# [1] ""2010-01-15 13:55:23""`
</code></pre>
"
2151147,260533,2010-01-27T23:30:08Z,12,Using Stata Variable Labels in R,"<p>I have a bunch of Stata .dta files that I would like to use in R.</p>

<p>My problem is that the variable names are not helpful to me as they are like ""q0100,"" ""q0565,"" ""q0500,"" and ""q0202.""  However, they are labelled like ""psu,"" ""number of pregnant,"" ""head of household,"" and ""waypoint.""</p>

<p>I would like to be able to grab the labels (""psu,"" ""waypoint,"" etc. . .) and use them as my variable/column names as those will be easier for me to work with.</p>

<p>Is there a way to do this, either preferably in R, or through Stata itself?  I know of read.dta in library(foreign) but don't know if it can convert the labels into variable names.</p>
"
2151212,140823,2010-01-27T23:40:22Z,243,How can I read command line parameters from an R script?,"<p>I've got a R script for which I'd like to be able to supply several command-line parameters (rather than hardcode parameter values in the code itself).  The script runs on Windows.</p>

<p>I can't find info on how to read parameters supplied on the command-line into my R script.  I'd be surprised if it can't be done, so maybe I'm just not using the best keywords in my Google search...</p>

<p>Any pointers or recommendations?</p>
"
2156935,170792,2010-01-28T18:34:37Z,3,How can I find all R packages that include graphics functions?,"<p>I always have difficulty in finding all available alternative ways to produce a specific graph, either one that I have already decided to use (looking for different variations) or one that I have not yet thought of.</p>

<p>The <a href=""http://bm2.genes.nig.ac.jp/RGM2/index.php?clear=all"" rel=""nofollow noreferrer"">R Graphical Manual</a> site provides a complete list of samples of R's graphics functions, however it's easier for me to search providing a package name (how else -for example- can I get a resultset including <code>superbarplot</code> function, when I want to look for barplots?. Let alone that the superbarplot graph does not appear in the results even if I try searching for it's package: <code>UsingR</code>)</p>

<p>The <a href=""http://sites.google.com/site/r4statistics/add-on-modules"" rel=""nofollow noreferrer"">R-SAS-SPSS Add-on Module Comparison</a> - and especially on topic <code>Graphics, Static</code> in the table provided - gave me the idea that it would be nice to have a place where all relevant packages are listed by topic.</p>

<p>Do you have any idea about something like that?</p>
"
2158002,261368,2010-01-28T21:14:59Z,0,what does object 'parental' not found in R mean ?,"<p>Im trying to check for constance of variance for residuals  with boxplots .
But when I ran the following expression in R: </p>

<pre><code>boxplot(split(model$res,parental))
</code></pre>

<p>I get this error:</p>

<pre><code>Error in split.default(model$res, parental) : object 'parental' not found
</code></pre>

<p>What is it about ? </p>
"
2158631,261421,2010-01-28T22:51:59Z,0,Packages for multiple allignment of Mass spec Data,"<p>I am searching for good R package to allign multiple spectra.</p>

<p>Thanks.</p>
"
2158780,37751,2010-01-28T23:25:22Z,29,catching an error and then branching logic,"<p>How do I write R code that allows me to execute a different path in my code if an error condition happens? I'm using a function that tends to throw an error. When it meets an error condition I would like to execute a different function. Here's a specific example:</p>

<pre><code>require(SuppDists)
parms &lt;- structure(list(gamma = -0.841109044800762, delta = 0.768672140584442, 
    xi = -0.359199299528801, lambda = 0.522761187947026, type = ""SB""), .Names = c(""gamma"", 
""delta"", ""xi"", ""lambda"", ""type""))
pJohnson(.18, parms)
</code></pre>

<p>the pJohnson function should fail with the following error:</p>

<pre><code> Error in pJohnson(0.18, parms) :
 Sb values out of range.
</code></pre>

<p>I can make the error go silent by using:</p>

<pre><code>try( pJohnson(.18, parms), silent=T)
</code></pre>

<p>but what I really want to do is execute the function <code>alternativeFunction()</code> if <code>pJohnson(.18, parms)</code> returns an error. </p>

<p>It seems like the <code>withCallingHandlers()</code> function should help me out, but I can't figure out how to capture the error and make it run the <code>alternativeFunction()</code> only upon an error condition. </p>
"
2160224,144278,2010-01-29T06:09:02Z,5,Percentile for Each Observation w/r/t Grouping Variable,"<p>I have some data that looks like the following. It is grouped by variable ""Year"" and I want to extract the percentiles of <em>each</em> observation of Score, with respect to the Year it is from, preferably as a vector.</p>

<pre><code>Year   Score
2001   89
2001   70
2001   72
2001   ...
..........
2004   87
2004   90
</code></pre>

<p>etc.</p>

<p>How can I do this? aggregate will not work, and I do not think apply will work either.</p>
"
2161052,216064,2010-01-29T09:43:52Z,11,"How to create an ""inkblot"" chart with R?","<p>How can I create a chart like</p>

<p><a href=""http://junkcharts.typepad.com/junk_charts/2010/01/leaving-ink-traces.html"" rel=""noreferrer"">http://junkcharts.typepad.com/junk_charts/2010/01/leaving-ink-traces.html</a></p>

<p>where several time series (one per country) are displayed horizontally as symmetric areas?</p>

<p>I think if I could display one time series in this way, it is easy to generalize to several using mfrow.</p>

<p>Sample data:  </p>

<pre><code>#Solar energy production in Europe, by country (EC),(1 000 toe)  
Country,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007  
Belgium,1,1,1,1,1,1,2,2,3,3,3,5  
Bulgaria,-,-,-,-,-,-,-,-,-,-,-,-  
Czech Republic,0,0,0,0,0,0,0,0,2,2,3,4  
Denmark,6,7,7,8,8,8,9,9,9,10,10,11  
Germany (including ex-GDR from 1991),57,70,83,78,96,150,184,216,262,353,472,580  
Estonia,-,-,-,-,-,-,-,-,-,-,-,-  
Ireland,0,0,0,0,0,0,0,0,0,0,1,1  
Greece,86,89,93,97,99,100,99,99,101,102,109,160  
Spain,26,23,26,29,33,38,43,48,58,65,83,137  
France,15,16,17,18,26,19,19,18,19,22,29,37  
Italy,8,9,11,11,12,14,16,18,21,30,38,56  
Cyprus,32,33,34,35,35,34,35,36,40,41,43,54  
Latvia,-,-,-,-,-,-,-,-,-,-,-,-  
Lithuania,-,-,-,-,-,-,-,-,-,-,-,-  
Luxembourg (Grand-Duché),0,0,0,0,0,0,0,0,1,2,2,2  
Hungary,0,0,0,0,0,1,2,2,2,2,2,3  
Netherlands,6,7,8,10,12,14,16,19,20,22,22,23  
Austria,42,48,55,58,64,69,74,80,86,92,101,108  
Poland,0,0,0,0,0,0,0,0,0,0,0,0  
Portugal,16,16,17,18,18,19,20,21,21,23,24,28  
Romania,0,0,0,0,0,0,0,0,0,0,0,0  
Slovenia,-,-,-,-,-,-,-,-,-,-,-,-  
Slovakia,0,0,0,0,0,0,0,0,0,0,0,0  
Finland,0,0,0,0,1,1,1,1,1,1,1,1  
Sweden,4,4,5,5,5,6,4,5,5,6,6,9  
United Kingdom,6,6,7,7,11,13,16,20,25,30,37,46  
Croatia,0,0,0,0,0,0,0,0,0,0,0,1  
Turkey,159,179,210,236,262,287,318,350,375,385,402,420  
Iceland,-,-,-,-,-,-,-,-,-,-,-,-  
Norway,0,0,0,0,0,0,0,0,0,0,0,0  
Switzerland,18,19,21,23,24,26,23,24,25,26,28,30  
#-='Not applicable' or 'Real zero' or 'Zero by default' :=Not available ""
#Source of Data:,Eurostat, http://spreadsheets.google.com/ccc?key=0Agol553XfuDZdFpCQU1CUVdPZ3M0djJBSE1za1NGV0E&amp;hl=en_GB  
#Last Update:,30.04.2009  
#Date of extraction:,17 Aug 2009 07:41:12 GMT, http://epp.eurostat.ec.europa.eu/tgm/table.do?tab=table&amp;init=1&amp;plugin=1&amp;language=en&amp;pcode=ten00082
</code></pre>
"
2161152,30911,2010-01-29T10:03:56Z,25,Sweave for python,"<p>I've recently started using <a href=""http://www.stat.uni-muenchen.de/~leisch/Sweave/"" rel=""noreferrer"">Sweave</a>* for creating reports of analyses run with R, and am now looking to do the same with my python scripts. </p>

<p>I've found references to <a href=""http://romainfrancois.blog.free.fr/index.php?post/2009/01/21/Python-and-Sweave"" rel=""noreferrer"">embedding python in Sweave</a> docs, but that seems like a bit of a hack. Has anyone worked out a better solution, or is there an equivalent for python I'm not aware of?</p>

<p>* <em>Sweave is a tool that allows to embed the R code for complete data analyses in latex documents</em></p>
"
2161384,255564,2010-01-29T10:52:49Z,5,ggplot2: mean in the function on time,"<p>If I have data like this</p>

<pre><code>DF &lt;- data.frame(
  date = seq(Sys.Date()-1000, len=1000, by=""1 day"")[sample(1000, 500)],
  price = runif(500)
)
</code></pre>

<p>How do I plot e.g. mean of price in the function of time, e.g. in months, using ggplot2?</p>
"
2161815,243588,2010-01-29T12:21:54Z,2,R zoo series sliding window calculation,"<p>Given I have a zoo dataset, I'd like to perform a sliding operation against it with the result being another zoo dataset.</p>

<pre>
> x
                      Y
(09/24/09 08:00:13)   3.1
(09/24/09 08:05:13)   4.2
(09/24/09 08:10:13)   4.5
(09/24/09 08:15:13)   9.4
(09/24/09 08:20:13)   9.8
(09/24/09 08:25:13)   7.7
(09/24/09 08:30:13)  13.3
(09/24/09 08:35:13)   6.5
(09/24/09 08:40:13)  14.7
(09/24/09 08:45:13)  23.5
(09/24/09 08:50:13)  20.9
(09/24/09 08:55:13)   8.5
</pre>

<p>My goal is to produce a ""smooth"" average by iterating through each time interval and obtaining the mean for the set of Y points that are +/- 15 minutes of the current point.</p>

<p>I have a bucketing method of averaging working, but it reduces the resolution of the data. I haven't worked out how to make relative subsets out of zoo with artibrary math, window should help but accessing the index is being difficult.</p>

<p>Thanks.</p>
"
2163108,216064,2010-01-29T15:52:49Z,10,Use Windows (TTF) font?,"<p>Is it possible to use a TTF font in R?</p>

<p>Is the cairo package intended for this task? How would a minimal example look like?</p>
"
2165342,37751,2010-01-29T21:39:06Z,26,R: calling a function from a namespace,"<p>I'm trying to alter the functionality of a few commands in a package in R. It's easy enough to see the source of the commands. However the function calls other functions that are in the package namespace. These functions are not exported objects. So how can I access them?</p>

<p>specific example:
How would I access the asCall() function that is used in copula::rmvdc?</p>

<pre><code>require(copula)
copula::rmvdc
getAnywhere(""asCall"")
</code></pre>

<p>so <code>as.Call()</code> exists in the copula package, but how do I access it? </p>

<pre><code>&gt; copula::asCall
Error: 'asCall' is not an exported object from 'namespace:copula'
</code></pre>
"
2169118,58394,2010-01-30T19:28:33Z,12,Installing all CRAN packages that are not already installed?,"<p>The following R commands will install all CRAN packages:</p>

<pre><code>availablePackages &lt;- available.packages()[,1]
install.packages(availablePackages)
</code></pre>

<p>And the following command will list all installed packages:</p>

<pre><code>installedPackages &lt;- .packages(all.available = TRUE)
</code></pre>

<p>My question is: <b>How do I instruct R to install all CRAN packages that are not already installed?</b></p>
"
2170043,58394,2010-01-31T00:14:04Z,25,"R: apt-get install r-cran-foo vs. install.packages(""foo"")","<p>When installing R packages (say <code>mcmcpack</code> in this example) under Ubuntu I have the choice between the following two methods of installation:</p>

<pre><code># Let the distribution's packaging system take care of installation/upgrades
apt-get install r-cran-mcmcpack

# Let R take care of installation/upgrades
install.packages(""mcmcpack"")
</code></pre>

<p>Questions:</p>

<ul>
<li>Is any of the two ways of installing R packages considered ""best practice""?</li>
<li>Assume that I first <code>install.packages(""mcmcpack"")</code> and later on <code>apt-get install r-cran-mcmcpack</code> - should I expect trouble?</li>
<li>Assume that I first <code>apt-get install r-cran-mcmcpack</code> and later on <code>install.packages(""mcmcpack"")</code> - should I expect trouble?</li>
</ul>
"
2172146,216064,2010-01-31T15:10:12Z,11,Inspect S4 methods,"<p>How can I view the definition of a S4 function? For instance, I would like to see the definition of TSconnect in package TSdbi. The command</p>

<pre><code>showMethods(""TSconnect"")
</code></pre>

<p>reveals that there is, among others, a function for drv=""histQuoteDriver"", dbname=""character"".</p>

<p>How can I see the definition of this function? If it were a S3 function, there would be only the first argument definable (drv), which could be inspected with print(TSconnect.histQuoteDriver).</p>

<p><strong>Edit</strong>: From r-forge I found out the desired output:</p>

<pre><code>setMethod(""TSconnect"",   signature(drv=""histQuoteDriver"", dbname=""character""),
  definition= function(drv, dbname, user="""", password="""", host="""", ...){
   #  user / password / host  for future consideration
   if (is.null(dbname)) stop(""dbname must be specified"")
   if (dbname == ""yahoo"") {
      con &lt;- try(url(""http://quote.yahoo.com""), silent = TRUE)
      if(inherits(con, ""try-error"")) 
         stop(""Could not establish TShistQuoteConnection to "",  dbname)
      close(con)
      }
   else if (dbname == ""oanda"") {
      con &lt;- try(url(""http://www.oanda.com""),   silent = TRUE)
      if(inherits(con, ""try-error"")) 
         stop(""Could not establish TShistQuoteConnection to "",  dbname)
      close(con)
      }
   else 
      warning(dbname, ""not recognized. Connection assumed working, but not tested."")

   new(""TShistQuoteConnection"", drv=""histQuote"", dbname=dbname, hasVintages=FALSE, hasPanels=FALSE,
        user = user, password = password, host = host ) 
   } )
</code></pre>

<p>Is there a way to get this definition from within an R session?</p>
"
2175809,183988,2010-02-01T09:54:53Z,34,"alternative to ""!is.null()"" in R","<p>my R code ends up containing plethora of statements of the form:</p>

<pre><code>if (!is.null(aVariable)) { 
     do whatever 
}
</code></pre>

<p>But this kind of statement is hard to read because it contains two negations. I would prefer something like: </p>

<pre><code> if (is.defined(aVariable)) { 
      do whatever 
 }
</code></pre>

<p>Does a <code>is.defined</code> type function that does the opposite of !is.null exist standard in R?</p>

<p>cheers,
yannick</p>
"
2180235,227818,2010-02-01T21:32:41Z,13,R from within Java,"<p>What's the best way to call R functionality from within Java? </p>

<p>I'm looking for a quick, easy and reliable way to make standard 2d scatter plots and histograms in R using my Java applications. I was wondering which packages/interfaces that came up in a quick Google search would be most convenient to use. </p>

<p>I look forward to your suggestions!</p>
"
2181902,171249,2010-02-02T04:31:41Z,25,How to use an image as a point in ggplot?,"<p>Is there some way to use a specific small image as a point in a scatterplot with ggplot2.  Ideally I will want to resize the images based on an variable.</p>

<p>Here's an example:</p>

<pre><code>library(ggplot2)
p &lt;- ggplot(mtcars, aes(wt, mpg))
p + geom_point(aes(size = qsec, shape = factor(cyl)))
</code></pre>

<p>So I basically want to know if there is a way to supply a specific image as the shape?</p>
"
2182337,207258,2010-02-02T06:56:00Z,1,How to use a variable name in a SQL statement?,"<p>I'm using R to call a mySQL statement, where I define the variable outside the statement e.g.</p>

<pre><code>foo = 23;
dbGetQuery(con, ""select surname from names WHERE age = '.foo.' ;"")
</code></pre>

<p>But this returns an empty set, I've googled around and tried'.&amp;foo.'   "".foo.""   '"".&amp;&amp;foo.""' 
 and many different combinations, but none of them work, I think this should be a mysql question rather than an R specific problem I'm having, but not sure.  Normally variables have $values but not in R.</p>
"
2183002,258334,2010-02-02T09:34:59Z,0,Display only one line for each NA Value,"<p>At some point in my script I like to see the number of <code>missing values</code>
in my <code>data.frame</code> and display them.
In my case I have:</p>

<pre><code>out &lt;- read.csv(file=""...../OUT.csv"", na.strings=""NULL"")

sum(is.na(out$codeHelper))

out[is.na(out$codeHelper),c(1,length(colnames(out)))]
</code></pre>

<p>It works perfectly fine.
However, the last command obviously gives me the whole <code>data.frame</code> where the <code>NA</code> is <code>TRUE</code>, eg:</p>

<pre><code>5561                  Yemen (PDR) &lt;NA&gt;
5562                  Yemen (PDR) &lt;NA&gt;
5563                  Yemen (PDR) &lt;NA&gt;
5564                  Yemen (PDR) &lt;NA&gt;
5565                  Yemen (PDR) &lt;NA&gt;
5566                  Yemen (PDR) &lt;NA&gt;
5567                  Yemen (PDR) &lt;NA&gt;
5568                  Yemen (PDR) &lt;NA&gt;
5601 Zaire (Democ Republic Congo) &lt;NA&gt;
5602 Zaire (Democ Republic Congo) &lt;NA&gt;
5603 Zaire (Democ Republic Congo) &lt;NA&gt;
5604 Zaire (Democ Republic Congo) &lt;NA&gt;
5605 Zaire (Democ Republic Congo) &lt;NA&gt;
</code></pre>

<p>With a big frame and a lot of NAs that looks pretty messy.
Important to me is only where the NA occurs i.e which country 
(in the second column) has a missing value in the third column.</p>

<p>So how can i only display a single row for each country?</p>

<p>It should look something like this:</p>

<pre><code>    1                  Yemen (PDR) &lt;NA&gt;
    2 Zaire (Democ Republic Congo) &lt;NA&gt;
    3                          USA &lt;NA&gt;
    4                     W. Samoa &lt;NA&gt;
</code></pre>
"
2185252,258334,2010-02-02T15:36:12Z,65,Reshaping data.frame from wide to long format,"<p>I have some trouble to convert my <code>data.frame</code> from a wide table to a long table.
At the moment it looks like this:</p>

<pre><code>wide &lt;- read.table(textConnection(
""Code Country        1950    1951    1952    1953    1954
AFG  Afghanistan    20,249  21,352  22,532  23,557  24,555
ALB  Albania        8,097   8,986   10,058  11,123  12,246""), header=TRUE)
</code></pre>

<p>Which yields data.frame <code>wide</code> looking like this:</p>

<pre><code>Code Country        1950    1951    1952    1953    1954
AFG  Afghanistan    20,249  21,352  22,532  23,557  24,555
ALB  Albania        8,097   8,986   10,058  11,123  12,246
</code></pre>

<p>I want to transform <code>wide</code> into a long <code>data.frame</code> e.g:</p>

<pre><code>Code Country        Year    Value
AFG  Afghanistan    1950    20,249
AFG  Afghanistan    1951    21,352
AFG  Afghanistan    1952    22,532
AFG  Afghanistan    1953    23,557
AFG  Afghanistan    1954    24,555
ALB  Albania        1950    8,097
ALB  Albania        1951    8,986
ALB  Albania        1952    10,058
ALB  Albania        1953    11,123
ALB  Albania        1954    12,246
</code></pre>

<p>As of 2016, options include <code>reshape2::melt()</code>, as well as <code>tidyr::gather()</code> and <code>data.table::melt()</code> solutions and the older <code>reshape::reshape()</code> function. However, so far I only get messy results trying to use these multiple similar-but-different functions.</p>

<p>If it is possible I would like to do it with the <code>reshape()</code> function since
it looks a little bit nicer to handle, but examples/rationales for using other packages appreciated.</p>
"
2185958,143319,2010-02-02T16:58:06Z,1,What R packages are available for binary data that is both correlated and clustered?,"<p>I'm working on a project now that's rather unlike anything I've done before.  I have two tests with binary results that will be administered to the same sample, which is drawn from a clustered population (i.e., some subjects will be from the same family).  I'd like to compare proportions of positive test results, but the clustering makes McNemar's test inappropriate so I've been reading up on alternative approaches.  The two main routes seem to be 1) the clustering-adjusted McNemar alternatives by Rao and Scott (1992), Eliasziw and Donner (1991), and Obuchowski (1998), and 2) GEE.</p>

<p>Do you know of any implementations of the Rao-Obuchowski lineage in R (or, I suppose, SAS)?  GEE is easy to find, but have you had a positive or negative experience with any particular packages?  Is there another route to analyzing these data that I'm completely missing?</p>

<p>Thanks in advance for your help - let me know if any clarification is needed.</p>
"
2186015,169947,2010-02-02T17:05:15Z,8,Bind variables in R DBI,"<p>In R's <code>DBI</code> package, I'm not finding a facility for using bound variables.  I did find a document (the original vignette from 2002) that says about bound variables, ""Perhaps the DBI could at some point in the future implement this feature"", but it looks like so far that's left undone.</p>

<p>What do people in R use for a substitute?  Just concatenate strings right into the SQL?  That's got some obvious problems for safety &amp; performance.</p>

<p>EDIT:</p>

<p>Here's an example of how placeholders could work:</p>

<pre><code>query &lt;- ""SELECT numlegs FROM animals WHERE color=?""
result &lt;- dbGetQuery(caseinfo, query, bind=""green"")
</code></pre>

<p>That's not a very well-thought-out interface, but the idea is that you can use a value for <code>bind</code> and the driver handles the details of escaping (if the underlying API doesn't handle bound variables natively) without the caller having to reimplement it [badly].</p>
"
2187448,264696,2010-02-02T20:29:42Z,7,How do I use plyr to number rows?,"<p>Basically I want an autoincremented id column based on my cohorts - in this case .(kmer, cvCut)</p>

<pre><code>    &gt; myDataFrame
       size kmer cvCut   cumsum
1      8132   23    10     8132
10000   778   23    10 13789274
30000   324   23    10 23658740
50000   182   23    10 28534840
100000   65   23    10 33943283
200000   25   23    10 37954383
250000  584   23    12 16546507
300000  110   23    12 29435303
400000   28   23    12 34697860
600000  127   23     2 47124443
600001  127   23     2 47124570
</code></pre>

<p>I want a column added that has new row names based on the kmer/cvCut group</p>

<pre><code>    &gt; myDataFrame
       size kmer cvCut   cumsum  newID
1      8132   23    10     8132      1
10000   778   23    10 13789274      2
30000   324   23    10 23658740      3
50000   182   23    10 28534840      4
100000   65   23    10 33943283      5 
200000   25   23    10 37954383      6
250000  584   23    12 16546507      1
300000  110   23    12 29435303      2
400000   28   23    12 34697860      3
600000  127   23     2 47124443      1
600001  127   23     2 47124570      2
</code></pre>
"
2187910,264761,2010-02-02T21:38:33Z,1,How can I estimate the logarithmic form of data points using R?,"<p>I have data points that represent a logarithmic function.</p>

<p>Is there an approach where I can just estimate the function that describes this data using R?</p>

<p>Thanks.</p>
"
2188414,55362,2010-02-02T22:56:58Z,4,Show an ASCII character,"<p>I want to show a block ASCII character █ (it's ASCII code is 219), </p>

<p>How can I show it in terminal?</p>

<p>I am using RGui on WinXP</p>
"
2189184,184010,2010-02-03T02:11:15Z,3,Plot multiple functions in R,"<p>I previously asked this <a href=""https://stackoverflow.com/questions/1853703/plotting-functions-in-r"">question</a> which was useful in plotting a function. I want to try and plot twenty functions on the same axes to illustrate how a function varies between two ranges.  I have successfully done this using individually specified functions, but I wanted to do this using a loop.</p>

<p>What I have attempted doing is:</p>

<pre><code>## add ggplot2
library(ggplot2)
library(lattice)

# Declare local variables
inPath = ""D:/R_Analysis/""
inFile = ""sample.txt""

outPath = ""D:/R_Analysis/""
outFile = ""processed_sample.txt""

pdfOutPath = ""D:/R_Analysis/""
pdfOutFile = ""processed_sample.pdf""

# Declare Chart values
y_label = ""x-axis""
x_label = ""y-axis""
chart_title = ""..."" 

#####################################################################
## Read in data;  
analysis &lt;- 
read.table(paste(inPath, inFile, sep=""""), header=TRUE, sep="","", 
na.strings=""NA"",  dec=""."", strip.white=TRUE)

# Setup pdf
pdf(paste(pdfOutPath, pdfOutFile, sep=""""),height=6,width=9)

# make plot object    
p &lt;- qplot(
data = data.frame(x = x, y = y), x, y, xlab = x_label, ylab = y_label, 
enter code herexlim = x_range, main = chart_title  )

# make empty function
eq_dummy = function(x){ 0 }
d = stat_function(fun = eq_dummy)

##############
# LOOP #######

for(i in 1 : 21){                                            

        # Specify Variables
        intercept = analysis[i,2]
        slope = analysis[i,3]    

        # Define Curve    
        eq &lt;- function(x) { slope * log(x) + intercept }

        # Make plot object            
        composite &lt;- stat_function(fun=eq)        
        composite = composite + d       

}

print(p + composite)  

# Show warnings
warnings()

# close the PDF file
dev.off() 
</code></pre>

<p>Any suggestions about syntax improvement, or programming structure would be appreciated. Thank you.</p>
"
2190154,457898,2010-02-03T06:38:34Z,3,"Getting ""raw"" data from frequency table","<p>I've been looking around for some data about naming trends in USA. I managed to get top 1000 names for babies born in 2008. The data is formated in this manor:</p>

<pre><code> male.name n.male female.name n.female
 Jacob 22272 Emma 18587
 Michael 20298 Isabella 18377
 Ethan 20004 Emily 17217
 Joshua 18924 Madison 16853
 Daniel 18717 Ava 16850
 Alexander 18423 Olivia 16845
 Anthony 18158 Sophia 15887
 William 18149 Abigail 14901
 Christopher 17783 Elizabeth 11815
 Matthew 17337 Chloe 11699
</code></pre>

<p>I want to get a <code>data.frame</code> with 2 variables: <code>name</code> and <code>gender</code>.
This can be done with looping, but I consider it rather inefficient way of solving this problem. I reckon that some <code>reshape</code> function will suite my needs.</p>

<p>Let's presuppose that this tab-delimited data is saved into a <code>data.frame</code> named <code>bnames</code>. Looping can be done with function:</p>

<pre><code> tmp &lt;- character()
  for (i in 1:nrow(bnames)) {
  tmp &lt;- c(tmp, rep(bnames[i,1], bnames[i,2]))
 }
</code></pre>

<p>But I want to achieve this with vector-based approach. Any suggestions?</p>
"
2190756,212593,2010-02-03T09:03:38Z,110,How to count TRUE values in a logical vector,"<p>In R, what is the most efficient/idiomatic way to count the number of <code>TRUE</code> values in a logical vector? I can think of two ways:</p>

<pre><code>z &lt;- sample(c(TRUE, FALSE), 1000, rep = TRUE)
sum(z)
# [1] 498

table(z)[""TRUE""]
# TRUE 
#  498 
</code></pre>

<p>Which do you prefer? Is there anything even better?</p>
"
2192316,12677,2010-02-03T13:49:24Z,62,Extract a regular expression match in R version 2.10,"<p>I'm trying to extract a number from a string.</p>

<p>And do something like this [0-9]+  on this string ""aaaa12xxxx"" and get ""12"".</p>

<p>I thought it would be something like:</p>

<pre><code>&gt; grep(""[0-9]+"",""aaa12xxx"", value=TRUE)
[1] ""aaa12xxx""
</code></pre>

<p>And then I figured... </p>

<pre><code>&gt; sub(""[0-9]+"", ""\\1"", ""aaa12xxxx"")
[1] ""aaa12xxx""
</code></pre>

<p>But I got some form of response doing:</p>

<pre><code>&gt; sub(""[0-9]+"", ""ARGH!"", ""aaa12xxxx"")
[1] ""aaaARGH!xxx""
</code></pre>

<p>There's a small detail I'm missing Please advice :-)</p>

<p>I'm using R version 2.10.1 (2009-12-14)</p>

<p>Thanks !</p>

<hr>

<p><strong>Comments on the solution</strong></p>

<p>The best solution is to ignore the standard functions and install Hadley Wickham's <strong><em>stringr</em></strong> package to get something that actually makes sense.</p>

<p>Kudos to Marek for figuring out how the standard library worked.</p>
"
2192360,183988,2010-02-03T13:55:22Z,9,Library/package development - message when loading,"<p>is there any way to display a message when a user loads <code>library(myCustomLibrary)</code>?
Upon loading, I want to display a message that tells the user how to run all the test functions.</p>
"
2192576,135944,2010-02-03T14:26:26Z,12,Execution Efficiency vs Programmer Efficiency in R,"<p>The classic and brilliant Programming Perl reference book has a section in which the authors provide a list of advice for how to write Perl that is maximally <em>computationally efficient</em>, followed by a list of advice for how to write Perl that is maximally <em>programmer efficient</em>, followed by more advice for <em>maintainer efficient</em>, <em>porter efficient</em>, and <em>user efficient</em>. The advice is usually completely contradictory. (E.g., ""use globals"", ""don't use globals."")</p>

<p>I thought of this while working on turning some ""programmer efficient"" R code into ""computationally and maintainer efficient"" code.</p>

<p>What are some interesting and useful tips for R style along these lines? What practices are maximally programmer efficient, and what are the equivalent practices that address other notions of efficiency?</p>
"
2194516,175029,2010-02-03T18:47:54Z,2,converting R code snippet to use the Matrix package?,"<p>I am not sure there are any R users out there, but just in case:</p>

<p>I am a novice at R and was kindly ""handed down"" the following R code snippet:</p>

<pre><code>Beta &lt;- exp(as.matrix(read.table('beta.transpose')))
WordFreq &lt;- read.table('freq-matrix')
WordProbs &lt;- WordFreq$V1 / sum(WordFreq)

infile &lt;- file('freq-matrix')
outfile &lt;- file('doc_topic_prob_matrix', 'w')

open(infile)
open(outfile)

for (i in 1:93049) {
  vec &lt;- t(scan(infile, nlines=1))
  topics &lt;- (vec/WordProbs) %*% Beta
  write.table(topics, outfile, append=T, row.names=F, col.names=F)
  }
</code></pre>

<p>When I tried running this on my dataset, the system thrashed and swapped like crazy. Now I realize that has a simple reason: the file freq-matrix holds a large (22GB) matrix and I was trying to read it into memory.</p>

<p>I have been told to use the <a href=""http://cran.r-project.org/web/packages/Matrix/Matrix.pdf"" rel=""nofollow noreferrer"">Matrix</a> package, because freq-matrix has many, many zeros all over the place and it handles such cases well. Will that help? If so, any hints on how to change this code would be most welcome. I have no R experience and just started reading through the introduction PDF available on the site.</p>

<p>Many thanks</p>

<p>~l</p>
"
2196985,246211,2010-02-04T02:34:42Z,15,Information Dashboards in R with ggplot2,"<p>I'm looking to create a static dashboard viewable in a web browser. And I'd like to create something like what Stephen Few does in his book <a href=""http://rads.stackoverflow.com/amzn/click/0596100167"" rel=""nofollow noreferrer"">Information Dashboard Design</a>. (see example at bottom)</p>

<ol>
<li><strong>Ggplot2</strong>: Shouldn't be any issue producing the graphs below, right?</li>
<li><strong>Dashboard Layout</strong>: Is grid suitable? Or should I lay things out in html/css? </li>
</ol>

<p>If grid can do this easily enough, do you know of any good resources for learning how to us it? I've read the manual but I'm not finding it too helpful. I've seen the LearnR blog's <a href=""http://learnr.wordpress.com/2009/04/09/ggplot2-sales-dashboard/"" rel=""nofollow noreferrer"">ggplot2 sales dashboard</a> (it uses grid) and I'm having trouble understanding the grid and layout part of things. </p>

<p><a href=""http://img251.imageshack.us/img251/1029/fewciodashboard800.png"" rel=""nofollow noreferrer"">dasboard sample http://img251.imageshack.us/img251/1029/fewciodashboard800.png</a></p>
"
2209258,258334,2010-02-05T18:01:59Z,27,Merge several data.frames into one data.frame with a loop,"<p>I am trying to <code>merge</code> several <code>data.frames</code> into one <code>data.frame</code>. Since I have a whole list of files I am trying to do it with a loop structure.</p>

<p>So far the loop approach works fine. However, it looks pretty inefficient and I am wondering if there is a faster and easier approach.</p>

<p>Here is the scenario:
I have a directory with several <code>.csv</code> files. Each file contains the same identifier which can be used as the merger variable. Since the files are rather large in size I thought to read each file one at a time into R instead of reading all files at once.
So I get all the files of the directory with <code>list.files</code> and read in the first two files. Afterwards I use <code>merge</code> to get one <code>data.frame</code>.</p>

<pre><code>FileNames &lt;- list.files(path="".../tempDataFolder/"")
FirstFile &lt;- read.csv(file=paste("".../tempDataFolder/"", FileNames[1], sep=""""),
             header=T, na.strings=""NULL"")
SecondFile &lt;- read.csv(file=paste("".../tempDataFolder/"", FileNames[2], sep=""""),
              header=T, na.strings=""NULL"")
dataMerge &lt;- merge(FirstFile, SecondFile, by=c(""COUNTRYNAME"", ""COUNTRYCODE"", ""Year""),
             all=T)
</code></pre>

<p>Now I use a <code>for</code> loop to get all the remaining <code>.csv</code> files and <code>merge</code> them into the already existing <code>data.frame</code>:</p>

<pre><code>for(i in 3:length(FileNames)){ 
ReadInMerge &lt;- read.csv(file=paste("".../tempDataFolder/"", FileNames[i], sep=""""),
               header=T, na.strings=""NULL"")
dataMerge &lt;- merge(dataMerge, ReadInMerge, by=c(""COUNTRYNAME"", ""COUNTRYCODE"", ""Year""),
             all=T)
}
</code></pre>

<p>Even though it works just fine I was wondering if there is a more elegant way to get the job done?</p>
"
2218395,256662,2010-02-07T21:23:28Z,15,"How do you compare the ""similarity"" between two dendrograms (in R)?","<p>I have two dendrograms which I wish to compare to each other in order to find out how ""similar"" they are. But I don't know of any method to do so (let alone a code to implement it, say, in R).</p>

<p>Any leads ?</p>

<p><strong>UPDATE</strong> (2014-09-13):</p>

<p>Since asking this question, I have written an R package called <a href=""http://cran.r-project.org/web/packages/dendextend/"" rel=""noreferrer"">dendextend</a>, for the visualization, manipulation and <strong>comparison</strong> of dendrogram. This package is on <a href=""http://cran.r-project.org/web/packages/dendextend/"" rel=""noreferrer"">CRAN</a> and comes with a <a href=""http://cran.r-project.org/web/packages/dendextend/vignettes/introduction.html"" rel=""noreferrer"">detailed vignette</a>. It includes functions such as <code>cor_cophenetic</code>, <code>cor_bakers_gamma</code> and <code>Bk</code> / <code>Bk_plot</code>. As well as a <code>tanglegram</code> function for visually comparing two trees.</p>
"
2219626,212593,2010-02-08T04:44:43Z,3,"Using ggplot, how to have the x-axis of time series plots set up automatically?","<p>Is there a way of plotting a univariate time series of class ""ts"" using ggplot that sets up the time axis automatically? I want something similar to plot.ts() of base graphics.</p>

<p>Also it seems to me that the coarsest time granularity is a day. Is that right? In my work I have to work with monthly and quarterly data and assigning each observation to the beginning/end of the month/quarter would cause the observations to be irregularly spaced horizontally since months/quarters are of unequal length. That may make more sense, but my audience is used to seeing months/quarters regularly spaced.</p>

<p>I know I can solve all of the above by manually setting up the x-axis as a time axis or as a numeric axis with my own labels. I am specifically looking for a method that does this automatically by using the time information in the ts object..</p>
"
2224196,218244,2010-02-08T19:17:16Z,3,Identifying unique terms from list of character vectors,"<p>I have a list of character vectors in R that represents sets of cooccuring words. From this, I would like to extract a character vector capturing all the words that appear in the list of character vectors. I think I know how to efficiently go from a character vector of words to a unique character vector of the words that appeared. What I don't know how to do is efficiently collapse the list of character vectors into a single character vector.  Any tips on how to approach this or the overall problem efficiently would be great appreciated! </p>
"
2226526,43729,2010-02-09T03:16:45Z,5,Generating dendrograms from genealogy data in R,"<p>Is there any way to generate a dendrogram where each level of the graph represents a generation and only sons of the same father are connected at each level?</p>

<p>I'm attempting to use R's hclust and plot functions to generate a dendrogram of father-son lineage.  The desired result is a dendrogram where each generation of sons is placed on the same line, under their father.  </p>

<p>I was hoping that hclust and the ""complete"" method would allow me to use the dissimilarity matrix to assign sons of the same father a 0 dissimilarity score and then be placed on the same hierarchical level, exclusive from any other entities in the dataset.  This doesn't work, there are sons of different generations on the same level.</p>

<p>Any help is greatly appreciated!</p>

<p>Here is some example data:</p>

<p>father,son<br>
A,C<br>
A,D<br>
A,E<br>
B,F<br>
B,G<br>
C,H<br>
C,I<br>
F,J<br>
F,K<br>
G,L  </p>

<p>Agent A has three sons: C, D, and E; and two grandsons through C: H and I.</p>

<p>Agent B has two sons: F and G; and a total of three grandsons: J, K, and L.</p>
"
2226867,143476,2010-02-09T05:04:56Z,16,Can R read from a file through an ssh connection?,"<p>R can read files on a web server using convenient syntax such as</p>

<pre><code>data &lt;- read.delim(""http://remoteserver.com/file.dat"")
</code></pre>

<p>I wonder if there is a way to do something similar with a file on an ssh server with passwordless-ssh already in place?</p>
"
2228544,121332,2010-02-09T11:10:44Z,34,higher level functions in R - is there an official compose operator or curry function?,"<p>I can create a compose operator in R:</p>

<pre><code> `%c%` = function(x,y)function(...)x(y(...)) 
</code></pre>

<p>To be used like this:</p>

<pre><code> &gt; numericNull = is.null %c% numeric
 &gt; numericNull(myVec)
 [2] TRUE FALSE
</code></pre>

<p>but I would like to know if there is an official set of functions to do this kind of thing and other operations such as currying in R.  Largely this is to reduce the number of brackets, function keywords etc in my code.</p>

<p>My curry function:</p>

<pre><code>&gt; curry=function(...){
    z1=z0=substitute(...);z1[1]=call(""list"");
    function(...){do.call(as.character(z0[[1]]),
                          as.list(c(eval(z1),list(...))))}}
&gt; p = curry(paste(collapse=""""))
&gt; p(letters[1:10])
[1] ""abcdefghij""
</code></pre>

<p>This is especially nice for e.g. aggregate:</p>

<pre><code>&gt; df = data.frame(l=sample(1:3,10,rep=TRUE), t=letters[1:10])
&gt; aggregate(df$t,df[""l""],curry(paste(collapse="""")) %c% toupper)
  l    x
1 1  ADG
2 2  BCH
3 3 EFIJ
</code></pre>

<p>Which I find much more elegant and editable than:</p>

<pre><code>&gt; aggregate(df$t, df[""l""], function(x)paste(collapse="""",toupper(x)))
  l    x
1 1  ADG
2 2  BCH
3 3 EFIJ
</code></pre>

<p>Basically I want to know - has this already been done for R?</p>
"
2231993,170352,2010-02-09T19:41:38Z,9,Merging two Data Frames using Fuzzy/Approximate String Matching in R,"<p><strong>DESCRIPTION</strong> </p>

<p>I have two datasets with information that I need to merge. The only common fields that I have are strings that do not perfectly match and a numerical field that can be substantially different </p>

<p>The only way to explain the problem is to show you the data. Here is <a href=""http://bertelsen.ca/R/a.csv"" rel=""nofollow noreferrer"">a.csv</a> and <a href=""http://bertelsen.ca/R/b.csv"" rel=""nofollow noreferrer"">b.csv</a>. I am trying to merge B to A.</p>

<p>There are three fields in B and four in A. Company Name (File A Only), Fund Name, Asset Class, and Assets. So far, my focus has been on attempting to match the Fund Names by replacing words or parts of the strings to create exact matches and then using: </p>

<pre><code>a &lt;- read.table(file = ""http://bertelsen.ca/R/a.csv"",header=TRUE, sep="","", na.strings=F, strip.white=T, blank.lines.skip=F, stringsAsFactors=T) 
b &lt;- read.table(file = ""http://bertelsen.ca/R/b.csv"",header=TRUE, sep="","", na.strings=F, strip.white=T, blank.lines.skip=F, stringsAsFactors=T)
merge(a,b, by=""Fund.Name"") 
</code></pre>

<p>However, this only brings me to about 30% matching. The rest I have to do by hand. </p>

<p>Assets is a numerical field that is not always correct in either and can vary wildly if the fund has low assets. Asset Class is a string field that is ""generally"" the same in both files, however, there are discrepancies. </p>

<p>Adding to the complication are the different series of funds, in File B. For example: </p>

<blockquote>
  <p>AGF Canadian Value </p>
  
  <p>AGF Canadian Value-D</p>
</blockquote>

<p>In these cases, I have to choose the one that is not seried, or choose the one that is called ""A"", ""-A"", or ""Advisor"" as the match. </p>

<p><strong>QUESTION</strong></p>

<p>What would you say is the best approach? This excercise is something that I have to do on a monthly basis and matching them manually is incredibly time consuming. Examples of code would be instrumental. </p>

<p><strong>IDEAS</strong></p>

<p>One method that I think may work is normalizing the strings based on the first capitalized letter of each word in the string. But I haven't been able to figure out how to pull that off using R.</p>

<p>Another method I considered was creating an index of matches based on a combination of assets, fund name, asset class and company. But again, I'm not sure how to do this with R. Or, for that matter, if it's even possible.</p>

<p>Examples of code, comments, thoughts and direction are greatly appreciated!   </p>
"
2232699,135944,2010-02-09T21:34:52Z,40,How to do a data.table merge operation,"<p><em>note: this question and the following answers refer to data.table versions &lt; 1.5.3; v. 1.5.3 was released in Feb 2011 to resolve this issue.</em> see more recent treatment (03-2012): <a href=""https://stackoverflow.com/questions/9914734/translating-sql-joins-on-foreign-keys-to-r-data-table-syntax"">Translating SQL joins on foreign keys to R data.table syntax</a></p>

<hr>

<p>I've been digging through the documentation for the <a href=""http://cran.r-project.org/web/packages/data.table/index.html"" rel=""nofollow noreferrer"">data.table package</a> (a replacement for data.frame that's much more efficient for certain operations), including <a href=""http://files.meetup.com/1406240/Data%20munging%20with%20SQL%20and%20R.pdf"" rel=""nofollow noreferrer"">Josh Reich's presentation on SQL and data.table at the NYC R Meetup</a> (pdf), but can't figure this totally trivial operation out.</p>

<pre><code>&gt; x &lt;- DT(a=1:3, b=2:4, key='a')
&gt; x
     a b
[1,] 1 2
[2,] 2 3
[3,] 3 4
&gt; y &lt;- DT(a=1:3, c=c('a','b','c'), key='a')
&gt; y
     a c
[1,] 1 a
[2,] 2 b
[3,] 3 c
&gt; x[y]
     a b
[1,] 1 2
[2,] 2 3
[3,] 3 4
&gt; merge(x,y)
  a b c
1 1 2 a
2 2 3 b
3 3 4 c
</code></pre>

<p>The docs say ""When [the first argument] is itself a data.table, a join is invoked similar to base::merge but uses binary search on the sorted key."" Clearly this is not the case. Can I get the other columns from y into the result of x[y] with data.tables? It seems like it's just taking the rows of x where the key matches the key of y, but ignoring the rest of y entirely...</p>
"
2233584,142879,2010-02-10T00:34:57Z,73,Does R have an assert statement as in python?,"<p>a statement that checks if something is true and if not prints a given error message and exits</p>
"
2237600,258755,2010-02-10T14:48:03Z,3,How can I plot multiple functions in R?,"<p>Using ggplot, is there a way of graphing several functions on the same plot? I want to use parameters from a text file as arguments for my functions and overlay these on the same plot.</p>

<p>I understand <a href=""https://stackoverflow.com/questions/1853703/plotting-functions-in-r/1853866#1853866"">this</a> but I do not know how to add the visualized function together if I loop through.</p>
"
2239851,270572,2010-02-10T19:50:39Z,3,R-thonic replacement for simple for loops containing a condition,"<p>I'm using R, and I'm a beginner. I have two large lists (30K elements each). One is called <code>descriptions</code> and where each element is (maybe) a tokenized string. The other is called <code>probes</code> where each element is a number. I need to make a dictionary that maps<code>probes</code> to something in <code>descriptions</code>, if that something is there. Here's how I'm going about this:</p>

<pre><code>probe2gene &lt;- list()
for (i in 1:length(probes)){
 strings&lt;-strsplit(descriptions[i]), '//')
 if (length(strings[[1]]) &gt; 1){ 
  probe2gene[probes[i]] = strings[[1]][2]
 }
}
</code></pre>

<p>Which works fine, but seems slow, much slower than the roughly equivalent python:</p>

<pre><code>probe2gene = {}
for p,d in zip(probes, descriptions):
    try:
     probe2gene[p] = descriptions.split('//')[1]
    except IndexError:
     pass
</code></pre>

<p>My question: is there an ""R-thonic"" way of doing what I'm trying to do? The <a href=""http://cran.r-project.org/doc/manuals/R-intro.html#Repetitive-execution"" rel=""nofollow noreferrer"">R manual entry on for loops</a> suggests that such loops are rare. Is there a better solution?</p>

<p>Edit: a typical good ""description"" looks like this:</p>

<pre><code>""NM_009826 // Rb1cc1 // RB1-inducible coiled-coil 1 // 1 A2 // 12421 /// AB070619 // Rb1cc1 // RB1-inducible coiled-coil 1 // 1 A2 // 12421 /// ENSMUST00000027040 // Rb1cc1 // RB1-inducible coiled-coil 1 // 1 A2 // 12421""
</code></pre>

<p>a bad ""description: looks like this</p>

<pre><code>""-----""
</code></pre>

<p>though it can quite easily be some other not-very-helpful string. Each probe is simply a number. The <code>probe</code> and <code>description</code> vectors are the same length, and completely correspond to each other, i.e. <code>probe[i]</code> maps to <code>description[i]</code>.</p>
"
2241290,13969,2010-02-11T00:02:43Z,4,Stacked Area Histogram in R,"<p>I ran a Pig job on a Hadoop cluster that crunched a bunch of data down into something R can handle to do a cohort analysis.  I have the following script, and as of the second to last line I have the data in the format:</p>

<pre><code>&gt; names(data)
[1] ""VisitWeek"" ""ThingAge""    ""MyMetric""
</code></pre>

<p>VisitWeek is a Date.  ThingAge and MyMetric are integers.</p>

<p>The data looks like:</p>

<pre><code>2010-02-07     49  12345
</code></pre>

<p>The script I have so far is:</p>

<pre><code># Load ggplot2 for charting 
library(ggplot2);

# Our file has headers - column names
data = read.table('weekly_cohorts.tsv',header=TRUE,sep=""\t"");

# Print the names
names(data)

# Convert to dates
data$VisitWeek = as.Date(data$VisitWeek)
data$ThingCreation = as.Date(data$ThingCreation)

# Fill in the age column
data$ThingAge = as.integer(data$VisitWeek - data$ThingCreation)

# Filter data to thing ages lt 10 weeks (70 days) + a sanity check for gt 0, and drop the creation week column
data = subset(data, data$ThingAge &lt;= 70, c(""VisitWeek"",""ThingAge"",""MyMetric""))
data = subset(data, data$ThingAge &gt;= 0)

print(ggplot(data, aes(x=VisitWeek, y=MyMetric, fill=ThingAge)) + geom_area())
</code></pre>

<p>This last line does not work.  I've tried lots of variations, bars, histograms, but as usual R docs defeat me.</p>

<p>I want it to show a standard Excel style stacked area chart - one time series for each ThingAge stacked across the weeks in the x axis, with the date on the y axis.  An example of this kind of chart is here: <a href=""http://upload.wikimedia.org/wikipedia/commons/a/a1/Mk_Zuwanderer.png"" rel=""nofollow noreferrer"">http://upload.wikimedia.org/wikipedia/commons/a/a1/Mk_Zuwanderer.png</a></p>

<p>I've read the docs here: <a href=""http://had.co.nz/ggplot2/geom_area.html"" rel=""nofollow noreferrer"">http://had.co.nz/ggplot2/geom_area.html</a> and <a href=""http://had.co.nz/ggplot2/geom_histogram.html"" rel=""nofollow noreferrer"">http://had.co.nz/ggplot2/geom_histogram.html</a> and this blog <a href=""http://chartsgraphs.wordpress.com/2008/10/05/r-lattice-plot-beats-excel-stacked-area-trend-chart/"" rel=""nofollow noreferrer"">http://chartsgraphs.wordpress.com/2008/10/05/r-lattice-plot-beats-excel-stacked-area-trend-chart/</a> but I can't quite make it work for me.</p>

<p>How can I achieve this?</p>
"
2241369,142879,2010-02-11T00:16:58Z,2,installing R packages on ubuntu 8.10,"<p>preface: i'm an os x user coming to linux, so excuse my ignorance in advance</p>

<p>I've installed R using synaptic and now i'm trying to install packages.</p>

<p>I open R then try </p>

<pre><code>install.packages(""some_package"")
</code></pre>

<p>system tries to default to <code>/site-library</code>, then tells me it's not writable, then asks about making a personal library?</p>

<p>Should I just make site-library writable? Or is there something more to this?</p>
"
2241583,84378,2010-02-11T01:16:10Z,2,Manipulating a data frame with contents from a different data frame similar to a SQL join,"<p>Say I have a data frame with the contents:</p>

<pre><code>Trial Person Time
1     John   1.2
2     John   1.3
3     John   1.1
1     Bill   2.3
2     Bill   2.5
3     Bill   2.7
</code></pre>

<p>and another data frame with the contents:</p>

<pre><code>Person Offset
John   0.5
Bill   1.0
</code></pre>

<p>and I want to modify the original frame based on the appropriate value from the second. I could do this easily in any other language or in SQL, and I'm sure I could manage using for loops and what, but with everything else I see in R, I'm guessing it has special syntax to do this as a one-liner. So, if so, how? And if not, could you show how it could be done using loops. I haven't actually got around to learning looping in R yet since it has amazing things to simply extract and manipulate whatever values.</p>

<p>For reference, the output would:</p>

<pre><code>Trial Person Time
1     John   0.7
2     John   0.8
3     John   0.6
1     Bill   1.3
2     Bill   1.5
3     Bill   1.7 
</code></pre>
"
2243046,900119,2010-02-11T08:08:58Z,7,Curve fitting in R using nls,"<p>I'm trying to fit a curve over (the tail of) the following data:</p>

<pre>
 [1]   1   1   1   1   1   1   2   1   2   2   3   2   1   1   4   3   2  11   6   2  16   7  17  36
[25]  27  39  41  33  42  66  92 138 189 249 665 224 309 247 641 777 671 532 749 506 315 292 281 130
[49] 137  91  40  27  34  19   1
</pre>

<p>I'm using the following function in R to accomplish this:</p>

<blockquote>
  <p>nls(y~a<em>x</em>exp(-b*x^2),start=list(a=1,b=1),trace=TRUE)</p>
</blockquote>

<p>However, I'm getting the following error:</p>

<blockquote>
  <p>3650202 :  1 1</p>
  
  <p>Error in numericDeriv(form[[3L]], names(ind), env) :
    Missing value or an infinity produced when evaluating the model</p>
</blockquote>

<p>When using the following, artificial values for x and y, everything works just fine:</p>

<blockquote>
  <p>y=x*exp(-.5*x^2)+rnorm(length(x),0,0.1)</p>
</blockquote>

<pre>
x
  [1] 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90
 [20] 0.95 1.00 1.05 1.10 1.15 1.20 1.25 1.30 1.35 1.40 1.45 1.50 1.55 1.60 1.65 1.70 1.75 1.80 1.85
 [39] 1.90 1.95 2.00 2.05 2.10 2.15 2.20 2.25 2.30 2.35 2.40 2.45 2.50 2.55 2.60 2.65 2.70 2.75 2.80
 [58] 2.85 2.90 2.95 3.00 3.05 3.10 3.15 3.20 3.25 3.30 3.35 3.40 3.45 3.50 3.55 3.60 3.65 3.70 3.75
 [77] 3.80 3.85 3.90 3.95 4.00 4.05 4.10 4.15 4.20 4.25 4.30 4.35 4.40 4.45 4.50 4.55 4.60 4.65 4.70
 [96] 4.75 4.80 4.85 4.90 4.95 5.00
y
  [1] -0.080214106  0.075247488  0.076355116 -0.020087646  0.181314038  0.075832658  0.248303254
  [8]  0.364244010  0.453655908  0.347854869  0.514373164  0.384051249  0.618584696  0.515684390
 [15]  0.534737770  0.609279111  0.618936091  0.534443863  0.739118585  0.677679546  0.526011452
 [22]  0.645645150  0.578274968  0.589619834  0.476186241  0.621638333  0.601663144  0.535981735
 [29]  0.518434367  0.581735107  0.423872948  0.445335110  0.340884242  0.317121065  0.342683141
 [36]  0.278351104  0.402947372  0.429483276  0.276655872  0.108164828  0.389994138  0.372300257
 [43] -0.057320612  0.131271986  0.226212869  0.131171973  0.245970674  0.009926555  0.173465207
 [50]  0.141220590  0.280616078  0.108515613  0.117697407  0.130700771  0.058540888  0.251613512
 [57]  0.168094899 -0.058382571  0.123306762 -0.048605186 -0.010131767  0.076701962 -0.051982924
 [64]  0.058427540  0.144665070  0.063998841 -0.010495697  0.119868854  0.114447318  0.006759691
 [71]  0.025041761 -0.178145771  0.041547126  0.122084819  0.034283141  0.209140060  0.197024853
 [78] -0.005491966 -0.033260219 -0.028123314 -0.005775553 -0.040781462  0.090024896  0.116390743
 [85] -0.017811031  0.094039200 -0.147064060 -0.057249278  0.211587898 -0.066153592  0.032100332
 [92] -0.092756136 -0.125906598  0.136937364  0.046453010  0.002000336 -0.134047101  0.089748847
 [99] -0.019355567 -0.042158950  0.149594368
</pre>

<p>Can anyone point out what I'm doing wrong? Thanks for your help.</p>
"
2247045,37751,2010-02-11T19:17:42Z,38,Chopping a string into a vector of fixed width character elements,"<p>I have an object containing a text string:</p>

<pre><code>x &lt;- ""xxyyxyxy""
</code></pre>

<p>and I want to turn that into a vector with each element containing two letters:</p>

<pre><code>[1] ""xx"" ""yy"" ""xy"" ""xy""
</code></pre>

<p>it seems like the strsplit() should be my ticket, but since I have no regular expression foo, I can't figure out how to make this function chop the string up the way I want it. How should I do this?</p>
"
2247111,258755,2010-02-11T19:27:18Z,3,Evaluating variable within R loop,"<p>I'm trying to iteratively generate some functions using a For Loop:</p>

<pre><code># Create a list to hold the functions
funcs &lt;- list()
funcs[]

# loop through to define functions
for(i in 1:21){

    # Make function name
    funcName &lt;- paste( 'func', i, sep = '' )

    # make function
    func = function(x){x * i}

    funcs[[funcName]] = func

    }
</code></pre>

<p>However, it's not working as I hoped as the i value is not being evaluated within each function. I want to try and define the function to equal x * 1; x * 2; etc, but what I end up with is a function that is x * i; where i is 21.</p>

<p>I tried using the eval() function and that just resulted in x * eval(i) being stored.</p>
"
2248261,155392,2010-02-11T22:28:50Z,5,R - how to use contents of one vector as the symbol in a plot?,"<p>I have a two vectors of numbers of equal length. How do I plot the first vector while using the corresponding element in the second vector as the printing character? (Background: I sorted the first column and the second column holds the original indices. I want to use the indices as the printable character so that I can see which data points are outliers, since each number represents one run of data).</p>

<pre><code> &gt; x
$x
 [1]   25   29   30   34   38  572  700  733  870  879  899  934  982 1054 1135 1258
[17] 1315 1491 1685 1700 2069 2131 2284 3498 3506 4467 4656 5633 6642 8348

$ix
 [1] 23  3 18 30 13  8  4 14 11 17 12 29  9 15 19 16  7  1 20  2  6 28 21 10  5 22 24 26
[29] 25 27
</code></pre>

<p>First vector is x$x, second vector is x$ix (results of calling sort with index.return = TRUE)</p>

<p>I've tried plot(x$x, pch=str(x$ix)) but that treats x$ix numerically. If this were Python I would do something like strings = [str(x) for x in x$ix]. but this is R and I've forgotten most of what I used to know.</p>

<p>I found that you can do as.character(x$ix) in order to get the strings,</p>

<pre><code>&gt; as.character(x$ix)
 [1] ""23"" ""3""  ""18"" ""30"" ""13"" ""8""  ""4""  ""14"" ""11"" ""17"" ""12"" ""29"" ""9""  ""15"" ""19"" ""16""
[17] ""7""  ""1""  ""20"" ""2""  ""6""  ""28"" ""21"" ""10"" ""5""  ""22"" ""24"" ""26"" ""25"" ""27""
</code></pre>

<p>and I can use this as the input to pch.  But only the first character is used (and according to the docs, that's normal).</p>

<p>I know there's a way to do this; I did it in college.  But I can't for the life of me remember how I did it.</p>

<p>Chart without labels:
<a href=""http://i47.tinypic.com/2aep88.png"">alt text http://i47.tinypic.com/2aep88.png</a></p>

<p>Chart with labels, but incorrect:
<a href=""http://i50.tinypic.com/2cicxtu.png"">alt text http://i50.tinypic.com/2cicxtu.png</a></p>
"
2249181,143813,2010-02-12T01:56:36Z,3,getting a hashmap in R using rJava,"<p>I have a plain hashmap with numeric values and would like to retrieve its content, ideally in a list (but that can be worked out). </p>

<p>Can it be done?</p>
"
2249457,258755,2010-02-12T03:13:01Z,3,Is there a way to remove the border of the legend in ggplot2?,"<p>I'm using qplot to plot a function and I want to position the legend within the plot. I've used </p>

<pre><code>opts( legend.position = c(0.7,0.7) )
</code></pre>

<p>to move the legend where I want it to be.</p>

<p>However there is a white border around the legend and that shows up on the gray background. </p>

<p>For example:</p>

<pre><code>library(ggplot2)
x = c(1:20)
y = c(1:20)

p &lt;- qplot(x,y, color = ""blue"")

p &lt;- p + scale_colour_identity(""Example"", breaks=c(""blue""), labels=c(""dots""))

p &lt;- p + opts(legend.position = c(0.6, 0.4))

print(p)
</code></pre>

<p>I would like to know how to remove this border from the legend. Thank you.</p>
"
2253179,258755,2010-02-12T16:11:31Z,5,Using ggplot2 how can I represent a dot and a line in the legend,"<p>Using ggplot2 I am plotting several functions and a series of points. I cannot figure out how to represent the points on the legend. I realize I need to use an aes() function, but I don't fully understand how to do this. I apologize that the example is so long, but I don't know how else to illustrate it.</p>

<pre><code>## add ggplot2
library(ggplot2)

# Declare Chart values
y_label = expression(""y_axis""~~bgroup(""("",val / km^{2},"")""))
x_label = ""x_axis""

#############################
## Define functions
# Create a list to hold the functions
funcs &lt;- list()
funcs[]

# loop through to define functions
for(k in 1:21){

# Make function name
funcName &lt;- paste('func', k, sep = '' )

# make function
func = paste('function(x){exp(', k, ') * exp(x*0.01)}', sep = '')

funcs[[funcName]] = eval(parse(text=func))

}

    # Specify values
    yval = c(1:20)                              
    xval = c(1:20)                                

    # make a dataframe
    d = data.frame(xval,yval)

    # Specify Range
    x_range &lt;- range(1,51)

# make plot
p &lt;-qplot(data = d,
        x=xval,y=yval,        
        xlab = x_label, 
        ylab = y_label,
        xlim = x_range
        )+ geom_point(colour=""green"")


for(j in 1:length(funcs)){

p &lt;- p + stat_function(aes(y=0),fun = funcs[[j]], colour=""blue"", alpha=I(1/5))

}

# make one function red
p &lt;- p + stat_function(fun = funcs[[i]], aes(color=""red""), size = 1) +
    scale_colour_identity("""", breaks=c(""red"", ""green"",""blue""),
    labels=c(""Fitted Values"", ""Measured values"",""All values"")) 

# position legend and make remove frame
p &lt;- p + opts(legend.position = c(0.85,0.7), legend.background = theme_rect(col = 0)) 

print(p)     
</code></pre>

<p>Thank you in advance - I have learned I a lot from this community over the last few days.</p>
"
2254608,155392,2010-02-12T19:40:56Z,3,R - idiomatic way to deal with lists of data frames,"<p>I have 30 runs of data, each stored in a separate CSV file, runi.csv, i = 0:29.</p>

<p>Let's say I want to collect them all into a list.  Best way I know how to do this is</p>

<pre><code>runs = list()
for (i in 1:30) { runs[[i]] = read.csv(paste(""run"", i-1, "".csv"")); }
</code></pre>

<p>Now let's further say that each of these data frames stored in the list has the same column layouts and that I'm interested in the column identified by ""x"" and the column identified by ""y"".</p>

<p>What is the easiest way to plot all 30 runs' worth of (x, y) pairs?  Here's how I would currently do it (and I feel there <em>must</em> be a better way):</p>

<pre><code>xList = list()
yList = list()
for (i in 1:30) { xList[[i]] = runs[[i]]$x; yList[[i]] = runs[[i]]$y; }
matplot(x=as.data.frame(xList), y=as.data.frame(yList))
</code></pre>

<p>This gets even more painful when I'm trying to do transformations to the data; I can't figure out how to apply a function to a specific column of each data frame stored in a list.</p>

<p>Any help here would be extremely helpful.</p>
"
2254701,84378,2010-02-12T19:56:39Z,0,Performing binary function to a column in a data frame,"<p>Say I have a data frame with the contents:</p>

<pre><code>Trial Person 
1     John   
2     John   
3     John   
4     John
1     Bill 
2     Bill
3     Bill
4     Bill
</code></pre>

<p>and I want to transform this to</p>

<pre><code>Trial Person Day
1     John   1
2     John   1
3     John   2
4     John   2
1     Bill   1
2     Bill   1
3     Bill   2
4     Bill   2
</code></pre>

<p>I can very easily make it</p>

<pre><code>Trial Person Day
1     John   TRUE
2     John   TRUE
3     John   FALSE
4     John   FALSE
1     Bill   TRUE
2     Bill   TRUE
3     Bill   FALSE
4     Bill   FALSE
</code></pre>

<p>by doing <code>d$day=d$trial&lt;3</code> but how can I get to what I want?</p>
"
2254986,142879,2010-02-12T20:41:57Z,28,How to subtract days in R?,"<p>I'm trying to build folders to store data pulls. I want to label the folders with the day of that data in the pull.</p>

<p>Ex. I pull 5 days ago data from mysql i want to name the folder the date from 5 days ago.</p>

<p>MySQL can easily handle date arithmetic. I'm not sure exactly how R does it. Should i just subtract the appropriate number of seconds in POSIXct and then convert to POSIXlt to name the folder MM_DD_YYYY?</p>

<p>Or is there a better way?</p>
"
2258511,37751,2010-02-13T18:04:37Z,7,R: serialize objects to text file and back again,"<p>I have a process in R that creates a bunch of objects, serializes them, and puts them into plain text files. This seemed like a really good way to handle things since I am working with Hadoop and all output needs to stream through stdin and stdout. </p>

<p>The problem I am left with is how to read these objects out of the text file and back into R on my desktop machine. Here's a working example that illustrates the challenge:</p>

<p>Let's create a tmp file and write a single object into it. This object is just a vector:</p>

<pre><code>outCon &lt;- file(""c:/tmp"", ""w"")
mychars &lt;- rawToChar(serialize(1:10, NULL, ascii=T))
cat(mychars, file=outCon)
close(outCon)
</code></pre>

<p>The mychars object looks like this:</p>

<pre><code>&gt; mychars
[1] ""A\n2\n133633\n131840\n13\n10\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n""
</code></pre>

<p>when written to the text file it looks like this:</p>

<pre><code>A
2
133633
131840
13
10
1
2
3
4
5
6
7
8
9
10
</code></pre>

<p>I'm probably overlooking something terribly obvious, but how do I read this file back into R and unserialize the object? When I try scan() or readLines() both want to treat the new line characters as record delimiters and I end up with a vector where each element is a row from the text file. What I really want is a text string with the whole contents of the file. Then I can unserialize the string. </p>

<p>Perl will read line breaks back into a string, but I can't figure out how to override the way R treats line breaks. </p>
"
2258784,170792,2010-02-13T19:46:32Z,65,List of ggplot2 theme options?,"<p>After some research I found the way to prevent an uninformative legend from displaying</p>

<pre><code>... + theme(legend.position = ""none"")
</code></pre>

<p>Where can I find all of the available <code>theme</code> options and their default values for ggplot2?</p>
"
2258844,60628,2010-02-13T20:02:10Z,5,"In R, how do I set the first values of a long vector to the values of a shorter one?","<p>In <code>R</code>, how can I overwrite the first values of a long vector with values obtained from a file, where the file contains possibly fewer values?</p>

<p>Example:</p>

<pre><code># fill with n=100 values
vec1 &lt;- runif(100)

# read m values, where m &lt;= n
vec2 &lt;- scan(""myfile"", sep=""\n"")

# now want to set the first m values of vec1 
# to the values in vec2
</code></pre>

<p>I could walk through <code>vec2</code> and copy the values into <code>vec1</code>, but I think there should be a more efficient way?</p>
"
2260147,3815,2010-02-14T04:34:37Z,5,Transposing JSON list-of-dictionaries for analysis in R,"<p>I have experimental data expressed as dicts of key-value pairs for each experiment. A set of related experiments is serialized as a list of these dicts in JSON. This is parseable in in R via the <code>rjson</code> package, but the data is loaded in a form which is challenging to analyze </p>

<pre><code>data &lt;- fromJSON('[{""k1"":""v1"",""k2"":""v2""}, {""k1"":""v3"",""k2"":""v4""}]')
</code></pre>

<p>yields</p>

<pre><code>[[1]]
[[1]]$k1
[1] ""v1""

[[1]]$k2
[1] ""v2""


[[2]]
[[2]]$k1
[1] ""v3""

[[2]]$k2
[1] ""v4""
</code></pre>

<p>Attempting to turn this into a <code>data.frame</code> directly with <code>as.data.frame(data)</code> yields:</p>

<pre><code>  k1 k2 k1.1 k2.1
1 v1 v2   v3   v4
</code></pre>

<p>clearly viewing the the sequence of key/value pairs across all experiments as a flat 1-dimensional list.</p>

<p>What I want is a more conventional table with a row for each experiment, and a column for each unique key:</p>

<pre><code>  k1 k2
1 v1 v2
2 v3 v4
</code></pre>

<p>How can I cleanly express this transform in R?</p>
"
2261079,258334,2010-02-14T12:44:02Z,269,How to trim leading and trailing whitespace in R?,"<p>I am having some troubles with leading and trailing whitespace in a data.frame.
Eg I like to take a look at a specific <code>row</code> in a <code>data.frame</code> based on a certain condition:</p>

<pre><code>&gt; myDummy[myDummy$country == c(""Austria""),c(1,2,3:7,19)] 

[1] codeHelper     country        dummyLI    dummyLMI       dummyUMI       
[6] dummyHInonOECD dummyHIOECD    dummyOECD      
&lt;0 rows&gt; (or 0-length row.names)
</code></pre>

<p>I was wondering why I didn't get the expected output since the country Austria obviously existed in my <code>data.frame</code>. After looking through my code history and trying to figure out what went wrong I tried:</p>

<pre><code>&gt; myDummy[myDummy$country == c(""Austria ""),c(1,2,3:7,19)]
   codeHelper  country dummyLI dummyLMI dummyUMI dummyHInonOECD dummyHIOECD
18        AUT Austria        0        0        0              0           1
   dummyOECD
18         1
</code></pre>

<p>All I have changed in the command is an additional whitespace after Austria. </p>

<p>Further annoying problems obviously arise. Eg when I like to merge two frames based on the country column. One <code>data.frame</code> uses <code>""Austria ""</code> while the other frame has <code>""Austria""</code>. The matching doesn't work.</p>

<ol>
<li>Is there a nice way to 'show' the whitespace on my screen so that i am aware of the problem? </li>
<li>And can I remove the leading and trailing whitespace in R?</li>
</ol>

<p>So far I used to write a simple <code>Perl</code> script which removes the whitespace but it would be nice if I can somehow do it inside R.</p>
"
2266200,192377,2010-02-15T13:28:27Z,9,Where can I find useful R tutorials with various implementations?,"<p>I'm using <a href=""http://www.r-project.org/"" rel=""nofollow noreferrer""><strong>R</strong></a> language and the manuals on the R site are really informative. However, I'd like to see some more examples and implementations with R which can help me develop my knowledge faster. Any suggestions?</p>
"
2266408,180626,2010-02-15T14:06:12Z,2,How can I load my .RProfile using Textmate's R Bundle,"<p>This question is for those of you who happen to use R, on a Mac, in combination with Macromate's [Textmate](http://macromates.com/) text editor and the ""R"" Bundle. All of which are nifty, needless to say, but that's beside the point for now :-)</p>

<p>I've got a .RProfile file sitting in my default ""~"" startup directory, and it's got a number of useful functions in it I like to have access to when writing R scripts. But I also use Textmate for most of my writing, and the cmd-R functionality to to run my scripts within Textmate.</p>

<h3>At the moment, I don't know how to tell Textmate where my .Rprofile is.</h3>

<p>Is there a way--most likely through Textmate's Bundle settings--that I can point Textmate to my .RProfile so I don't have to write my functions into every script on a per-script basis?</p>

<p>OR</p>

<p>Is it actually better to include any custom functions in any script I write, so that anyone with a basic R setup can source and run my scripts?</p>

<p>I feel like I must be missing a dead-easy setting or config file here within either Textmate or the R environment it calls to run my scripts.</p>

<p>Thanks so much in advance!</p>
"
2269084,170408,2010-02-15T21:32:28Z,6,Handling NA values in apply and unique,"<p>I have a 114 row by 16 column data frame where the rows are individuals, and the columns are either their names or NA. For example, the first 3 rows looks like this:</p>

<pre><code>            name name.1      name.2 name.3       name.4 name.5       name.6 name.7       name.8 name.9       name.10 name.11       name.12 name.13        name.14 name.15
1           &lt;NA&gt;   &lt;NA&gt;        &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;   &lt;NA&gt;      Aanestad    &lt;NA&gt;      Aanestad    &lt;NA&gt;       Aanestad    &lt;NA&gt;
2           &lt;NA&gt;   &lt;NA&gt;        &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;   &lt;NA&gt;     Ackerman   &lt;NA&gt;      Ackerman    &lt;NA&gt;      Ackerman    &lt;NA&gt;       Ackerman    &lt;NA&gt;
3           &lt;NA&gt;   &lt;NA&gt;        &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;   &lt;NA&gt;      Alarcon   &lt;NA&gt;      Alarcon   &lt;NA&gt;       Alarcon    &lt;NA&gt;       Alarcon    &lt;NA&gt;           &lt;NA&gt;    &lt;NA&gt;
</code></pre>

<p>I want to generate a list (if multiple unique names per row) or vector (if only one unique name per row) of all the unique names, with length 114.</p>

<p>When I try <code>apply(x,1,unique)</code> I get a 2xNcol array where sometimes the first row cell is NA and sometimes the second row cell is NA.</p>

<pre><code>    [,1]       [,2]       [,3]      [,4]     [,5]      [,6]      [,7]    [,8]   [,9]    
[1,] NA         NA         NA        NA       ""Alquist"" NA        ""Ayala"" NA     NA      
[2,] ""Aanestad"" ""Ackerman"" ""Alarcon"" ""Alpert"" NA        ""Ashburn"" NA      ""Baca"" ""Battin""
</code></pre>

<p>When what I'd like is just:</p>

<pre><code>Aanestad
Ackerman
Alarcon
...
</code></pre>

<p>I can't seem to figure out how to apply unique() while ignoring NA. na.rm, na.omit etc don't seem to work. I feel like I'm missing something real simple ...</p>

<p>Thanks!</p>
"
2270201,191547,2010-02-16T01:59:23Z,4,How to get geom_vline and facet_wrap from ggplot2 to work inside a function,"<p>I'm using ggplot2 to explore the effects of different military operations on murder rates. To show the effect I draw a vertical line when the operation occurred and a smoothed line of the murder rate before and after the operation. </p>

<p>I've written a facet_wrap plot to show this for a whole bunch of counties. It works beautifully, but when converted to a function I get an error when using a local variable to draw the vertical line. </p>

<p>Here's some example code:</p>

<pre><code>drawTS &lt;- function(df, dates, text) {
    p &lt;- ggplot(df, aes(date, murders)) +
      facet_wrap(~ county, ncol = 1,
                 scale=""free_y"") +
      scale_x_date() +
      geom_smooth(aes(group = group), se = FALSE)
    for(i in 1:length(dates)) {
      #If it's not a global variable I get an object not found error
      temp[i] &lt;&lt;- dates[i]
      p &lt;- p + geom_text(aes(x,y), label = text[i],
                  data = data.frame(x = dates[i], y = -10),
                  size = 3, hjust = 1, vjust = 0) +
           #Here's the problem
           geom_vline(xintercept=temp[i], alpha=.4)
    }
    p
}

library(ggplot2)
df &lt;- data.frame(date = rep(seq(as.Date(""2007/1/01""),
                          length=36, by='1 month'),4),
               murders = round(runif(36*4) * 100),
               county = rep(rep(factor(1:4),9),each=4),
               group = rep(c(rep(1,6), rep(2,12),rep(3,18))), each=4)
dates &lt;- c(as.Date(""2007/6/15""), as.Date(""2008/6/15""))
temp &lt;- c()
drawTS(df, dates, c(""Op 1"",""Op 2""))
</code></pre>

<p>There's no error with the global variable, but it looks ugly.</p>

<p>If instead of the <code>temp[i]</code> variable I use <code>dates[i]</code> inside <code>geom_vline()</code>, I get this: </p>

<blockquote>
  <p><em>Error in NextMethod(""["") : object 'i' not found</em></p>
</blockquote>

<p>If I wrap the variable <code>dates[i]</code> in <code>aes()</code>, I get: </p>

<blockquote>
  <p><em>Error in eval(expr, envir, enclos) : object 'county' not found</em></p>
</blockquote>

<p>Anybody know how to fix this?</p>
"
2274186,900119,2010-02-16T16:00:14Z,3,plot line over last part of barplot,"<p>I have a barplot for which the second half should fit to this formula:
<code>y~a<em>x</em>exp(-b*x^2)</code>. Now I want to plot the entire barplot and display the fitted model over the last part of the barplot as it only holds for that part. However, I cannot find a way to display the line-graph only over the second half. If I just do something like</p>

<pre><code>
submitted=c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 3L, 2L, 1L, 1L, 4L, 
3L, 2L, 11L, 6L, 2L, 16L, 7L, 17L, 36L, 27L, 39L, 41L, 33L, 42L, 
66L, 92L, 138L, 189L, 249L, 665L, 224L, 309L, 247L, 641L, 777L, 
671L, 532L, 749L, 506L, 315L, 292L, 281L, 130L, 137L, 91L, 40L, 
27L, 34L, 19L, 1L)
x=seq(0:(length(submitted)-1))
y1=rs$submitted[30:(length(submitted)-1)]
x1=seq(0:(length(y1)-1))
fit1=nls(y1~a*x1*exp(-b*x1^2),start=list(a=500,b=.01),trace=TRUE)
barplot(submitted,names.arg=x, las=2, cex.axis=0.8, cex=0.8)
lines(predict(fit1))
</code></pre>

<p>The line is displayed, but in the wrong position. So how can I control where the line is drawn?</p>
"
2274487,256662,2010-02-16T16:34:17Z,4,What is the easiest way to install a R web application through RApache?,"<p>I use windows XP and R for my desktop use. And a shared hosting account (at some company) for my web hosting needs.</p>

<p>I wish to create an R web application and I understand that one such way is by using R with Apache through <a href=""http://biostat.mc.vanderbilt.edu/rapache/"" rel=""nofollow noreferrer"">RApache</a> , but since my current shared hosting plan doesn't allow me to install RApache I am a bit stuck.</p>

<p>So... (and here's my question) what would be the easiest/fastest/cost-effective way to get started?</p>

<ul>
<li><p>Buying a more expensive hosting package ?</p></li>
<li><p>Hosting the thing myself? (on windows ?!)</p></li>
<li><p>switch to some other hosting company that permits the use of RApache?</p></li>
</ul>

<p>Any suggestion will be most helpful.</p>
"
2275896,274686,2010-02-16T20:00:04Z,124,Is R's apply family more than syntactic sugar?,"<p>...regarding execution time and / or memory.</p>

<p>If this is not true, prove it with a code snippet. Note that speedup by vectorization does not count. The speedup must come from <code>apply</code> (<code>tapply</code>, <code>sapply</code>, ...) itself.</p>
"
2278951,182378,2010-02-17T07:22:28Z,4,Frequencies of all subsequences of size 3 in a given 0-1 sequnce?,"<p>Given data     </p>

<pre><code>s&lt;-c(1,0,0,0,1,0,0,0,0,0,1,1,1,0,0)
</code></pre>

<p>I can count 1s and 0s with table or ftable</p>

<pre><code>ftable(s,row.vars =1:1)
</code></pre>

<p>and the totals of 11s,01s,10s,00s occurred in s with</p>

<pre><code>table(s[-length(s)],s[-1]).
</code></pre>

<p>What would be the clever way to count occurrences of 111s, 011s, ..., 100s, 000s? Ideally, I want a table of counts x like </p>

<pre><code>   0 1
11 x x
01 x x
10 x x
00 x x
</code></pre>

<p>Is there a general way to compute the total occurrences for all possible sub-sequences of length k=1,2,3,4, ... occurred in data? Thanks. </p>
"
2280276,192377,2010-02-17T11:46:52Z,8,Vector vs. Data frame in R,"<p>What is the difference between a vector and a data frame in R? Under what circumstances vectors should be converted to data frames?</p>
"
2280724,192377,2010-02-17T12:57:13Z,2,Upgrading Tinn-R,"<p>I'm using Tinn-R version 2.2.0.2 and I want to upgrade to the latest version 2.3.4.4. I couldn't find any upgrade options in the menus of Tinn-R. So my question is: Is it safe to download and just install the new version? Will it overwrite my current Tinn-R settings?</p>
"
2281353,192377,2010-02-17T14:20:08Z,40,Row names & column names in R,"<p>Do the following function pairs generate exactly the same results?</p>

<p>Pair 1) <code>names()</code> &amp; <code>colnames()</code>  </p>

<p>Pair 2) <code>rownames()</code> &amp; <code>row.names()</code></p>
"
2281561,144297,2010-02-17T14:46:18Z,5,Random sample from given bivariate discrete distribution,"<p>Suppose I have a bivariate discrete distribution, i.e. a table of probability values P(X=i,Y=j), for i=1,...n and j=1,...m. How do I generate a random sample (X_k,Y_k), k=1,...N from such distribution? Maybe there is a ready R function like:</p>

<pre><code>sample(100,prob=biprob)
</code></pre>

<p>where biprob is 2 dimensional matrix? </p>

<p>One intuitive way to sample is the following. Suppose we have a data.frame</p>

<pre><code>dt=data.frame(X=x,Y=y,P=pij)
</code></pre>

<p>Where x and y come from</p>

<pre><code>expand.grid(x=1:n,y=1:m)
</code></pre>

<p>and pij are the P(X=i,Y=j). </p>

<p>Then we get our sample (Xs,Ys) of size N, the following way:</p>

<pre><code>set.seed(1000) 
Xs &lt;- sample(dt$X,size=N,prob=dt$P)
set.seed(1000)
Ys &lt;- sample(dt$Y,size=N,prob=dt$P)
</code></pre>

<p>I use set.seed() to simulate the ""bivariateness"". Intuitively I should get something similar to what I need. I am not sure that this is correct way though. Hence the question :) </p>

<p>Another way is to use Gibbs sampling, marginal distributions are easy to compute. </p>

<p>I tried googling, but nothing really relevant came up.</p>
"
2282892,256662,2010-02-17T17:23:43Z,5,How can Notepad++ be extended as an IDE for R?,"<p>I am working with NppToR as an extension allowing the use of notepad++ to be an IDE for R.</p>

<p>But there are a few features I didn't yet see implemented (I compiled the list from another IDE solution, which is not open source) :</p>

<p><strong>Object Browser</strong> - Allow users to see all the data and function objects that are available, including those in loaded and installed R packages.  Context menus provide the capability to quickly edit and plot data or load a package.</p>

<p><strong>Full-featured Visual Debugger</strong> - Debug R scripts, with step-in, step-over, and step-out capability, allowing users to inspect and modify R objects as they are debugging</p>

<p><strong>A Visual Solution Explorer</strong> - Organize, view, add, remove, rearrange, and deploy R scripts. Users can create their own Project Templates for automatic creation of a set of customized scripts for a new R project. Dockable, Floating, and Tabbed Tool Windows. for Creating personally customized workspaces.</p>

<p><strong>Enhanced Help</strong> - Complete search capabilities and hover-over tooltips for functions and data objects.</p>

<p><strong>R Code Snippets</strong> - Automatically generate fill-in-the-blank sections of R code for a variety of analyses. Tooltip help gives guidance in filling out the snippet.</p>

<p>Any Idea on how to get some of these already in notepad++ through some other noteps++ extensions or R packages ?</p>

<p>Thanks,
Tal</p>
"
2284446,218244,2010-02-17T21:12:22Z,44,Organizing R Source Code,"<p>All,</p>

<p>I am starting to write object-oriented R code for the first time and anticipate having multiple R files with dependencies in between.  I'm new to R and have not yet wrote anything outside of a single massive script to test ideas.  Are there resources online that give tips on how one ought to organize code?  Short of descriptions on how to build packages, I'm failing to find such guidance.  At this point, I just want to organize the code in such a way that it makes loading and interacting with the collection of routines as straightforward as possible.  </p>

<p>Appreciate any guidance you can provide.  </p>

<p>Chris</p>
"
2286085,256662,2010-02-18T03:22:47Z,3,Plotting of multiple comparisons?,"<p>When one wishes to compare (test) multiple groups (as is the case, for example, when doing anova), one is confronted with the issue of multiple comparisons. The same applys if we wish to plot the comparisons.</p>

<p>My question is thus, <strong>what tools (in R) do you know of that allow plotting that reflects multiple comparisons?</strong></p>

<p>Currently, I know of only two (although I am sure there are more):</p>

<ol>
<li>TukeyHSD( ) combined with plot( )</li>
<li>The way boxplot chooses the ""notches""</li>
</ol>
"
2286831,256662,2010-02-18T06:59:11Z,19,"How do you combine ""Revision Control"" with ""Workflow"" for R?","<p>I remember coming across R users writing that they use ""Revision control"" (<a href=""https://stackoverflow.com/questions/1056912/source-control-vs-revision-control"">e.g: ""Source control""</a>), and I am curious to know: How do you combine ""Revision control"" with your statistical analysis workflow?</p>

<p>Two (very) interesting discussions talk about how to deal with the workflow. But neither of them refer to the revision control element:</p>

<ul>
<li><a href=""https://stackoverflow.com/questions/1266279/how-to-organize-large-r-programs"">How to organize large R programs?</a></li>
<li><a href=""https://stackoverflow.com/questions/1429907/workflow-for-statistical-analysis-and-report-writing"">Workflow for statistical analysis and report writing</a></li>
</ul>

<p><strong>A Long Update To The Question</strong>: Following some of the people's answers, and Dirk's question in the comment, I would like to direct my question a bit more.</p>

<p>After reading the Wiki article about ""<a href=""http://en.wikipedia.org/wiki/Revision_control"" rel=""nofollow noreferrer"">revision control</a>"" (which I was previously not familiar with), it was clear to me that when using revision control, what one does is to build a <strong>development structure</strong> of his code. This structure either leads to a ""final product"" or to several branches.</p>

<p>When building something like, let's say, a website. There is usually one end product you work towards (the website), with some prototypes along the way.</p>

<p>But when doing a statistical analysis, the work (to my view) is different. Sometimes you know where you want to get to. But more often, you explore. Explore cleaning the dataset. Explore different methods for statistical analysis, and ask various questions of your data (and I am writing this, knowing how Frank Harrell, and other experience statisticians feels about <a href=""http://en.wikipedia.org/wiki/Data_dredging"" rel=""nofollow noreferrer"">Data dredging</a>).</p>

<p>That is why the workflow question with statistical programming is (in my view) a serious and deep question, raising many issues, The simpler ones are technical:</p>

<ul>
<li>Which revision control software do you use (and why) ?</li>
<li>Which IDE do you use(and why) ? 
The more interesting question are about work process:</li>
<li>How do you structure your files?</li>
<li>What do you keep as a separate file and what as a revision? or asking in a different way - What should be a ""branch"" and what should be a ""sub project"" in your code? For example: When starting to explore your data, should a plot be creating and then erased because it didn't lead any where (but kept as a revision) or should there be a backup file of that path?</li>
</ul>

<p>How <strong>you</strong> solve this tension was my initial curiosity. The second question is ""what might I be missing?"". What rules (of thumb) should one follow so to avoid common pitfalls doing statistical programming with version control?</p>

<p>In my <strong>intuition</strong>, I feel that statistical programming is inherently different then software development (I am writing this without being a real expert in statistical programming, and even less so in software development). That's way I am unsure which of the lessons I have read here about version control would be applicable.</p>

<p>Thanks a lot,
Tal</p>
"
2287374,275913,2010-02-18T09:04:23Z,2,"Ellipsis expansion in nested functions: Error ""..3 used in an incorrect context, no ... to look in""","<p>I have the following code snippet:</p>

<pre><code>require(lattice)
f.barchart &lt;- function(...) {
    barchart(...,
        panel = function(x, y, ...) {
            panel.barchart(x, y, ...)
        }
    )
}

x &lt;- data.frame(a = c(1,1,2,2), b = c(1,2,3,4), c = c(1,2,2,1))
f.barchart(a ~ b, data = x, groups = c)
</code></pre>

<p>Which results in the following error being thrown:</p>

<pre><code>..3 used in an incorrect context, no ... to look in
</code></pre>

<p>When I use the following definition:</p>

<pre><code>f.barchart &lt;- function(...) {
    substitute(barchart(...,
        panel = function(x, y, ...) {
            panel.barchart(x, y, ...)
        }
    ))
}
</code></pre>

<p>I get:</p>

<pre><code>barchart(a ~ b, data = x, groups = c,
    panel = function(x, y, ...) {
        panel.barchart(x, y, a ~ b, data = x, groups = c)
    })
</code></pre>

<p>I'm not sure if this is the cause of above error but this would mean
that the ellipsis in panel.barchart gets wrongly expanded with the
contents of the arguments given to f.barchart and not the panel
function.</p>

<p>Is there a way to avoid this problem? How can I make the function
work? </p>
"
2287616,192377,2010-02-18T09:48:37Z,72,Controlling number of decimal digits in print output in R,"<p>There is an option in R to get control over digit display. For example:</p>

<pre><code>options(digits=10)
</code></pre>

<p>is supposed to give the calculation results in 10 digits till the end of R session. In the help file of R, the definition for digits parameter is as follows:</p>

<blockquote>
  <p>digits: controls the number of digits
  to print when printing numeric values.
  It is a suggestion only. Valid values
  are <strong>1...22</strong> with default <strong>7</strong></p>
</blockquote>

<p>So, it says this is a suggestion only. What if I like to always display 10 digits, not more or less?</p>

<p>My second question is, what if I like to display more than 22 digits, i.e. for more precise calculations like 100 digits? Is it possible with base R, or do I need an additional package/function for that?</p>

<p><strong>Edit:</strong> Thanks to jmoy's suggestion, I tried <code>sprintf(""%.100f"",pi)</code> and it gave</p>

<pre><code>[1] ""3.1415926535897931159979634685441851615905761718750000000000000000000000000000000000000000000000000000""
</code></pre>

<p>which has 48 decimals. Is this the maximum limit R can handle? Actually pi has an infinite number of decimals.</p>
"
2288485,236703,2010-02-18T12:17:58Z,163,How to convert a data frame column to numeric type?,"<p>How do you convert a data frame column to a numeric type?</p>
"
2294163,144601,2010-02-19T05:01:14Z,5,Including model specifications in xtable(anova(...)),"<p>I have a bunch of loglinear models, which, for our purposes will just be <code>glm()</code> objects called <code>mx, my, mz</code>.  I want to get a nicely-formatted <code>xtable</code> of the analysis of deviance, so naturally I would want to perform <code>xtable(anova(mx, my, mz, test = ""Chisq""))</code>.</p>

<p>The vanilla output of <code>xtable</code>, however, doesn't include the model specifications.  I'd like to include those for all the ANOVA tests I'm running, so if there is not a param I'm missing that does this I'll probably just have to hack up my own solution.  But looking over the help page, there doesn't seem to be an easy way to include the model specifications.  </p>

<p>Any thoughts?  Alternatives?</p>

<p>If it helps this was done in 2.9.1 with xtable 1.5-5.</p>
"
2296325,NA,2010-02-19T12:50:46Z,3,How to upload an image to SQL Server in R,"<p>I am creating some graphs which I want to update into a database table. The procedure I am following is:</p>

<ol>
<li>create the graphs as a png/jpeg file.</li>
<li>Read that file as a binary vector</li>
<li>sqlUpdate</li>
</ol>

<p>My code for steps 2 &amp; 3:</p>

<pre><code>  pngfile &lt;- file(&lt;filename&gt;, ""rb"")
  N &lt;- 1e6
  repeat{
    pngfilecontents &lt;- readBin(pngfile, what=""raw"", n=N)
    if(length(pngfilecontents) == N) N &lt;- 5 * N else break
  }
  close(pngfile)
</code></pre>

<p>There is a table df_DemandPatternMaster in the database with primary key DemandPatternID, with appropriate record in place with NULL value in pngFile field.</p>

<pre><code>  update.query &lt;- ""update df_DemandPatternMaster set ""
  update.query &lt;- paste( update.query, "" pngFile = '"", serialize(pngfilecontents, NULL) , ""' where DemandPatternID = "", , sep="""")
  d &lt;- sqlQuery(connection, update.query)
</code></pre>

<p>I end up inserting only a byte of data. The reason it seems is that paste sees the serialized vector and creates a vector with the prefix &amp; suffix text.
I have also tried passing the pngfile handle directly</p>

<pre><code>pngfile &lt;- file(&lt;filename&gt;, ""rb"")
update.query &lt;- paste( update.query, "" pngFile = '"", pngfile, ""' where DemandPatternID = "", , sep="""")
</code></pre>

<p>This also fails.</p>

<p>Please advise.</p>
"
2296451,192377,2010-02-19T13:11:06Z,5,Changing dimnames of matrices and data frames in R,"<p>Let's say I have created the following matrix:</p>

<pre><code>&gt; x &lt;- matrix(1:20000,nrow=100)
&gt; x[1:10,1:10]
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    1  101  201  301  401  501  601  701  801   901
 [2,]    2  102  202  302  402  502  602  702  802   902
 [3,]    3  103  203  303  403  503  603  703  803   903
 [4,]    4  104  204  304  404  504  604  704  804   904
 [5,]    5  105  205  305  405  505  605  705  805   905
 [6,]    6  106  206  306  406  506  606  706  806   906
 [7,]    7  107  207  307  407  507  607  707  807   907
 [8,]    8  108  208  308  408  508  608  708  808   908
 [9,]    9  109  209  309  409  509  609  709  809   909
[10,]   10  110  210  310  410  510  610  710  810   910
</code></pre>

<p>What are the methods in R to change row and column names? For example, I like row names to be <code>SS1, SS2, ..., SS100</code> and column names to be <code>M1, M2, ..., M200</code>. I usually work with data with 1000s of rows and columns, and I need a good method to do that. Some people use something like <code>attributes(x)$dimnames &lt;- list(...)</code> and some use <code>rownames &lt;- paste(...)</code>. What are all possible methods?</p>

<p>My second question is, can I use the same methods after I convert the matrix to a data frame? </p>
"
2296694,266819,2010-02-19T13:50:30Z,15,Is there an R implementation for Java or .NET?,"<p>Is there Java or .NET version of R?
(like Jython / IronPython for the Python language)</p>

<p>I guess some R-packages which use C or Fortran may not run on Java/.NET version of R, but as long as pure R code can be run, it must be great.</p>
"
2300629,180718,2010-02-20T01:09:29Z,4,Plotting axes with different scales for one data set in R,"<p>I have a large data set I am plotting in R, and I'd like to have an axis on each side of the graph show the data in two different scales. So for example, on the left vertical axis I'd like to plot the data directly (e.g. plot(y ~ x) ) and on the right axis, I'd like to have a linear scaling of the left axis. (e.g. plot( y*20 ~ x). </p>

<p>So there would only be one data set displayed, but the axes would show different meanings for those data points.</p>

<p>I've tried the following:</p>

<pre><code>plot(x = dataset$x, y = dataset$y)
axis(4, pretty(dataset$y,10) )
</code></pre>

<p>This will correctly print a new right axis with the same scale as the default left axis. (essentially useless, but it works) However, if I make this tiny change:</p>

<pre><code>plot(x = dataset$x, y = dataset$y)
axis(4, pretty(10*dataset$y,10) )
</code></pre>

<p>Suddenly, it refuses to add my new right axis. I suspect this has something to do with R seeing if the axis matches the data set in some way and rejecting it if not. How can I get R to ignore the data set and just print an arbitrary axis of my choosing?</p>
"
2300767,211450,2010-02-20T02:16:54Z,3,read.table as it is,"<p>I'm trying to read data from csv file, but instead of e.g. 001000 I get 1000 in my data.<br>
I've tried to set <code>as.is=!stringsAsFactors</code>, but got the following error message:</p>

<pre><code> error: object stringsAsFactors not found.  
</code></pre>

<p>Anybody can help?</p>
"
2307443,101152,2010-02-21T20:53:13Z,7,How to add two vectors WITHOUT repeating in R?,"<p>I have two vectors in R of different size, and I want to add them, but without repeating the shorter one - instead, I want the ""missing"" numbers to be zeroes.</p>

<p>Example:</p>

<pre><code>x&lt;-c(1,2)
y&lt;-c(3,4,5)
z&lt;-x+y 
</code></pre>

<p>Now, <code>z</code> is <code>4 6 6</code>, but I want it only <code>4 6 5</code>.</p>
"
2307925,23903,2010-02-21T23:34:40Z,5,Most efficient way to sort two vectors in lockstep in R?,"<p>What's the most efficient way to sort two vectors in lockstep in R?  The first vector should be sorted in ascending order and the second should be reordered in lockstep such that elements with corresponding indices before the sort still have corresponding indices after the sort.  For example:</p>

<pre><code>foo &lt;- c(1,3,2, 5,4)
bar &lt;- c(2,6,4,10,8)
sort2(foo, bar)

# foo == c(1,2,3,4, 5)
# bar == c(2,4,6,8,10)
</code></pre>

<p>Note:  Efficiency is an absolute must here as I am trying to use this as the basis for creating an O(N log N) implementation of Kendall's Tau to submit as a patch.  I'd like to avoid writing my own special function in C to do this, but would be willing to if it can't be done efficiently within R.</p>
"
2308991,180626,2010-02-22T05:24:29Z,4,How can I generate conditional distributions of data by taking slices of scatterplots?,"<p>
    I'm taking my first course in multiple linear regression, so I'm still a beginner in R. We've recently learned a bit about taking slices of bivariate scatterplot data, both horizontally and vertically. What I'd like to know is how to go beyond a basic scatterplot, and take advantage of conditionally grouping data by slices to examine patterns.
    </p>

<p><p>
  As an example, I'm working with high-octane data from a bank where we're regressing employee's current salary <code>csalary</code> onto their beginning salary <code>bsalary</code>. Here's what my dataframe looks like.</p>

<pre>
  <code>
    > str(data)
    'data.frame':   474 obs. of  10 variables:
     $ id     : num  628 630 632 633 635 637 641 649 650 652 ...
     $ bsalary: num  8400 24000 10200 8700 17400 ...
     $ gender : Factor w/ 2 levels ""Male"",""Female"": 1 1 1 1 1 1 1 1 1 1 ...
     $ time   : num  81 73 83 93 83 80 79 67 96 77 ...
     $ age    : num  28.5 40.3 31.1 31.2 41.9 ...
     $ csalary: num  16080 41400 21960 19200 28350 ...
     $ educlvl: num  16 16 15 16 19 18 15 15 15 12 ...
     $ work   : num  0.25 12.5 4.08 1.83 13 ...
     $ jobcat : Factor w/ 7 levels ""Clerical"",""Office Trainee"",..: 4 5 5 4 5 4 1 1 1 3 ...
     $ ethnic : Factor w/ 2 levels ""White"",""Non-White"": 1 1 1 1 1 1 1 1 1 1 ...
  </code>
</pre>

<p>
  To explore the relationship of <code>bsalary</code> and <code>csalary</code> I created a scatterplot using some of the functionality of <code>lattice</code> library. I arbitrarily drew vertical lines at $5000 intervals along <code>bsalary</code>.
</p>

<p>
<pre>
  <code>
    library (lattice)
    # Constructing vertical ""slices"" of our csalary ~ bsalary data
    # First we define a vector with our slice points, in this case 
    # $5,000 bsalary increments
    bslices = seq (from = 5000, to = 30000, by = 5000)
    length (bslices)
    xyplot (csalary ~ bsalary,
        main  = ""Current Bank Employee Salary as Predicted by Beginning Salary"",
        xlab  = ""Beginning Salary ($USD)"",
        ylab  = ""Current Salary ($USD)"",
        panel = function(...){
            panel.abline(v = bslices, col=""red"", lwd=2);
            panel.xyplot(...);
        }
    )
  </code>
</pre>
</p>

<p>
  The above code gets me this.
</p>

<a href=""http://skitch.com/capbri/nsq1r/rplot002.pdf-1-page"" rel=""nofollow noreferrer"">Rplot002.pdf (1 page) http://img.skitch.com/20100222-tkcu613r9cjqc4cs3314hc1i7h.preview.jpg</a><br />

<p>
  Which is fantastic. But I feel like there ought to be a simple way to generate, from my data, graphs that group slice data into boxplots:
</p>

<p><a href=""http://skitch.com/capbri/nsq1y/01linreg.pdf-page-3-of-25"" rel=""nofollow noreferrer"">01LinReg.pdf (page 3 of 25) http://img.skitch.com/20100222-rhjudjw4txnfu43pycuqneuqan.preview.jpg</a><br /></p>

<p><p>
   Or stacked-dot scatterplots, again grouped by slice, like this:
 </p></p>

<p><a href=""http://skitch.com/capbri/nsq1b/01linreg.pdf-page-3-of-25"" rel=""nofollow noreferrer"">01LinReg.pdf (page 3 of 25) http://img.skitch.com/20100222-cgsqwnhnd26k5qhb6gb2sjk1bs.preview.jpg</a><br /></p>

<p><p>
  Ultimately, my question is how to turn raw scatterplot data into conditionally-grouped data. I feel like there are some simple, underlying features of lattice (or even the simpler plot commands that don't require it) that would allow me to start slicing my data to explore for patterns.
 </p></p>

<p><p>
  Thanks in advance for your help!
 </p></p>
"
2309826,278555,2010-02-22T09:10:12Z,5,How does one extract the name of a variable in a function that is called from another function in R?,"<p>My question is how to extract the name of a variable from a function that is called in another function in R?</p>

<p>To illustrate, here is an example: </p>

<pre><code>a &lt;- function(variable) {

    print(deparse(substitute(variable)))

    internala(substitute(variable))

}

internala &lt;- function(variableXX) {

    namex=deparse(substitute(variableXX))

    print(namex)
}
</code></pre>

<p>Calling the function  <code>a</code>  gives the following result:</p>

<pre><code>&gt;a(whatever)

[1] ""whatever""

[1] ""substitute(variable)""
</code></pre>

<p>which means that i can extract the name of the variable <code>whatever</code> from <code>a</code>, but not from <code>internala</code>.</p>

<p>Any thoughts on this?</p>

<p>Any help will be appreciated!</p>

<p>Maria</p>
"
2310409,216064,2010-02-22T11:03:59Z,36,How can I document data sets with roxygen?,"<p>Is it possible to include .R files in the data directory of my package in the roxygen process?</p>

<p>I have put several .R files in the data directory. When they are sourced with data(), they read in raw data files and perform some transformations.</p>
"
2310913,256662,2010-02-22T12:50:03Z,11,"How do I manually create a dendrogram (or ""hclust"") object ? (in R)","<p>I have a dendrogram given to me as images. Since it is not very large, I can construct it ""by hand"" into an R object.</p>

<p>So my question is how do I manually create a dendrogram (or ""hclust"") object, when all I have is the dendrogram image ?</p>

<p>I see that there is a function called ""as.dendrogram"" But I wasn't able to find an example on how to use it.</p>

<p>(p.s: This post is following my question from <a href=""https://stackoverflow.com/questions/2218395/how-do-you-compare-the-similarity-between-two-dendrograms-in-r"">here</a>)</p>

<p>Many thanks,
Tal</p>
"
2312913,170792,2010-02-22T17:53:52Z,13,What method do you use for selecting the optimum number of clusters in k-means and EM?,"<p>Many algorithms for clustering are available. A popular algorithm is the K-means where, based on a given number of clusters, the algorithm iterates to find best clusters for the objects. </p>

<p>What method do you use to determine the number of clusters in the data in k-means clustering?</p>

<p>Does any package available in R contain the <code>V-fold cross-validation</code> method for determining the right number of clusters?</p>

<p>Another well used approach is Expectation Maximization (EM) algorithm which assigns a probability distribution to each instance which indicates the probability of it belonging to each of the clusters.</p>

<p>Is this algorithm implemented in R?</p>

<p>If it is, does it have the option to automatically select the optimum number of clusters by cross validation?</p>

<p>Do you prefer some other clustering method instead?</p>
"
2315601,279153,2010-02-23T01:41:04Z,55,Understanding the order() function,"<p>I'm trying to understand how the <code>order()</code> function works.  I was under the impression that it returned a permutation of indices, which when sorted, would sort the original vector.</p>

<p>For instance,</p>

<pre><code>&gt; a &lt;- c(45,50,10,96)
&gt; order(a)
[1] 3 1 2 4
</code></pre>

<p>I would have expected this to return <code>c(2, 3, 1, 4)</code>, since the list sorted would be 10 45 50 96.</p>

<p>Can someone help me understand the return value of this function?</p>
"
2316356,135870,2010-02-23T05:36:56Z,9,Can Roxygen ignore non-user functions?,"<p>I've just started playing around with the <code>roxygen</code> package and I've very happy with the results so far.  However I was wondering, is there a way to specify to <code>roxygen</code> that it should ignore certain functions that are not user-accessible?</p>

<p>Specifically, I'd rather not have a <code>.Rd</code> file pop up because I'm using the <code>.onLoad()</code> hook in my package.  This function is already documented in the <code>base</code> package so there's no reason for me to re-document it.</p>
"
2316630,207258,2010-02-23T08:17:54Z,4,How can I include a variable name in a function call in R?,"<p>I'm trying to change the name of a variable that is included inside a for loop and function call.  In the example below, I'd like column_1 to be passed to the plot function, then column_2 etc.  I've tried using do.call, but it returns ""object 'column_j' not found"".  But object column_j is there, and the plot function works if I hard-code them in.   Help much appreciated.</p>

<pre><code>for (j in 2:12) {
    column_to_plot = paste(""column_"", j, sep = """")
    do.call(""plot"", list(x, as.name(column_to_plot)))
}
</code></pre>
"
2317446,192380,2010-02-23T10:51:59Z,7,Error plotting SVM classification graph,"<p>I'm using the support vector machine from the e1071 package to classify my data and want to visualize how the machine actually does the classification. However, when using the plot.svm function, I get an error that I can't resolve.</p>

<p>Script:</p>

<pre><code>library(""e1071"")

data &lt;-read.table(""2010223_11042_complete"")
names(data) &lt;- c(""Class"",""V1"", ""V2"")

model &lt;- svm(Class~.,data, type = ""C-classification"", kernel = ""linear"")
plot(model,data,fill=TRUE, grid=200, svSymbol=4, dataSymbol=1, color.palette=terrain.colors)
</code></pre>

<p>Output:</p>

<pre><code>plot(model,data,fill=TRUE, grid=200, svSymbol=4, dataSymbol=1, color.palette=terrain.colors)
Error in rect(0, levels[-length(levels)], 1, levels[-1L], col = col) : 
  cannot mix zero-length and non-zero-length coordinates
</code></pre>

<p>Traceback:</p>

<pre><code>traceback()
4: rect(0, levels[-length(levels)], 1, levels[-1L], col = col)
3: filled.contour(xr, yr, matrix(as.numeric(preds), nr = length(xr), 
       byrow = TRUE), plot.axes = {
       axis(1)
       axis(2)
       colind &lt;- as.numeric(model.response(model.frame(x, data)))
       dat1 &lt;- data[-x$index, ]
       dat2 &lt;- data[x$index, ]
       coltmp1 &lt;- symbolPalette[colind[-x$index]]
       coltmp2 &lt;- symbolPalette[colind[x$index]]
       points(formula, data = dat1, pch = dataSymbol, col = coltmp1)
       points(formula, data = dat2, pch = svSymbol, col = coltmp2)
   }, levels = 1:(length(levels(preds)) + 1), key.axes = axis(4, 
       1:(length(levels(preds))) + 0.5, labels = levels(preds), 
       las = 3), plot.title = title(main = ""SVM classification plot"", 
       xlab = names(lis)[2], ylab = names(lis)[1]), ...)
2: plot.svm(model, data, fill = TRUE, grid = 200, svSymbol = 4, 
       dataSymbol = 1, color.palette = terrain.colors)
1: plot(model, data, fill = TRUE, grid = 200, svSymbol = 4, 
       dataSymbol = 1, color.palette = terrain.colors)
</code></pre>

<p>Part of my (4488 lines long) data file:</p>

<pre><code>-1 0 23.532
+1 1 61.1157
+1 1 61.1157
+1 1 61.1157
-1 1 179.03
-1 0 17.0865
-1 0 27.6201
-1 0 17.0865
-1 0 27.6201
-1 1 89.6398
-1 0 42.7418
-1 1 89.6398
</code></pre>

<p>Since I`m just starting with R, I have no idea what this means and how I should deal with it, nor did I find anything useful in other places.</p>
"
2318368,101152,2010-02-23T13:19:53Z,15,Can a function in R return two vectors?,"<p>Can a function in R return not one, but two vectors?</p>

<p><em>(I am really beginning with R, so I might be overlooking something simple)</em></p>
"
2321333,207258,2010-02-23T20:09:02Z,3,How to read in a text file to R using textConnection and library(sqldf),"<p>I'm trying to read a text file into R so I can use the sqldf functions.  I'm following this example, <a href=""https://stat.ethz.ch/pipermail/r-help/2008-January/152040.html"" rel=""nofollow noreferrer"">https://stat.ethz.ch/pipermail/r-help/2008-January/152040.html</a>, but I have a text file holding my data instead of the data being pasted as the example has it.   My text file is below:</p>

<pre><code>#""test.table.1.0"" file has this contents:
id  Source
1     A10
2     A32
3     A10
4     A25
</code></pre>

<p>I tried this following the example</p>

<pre><code>test_table &lt;- read.table(textConnection(""test.table.1.0""))
</code></pre>

<p>I can see that the problem is that textConnection is supposed to take a character vector, 
and I'm giving it a data.frame, but converting it via as.character also fails.  Ultimately, I want to run a query like this:</p>

<pre><code>sqldf(""select test_table.source from test_table"");
</code></pre>
"
2321786,5222,2010-02-23T21:15:58Z,9,Best way to store variable-length data in an R data.frame?,"<p>I have some mixed-type data that I would like to store in an R data structure of some sort.  Each data point has a set of fixed attributes which may be 1-d numeric, factors, or characters, and also a set of variable length data.  For example:</p>

<pre><code>id  phrase                    num_tokens  token_lengths
1   ""hello world""             2           5 5
2   ""greetings""               1           9
3   ""take me to your leader""  4           4 2 2 4 6
</code></pre>

<p>The actual values are not all computable from one another, but that's the flavor of the data. The operations I'm going to want to do include subsetting the data based on boolean functions (e.g. something like <code>nchar(data$phrase) &gt; 10</code> or <code>lapply(data$token_lengths, length) &gt; 2)</code>.  I'd also like to index and average values in the variable length portion by index. This doesn't work, but something like: <code>mean(data$token_lengths[1], na.rm=TRUE))</code></p>

<p>I've found I can shoehorn ""token_lengths"" into a data.frame by making it an array:</p>

<pre><code>d &lt;- data.frame(id=c(1,2,3), ..., token_lengths=as.array(list(c(5,5), 9, c(4,2,2,4,6)))
</code></pre>

<p>But is this the best way?</p>
"
2326351,260174,2010-02-24T13:41:06Z,1,bar width in ggplot2 geom_bar,"<p>I am trying to produce plots with a loop.</p>

<pre><code>l1&lt;-factor(rep(letters,4))
n1&lt;-abs(rnorm(104))*10000
b1&lt;-rep(c(""1"",""2"",""3"",""4"",""5"",""6"",""7"",""8""),c(2,2,11,24,11,20,33,1))
k1&lt;-rep((rep(c(""A"",""B"",""C"",""D""),c(2,3,4,4))),8)
my.df&lt;-data.frame(l1,b1,k1,n1)                            #make a dataframe

names(my.df)&lt;-c(""letter"",""branch"",""ltrtype"",""number"")     #factor names
library(ggplot2)

branch.list&lt;-unique(my.df$branch)
sayi&lt;-length(branch.list)                                 # list of factor:letters

for (i in 1:sayi) {

branch.iter&lt;-branch.list[i]
my.df.plot&lt;-subset(my.df,my.df$branch==branch.iter,drop=T)

my.df.plot$branch&lt;-factor(my.df.plot$branch)               #So that unused levels don't show up
my.df.plot$letter&lt;-factor(my.df.plot$letter)               #So that unused levels don't show up
my.df.plot$ltrtype&lt;-factor(my.df.plot$ltrtype)             #So that unused levels don't show up
my.df.plot$number&lt;-as.numeric(as.character(my.df.plot$number))
my.df.plot&lt;-data.frame(my.df.plot)

myfilename&lt;-paste(branch.iter,"".jpeg"",sep="""")
jpeg(file=myfilename)

cizim&lt;-ggplot(my.df.plot,aes(letter,number,fill=ltrtype))
cizim&lt;-cizim + geom_bar(width = 1, position = ""fill"", binwidth = 1) +     facet_grid(ltrtype~.)
cizim&lt;-cizim + opts(title=branch.iter)

print(cizim)
dev.off()

}
</code></pre>

<p>(Q1): When number of levels in x-axis change width of bars change
How can i prevent this and make bar width in every plot same?</p>

<p><a href=""http://img411.imageshack.us/i/95325388.jpg/"" rel=""nofollow noreferrer"">alt text http://img411.imageshack.us/i/95325388.jpg/</a></p>

<p><a href=""http://img411.imageshack.us/i/91510133.jpg/"" rel=""nofollow noreferrer"">alt text http://img411.imageshack.us/i/91510133.jpg/</a></p>

<p>(Q2): when <code>i=7</code> R gives following warning:</p>

<blockquote>
  <p>(data$ymin == 0)) warning(""Filling not well defined when ymin != 0"") :
  missing value where TRUE/FALSE needed</p>
</blockquote>

<p>what can i do about it?</p>

<p>(Q3): Is there an easier way to drop unused levels in such a case so i don't have to use</p>

<pre><code> my.df.plot$branch&lt;-factor(my.df.plot$branch)
</code></pre>

<p>everytime?</p>
"
2329036,207258,2010-02-24T19:58:12Z,3,How to reference columns of a data.frame within a data.frame?,"<p>I have a data.frame called series_to_plot.df which I created by combining a number of other data.frames together (shown below).  I now want to pull out just the .mm column from each of these, so I can plot them.   So I want to pull out the 3rd column of each data.frame (e.g. p3c3.mm, p3c4.mm etc...), but I can't see how to do this for all data.frames in the object without looping through the name.  Is this possible?</p>

<p>I can pull out just one set: e.g. series_to_plot.df[[3]]   and another by 
series_to_plot.df[[10]] (so it is just a list of vectors..) and I can reference directly with  series_to_plot.df$p3c3.mm, but is there a command to get a vector containing all mm's from each data.frame?  I was expecting an index something like this to work: series_to_plot.df[,3[3]]  but it returns  Error in <code>[.data.frame</code>(series_to_plot.df, , 3[3]) : undefined columns selected</p>

<pre><code>series_to_plot.df
          p3c3.rd         p3c3.day    p3c3.mm      p3c3.sd                 p3c3.n p3c3.noo p3c3.no_NAs
    1     2010-01-04             0    0.1702531    0.04003364              7                1           0
    2     2010-01-06             2    0.1790594    0.04696674              7                1           0
    3     2010-01-09             5    0.1720404    0.03801756              8                0           0

          p3c4.rd         p3c4.day    p3c4.mm      p3c4.sd                 p3c4.n p3c4.noo p3c4.no_NAs
    1     2010-01-04             0    0.1076581   0.006542157              6                2           0
    2     2010-01-06             2    0.1393447   0.066758781              7                1           0
    3     2010-01-09             5    0.2056846   0.047722862              7                1           0

          p3c5.rd         p3c5.day    p3c5.mm      p3c5.sd                 p3c5.n p3c5.noo p3c5.no_NAs
    1     2010-01-04             0   0.07987147   0.006508766              7                1           0
    2     2010-01-06             2   0.11496167   0.046478767              8                0           0
    3     2010-01-09             5   0.40326471   0.210217097              7                1           0
</code></pre>
"
2329851,207258,2010-02-24T21:50:24Z,24,How can I add another layer / new series to a ggplot?,"<p>In ggplot I can add a series to a plot with:</p>

<pre><code>ggplot(diamonds, aes(x = carat, y = price)) + geom_point()
</code></pre>

<p>How do I simply add another series, e.g. plotting the cost of rubies against diamonds.  Assuming rubies was also in the diamonds dataset.  I have tried to lay over the top another layer with the rubies data, but it just plots the rubies and not the diamonds/carat.</p>

<pre><code>ggplot(diamonds, aes(x = carat, y = price)) + geom_point() + aes(x = rubies, y = price)
</code></pre>

<p>I can see that this would be possible by melding all the data together first, ready to plot it, so maybe I should go down that route.   However, just adding another series to a plot like this seems like it should not be too hard, but I can't figure out how to do it.</p>
"
2330169,280761,2010-02-24T22:35:10Z,1,How do I position a central subtitle in my two-sided gplot-pyramid?,"<p>I created an age-sex-pyramid using gplots. I would like to center a subtitle between the two sides of the pyramid.</p>

<p>However, I can only get the subtitle aligned with one of the two sides of the pyramid:</p>

<pre><code>library(gplots)
agetable &lt;- as.data.frame(cbind (c(2, 4, 7, 8, 10, 8, 6, 4, 2, 1), 
                                 c(1, 3, 5, 9, 11, 6, 4, 1, 0, 1)))
names(agetable) &lt;- c(""Male"", ""Female"")
maxdir &lt;- max(agetable)
subtitle &lt;- ""34% of data are mising age or sex""

agegraph.general.bysex &lt;- function(agetable, maxdir, varname, miss){
agegroups &lt;- 
if (varname=='Male') {
  datavec &lt;- agetable[,'Male']
  lim = c(maxdir,0)
  agelabels = c('0-9','10-19','20-29','30-39','40-49','50-59',
                '60-69','70-79','80-89','90+')
} else {
  datavec &lt;- agetable[,'Female']
  lim = c(0, maxdir)
     agelabels = ''
}
barplot2(
       datavec, horiz=TRUE, space=0, xlab = varname, xlim=lim, col='grey85',
       axisnames=TRUE, cex.axis = 1, cex.names = 1, names.arg=agelabels, 
       plot.grid=TRUE, cex.sub = 0.8, sub = miss)
}


layout(matrix(1:2, ncol=2, nrow=1))
par(las=1, adj=0.5, omi=c(0.1, 0.1, 0.1 ,0.1), cex=0.8 , cex.lab=0.8)
par(mar=c(7,5,0,0))
agegraph.general.bysex(agetable, maxdir, 'Male', subtitle)
par(mar=c(7,0,0,5))
agegraph.general.bysex(agetable, maxdir, 'Female', '')
</code></pre>

<p>I would be grateful for any suggestions!</p>
"
2331070,246211,2010-02-25T01:59:04Z,3,R & ggplot2: Sparklines from dynamic variables (based on query results),"<p>I've written an SQL query that tells me the names of the previous week's top 10 most frequent Alarms. And I've written a query that takes those top 10 alarms and provides a YTD weekly totals for each of those alarms.</p>

<p>Now I'm looking to create a panel of sparklines showing the YTD trend for each of the week's top 10 alarms. </p>

<p>I got something resembling what I'd like, but I now need to make it ""dynamic"". i.e. to make it work without hardcoding the names of the alarms (since these will change with the SQL query every week).</p>

<p>How can I go about changing the R code below to work without hardcoding the names of the alarms? </p>

<p>Does levels(spark$Alarm) have something to do with?</p>

<p>Thanks kindly for the advice :-)</p>

<pre><code>Week = c(rep(1:8,2))
Total = rnorm(16,1000,600)
Alarm = c(rep(""BELTWEIGHER HIGH HIGH"",8), rep(""MICROWAVE LHS"",8))
spark &lt;- data.frame(Week, Alarm, Total)

s &lt;- ggplot(spark, aes(Week, Total)) +
     facet_grid(Alarm ~ ., scales = ""free"", as.table = FALSE) +
     opts(
  panel.background = theme_rect(size = 1, colour = ""lightgray""),
  panel.grid.major = theme_blank(),
  panel.grid.minor = theme_blank(),
  axis.line = theme_blank(),
  axis.text.x = theme_blank(),
  axis.text.y = theme_blank(),
  axis.title.x = theme_blank(),
  axis.title.y = theme_blank(), 
  axis.ticks = theme_blank(),
  strip.background = theme_blank(),
  strip.text.y = theme_text(size = 7, colour = ""red"", angle = 90)
 )

s1 &lt;- s  + geom_line(subset = .(Alarm == ""BELTWEIGHER HIGH HIGH""))
s2 &lt;- s1 + geom_line(subset = .(Alarm == ""MICROWAVE LHS""))
s2
</code></pre>
"
2331237,148621,2010-02-25T02:41:24Z,3,When will simple parallization not offer a speedup?,"<p>I have a simple program that breaks a dataset (a CSV file) into 4 chunks, reads each chunk in, does some calculations, and then appends the output together.  Think of it as a simple map-reduce operation.  Processing a single chunk uses about 1GB of memory.  I'm running the program on a quad core PC, with 4GB of ram, running Windows XP.  I happen to have coded it up using R, but I don't think it's relevant.</p>

<p>I coded up two versions.  One version processes each chunk in sequence.  The other version processes chunks two at a time in parallel.  Both versions take nearly the same amount of time to finish.</p>

<p>Under what circumstances would you expect to see this performance result?</p>

<p>My current hypothesis is that the processes are bounded by the memory performance, but I don't know the best way to investigate this further.  Any suggestions or guesses?</p>

<p>Edit: The program is not IO-bound in terms of the disk.  The processing step reads a chunk of a CSV file into memory, churns on it for 5 minutes or so, and then writes the result back out to a file on disk.  The file input and output takes a few seconds at most.</p>
"
2333436,74658,2010-02-25T11:01:38Z,3,Is there a better way to code this sqlQuery in R?,"<p>I'm writing an R script to get some database data and then do stuff with it, using the RODBC package.  Currently all my sqlQuery commands are one long string;</p>

<pre><code>stsample&lt;-sqlQuery(odcon, paste""select * from bob.DESIGNSAMPLE T1, bob.DESIGNSUBJECTGROUP T2, bob.DESIGNEVENT T3, bob.CONFIGSAMPLETYPES T4 WHERE T1.SUBJECTGROUPID = T2.SUBJECTGROUPID AND T1.TREATMENTEVENTID = T3.TREATMENTEVENTID AND T1.SAMPLETYPEKEY = T4.SAMPLETYPEKEY AND T1.STUDYID = T2.STUDYID AND T1.STUDYID = T3.STUDYID AND T1.STUDYID = "", chstudid, sep=""""))
head(stsample)
</code></pre>

<p>which looks ugly and is hard to read/update.  I've tried putting them multiline, but then new line characters get in the way, currently my best is this using lots of paste's;</p>

<pre><code>stsample&lt;-sqlQuery(odcon,
    paste(
        ""select "",
            ""* "", 
        ""from "", 
            ""BOB.DESIGNSAMPLE T1, "",
            ""BOB.DESIGNSUBJECTGROUP T2, "",
            ""BOB.DESIGNEVENT T3, "",
            ""BOB.CONFIGSAMPLETYPES T4 "",
        ""WHERE "",
            ""T1.SUBJECTGROUPID = T2.SUBJECTGROUPID "",
            ""AND T1.TREATMENTEVENTID = T3.TREATMENTEVENTID "",
            ""AND T1.SAMPLETYPEKEY = T4.SAMPLETYPEKEY "",
            ""AND T1.STUDYID = T2.STUDYID "",
            ""AND T1.STUDYID = T3.STUDYID "",
            ""AND T1.STUDYID = "",chstudid,
        sep="""")
    )
head(stsample)
</code></pre>

<p>But I don't like having to put quotes around everyline, and getting my whitespace correct.  Is there a better way ?</p>
"
2333521,170792,2010-02-25T11:16:50Z,1,Why do I get an error when I run some examples from the online ggplot2 reference manual?,"<p>Trying the ggplot2 examples in the online reference manual, and particularly in <a href=""http://had.co.nz/ggplot2/stat_density2d.html"" rel=""nofollow noreferrer"">this page</a>, I fail to produce all but the first of the second example's plots.</p>

<pre><code>&gt; d + stat_density2d(geom=""tile"", aes(fill = ..density..), contour = FALSE) 
Error in `[&lt;-.data.frame`(`*tmp*`, var, value = list(`NA` = NULL)) : 
  missing values are not allowed in subscripted assignments of data frames
In addition: Warning message:
Removed 34912 rows containing missing values (stat_density2d).
</code></pre>

<p>I have R ver. 2.10.1 and ggplot2 ver. 0.8.6</p>

<p>What is wrong?</p>
"
2336056,256662,2010-02-25T17:19:53Z,2,"How to do: Correlation with ""blocks"" (or - ""repeated measures"" ?!)?","<p>I have the following setup to analyse:
We have about 150 subjects, and for each subject we performed a pair of tests (under different conditions) 18 times.
The 18 different conditions of the test are complementary, in such a way so that if we where to average over the tests (for each subject), we would get no correlation between the tests (between subjects).
What we wish to know is the correlation (and P value) between the tests, in within subjects, but over all the subjects.</p>

<p>The way I did this by now was to perform the correlation for each subject, and then look at the distribution of the correlations received so to see if it's mean is different then 0.
But I suspect there might be a better way for answering the same question (someone said to me something about ""geographical correlation"", but a shallow search didn't help).</p>

<p>p.s: I understand there might be a place here to do some sort of mixed model, but I would prefer to present a ""correlation"", and am not sure how to extract such an output from a mixed model.</p>

<p>Also, here is a short dummy code to give an idea of what I am talking about:</p>

<pre><code>attach(longley)
N &lt;- length(Unemployed)
block &lt;- c(
        rep( ""a"", N),
        rep( ""b"", N),
        rep( ""c"", N)
        )

Unemployed.3 &lt;- c(Unemployed + rnorm(1),
                    Unemployed + rnorm(1),
                    Unemployed + rnorm(1))

GNP.deflator.3 &lt;- c(GNP.deflator + rnorm(1),
                    GNP.deflator + rnorm(1),
                    GNP.deflator + rnorm(1))

cor(Unemployed, GNP.deflator)
cor(Unemployed.3, GNP.deflator.3)
cor(Unemployed.3[block == ""a""], GNP.deflator.3[block == ""a""])
cor(Unemployed.3[block == ""b""], GNP.deflator.3[block == ""b""])
cor(Unemployed.3[block == ""c""], GNP.deflator.3[block == ""c""])
(I would like to somehow combine the last three correlations...)
</code></pre>

<p>Any ideas will be welcomed.</p>

<p>Best,
Tal</p>
"
2337018,281537,2010-02-25T19:37:03Z,2,"What does the rpart ""Error in as.character(x) : cannot coerce type 'builtin' to vector of type 'character' "" message mean?","<p>I've been banging my head against <code>rpart</code> for a few days now (trying to make classification trees for this dataset that I have), and I think it's time to ask a lifeline at this point :-)  I'm sure it's something silly that I'm not seeing, but here's what I've been doing:</p>

<pre><code>EuropeWater &lt;- read.csv(file=paste(""/Users/artessaniccola/Documents/"",
                       ""Magic Briefcase/CityTypology/Europe_water.csv"",sep=""""))
library(rpart)
attach(EuropeWater)
names(EuropeWater)
[1] ""City""          ""waterpercapita_m3"" ""water_class""       ""population""       
[5] ""GDPpercapita""  ""area_km2""          ""populationdensity"" ""climate""            
EuropeWater$water_class &lt;- factor(EuropeWater$water_class, levels=1:3, 
                                  labels=c(""Low"", ""Medium"", ""High""))
EuropeWater$climate &lt;- factor(EuropeWater$climate, levels=2:4, 
                              labels=c(""Arid"", ""Warm temperate"", ""Snow""))
EuropeWater_tree &lt;- rpart(EuropeWater$water_class ~ 
               population+GDPpercapita + area_km2 + populationdensity + 
               EuropeWater$climate, 
               data=EuropeWater, method=class)   
Error in as.character(x) : 
          cannot coerce type 'builtin' to vector of type 'character'
</code></pre>

<p>and for the life of me, I can't figure out what the Error is about.</p>
"
2338152,260533,2010-02-25T22:28:21Z,0,Using sim() with lmer(),"<p>I have run two multilevel logistic regressions using the same predictors, but on two different responses:</p>

<pre><code>fruitMLM &lt;- lmer(InsuffFruit ~ Income + HDI + Income:HDI + (1 + Income | Country),family=binomial(link=""logit""))  
fuelMLM &lt;- lmer(Pollution ~ Income + HDI + Income:HDI + (1 + Income | Country),family=binomial(link=""logit""))
</code></pre>

<p><code>Income</code> is discrete with values <code>c(-2,-1,0,1,2)</code>, <code>HDI</code> is continuous between 0 and 1, <code>Country</code> is categorical, and the responses are both 1/0.</p>

<p>To plot confidence bands I run a simulation using the sim() function from the arm package:</p>

<pre><code>sim(fruitMLM,100)  
sim(fuelMLM,100)
</code></pre>

<p>The first one computes fine.  The second one returns the following error:</p>

<pre><code>Error in mvnorm(n.sims, bhat[j,], V.beta) :  
  'Sigma' is not positive definite
</code></pre>

<p>I actually am doing this with 8 different responses.  Six of them worked fine and two of them returned this error.</p>

<p>Does anyone know how to rectify this?</p>
"
2338228,264696,2010-02-25T22:42:29Z,10,How do I produce a boxplot in ggplot using a matrix,"<p>In R it is easy to turn a matrix into a boxplot</p>

<pre><code>&gt; myMatrix
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]   27   32   31   28   20   28   10   29   15    29
 [2,]   31   33   20   28   21    9   14   21   34    33
 [3,]   27   33   28   23   26   33   19   11   26    30
 [4,]   33   17   10   31   10   32   10   29   31    28
 [5,]   25   10   29   34   32   33   28   32   32    32
 [6,]   32   19   13   32   26   20    9   26   32    33
 [7,]   33   32   18   26   27   28   29   32   24    25
 [8,]   33   34   32   30   27   31   22   32   33    30
 [9,]   32   34   31   22   17   31   11   27   18    23
[10,]   26   10   30   30   27    4    4    4    4     4

&gt; boxplot(as.data.frame(myMatrix))
</code></pre>

<p>How do I accomplish the same thing in ggplot?</p>
"
2339953,207258,2010-02-26T06:54:28Z,5,How to add custom series labels to a legend in R's ggplot?,"<p>I have a plot (sample code pasted below) that I am trying to add by own labels for the series information.  Instead of plotting ""p1s1"" ""p1s2"" ""p3s4"", I would like ""treatment 1"" ""treatment 2"" ""treatment 3"".  I have used levels(series_id) to get the unique series names and used a lookup table to get the descriptions.  (I think this gets them in the same order they are plotted?) and I have these descriptions in a vector called treatment_descriptions.   </p>

<p>From the documentation I think that I should be using a scale here, but I can't figure out which one, or how to do it.  Something like:  scale_something(name=""Treatment Descriptions"", breaks=NULL, labels=treatment_descriptions, formatter=NULL)  ?  But where should this go?</p>

<pre><code>library(ggplot2)

# Create a long data.frame to store data...
growth_series = data.frame (""read_day"" = c(0, 3, 9, 0, 3, 9, 0, 2, 8), 
""series_id"" = c(""p1s1"", ""p1s1"", ""p1s1"", ""p1s2"", ""p1s2"", ""p1s2"", ""p3s4"", ""p3s4"", ""p3s4""),
""mean_od"" = c(0.6, 0.9, 1.3, 0.3, 0.6, 1.0, 0.2, 0.5, 1.2),
""sd_od"" = c(0.1, 0.2, 0.2, 0.1, 0.1, 0.3, 0.04, 0.1, 0.3),
""n_in_stat"" = c(8, 8, 8, 8, 7, 5, 8, 7, 2)
)

&gt; # Now gives us some example long form data...
&gt; &gt; growth_series 
&gt;  read_day series_id mean_od sd_od        n_in_stat   
&gt;   1       p1s1     0.6      0.10         8 2       
&gt;   3       p1s1     0.9      0.20         8 3    
&gt;   9       p1s1     1.3      0.20         8 4    
&gt;   0       p1s2     0.3      0.10         8 5    
&gt;   3       p1s2     0.6      0.10         7 6    
&gt;   9       p1s2     1.0      0.30         5 7    
&gt;   0       p3s4     0.2      0.04         8 8    
&gt;   2       p3s4     0.5      0.10         7 9    
&gt;   8       p3s4     1.2      0.30         2 2

# Plot using ggplot...
ggplot(data = growth_series, aes(x = read_day, y = mean_od, group = series_id, color = series_id)) +
geom_line(size = 1.5) +
geom_point(aes(size = n_in_stat)) +
geom_errorbar(aes(ymin = mean_od - sd_od, ymax = mean_od + sd_od), size = 1, width = 0.3) +
xlab(""Days"") + ylab(""Log (O.D. 730 nm)"") +
scale_y_log2() +
scale_colour_hue('my legend', breaks = levels(growth_series$series_id), labels=c('t1', 't2', 't3'))
</code></pre>
"
2342472,457898,2010-02-26T15:00:55Z,9,Recode/relevel data.frame factors with different levels,"<p>Each time when I have to recode some set of variables, I have SPSS recode function in mind. I must admit that it's quite straightforward. There's a similar <code>recode</code> function in <code>car</code> package, and it does the trick, but let's presuppose that I want to get things done with <code>factor</code>.</p>

<p>I have <code>data.frame</code> with several variables with value range from 1 to 7. I want to ""reverse"" variable values, hence replacing 1s with 7s, 2s with 6s, 3s with 5s etc. I can utilize <code>factor</code> function:</p>

<pre><code># create dummy factor
set.seed(100)
x &lt;- as.factor(round(runif(100,1,7)))
y &lt;- factor(x, levels = rev(levels(x)))
</code></pre>

<p>And if I run:</p>

<pre><code>&gt; levels(x)
[1] ""1"" ""2"" ""3"" ""4"" ""5"" ""6"" ""7""
&gt; levels(y)
[1] ""7"" ""6"" ""5"" ""4"" ""3"" ""2"" ""1""
</code></pre>

<p>Problem starts when I want to recode factors that do not have equal levels. If some factor, z, has levels <code>c(""1"", ""3"", ""4"", ""6"", ""7"")</code>, is there any chance that I can ""reverse"" levels so 1=7, 2=6, 3=5 etc. by utilizing <code>factor</code> function?</p>

<p>Other efficient recode functions should suffice!</p>
"
2343783,211450,2010-02-26T18:11:29Z,4,R : multidimensional scaling,"<p>I have several questions:<br>
1. What's the difference between isoMDS and cmdscale?<br>
2. May I use asymmetric matrix?<br>
3. Is there any way to determine optimal number of dimensions (in result)?</p>
"
2344368,218244,2010-02-26T19:48:18Z,2,Problem Configuring RApache on OS X 10.5.8,"<p>I've been trying to get RApache set up properly on my Macbook Pro running OS X 10.5.8.  After installing RApache successfully (I think), I added the following to the httpd.conf file as suggested in the manual.</p>

<pre><code>LoadModule R_module /apache/module/path/mod_R.so 
ROutputErrors
&lt;Location /RApacheInfo&gt; 
    SetHandler r-info 
&lt;/Location&gt; 
</code></pre>

<p>With these additions, I was then able to successfully go to <a href=""http://localhost/RApacheInfo"" rel=""nofollow noreferrer"">http://localhost/RApacheInfo</a> and see the status information. If I add the following additional line, 
REvalOnStartup ""library(brew)"" 
I can no longer load the RApacheInfo page successfully. </p>

<p>I don't know what the issue is here. Without the REvalOnStartup call, I'm seeing the following in the Apache error log. </p>

<pre><code>[Fri Feb 26 11:36:36 2010] [notice] Apache/2.2.13 (Unix) mod_ssl/2.2.13 OpenSSL/0.9.7l DAV/2 mod_R/1.1.8 R/2.10.1 configured -- resuming normal operations
The process has forked and you cannot use this CoreFoundation functionality safely. You MUST exec().
Break on __THE_PROCESS_HAS_FORKED_AND_YOU_CANNOT_USE_THIS_COREFOUNDATION_FUNCTIONALITY___YOU_MUST_EXEC__() to debug.
The process has forked and you cannot use this CoreFoundation functionality safely. You MUST exec().
Break on __THE_PROCESS_HAS_FORKED_AND_YOU_CANNOT_USE_THIS_COREFOUNDATION_FUNCTIONALITY___YOU_MUST_EXEC__() to debug.
</code></pre>

<p>Not a good sign.  Any thoughts on what might be going on?  Or things to check?  </p>

<p>Chris</p>
"
2344950,216064,2010-02-26T21:30:10Z,2,How can I alter the appearance of nodes in igraph?,"<p>I would like to lay out graphs (trees) with two types of nodes: boxes and circles.</p>

<p>Is this possible with igraph and how would a minimal example look like?</p>
"
2347410,216064,2010-02-27T13:09:46Z,11,How can I declare a thousand separator in read.csv?,"<p>The dataset I want to read in contains numbers with and without a comma as thousand separator:</p>

<pre><code>""Sudan"", ""15,276,000"", ""14,098,000"", ""13,509,000""
""Chad"", 209000, 196000, 190000
</code></pre>

<p>and I am looking for a way to read this data in.</p>

<p>Any hint appreciated!</p>
"
2349205,157872,2010-02-27T22:38:35Z,20,"Can't draw Histogram, 'x' must be numeric","<p>I have a data file with this format:</p>

<p>Weight    Industry Type<br>
251,787   Kellogg  h<br>
253,9601  Kellogg  a<br>
256,0758  Kellogg  h<br>
....</p>

<p>I read the data and try to draw an histogram with this commands:</p>

<pre><code> ce= read.table(""file.txt"", header= T)

 we = ce[,1]
 in = ce[,2]
 ty = ce[,3]

hist(we)
</code></pre>

<p>But I get this error:
Error en hist.default(we) : 'x' must be numeric.<br>
What do I need to do in order to draw histograms for my three variables ?</p>
"
2349511,282892,2010-02-28T00:19:02Z,5,Combining 2 columns into 1 column many times in a very large dataset in R,"<p>Combining  2 columns into 1 column many times in a very large dataset in R</p>

<p>The clumsy solutions I am working on are not going to be very fast if I can get them to work and the true dataset is ~1500 X 45000 so they need to be fast. I definitely at a loss for 1) at this point although have some code for 2) and 3).</p>

<p>Here is a toy example of the data structure:</p>

<pre><code>pop = data.frame(status = rbinom(n, 1, .42), sex = rbinom(n, 1, .5),
age = round(rnorm(n, mean=40, 10)), disType = rbinom(n, 1, .2),
rs123=c(1,3,1,3,3,1,1,1,3,1), rs123.1=rep(1, n), rs157=c(2,4,2,2,2,4,4,4,2,2),
rs157.1=c(4,4,4,2,4,4,4,4,2,2),  rs132=c(4,4,4,4,4,4,4,4,2,2),
rs132.1=c(4,4,4,4,4,4,4,4,4,4))
</code></pre>

<p>Thus, there are a few columns of basic demographic info and then the rest of the columns are biallelic SNP info.  Ex: rs123 is allele 1 of rs123 and rs123.1 is the second allele of rs123.</p>

<p>1) I need to merge all the biallelic SNP data that is currently in 2 columns into 1 column, so, for example: rs123 and rs123.1 into one column (but within the dataset):</p>

<pre><code>11
31
11
31
31
11
11
11
31
11
</code></pre>

<p>2) I need to identify the least frequent SNP value (in the above example it is 31).</p>

<p>3) I need to replace the least frequent SNP value with 1 and the other(s) with 0.</p>
"
2349820,246211,2010-02-28T02:28:02Z,5,Using R in Processing through rJava/JRI?,"<p>Is it possible to run R in Processing through rJava/JRI? If I deployed a Processing app on the web, would the client need R on their system?</p>

<p>I'm looking to create an interactive information dashboard that I can deploy on the web. It seems that Processing is probably my best bet for the interactive/web part of things. Unfortunately, it doesn't look like there are many math/stats functions built-in. And there aren't any libraries for plotting data either. </p>

<p>I've been using R and gpplot2 for a few months and am thrilled (amazed) at how easily it manipulates and plots data. </p>

<p>So I'm wondering now if can get the best of both worlds and run R through a Processing applet.</p>

<p>From the <a href=""http://rosuda.org/JRI/"" rel=""noreferrer"">JRI</a> website:</p>

<blockquote>
  <p>JRI is a Java/R Interface, which allows to run R inside Java
  applications as a single thread.
  Basically it loads R dynamic library
  into Java and provides a Java API to R
  functionality. It supports both simple
  calls to R functions and a full
  running REPL.</p>
  
  <p>In a sense JRI is the inverse of rJava
  and both can be combined (i.e. you can
  run R code inside JRI that calls back
  to the JVM via rJava). The JGR project
  makes the full use of both JRI and
  rJava to provide a full Java GUI for
  R.</p>
  
  <p>JRI uses native code, but it supports
  all platforms where Sun's Java (or
  compatible) is available, including
  Windows, Mac OS X, Sun and Linux (both
  32-bit and 64-bit).</p>
</blockquote>

<p>Thanks for the advice :)</p>
"
2351204,457898,2010-02-28T13:47:03Z,2,"Subset a data.frame by list and apply function on each part, by rows","<p>This may seem as a typical <code>plyr</code> problem, but I have something different in mind.
Here's the function that I want to optimize (skip the <code>for</code> loop).</p>

<pre><code># dummy data
set.seed(1985)
lst &lt;- list(a=1:10, b=11:15, c=16:20)
m &lt;- matrix(round(runif(200, 1, 7)), 10)
m &lt;- as.data.frame(m)


dfsub &lt;- function(dt, lst, fun) {
    # check whether dt is `data.frame`
    stopifnot (is.data.frame(dt))
    # check if vectors in lst are ""whole"" / integer
    # vector elements should be column indexes
    is.wholenumber &lt;- function(x, tol = .Machine$double.eps^0.5)  abs(x - round(x)) &lt; tol
    # fall if any non-integers in list
    idx &lt;- rapply(lst, is.wholenumber)
    stopifnot(idx)
    # check for list length
    stopifnot(ncol(dt) == length(idx))
    # subset the data
    subs &lt;- list()
    for (i in 1:length(lst)) {
            # apply function on each part, by row
            subs[[i]] &lt;- apply(dt[ , lst[[i]]], 1, fun)
    }
    # preserve names
    names(subs) &lt;- names(lst)
    # convert to data.frame
    subs &lt;- as.data.frame(subs)
    # guess what =)
    return(subs)
}
</code></pre>

<p>And now a short demonstration... actually, I'm about to explain what I primarily intended to do. I wanted to subset a <code>data.frame</code> by vectors gathered in <code>list</code> object. Since this is a part of code from a function that accompanies data manipulation in psychological research, you can consider <code>m</code> as a results from personality questionnaire (10 subjects, 20 vars). Vectors in list hold column indexes that define questionnaire subscales (e.g. personality traits). Each subscale is defined by several items (columns in <code>data.frame</code>). If we presuppose that the score on each subscale is nothing more than <code>sum</code> (or some other function) of row values (results on that part of questionnaire for each subject), you could run:</p>

<pre><code>&gt; dfsub(m, lst, sum)
    a  b  c
1  46 20 24
2  41 24 21
3  41 13 12
4  37 14 18
5  57 18 25
6  27 18 18
7  28 17 20
8  31 18 23
9  38 14 15
10 41 14 22
</code></pre>

<p>I took a glance at this function and I must admit that this little loop isn't spoiling the code at all... BUT, if there's an easier/efficient way of doing this, please, let me know!</p>
"
2351744,216064,2010-02-28T16:48:51Z,12,Insert line breaks in long string -- word wrap,"<p>Here is a function I wrote to break a long string into lines not longer than a given length</p>

<pre><code>strBreakInLines &lt;- function(s, breakAt=90, prepend="""") {
  words &lt;- unlist(strsplit(s, "" ""))
  if (length(words)&lt;2) return(s)
  wordLen &lt;- unlist(Map(nchar, words))
  lineLen &lt;- wordLen[1]
  res &lt;- words[1]
  lineBreak &lt;- paste(""\n"", prepend, sep="""")
  for (i in 2:length(words)) {
    lineLen &lt;- lineLen+wordLen[i]
    if (lineLen &lt; breakAt) 
      res &lt;- paste(res, words[i], sep="" "")
    else {
      res &lt;- paste(res, words[i], sep=lineBreak)
      lineLen &lt;- 0
    }
  }
  return(res)
}
</code></pre>

<p>It works for the problem I had; but I wonder if I can learn something here. Is there a shorter or more efficient solution, especially can I get rid of the for loop?</p>
"
2352617,256662,2010-02-28T20:51:13Z,29,How (and why) do you use contrasts?,"<p>Under what cases do you create contrasts in your analysis? How is it done and what is it used for?</p>

<p>I checked <code>?contrasts</code> and <code>?C</code> - both lead to ""Chapter 2 of Statistical Models in S"", which is not readily available to me.</p>
"
2352813,207258,2010-02-28T21:46:53Z,4,"How to merge two data.frames together in R, referencing a lookup table","<p>I am trying to merge two <code>data.frames</code> together, based on a common column name in each of them called <code>series_id</code>.  Here is my merge statement: </p>

<pre><code>merge(test_growth_series_LUT,  test_growth_series, by = intersect(series_id, series_id))
</code></pre>

<p>The error I'm getting is </p>

<blockquote>
  <p>Error in as.vector(y) : object 'series_id' not found</p>
</blockquote>

<p>The help gives this description, but I can't see why it can't find the <code>series_id</code>.   Example data is below.  </p>

<pre><code>### S3 method for class 'data.frame':
   #merge(x, y, by = intersect(names(x), names(y)),
   #      by.x = by, by.y = by, all = FALSE, all.x = all, all.y = all,
   #      sort = TRUE, suffixes = c("".x"","".y""), ...)



# Create a long data.frame to store data...
test_growth_series = data.frame (""read_day"" = c(0, 3, 9, 0, 3, 9, 0, 2, 8), 
""series_id"" = c(""p1s1"", ""p1s1"", ""p1s1"", ""p1s2"", ""p1s2"", ""p1s2"", ""p3s4"", ""p3s4"", ""p3s4""),
""mean_od"" = c(0.6, 0.9, 1.3, 0.3, 0.6, 1.0, 0.2, 0.5, 1.2),
""sd_od"" = c(0.1, 0.2, 0.2, 0.1, 0.1, 0.3, 0.04, 0.1, 0.3),
""n_in_stat"" = c(8, 8, 8, 8, 7, 5, 8, 7, 2)
)

# Create a name LUT
test_growth_series_LUT = data.frame (""series_id"" = c(""p1s1"", ""p1s2"", ""p3s4"", ""p4s2"", ""p5s2"", ""p6s2"", ""p7s4"", ""p8s4"", ""p9s4""),""description"" = c(""blah1"", ""blah2"", ""blah3"", ""blah4"", ""blah5"", ""blah6"", ""blah7"", ""blah8"", ""blah9"")
)

&gt; test_growth_series
  read_day series_id mean_od sd_od n_in_stat
1        0      p1s1     0.6  0.10         8
2        3      p1s1     0.9  0.20         8
3        9      p1s1     1.3  0.20         8
4        0      p1s2     0.3  0.10         8
5        3      p1s2     0.6  0.10         7
6        9      p1s2     1.0  0.30         5
7        0      p3s4     0.2  0.04         8
8        2      p3s4     0.5  0.10         7
9        8      p3s4     1.2  0.30         2
&gt; test_growth_series_LUT
  series_id description
1      p1s1       blah1
2      p1s2       blah2
3      p3s4       blah3
4      p4s2       blah4
5      p5s2       blah5
6      p6s2       blah6
7      p7s4       blah7
8      p8s4       blah8
9      p9s4       blah9
&gt; 



this is what I'm trying to achieve:  
&gt; new_test_growth_series
  read_day series_id mean_od sd_od n_in_stat        description
1        0      p1s1     0.6  0.10         8        blah1
2        3      p1s1     0.9  0.20         8        blah1
3        9      p1s1     1.3  0.20         8        blah1
4        0      p1s2     0.3  0.10         8        blah2
5        3      p1s2     0.6  0.10         7        blah2
6        9      p1s2     1.0  0.30         5        blah2
7        0      p3s4     0.2  0.04         8        blah3
8        2      p3s4     0.5  0.10         7        blah3
9        8      p3s4     1.2  0.30         2        blah3
</code></pre>
"
2355727,271844,2010-03-01T12:32:02Z,5,Fixed effects regression in R (with a very large number of dummy variables),"<p>Is there an easy way to do a fixed-effects regression in R when the number of dummy variables leads to a model matrix that exceeds the R maximum vector length? E.g., </p>

<pre><code>&gt; m &lt;- lm(log(bid) ~ after + I(after*score) + id, data = data)
Error in model.matrix.default(mt, mf, contrasts) : 
cannot allocate vector of length 905986769
</code></pre>

<p>where id is a factor (and is the variable causing the problem above). </p>

<p>I know that I could go through and de-mean all the data, but this throws the standard errors off (yes, you could compute the SE's ""by hand"" w/ a df adjustment but I'd like to minimize the probability that I'm introducing new errors). I've looked at the plm package but it seems only designed for classical panel data w/ a time component, which is not the structure of my data.  </p>
"
2359444,264696,2010-03-01T22:08:01Z,1,"In R, how do I set an S4 class based on another object's class","<p>I need to create an object of type ShortReadQ from Bioconductor's ShortRead library.</p>

<pre><code>ShortReadQ 'signature(sread = ""DNAStringSet"", quality =
          ""QualityScore"", id = ""BStringSet"")'
</code></pre>

<p>The quality slot needs to be an object inheriting from QualityScore, of which I can easily determine from another ShortReadQ object that I wish to emulate.</p>

<pre><code>&gt; class(quality(anotherObject))
[1] ""SFastqQuality""
attr(,""package"")
[1] ""ShortRead""
</code></pre>

<p>What is the best way to use that information (""SFastqQuality"") in the contructor argument?</p>

<pre><code>newObject&lt;-ShortReadQ(sread=...,
             quality=SFastqQuality(...), 
             id=...)
</code></pre>
"
2359723,207258,2010-03-01T22:52:50Z,37,How to add a title to a ggplot when the title is a variable name?,"<p>At the end of a ggplot, this works fine:</p>

<pre><code>+ opts(title = expression(""Chart chart_title...""))
</code></pre>

<p>But this does not:</p>

<pre><code>chart_title = ""foo""
+ opts(title = expression(chart_title))
</code></pre>

<p>nor this: </p>

<pre><code>chart_title = ""foo""
+ opts(title = chart_title)
</code></pre>

<p>How can I add a title to a ggplot when the title is a variable name?</p>
"
2360490,NA,2010-03-02T02:12:47Z,1,Applying nlminb to subsets of data (by index or label) and store what the program returns as a new data frame,"<p>I was wondering if anyone could kindly help me on this seemingly easy task.  I'm using nlminb to conduct optimization and compute some statistics by index. Here's an example from nlminb help.</p>

<pre><code>&gt; x &lt;- rnbinom(100, mu = 10, size = 10)
&gt; hdev &lt;- function(par) {
+     -sum(dnbinom(x, mu = par[1], size = par[2], log = TRUE))
+ }
&gt; nlminb(c(9, 12), hdev)
$par
[1] 9.730000 5.954936
$objective
[1] 297.2074
$convergence
[1] 0
$message
[1] ""relative convergence (4)""
$iterations
[1] 10
$evaluations
function gradient
      12       27
</code></pre>

<p>Suppose I generate random variables <code>x, y</code> and <code>z</code> where <code>z</code> acts as an index (from 1 to 3).</p>

<pre><code>&gt; x &lt;- rnbinom(100, mu = 10, size = 10)
&gt; y &lt;- rnbinom(100, mu = 10, size = 10)
&gt; z &lt;- rep(1:3, length=100)
&gt; A &lt;- cbind(x,y,z)
&gt; hdev &lt;- function(par) {
+     -sum(dnbinom(x+y, mu = par[1], size = par[2], log = TRUE))}
</code></pre>

<p>1) How can I apply <code>nlminb(c(9, 12), hdev)</code> to the data set by index <code>z</code>? In other words, I would like to compute <code>nlminb(c(9, 12), hdev)</code> for <code>z=1, z=2</code>, and <code>z=3</code> separately. I tried <code>by(A, z, function(A) nlminb(c(9,12), hdev))</code> and <code>sparseby(A, z, function(A) nlminb(c(9,12), hdev))</code>, but they return exactly the same values for each value of <code>z</code>.</p>

<p>2) I would like to turn each output into a new data frame so that it will become a 3X2 matrix.</p>

<pre><code>[1] Z1_ANSWER_1 Z1_ANSWER_2
[2] Z2_ANSWER_1 Z2_ANSWER_2
[3] Z3_ANSWER_1 Z3_ANSWER_2
</code></pre>

<p>Since nlminb returns the summary of statistics, I needed to use <code>CASEZ1&lt;-nlminb$par, CASEZ2&lt;-nlminb$par, CASEZ3&lt;-nlminb$par</code> and then use cbind to combine them. However, I would like to automate this process as the real data I'm working on has a lot more categories than <code>z</code> presented here.</p>

<p>If I'm not making myself clear, please let me know. I'll see if I can replicate the actual data set and functions I'm working on (I just don't have them on this computer).</p>

<p>Thank you very much in advance.</p>
"
2361557,207258,2010-03-02T07:43:37Z,3,How to add a condition to the geom_point size?,"<p>I am trying to add a condition to geom_point size and I've pasted my example below.  I would like geom_point size to be 2 when n_in_stat is 4 or more, and size = 5 when n_in_stat is less than 4.   I tried putting an ifelse statement inside the geom_point, but this failed.  Perhaps I can't include logical operators here and I have to create a new column in the data.frame and set the size to that?</p>

<p>geom_point(size = ifelse(n_in_stat &lt; 4, 5, 2)) +   # trying to set size with an ifelse</p>

<p>geom_point(aes(size = n_in_stat)) +  # original scaled linearly</p>

<pre><code>library(ggplot2)

# Create a long data.frame to store data...
growth_series = data.frame (""read_day"" = c(0, 3, 9, 0, 3, 9, 0, 2, 8), 
""series_id"" = c(""p1s1"", ""p1s1"", ""p1s1"", ""p1s2"", ""p1s2"", ""p1s2"", ""p3s4"", ""p3s4"", ""p3s4""),
""mean_od"" = c(0.6, 0.9, 1.3, 0.3, 0.6, 1.0, 0.2, 0.5, 1.2),
""sd_od"" = c(0.1, 0.2, 0.2, 0.1, 0.1, 0.3, 0.04, 0.1, 0.3),
""n_in_stat"" = c(8, 8, 8, 8, 7, 5, 8, 7, 2)
)

# Plot using ggplot...
ggplot(data = growth_series, aes(x = read_day, y = mean_od, group = series_id, color = series_id)) +
geom_line(size = 1.5) +
geom_point(aes(size = n_in_stat)) +
geom_errorbar(aes(ymin = mean_od - sd_od, ymax = mean_od + sd_od), size = 1, width = 0.3) +
xlab(""Days"") + ylab(""Log (O.D. 730 nm)"") +
scale_y_log2() +
scale_colour_hue('my legend', breaks = levels(growth_series$series_id), labels=c('t1', 't2', 't3'))
</code></pre>
"
2363881,284485,2010-03-02T14:42:25Z,4,ggplot2 geom_area overlapping instead of stacking,"<p>I'm trying to generate a stacked area plot, but instead, ggplot makes overlapping areas. I've tried other examples that seems analogous to me, but they work and mine doesn't.</p>

<pre><code>&gt; cx
         date type visitors
1  2009-11-23    A        2
2  2010-01-07    A        4
3  2010-01-09    A        6
4  2010-02-07    A        8
5  2009-12-02    B        2
6  2009-12-03    B        4
7  2009-12-11    B        6
8  2010-01-20    B        8
9  2010-01-26    B       10
10 2010-01-30    B       11
11 2010-02-01    B       12
12 2009-12-07   LU        2
13 2009-12-28   LU        4
14 2010-01-27   LU        7
15 2010-02-04    L        1
16 2010-02-22    L        2
17 2009-11-14    O        2
18 2009-11-27    O        4
19 2010-01-11    O        6
20 2010-01-13    O        8
21 2010-02-10    O        9
22 2009-11-24    R        2
23 2009-12-01    R        4
24 2009-12-13    R        6
25 2009-12-14    R        8
26 2010-01-03    R       10
27 2010-01-16    R       12
28 2010-02-06    R       13
29 2010-02-08    R       15
30 2009-11-15    T        2
31 2009-11-19    T        4
32 2009-11-25    T        6
33 2009-11-26    T        8
34 2009-12-09    T       10
35 2009-12-10    T       12
36 2009-12-15    T       14
37 2009-12-19    T       16
38 2009-12-22    T       18
39 2010-02-23    T       19
40 2010-02-24    T       20
41 2010-01-21   Tr        2
42 2010-01-23   Tr        4
43 2010-01-24   Tr        6
44 2010-01-06    U        2
45 2009-11-09    V        2
46 2009-11-18    V        4
47 2009-12-16    V        6
48 2009-12-23    V        8
49 2009-12-25    V       10
50 2010-01-02    V       12
51 2010-01-12    V       14
52 2010-01-14    V       16
53 2010-01-15    V       18
54 2010-01-17    V       20
55 2010-01-19    V       22
56 2010-01-25    V       25
57 2010-02-05    V       26
&gt; ggplot(cx) + geom_area(aes(x=date, y=visitors, fill=type), position=""stack"")
</code></pre>

<p>This gives a plot where each type is plotted as its own area, and these are overlaid instead of stacked. If I sort them right, I then get a series of smaller areas inside larger, but that's not what I'm after.</p>

<p>I've tried different arguments of position, to no avail.</p>

<p>How can I get the stacked areas?</p>
"
2367328,256662,2010-03-02T22:26:27Z,15,How to change current Plot Window Size (in R),"<p>For example. Assume I do:</p>

<pre><code>dev.new(width=5, height=4)
plot(1:20)
</code></pre>

<p>And now I wish to do</p>

<pre><code>plot(1:40)
</code></pre>

<p>But I want a bigger window for it.</p>

<p>I would guess that the way to do it would be (assuming I don't want to open a new window) to do</p>

<pre><code>plot(1:40, width=10, height=4)
</code></pre>

<p>Which of course doesn't work.</p>

<p>The only solution I see to it would be to turn off the window and start a new one. (Which will end my plotting history)</p>

<p>Is there a better way ?</p>

<p>Thanks.</p>
"
2370094,284485,2010-03-03T09:45:15Z,1,Melting a cast data frame gives incorrect output (Hadley Wickham's reshape package in R),"<p>I've encountered a strange behaviour in cast/melt from Hadley Wickham's reshape package. If I cast a data frame, and then try to melt it, the melt comes out wrong. Manually unsetting the ""df.melt"" class from the cast dataframe lets it be melted properly.</p>

<p>Does anyone know if this is intended behaviour, and if so, what is the use case when you'd want it?</p>

<p>A small code example which shows the behaviour:</p>

<pre><code>&gt; df &lt;- data.frame(type=c(1, 1, 2, 2, 3, 3), variable=""n"", value=c(71, 72, 68, 80, 21, 20))

&gt; df
  type variable value
1    1        n    71
2    1        n    72
3    2        n    68
4    2        n    80
5    3        n    21
6    3        n    20

&gt; df.cast &lt;- cast(df, type~., sum)
&gt; names(df.cast)[2] &lt;- ""n""

&gt; df.cast
  type   n
1    1 143
2    2 148
3    3  41

&gt; class(df.cast)
[1] ""cast_df""    ""data.frame""

&gt; melt(df.cast, id=""type"", measure=""n"")
         type value value
X.all.      1   143 (all)
X.all..1    2   148 (all)
X.all..2    3    41 (all)

&gt; class(df.cast) &lt;- ""data.frame""
&gt; class(df.cast)
[1] ""data.frame""

&gt; melt(df.cast, id=""type"", measure=""n"")
  type variable value
1    1        n   143
2    2        n   148
3    3        n    41
</code></pre>
"
2370515,63605,2010-03-03T10:52:42Z,30,How to get row index number in R?,"<p>Suppose I have a list or data frame in R, and I would like to get the row index, how do I do that? That is, I would like to know how many rows a certain matrix consists of.</p>
"
2370648,95048,2010-03-03T11:12:28Z,9,modify lm or loess function to use it within ggplot2's geom_smooth,"<p>I need to modify the <code>lm</code> (or eventually <code>loess</code>) function so I can use it in ggplot2's <code>geom_smooth</code> (or <code>stat_smooth</code>).</p>

<p>For example, this is how <code>stat_smooth</code> is used normally:</p>

<pre><code>&gt; qplot(data=diamonds, carat, price, facets=~clarity) + stat_smooth(method='lm')`
</code></pre>

<p>I would like to define a custom <code>lm2</code> function to use as value for the <code>method</code> parameter in <code>stat_smooth</code>, so I can customize its behaviour.</p>

<pre><code>&gt; lm2 &lt;- function(formula, data, ...)
  {
      print(head(data))
      return(lm(formula, data, ...))
  }
&gt; qplot(data=diamonds, carat, price, facets=~clarity) + stat_smooth(method='lm2')
</code></pre>

<p>Note that I have used <code>method='lm2'</code> as parameter in <code>stat_smooth</code>.
When I execute this code a get the error:</p>

<blockquote>
  <p>Error in eval(expr, envir, enclos) : 'nthcdr' needs a list to CDR down</p>
</blockquote>

<p>Which I don't understand very well. The <code>lm2</code> method works very well when run outside of <code>stat_smooth</code>. I played with this a bit and I have got different types of error, but since I am not comfortable with R's debug tools it is difficult for me to debug them. Honestly, I  don't get what I should put inside the <code>return()</code> call.</p>
"
2373334,216064,2010-03-03T17:09:20Z,1,"How can I draw a tree with igraph ""bottom-up""?","<p>It is very straight-forward to plot a tree using igraph in R</p>

<pre><code>library(igraph)
plot(graph.tree(20, 2), layout=layout.reingold.tilford)
</code></pre>

<p>Is it possible to ""turn the graph around"", so that the root (node 0) is at the top of the plot? Or, alternatively, is it possible to put the root to middle left?</p>
"
2374947,270572,2010-03-03T21:04:14Z,0,Indexing data.frames using arrays of TRUEs and FALSEs,"<p>I'm having some trouble indexing data.frames in R. I'm an R beginner. I have a <code>data.frame</code> called <code>d</code> which has 35512 columns and 77 rows. I have a list called <code>rd</code> which contains 35512 elements. I'd like all the columns of <code>d</code> which correspond to the items in <code>rd</code> less than 100. Here's what I'm doing:</p>

<pre><code># just to prove I'm not crazy
&gt; length(colnames(d))
[1] 35512
&gt; length(rownames(d))
[1] 77
&gt; length(rd)
[1] 35512
# find all the elements of rd less than 100 (+ unnecessary faffing?)
&gt; i &lt;- unlist(rd&lt;100)
&gt; names(i) &lt;- NULL
# try to extract all the elements of d corresponding to rd &lt; 100
&gt; d &lt;- d[,i]
Error in `[.data.frame`(d, , i) : undefined columns selected
</code></pre>

<p>I don't really want to be doing the <code>unlist</code> and <code>names(i) &lt;- NULL</code> stuff but I'm getting seriously paranoid. Can anyone help with what the hell this error message means?</p>

<p>In case it helps, the <code>rd</code> variable is created using the following:</p>

<pre><code>rd = lapply(lapply(d, range), diff)
</code></pre>

<p>Which hopefully tells me the difference in the range of each column of <code>d</code>.</p>

<p>P.S. bonus awesomeness for anyone who can tell me a command to find the shape of a data.frame other than querying the length of its row and column names.</p>

<p>Edit: Here's what <code>rd</code> looks like:</p>

<pre><code>&gt; rd[1:3]
$`10338001`
[1] 7198.886

$`10338003`
[1] 4748.963

$`10338004`
[1] 3173.046
</code></pre>

<p>and when I've done my faffing, <code>i</code> looks like this:</p>

<pre><code>&gt; i[7:10]
[1] FALSE FALSE FALSE  TRUE
</code></pre>
"
2375587,285812,2010-03-03T22:44:57Z,87,Reorder levels of a factor without changing order of values,"<p>I have data frame with some numerical variables and some categorical <code>factor</code> variables. The order of levels for those factors is not the way I want them to be. </p>

<pre><code>numbers &lt;- 1:4
letters &lt;- factor(c(""a"", ""b"", ""c"", ""d""))
df &lt;- data.frame(numbers, letters)
df
#   numbers letters
# 1       1       a
# 2       2       b
# 3       3       c
# 4       4       d
</code></pre>

<p>If I change the order of the levels, the letters no longer are with their corresponding numbers (my data is  total nonsense from this point on).</p>

<pre><code>levels(df$letters) &lt;- c(""d"", ""c"", ""b"", ""a"")
df
#   numbers letters
# 1       1       d
# 2       2       c
# 3       3       b
# 4       4       a
</code></pre>

<p>I simply want to change the <em>level</em> order, so when plotting, the bars are shown in the desired order - which may differ from default alphabetical order.</p>
"
2376034,277434,2010-03-04T00:14:16Z,1,How to color points in a different color if a data attribute is not null,"<p>I have a scatter plot in R (with ggplot2). The data has a numeric column (let's call it <code>bin</code>) which can contain various integer values or null.</p>

<p>I would like to colour the points with non-null bin values differently from the others. I do not want to one colour per value of bin, that would be too noisy. Just simply, say, red for those with a non-null bin and black for the others.</p>

<p>qplot has a <code>colour</code> attribute, but I don't know how to express a condition like <code>colour = bin != null ? ""red"" : ""black""</code></p>
"
2376614,277434,2010-03-04T03:04:30Z,2,Create qplots (with ggplot2) larger than the window?,"<p>I have a large chart with many data points. When I create the qplot in R, the chart is auto-fitted to the window. Even if I maximize the window, the chart is still too small and details are lost. I would like to save it as a large PNG and then look at certain areas at 1:1 resolution with an image viewer (as I cannot zoom in easily in R). Rendering the chart for a range of the values is not really convenient, I'd like to have one PNG and scroll around and discuss it with my peers, rather than pre-generating a bunch of subgraphs.</p>

<p>Is this possible? I kind of expect to be so, but some help would be appreciated (I've recently started with R so am still finding my way around).</p>

<p>Thank you.</p>
"
2379701,74658,2010-03-04T13:49:43Z,2,Can you merge cells in an xtable in R,"<p>I've got some data (the output of a ddply function) that I want to present in an xtable for use somewhere else.</p>

<pre><code>calqc_table&lt;-structure(list(RUNID = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L), ANALYTEINDEX = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L), ID = structure(1:11, .Label = c(""Cal A"", ""Cal B"", ""Cal C"", 
""Cal D"", ""Cal E"", ""Cal F"", ""Cal G"", ""Cal H"", ""Cal High"", ""Cal Low"", 
""Cal Mid""), class = ""factor""), mean_conc = c(200.619459644855, 
158.264703128903, 102.469121407733, 50.3551544728544, 9.88296440865076, 
4.41727762501703, 2.53494715706024, 1.00602831741361, 199.065054555735, 
2.48063347296935, 50.1499780776199), sd_conc = c(2.3275711264554, 
NA, NA, NA, NA, NA, NA, 0.101636943231162, 0, 0, 0), nrow = c(3, 
1, 1, 1, 1, 1, 1, 3, 2, 2, 2)), .Names = c(""RUNID"", ""ANALYTEINDEX"", 
""ID"", ""mean_conc"", ""sd_conc"", ""nrow""), row.names = c(NA, -11L
), class = ""data.frame"")
calqc_xtable&lt;-xtable(calqc_table)
print(calqc_xtable,type=""html"")
</code></pre>

<p>which gives me the table in html format.  However, I want to Merge together the content of the RUNID and ANALYTEINDEX columns vertically where the values are the same.  Anyone know how to do that via xtable (or some other way ?)</p>
"
2381618,286496,2010-03-04T18:13:55Z,6,How to draw a chart with sorted horizontal error bars (sorted barcharts with error marks)?,"<p>I would like to plot means and standard errors as a horizontal barchart, and I want the mean sorted. </p>

<p>I've found the way to plot horizontal sorted barcharts using lattice, but I do not know how to add error marks. The following are my data and the R code I came up with.</p>

<pre><code>data &lt;- structure(c(0.67, 0.67, 0.76, 0.66, 0.71, 0.6, 0.52, 0.6, 0.71, 0.76, 
0.76, 0.71, 0.6, 0.61, 0.9, 0.5, 0.58, 0.84, 0.68, 0.88,
0.89, 0.96, 1, 0.95, 1, 1, 0.98, 0.78, 0.98, 1, 
1, 0.99, 1, 1, 0.95, 0.92, 1, 0.91, 1, 0.87, 
0.91, 0.72, 0.73, 0.55, 0.82, 0.87, 0.64, 0.75, 0.75, 1, 
0.81, 0.79, 1, 0.74, 0.57, 0.84, 1, 0.95, 0.78, 0.95), .Dim = c(20L, 3L), .Dimnames = list(
    c(""1"", ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"", ""11"", 
    ""12"", ""13"", ""14"", ""15"", ""16"", ""17"", ""18"", ""19"", ""20""), c(""A"", 
    ""B"", ""C"")))

means &lt;- apply(data, 2, mean)

errors &lt;- apply(data, 2, sd)

plot.data &lt;- data.frame(colnames(data), means, errors)

colnames(plot.data) &lt;- c(""var"", ""mean"", ""error"")

library(""lattice"")
plot.new()

barchart(reorder(var, mean) ~ mean, plot.data, xlim = c(0, 1))
</code></pre>

<p>Is there any way to add error marks to this chart? If not, any suggestion on how to plot the chart I want in R?</p>

<p>Thank you in advance!</p>
"
2384517,143813,2010-03-05T04:10:08Z,26,using R to copy files,"<p>As part of a larger task performed in R run under windows, I would like to copy selected files between directories. Is it possible to give within R a command like <code>cp patha/filea*.csv pathb</code> (notice the wildcard, for extra spice)?</p>
"
2386086,162154,2010-03-05T10:45:35Z,3,How escape or sanatize slash using regex in R?,"<p>I'm trying to read in a (tab separted) csv file in R. When I want to read the column including a <code>/</code>, I get an error. <p></p>

<pre><code>doSomething &lt;- function(dataset) {
     a &lt;- dataset$data_transfer.Jingle/TCP.total_size_kb
     ...
     }
</code></pre>

<p>The error says, that this object cannot be found. I've tried escaping with backslash but it did not work.</p>

<p>If anybody has got some idea, I'd really appreciate it!</p>
"
2388974,136862,2010-03-05T18:18:35Z,17,How do I use cookies with RCurl?,"<p>I am trying to write an R package that accesses some data via a REST API. The API, however, doesn't use http authentication, but rather relies on cookies to keep credentials with the session.</p>

<p>Essentially, I'd like to replace the following two lines from a bash script with two R functions: One to perform the login, and store the session cookie, and the second to GET the data.</p>

<pre><code>curl -X POST -c cookies.txt -d""username=xxx&amp;password=yyy"" http://api.my.url/login
curl         -b cookies.txt                               http://api.my.url/data
</code></pre>

<p>I'm clearly not understanding how RCurl works with curl options. My script as it stands has:</p>

<pre><code>library(RCurl)
curl &lt;- getCurlHandle()
curlSetOpt(cookiejar='cookies.txt', curl=curl)
postForm(""http://api.my.url/login"", username='xxx', password='yyy', curl=curl)
getURL('http://api.my.url/data"", curl=curl)
</code></pre>

<p>The final <code>getURL()</code> fails with a ""Not logged in."" message from the server, and after the <code>postForm()</code> no <code>cookies.txt</code> file exists.</p>
"
2390338,190597,2010-03-05T22:19:58Z,1,How can I get aov to show me the F-statistic and p-value?,"<p>The following script </p>

<pre><code>#!/usr/bin/Rscript --vanilla
x &lt;- c(4.5,6.4,7.2,6.7,8.8,7.8,9.6,7.0,5.9,6.8,5.7,5.2)
fertilizer&lt;- factor(c('A','A','A','A','B','B','B','B','C','C','C','C'))
crop &lt;- factor(c('I','II','III','IV','I','II','III','IV','I','II','III','IV'))
av &lt;- aov(x~fertilizer*crop)
summary(av)
</code></pre>

<p>yields</p>

<pre><code>                Df  Sum Sq Mean Sq
fertilizer       2 13.6800  6.8400
crop             3  2.8200  0.9400
fertilizer:crop  6  6.5800  1.0967
</code></pre>

<p>For other data, <code>aov</code> usually gives the F-statistic and associated p-value. What is wrong/special about this data that causes R to omit the juicy parts?</p>
"
2391364,142477,2010-03-06T04:31:47Z,4,converting multiple lines of text into a data frame,"<p>I'm trying to find a way to convert multiple lines of text into a
data frame.  I'm not sure if there's a way where you can use <code>read.delim()</code>
to read in multiple lines of text and create the following data frame
with something akin to <code>rehape()</code>?.</p>

<p>The data is structured as follows:</p>

<pre><code>A: 1
B: 2
C: 10
A: 34
B: 20
C: 6.7
A: 2
B: 78
C: 35
</code></pre>

<p>I'd like to convert this data to something that looks like the following data frame:</p>

<pre><code>A             B             C
1             2             10
34            20            6.7
2             78            35
</code></pre>

<p>Apologies if there is an obvious way to do this!</p>
"
2391739,207258,2010-03-06T07:34:24Z,4,How can I run a OSX terminal command from within R?,"<p>How can I run a OSX terminal command from within R?</p>
"
2392017,143476,2010-03-06T09:30:49Z,8,SQLite or flat text file?,"<p>I process a lot of text/data that I exchange between Python, R, and sometimes Matlab.</p>

<p>My go-to is the flat text file, but also use SQLite occasionally to store the data and access from each program (not Matlab yet though). I don't use GROUPBY, AVG, etc. in SQL as much as I do these operations in R, so I don't necessarily require the database operations.</p>

<p>For such applications that requires exchanging data among programs to make use of available libraries in each language, is there a good rule of thumb on which data exchange format/method to use (even XML or NetCDF or HDF5)?</p>

<p>I know between Python -> R there is rpy or rpy2 but I was wondering about this question in a more general sense - I use many computers which all don't have rpy2 and also use a few other pieces of scientific analysis software that require access to the data at various times (the stages of processing and analysis are also separated).</p>
"
2392216,256662,2010-03-06T10:57:00Z,11,Why does as.factor return a character when used inside apply?,"<p>I want to convert variables into factors using <code>apply()</code>:</p>

<pre><code>a &lt;- data.frame(x1 = rnorm(100),
                x2 = sample(c(""a"",""b""), 100, replace = T),
                x3 = factor(c(rep(""a"",50) , rep(""b"",50))))

a2 &lt;- apply(a, 2,as.factor)
apply(a2, 2,class)
</code></pre>

<p>results in:</p>

<pre><code>         x1          x2          x3 
""character"" ""character"" ""character"" 
</code></pre>

<p>I don't understand why this results in character vectors instead of factor vectors.</p>
"
2394902,457898,2010-03-07T02:08:09Z,8,Remove variable labels attached with foreign/Hmisc SPSS import functions,"<p>As usual, I got some SPSS file that I've imported into R with <code>spss.get</code> function from <code>Hmisc</code> package. I'm bothered with <code>labelled</code> class that <code>Hmisc::spss.get</code> adds to all variables in <code>data.frame</code>, hence want to remove it.</p>

<p><code>labelled</code> class gives me headaches when I try to run <code>ggplot</code> or even when I want to do some menial analysis! One solution would be to remove <code>labelled</code> class from each variable in <code>data.frame</code>. How can I do that? Is that possible at all? If not, what are my other options?</p>

<p>I really want to bypass reediting variables ""from scratch"" with <code>as.data.frame(lapply(x, as.numeric))</code> and <code>as.character</code> where applicable... And I certainly don't want to run SPSS and remove labels manually (don't like SPSS, nor care to install it)!</p>

<p>Thanks!</p>
"
2397097,288281,2010-03-07T17:12:48Z,20,How can a data ellipse be superimposed on a ggplot2 scatterplot?,"<p>I have an R function which produces 95% confidence ellipses for scatterplots. The output looks like this, having a default of 50 points for each ellipse (50 rows):</p>

<pre><code>           [,1]         [,2]
 [1,]  0.097733810  0.044957994
 [2,]  0.084433494  0.050337990
 [3,]  0.069746783  0.054891438
</code></pre>

<p>I would like to superimpose a number of such ellipses for each level of a factor called 'site' on a <code>ggplot2</code> scatterplot, produced from this command:</p>

<pre><code>&gt; plat1 &lt;- ggplot(mapping=aes(shape=site, size=geom), shape=factor(site)); plat1 + geom_point(aes(x=PC1.1,y=PC2.1))
</code></pre>

<p>This is run on a dataset, called <code>dflat</code> which looks like this:</p>

<pre><code>site      geom         PC1.1        PC2.1       PC3.1        PC1.2       PC2.2
1 Buhlen 1259.5649 -0.0387975838 -0.022889782  0.01355317  0.008705276  0.02441577
2 Buhlen  653.6607 -0.0009398704 -0.013076251  0.02898955 -0.001345149  0.03133990
</code></pre>

<p>The result is fine, but when I try to add the ellipse (let's say for this one site, called ""Buhlen""):</p>

<pre><code>&gt; plat1 + geom_point(aes(x=PC1.1,y=PC2.1)) + geom_path(data=subset(dflat, site=""Buhlen""),mapping=aes(x=ELLI(PC1.1,PC2.1)[,1],y=ELLI(PC1.1,PC2.1)[,2]))
</code></pre>

<p>I get an error message: <code>""Error in data.frame(x = c(0.0977338099339815, 0.0844334944904515, 0.0697467834016782,  : 
  arguments imply differing number of rows: 50, 211</code></p>

<p>I've managed to fix this in the past, but I cannot remember how. It seems that geom_path is relying on the same points rather than plotting new ones. Any help would be appreciated.</p>
"
2397349,256662,2010-03-07T18:25:07Z,1,"Is there an equivalence of ""anova"" (for lm) to an rpart object?","<p>When using R's <code>rpart</code> function, I can easily fit a model with it. for example:</p>

<pre><code># Classification Tree with rpart
library(rpart)

# grow tree 
fit &lt;- rpart(Kyphosis ~ Age + Number + Start,
     method=""class"", data=kyphosis)

printcp(fit) # display the results 
plotcp(fit) 
summary(fit) # detailed summary of splits

# plot tree 
plot(fit, uniform=TRUE, 
     main=""Classification Tree for Kyphosis"")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
</code></pre>

<p>My question is - 
How can I measure the ""importance"" of each of my three explanatory variables (Age, Number, Start) to the model?</p>

<p>If this was a regression model, I could have looked at p-values from the ""anova"" F-test (between <code>lm</code> models with and without the variable). But what is the equivalence of using ""anova"" on <code>lm</code> to an <code>rpart</code> object?</p>

<p>(I hope I managed to make my question clear)</p>

<p>Thanks.</p>
"
2399027,168139,2010-03-08T02:52:30Z,9,Cannot load rJava because cannot load a shared library,"<p>I have been struggling to load the rJava package in R. </p>

<p>I get the following messages</p>

<pre><code>&gt; library(rJava)
Error in inDL(x, as.logical(local), as.logical(now), ...) : 
  unable to load shared library \
     'C:/PROGRA~1/R/R-210~1.1/library/rJava/libs/rJava.dll':
  LoadLibrary failure:  The specified module could not be found.


Error : .onLoad failed in 'loadNamespace' for 'rJava'
Error: package/namespace load failed for 'rJava'
</code></pre>

<p>I have tried so many solutions that they are all bamboozeled in my head. 
At some point I even got </p>

<pre><code>&gt; R Console: Rgui.exe - System Error The
&gt; program can't start because
&gt; MSVCR71.dll is is missing from your
&gt; computer. Try reinstalling the program
&gt; to fix this problem.
</code></pre>

<p>I made sure everything I could think of was on the path</p>

<pre><code>&gt; C:\Program Files\R\Rtools\bin;C:\Program Files\R\Rtools\perl\bin;
  C:\Program Files\R\Rtools\MinGW\bin;%SystemRoot%\system32;
  %SystemRoot%;%SystemRoot%\System32\Wbem;
  %SYSTEMROOT%\System32\WindowsPowerShell\v1.0\;
  C:\Program Files\QuickTime\QTSystem\;
  C:\Program Files\R\R-2.10.1\library\rJava\libs\;
  C:\Program Files\R;C:\Program Files\Java\jre6\bin\client  
</code></pre>

<p>What should I try next?</p>

<p>I am running R version 2.10.1 (2009-12-14) and I have also tried R version 2.10.1 Patched (2010-03-03 r51210). It is on a Windows machine running windows 7 enterprise</p>
"
2402885,193143,2010-03-08T16:37:21Z,1,"Barplot in R, aggregation of sampled data","<p>I want an stacked barplot, or at least two barplots (histogramms) of the data below. But I cant't figure out how. plot(online) is not the solution, I´m looking for. Please see below.</p>

<pre><code>          online              offline
1         sehrwichtig             wichtig
2             wichtig           unwichtig
3         sehrwichtig           unwichtig
4         sehrwichtig         sehrwichtig
5         sehrwichtig         sehrwichtig
6         sehrwichtig           unwichtig
7         sehrwichtig           unwichtig
8             wichtig             wichtig
9             wichtig           unwichtig
10        sehrwichtig         sehrwichtig
11        sehrwichtig             wichtig
12        sehrwichtig           unwichtig
13            wichtig         sehrwichtig
14        sehrwichtig             wichtig
</code></pre>

<p><strong>I know I need a step, where the data is aggregated to:</strong></p>

<pre><code>                   online        offline 
   sehrwichtig           6         7 
   unwichtig             0         1 
   wichtig               3         5 
</code></pre>

<p>But how?</p>
"
2403466,134830,2010-03-08T17:59:45Z,9,Greek letters in ggplot strip text,"<p>I'm trying to override the text in some ggplot strips to incorporate Greek characters.  Here's some sample data, and the base for the plot.</p>

<pre><code>dfr &lt;- data.frame(
   x = rep(1:10, times = 6),
   y = runif(60),
   fx = rep(c(""foo"", ""bar""), each = 30),
   fy = rep(c(""alpha"", ""beta"", ""gamma""), each = 10, times = 2)
)

p &lt;- ggplot(dfr, aes(x, y)) + geom_point()
</code></pre>

<p>My first attempt at a plot has no Greek in the strip labels.</p>

<pre><code> p + facet_grid(fy ~ fx)
</code></pre>

<p>I gather that I'm supposed to add a labeller argument to <code>facet_grid</code> to override the text.  I presumed that this should spit out an expression to handle the greek characters, but my code just throws an error when the graphic is printed.</p>

<pre><code>lbl &lt;- function(variable, value)
{
   if(variable == ""fy"") parse(text=as.character(value)) else value
}
p + facet_grid(fy ~ fx, labeller = lbl)


Error in aperm(X, c(s.call, s.ans)) : 
  unimplemented type 'expression' in 'aperm'
</code></pre>

<p>How should I be creating the strip labels?</p>
"
2404085,3514,2010-03-08T19:27:38Z,12,Reshape data frame to convert factors into columns in R,"<p>I have a data frame where one particular column has a set of specific values (let's say, 1, 2, ..., 23). What I would like to do is to convert from this layout to the one, where the frame would have extra 23 (in this case) columns, each one representing one of the factor values. The data in these columns would be booleans indicating whether a particular row had a given factor value... To show a specific example:</p>

<p>Source frame:</p>

<pre><code>ID       DATE         SECTOR
123      2008-01-01   1
456      2008-01-01   3
789      2008-01-02   5
... &lt;more records with SECTOR values from 1 to 5&gt;
</code></pre>

<p>Desired format:</p>

<pre><code>ID       DATE         SECTOR.1   SECTOR.2   SECTOR.3   SECTOR.4   SECTOR.5
123      2008-01-01      T          F          F          F          F
456      2008-01-01      F          F          T          F          F
789      2008-01-02      F          F          F          F          T
</code></pre>

<p>I have no problem doing it in a loop but I hoped there would be a better way. So far <code>reshape()</code> didn't yield the desired result. Help would be much appreciated.</p>
"
2405575,290765,2010-03-08T23:26:12Z,10,How does one plot a 3D stacked histogram in R?,"<p>I want to plot stacked histograms in R; i.e. stack individual histograms in the third dimension.</p>

<hr>

<p>thank you all for your suggestions, especially the one by Shane.</p>

<p>@hadley, I agree with your points, however, my situation is different: the main point I'm trying to convey by plotting four stacked histograms is that the tails vary significantly....the part that will get obscured is of no consequence in the data I'm presenting....also, being able to read the frequency axis is also not important since I'll be plotting the relative frequencies...</p>
"
2409317,289692,2010-03-09T13:31:41Z,11,How to adjust time scale axis for ggplot histogram,"<p>I am working with a data frame where one of the columns consists of <code>POSIXct</code> date-time values.  I am trying to plot a histogram of these timestamps using <code>ggplot2</code> but I'm having two issues:</p>

<ol>
<li><p>I don't know how to set the binwidth in <code>geom_histogram()</code>.  I'd like to set each bin to a day or a week.  I've tried providing a difftime object, but I get an error.  I also tried <code>binwidth=1</code> but R just hangs.</p></li>
<li><p>How do I set the limits in <code>scale_x_time()</code>?  The only way I could get it to work was by converting my <code>POSIXct</code> timestamps using <code>as.Date()</code>.</p></li>
</ol>
"
2409357,162832,2010-03-09T13:38:56Z,39,How to nicely annotate a ggplot2 (manual),"<p>Using <code>ggplot2</code> I normally use <code>geom_text</code> and something like <code>position=jitter</code> to annotate my plots.</p>

<p>However - for a nice plot I often finds it worthwhile to annotate manually. like below:</p>

<pre><code>data2 &lt;- structure(list(type = structure(c(5L, 1L, 2L, 4L, 3L, 5L, 1L, 
2L, 4L, 3L, 5L, 1L, 2L, 4L, 3L, 5L, 1L, 2L, 4L, 3L), .Label = c(""EDS"", 
""KIU"", ""LAK"", ""MVH"", ""NA*""), class = ""factor""), value = c(0.9, 
0.01, 0.01, 0.09, 0, 0.8, 0.05, 0, 0.15, 0, 0.41, 0.04, 0.03, 
0.52, 0, 0.23, 0.11, 0.02, 0.64, 0.01), time = c(3L, 3L, 3L, 
3L, 3L, 6L, 6L, 6L, 6L, 6L, 15L, 15L, 15L, 15L, 15L, 27L, 27L, 
27L, 27L, 27L), year = c(2008L, 2008L, 2008L, 2008L, 2008L, 2007L, 
2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 
2006L, 2006L, 2006L, 2006L, 2006L)), .Names = c(""type"", ""value"", 
""time"", ""year""), row.names = c(1L, 3L, 4L, 5L, 6L, 7L, 9L, 10L, 
11L, 12L, 13L, 15L, 16L, 17L, 18L, 19L, 21L, 22L, 23L, 24L), class = ""data.frame"")
ggplot(data2, aes(x=time, y=value, group=type, col=type))+
geom_line()+
geom_point()+
theme_bw()+
annotate(""text"", x=6, y=0.9, label=""this is a wrong color"")+
annotate(""text"", x=15, y=0.6, label=""this is a second annotation with a wrong color"")
</code></pre>

<p>The problem is, that I can't get the text annotations color to match the line color. I assume I could fix this with a manual scale, but I hope there is a better way?</p>
"
2413163,457898,2010-03-09T22:41:00Z,2,Emacs - help() output in web-browser,"<p>I started using Emacs (ESS) as a default R editor (yes, @Dirk, as you've said, I want ESS), and I must admit it's by far <b> the best</b> <code>R</code> editor I've been using so far. However, I cannot manage to get an output of <code>help()</code> function up to web browser. It keeps displaying help page in a separate R buffer, even if <code>options(help_type = ""html"", browser = ""firefox"")</code> are set.</p>

<p>How can I get help back to browser, while using Emacs/ESS?</p>
"
2414915,143476,2010-03-10T06:21:50Z,5,Concepts and tools required to scale up algorithms,"<p>I'd like to begin thinking about how I can scale up my algorithms that I write for data analysis so that they can be applied to arbitrarily large sets of data. I wonder what are the relevant concepts (threads, concurrency, immutable data structures, recursion) and tools (Hadoop/MapReduce, Terracota, and Eucalyptus) to make this happen, and how specifically these concepts and tools are related to each other. I have a rudimentary background in R, Python, and bash scripting and also C and Fortran programming, though I'm familiar with some basic functional programming concepts also. Do I need to change the way that I program, use a different language (Clojure, Haskell, etc.), or simply (or not so simply!) adapt something like R/Hadoop (HRIPE)... or write wrappers for Python to enable multi-threading or Hadoop access? I understand this would might involve requirements for additional hardware and I would like some basic idea of what the requirements/options available might be. My apologies for this rather large and yet vague question, but just trying to get started - thanks in advance!</p>
"
2417623,162832,2010-03-10T14:30:36Z,11,"Manual annotate a ggplot with different labels, in different facets","<p>JD Long helped me with this: <a href=""https://stackoverflow.com/questions/2409357/how-to-nicely-annotate-a-ggplot2-manual"">question about manual annotation</a>. But is it possible to do something similar on a facetted plot, such that the label style corresponds to the linestyle (aestetics) and in a way that I can annotate different facets individually?
Some data</p>

<p><code>funny &lt;- structure(list(Institution = structure(c(1L, 1L, 1L, 1L, 2L, 
2L, 2L, 2L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 
3L, 3L, 3L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 1L, 
1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L), .Label = c(""Q-branch"", 
""Some-Ville"", ""Spectre""), class = ""factor""), Type = structure(c(5L, 
6L, 1L, 3L, 5L, 6L, 2L, 4L, 5L, 6L, 2L, 4L, 5L, 6L, 2L, 4L, 5L, 
6L, 2L, 4L, 5L, 6L, 2L, 4L, 5L, 6L, 2L, 4L, 5L, 6L, 2L, 4L, 5L, 
6L, 2L, 4L, 5L, 6L, 2L, 4L, 5L, 6L, 2L, 4L, 5L, 6L, 2L, 4L), .Label = c(""Korte videregående uddannelser"", 
""Mammas beer"", ""Mellemlange videregående uddannelser"", ""Tastes good"", 
""Unknown"", ""Your""), class = ""factor""), År = c(2008L, 2008L, 
2008L, 2008L, 2008L, 2008L, 2008L, 2008L, 2008L, 2008L, 2008L, 
2008L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 
2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 
2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2006L, 2006L, 
2006L, 2006L, 2006L, 2006L, 2006L, 2006L, 2006L, 2006L, 2006L, 
2006L), Mndr = c(3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 15L, 15L, 
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 27L, 27L, 27L, 
27L, 27L, 27L, 27L, 27L, 27L, 27L, 27L, 27L), Data = c(159L, 
NA, NA, 23L, 204L, NA, NA, 12L, 256L, NA, NA, 24L, 166L, 6L, 
NA, 43L, 228L, NA, NA, 20L, 196L, 11L, NA, 37L, 99L, 14L, 9L, 
96L, 147L, 7L, 5L, 91L, 100L, 10L, 7L, 126L, 60L, 17L, 6L, 106L, 
78L, 18L, 13L, 140L, 48L, 23L, 5L, 136L)), .Names = c(""Institution"", 
""Type"", ""År"", ""Mndr"", ""Data""), class = ""data.frame"", row.names = c(NA, 
-48L))</code></p>

<p>And a facetted plot:</p>

<pre><code>ggplot(funny, aes(Mndr, y=Data, group=Type, col=Type))+geom_line()+facet_grid(.~Institution)
</code></pre>

<p>Thanks in advance for your help!</p>
"
2427279,169947,2010-03-11T17:41:29Z,7,Extract information from conditional formula,"<p>I'd like to write an R function that accepts a formula as its first argument, similar to lm() or glm() and friends.  In this case, it's a function that takes a data frame and writes out a file in <a href=""http://svmlight.joachims.org/"" rel=""nofollow noreferrer"">SVMLight</a> format, which has this general form:</p>

<pre><code>&lt;line&gt; .=. &lt;target&gt; &lt;feature&gt;:&lt;value&gt; &lt;feature&gt;:&lt;value&gt; ... &lt;feature&gt;:&lt;value&gt; # &lt;info&gt;
&lt;target&gt; .=. +1 | -1 | 0 | &lt;float&gt; 
&lt;feature&gt; .=. &lt;integer&gt; | ""qid""
&lt;value&gt; .=. &lt;float&gt;
&lt;info&gt; .=. &lt;string&gt;
</code></pre>

<p>for example, the following data frame:</p>

<pre><code>  result qid     f1     f2     f3     f4   f5     f6     f7     f8
1     -1   1 0.0000 0.1253 0.0000 0.1017 0.00 0.0000 0.0000 0.9999
2     -1   1 0.0098 0.0000 0.0000 0.0000 0.00 0.0316 0.0000 0.3661
3      1   1 0.0000 0.0000 0.1941 0.0000 0.00 0.0000 0.0509 0.0000
4     -1   2 0.0000 0.2863 0.0948 0.0000 0.34 0.0000 0.7428 0.0608
5      1   2 0.0000 0.0000 0.0000 0.4347 0.00 0.0000 0.9539 0.0000
6      1   2 0.0000 0.7282 0.9087 0.0000 0.00 0.0000 0.0000 0.0355
</code></pre>

<p>would be represented as follows:</p>

<pre><code>-1 qid:1 2:0.1253 4:0.1017 8:0.9999
-1 qid:1 1:0.0098 6:0.0316 8:0.3661
1  qid:1 3:0.1941 7:0.0509
-1 qid:2 2:0.2863 3:0.0948 5:0.3400 7:0.7428 8:0.0608
1  qid:2 4:0.4347 7:0.9539
1  qid:2 2:0.7282 3:0.9087 8:0.0355
</code></pre>

<p>The function I'd like to write would be called something like this:</p>

<pre><code>write.svmlight(result ~ f1+f2+f3+f4+f5+f6+f7+f8 | qid, data=mydata, file=""out.txt"")
</code></pre>

<p>Or even</p>

<pre><code>write.svmlight(result ~ . | qid, data=mydata, file=""out.txt"")
</code></pre>

<p>But I can't figure out how to use <code>model.matrix()</code> and/or <code>model.frame()</code> to know what columns it's supposed to write.  Are these the right things to be looking at?</p>

<p>Any help much appreciated!</p>
"
2427742,264696,2010-03-11T18:47:40Z,8,How do I change the stacking order in a bar chart in ggplot2?,"<p>From the <a href=""http://docs.ggplot2.org/0.9.2.1/geom_bar.html"" rel=""nofollow noreferrer"">online bar chart guide</a>:</p>

<pre><code>qplot(factor(cyl), data=mtcars, geom=""bar"", fill=factor(gear)) 
</code></pre>

<p><a href=""https://i.stack.imgur.com/T9H6N.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/T9H6N.png"" alt=""barplot using &lt;code&gt;qplot&lt;/code&gt; feature of &lt;code&gt;ggplot2&lt;/code&gt;""></a></p>

<p>How do I get 5 to sit on the bottom, 4 above that, and 3 on top?</p>
"
2434833,216064,2010-03-12T18:15:44Z,8,How can I partition a vector?,"<p>How can I build a function </p>

<pre><code>slice(x, n) 
</code></pre>

<p>which would return a list of vectors where each vector except maybe the last has size n, i.e.</p>

<pre><code>slice(letters, 10)
</code></pre>

<p>would return</p>

<pre><code>list(c(""a"", ""b"", ""c"", ""d"", ""e"", ""f"", ""g"", ""h"", ""i"", ""j""),
     c(""k"", ""l"", ""m"", ""n"", ""o"", ""p"", ""q"", ""r"", ""s"", ""t""),
     c(""u"", ""v"", ""w"", ""x"", ""y"", ""z""))
</code></pre>

<p>?</p>
"
2436129,160794,2010-03-12T21:49:03Z,1,Optimal Sharing of heavy computation job using Snow and/or multicore,"<p>I have the following problem.  </p>

<p>First my environment, I have two 24-CPU servers to work with and one big job (resampling a large dataset) to share among them.  I've setup multicore and (a socket) Snow cluster on each. As a high-level interface I'm using foreach.</p>

<p>What is the optimal sharing of the job? Should I setup a Snow cluster using CPUs from both machines and split the job that way (i.e. use doSNOW for the foreach loop). Or should I use the two servers separately and use multicore on each server (i.e. split the job in two chunks, run them on each server and then stich it back together). </p>

<p>Basically what is an easy way to:
 1. Keep communication between servers down (since this is probably the slowest bit).
 2. Ensure that the random numbers generated in the servers are not highly correlated.</p>
"
2436502,169947,2010-03-12T23:15:30Z,1,Accessing 'data' argument of with() function?,"<p>Is it possible, in the <code>expr</code> expression of the <code>with()</code> function, to access the <code>data</code> argument directly?  Here's what I mean conceptually:</p>

<pre><code>&gt; print(df)
  result qid     f1     f2     f3
1     -1   1 0.0000 0.1253 0.0000
2     -1   1 0.0098 0.0000 0.0000
3      1   1 0.0000 0.0000 0.1941
4     -1   2 0.0000 0.2863 0.0948
5      1   2 0.0000 0.0000 0.0000
6      1   2 0.0000 0.7282 0.9087
&gt; with(df, subset(.data, select=f1:f3))  # Doesn't work
</code></pre>

<p>Of course the above example is kind of silly, but it would be handy for things like this:</p>

<pre><code>with(subset(df, f2&gt;0), foo(qid, vars=subset(.data, select=f1:f3)))
</code></pre>

<p>I tried to poke around with <code>environment()</code> and <code>parent.frame()</code> etc., but didn't come up with anything that worked.</p>

<p>Maybe this is really a question about <code>eval()</code>, since that's how <code>with.default()</code> is implemented.</p>
"
2436688,5222,2010-03-13T00:14:09Z,194,"Append an object to a list in R in amortized constant time, O(1)?","<p>If I have some R list <code>mylist</code>, you can append an item <code>obj</code> to it like so:</p>

<pre><code>mylist[[length(mylist)+1]] &lt;- obj
</code></pre>

<p>But surely there is some more compact way.  When I was new at R, I  tried writing <code>lappend()</code> like so:</p>

<pre><code>lappend &lt;- function(lst, obj) {
    lst[[length(lst)+1]] &lt;- obj
    return(lst)
}
</code></pre>

<p>but of course that doesn't work due to R's call-by-name semantics (<code>lst</code> is effectively copied upon call, so changes to <code>lst</code> are not visible outside the scope of <code>lappend()</code>.  I know you can do environment hacking in an R function to reach outside the scope of your function and mutate the calling environment, but that seems like a large hammer to write a simple append function.</p>

<p>Can anyone suggest a more beautiful way of doing this? Bonus points if it works for both vectors and lists.</p>
"
2436735,457898,2010-03-13T00:30:55Z,3,Preview colours in Emacs-ESS,"<p>I accidentally managed to get colour names, #HEX, and a colour preview in Emacs. Don't have a bloody idea how, must've pressed some keybinding or menu item... But, now I can't seem to find where's that feature... I'm quite sure I wasn't hallucinating, so it's gotta be there, under some keystroke that I can't reproduce!!! =)</p>
"
2437312,209536,2010-03-13T04:56:43Z,2,How to center an R plot after removing axis labels,"<p>I'm working on visualizing a matrix in R (almost exactly like <a href=""http://reference.wolfram.com/mathematica/ref/MatrixPlot.html"" rel=""nofollow noreferrer"">http://reference.wolfram.com/mathematica/ref/MatrixPlot.html</a>), and I've been using </p>

<pre><code>image(&lt;matrix&gt;,axes=FALSE) 
</code></pre>

<p>to draw the picture. However, I noticed that with the y-axis turned off, the plot isn't centered--the space is still there for the axis ticks + label. I can finagle some centering with </p>

<pre><code>par(oma=c(0,0,0,2.5))
</code></pre>

<p>but this seems inefficient and error-prone (if my matrix were to change dimensions/become non-square). Is there a better way to force the graphic to center?
<a href=""http://img694.imageshack.us/img694/9891/metropolis.png"" rel=""nofollow noreferrer"">Reference image http://img694.imageshack.us/img694/9891/metropolis.png</a></p>

<p>The right hand margin is significantly smaller than the left.</p>
"
2438486,457898,2010-03-13T13:23:25Z,2,Rreport/LaTeX quality output package,"<p>I'm looking for some LaTeX template for creating quality output. On R-bloggers I've bumped on Frank Harrel's Rreport package. Due to my quite modest LaTeX abilities, only a user-friendly (and noob-friendly) interface should suffice. Here's a <a href=""http://biostat.mc.vanderbilt.edu/wiki/Main/Rreport"" rel=""nofollow noreferrer"">link</a> to an official website. I'm following the instructions, but I cannot manage to install an app. I use Ubuntu 9.10, R version is 2.10.1 (updated regularly from UCLA's CRAN server), and of course, cvs is installed on my system.</p>

<p>Now, I'd like to know if there is some user-friendly LaTeX template package (Sweave is still to advanced/spartan for me). I'm aware that my question is quite confounding, but a brief glance on examples on Rreport page should give you a hint. I'm aware that LaTeX skills are a must, but just for now I need something that will suit my needs (as a psychological researcher).</p>

<p>Is there any package similar with Rreport?</p>
"
2441136,43729,2010-03-14T04:04:24Z,5,What is an efficient method for partitioning and aggregating intervals from timestamped rows in a data frame?,"<p>From a data frame with timestamped rows (strptime results), what is the best method for aggregating statistics for intervals?  </p>

<p>Intervals could be an hour, a day, etc. </p>

<p>There's the <code>aggregate</code> function, but that doesn't help with assigning each row to an interval.  I'm planning on adding a column to the data frame that denotes interval and using that with <code>aggregate</code>, but if there's a better solution it'd be great to hear it.</p>

<p>Thanks for any pointers!</p>

<hr>

<p><strong><em>Example Data</em></strong></p>

<p>Five rows with timestamps divided into 15-minute intervals starting at 03:00.</p>

<p><strong>Interval 1</strong></p>

<ul>
<li>""2010-01-13 03:02:38 UTC"" </li>
<li>""2010-01-13 03:08:14 UTC"" </li>
<li>""2010-01-13 03:14:52 UTC""</li>
</ul>

<p><strong>Interval 2</strong></p>

<ul>
<li>""2010-01-13 03:20:42 UTC""</li>
<li>""2010-01-13 03:22:19 UTC""</li>
</ul>

<hr>

<p><strong><em>Conclusion</em></strong></p>

<p>Using a time series package such as <code>xts</code> should be the solution; however I had no success using them and winded up using <code>cut</code>.  As I presently only need to plot histograms, with rows grouped by interval, this was enough.</p>

<p><code>cut</code> is used liked so:</p>

<pre><code>interv &lt;- function(x, start, period, num.intervals) {
  return(cut(x, as.POSIXlt(start)+0:num.intervals*period))
}
</code></pre>
"
2441562,258334,2010-03-14T08:06:26Z,4,Coding the R-ight way - avoiding the for loop,"<p>I am going through one of my .R files and by cleaning it up a little bit I am trying to get more familiar with writing the code the r-ight way. As a beginner, one of my favorite starting points is to get rid of the <code>for()</code> loops and try to transform the expression into a functional programming form.
So here is the scenario:</p>

<p>I am assembling a bunch of <code>data.frames</code> into a <code>list</code> for later usage. </p>

<pre><code>dataList &lt;- list (dataA,
                  dataB,
                  dataC,
                  dataD,
                  dataE
                  )
</code></pre>

<p>Now I like to take a look at each data.frame's column names and substitute certain character strings. Eg I like to substitute each ""foo"" and ""bar"" with ""baz"". At the moment I am getting the job done with a <code>for()</code> loop which looks a bit awkward.</p>

<pre><code>colnames(dataList[[1]])
[1] ""foo""        ""code"" ""lp15""       ""bar""       ""lh15""  
colnames(dataList[[2]])
[1] ""a""        ""code"" ""lp50""       ""ls50""       ""foo""  

matchVec &lt;- c(""foo"", ""bar"")
for (i in seq(dataList)) {
  for (j in seq(matchVec)) {
    colnames (dataList[[i]])[grep(pattern=matchVec[j], x=colnames (dataList[[i]]))] &lt;- c(""baz"")
  }
}
</code></pre>

<p>Since I am working here with a <code>list</code> I thought about the <code>lapply</code> function. My attempts handling the job with the <code>lapply</code> function all seem to look alright but only at first sight. If I write</p>

<pre><code>f &lt;- function(i, xList) {
  gsub(pattern=c(""foo""), replacement=c(""baz""), x=colnames(xList[[i]]))
}
lapply(seq(dataList), f, xList=dataList)
</code></pre>

<p>the last line prints out almost what I am looking for. However, if i take another look at the actual names of the data.frames in dataList:</p>

<pre><code>lapply (dataList, colnames)
</code></pre>

<p>I see that no changes have been made to the initial character strings.</p>

<p>So how can I rewrite the <code>for()</code> loop and transform it into a functional programming form?
And how do I substitute both strings, ""foo"" and ""bar"", in an efficient way? Since the <code>gsub()</code> function takes as its <code>pattern</code> argument only a character vector of length one.</p>
"
2443095,170792,2010-03-14T17:53:25Z,1,Strange findFn malfunction,"<p>I noticed a strange malfunction in using <code>findFn</code> function (library <code>sos</code>) and I can't find out the source. While it works fine on my Windows XP pc, it does not on my Vista one.</p>

<pre><code>library (sos)

findFn(""randomization test"")
# in both finds 72 results

findFn(""{randomization test}"")
# In XP finds 19 or about so, but in Vista whenever I use {} and more than one word inside, 
# I keep getting the following:

found 0 matches
x has zero rows;  nothing to display.
Warning message:
In findFn(""{randomization test}"") :
  HIT not found in HTML;  processing one page only.
</code></pre>

<p>R ver = 2.10.1 and packages updated.
Any ideas where the problem might be?</p>

<p>Bonus: As it's obvious, I was looking for functions about <code>tests for randomized experiments</code>  </p>
"
2443127,256662,2010-03-14T18:03:23Z,10,How can I use R (Rcurl/XML packages ?!) to scrape this webpage?,"<p>I have a (somewhat complex) web scraping challenge that I wish to accomplish and would love for some direction (to whatever level you feel like sharing) here goes:</p>

<p>I would like to go through all the ""species pages"" present in this link:</p>

<p><a href=""http://gtrnadb.ucsc.edu/"" rel=""nofollow noreferrer"">http://gtrnadb.ucsc.edu/</a></p>

<p>So for each of them I will go to:</p>

<ol>
<li>The species page link (for example: <a href=""http://gtrnadb.ucsc.edu/Aero_pern/"" rel=""nofollow noreferrer"">http://gtrnadb.ucsc.edu/Aero_pern/</a>)</li>
<li>And then to the ""Secondary Structures"" page link (for example: <a href=""http://gtrnadb.ucsc.edu/Aero_pern/Aero_pern-structs.html"" rel=""nofollow noreferrer"">http://gtrnadb.ucsc.edu/Aero_pern/Aero_pern-structs.html</a>)</li>
</ol>

<p>Inside that link I wish to scrap the data in the page so that I will have a long list containing this data (for example):</p>

<pre><code>chr.trna3 (1-77)    Length: 77 bp
Type: Ala   Anticodon: CGC at 35-37 (35-37) Score: 93.45
Seq: GGGCCGGTAGCTCAGCCtGGAAGAGCGCCGCCCTCGCACGGCGGAGGcCCCGGGTTCAAATCCCGGCCGGTCCACCA
Str: &gt;&gt;&gt;&gt;&gt;&gt;&gt;..&gt;&gt;&gt;&gt;.........&lt;&lt;&lt;&lt;.&gt;&gt;&gt;&gt;&gt;.......&lt;&lt;&lt;&lt;&lt;.....&gt;&gt;&gt;&gt;&gt;.......&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;....
</code></pre>

<p>Where each line will have it's own list (inside the list for each ""trna"" inside the list for each animal)</p>

<p>I remember coming across the packages Rcurl and XML (in R) that can allow for such a task.  But I don't know how to use them.  So what I would love to have is:
1. Some suggestion on how to build such a code.
2. And recommendation for how to learn the knowledge needed for performing such a task.</p>

<p>Thanks for any help,</p>

<p>Tal</p>
"
2443556,293548,2010-03-14T20:03:38Z,-2,How do I specify random factors in R?,"<p>How do I specify random factors in R ? </p>

<p>If I have a factor <code>x1</code>  which is supposed to be random , can I try something like this ? </p>

<pre><code>lm(y ~ x1, data = p)
</code></pre>
"
2444686,293548,2010-03-15T02:08:44Z,2,ANOVA with 3 fixed factors in R,"<p>Im trying to run a model with a response variable p and  3 fixed factors to get ANOVA. this is how my code looks like : </p>

<pre><code>#run it as 3 fixed factor model 
p1=c(37,38,37,41,41,40,41,42,41)
p2=c(42,41,43,42,42,42,43,42,43)
p3=c(30,31,31,31,31,31,29,30,28)
p4=c(42,43,42,43,43,43,42,42,42)
p5=c(28,30,29,29,30,29,31,29,29)
p6=c(42,42,43,45,45,45,44,46,45)
p7=c(25,26,27,28,28,30,29,27,27)
p8=c(40,40,40,43,42,42,43,43,41)
p9=c(37,38,37,41,41,40,41,42,41)
p10=c(35,34,34,35,35,34,35,34,35)
p = cbind(p1,p2,p3,p4,p5,p6,p7,p8,p9,p10)
partnumber=c(rep(1,9),rep(2,9),rep(3,9),rep(4,9),rep(5,9),rep(6,9),rep(7,9),rep(8,9),rep(9,9),rep(10,9))
test=c(rep(c(rep(1:3,3)),10))
inspector = rep(c(rep(1,3),rep(2,3),rep(3,3)),10)
fpartnumber = factor(partnumber)
ftest = factor(test)
finspector = factor(inspector)
model=lm(p~fpartnumber*ftest*finspector)
summary(model)
anova(model)
</code></pre>

<p>but when I run it I get this error : it says my variable length for fpartnumber is different , but when I checked the length of each variable and is 90. What is going on ?</p>

<blockquote>
  <p>model=lm(y~fpartnumber<em>ftest</em>finspector)
      Error in model.frame.default(formula = yang ~ fpartnumber * ftest * finspector,  : 
      variable lengths differ (found for 'fpartnumber')</p>
</blockquote>
"
2444973,246211,2010-03-15T03:45:42Z,4,Arrange facet_grid by non-facet column (and labels using non-facet column),"<p>I have a couple of questions regarding facetting in ggplot2...</p>

<p>Let's say I have a query that returns data that looks like this:</p>

<p>(note that it's ordered by Rank asc, Alarm asc and two Alarms have a Rank of 3 because their Totals = 1798 for Week 4, and Rank is set according to Total for Week 4)</p>

<pre><code>   Rank Week                      Alarm Total
      1    1      BELTWEIGHER HIGH HIGH  1000
      1    2      BELTWEIGHER HIGH HIGH  1050
      1    3      BELTWEIGHER HIGH HIGH   900
      1    4      BELTWEIGHER HIGH HIGH  1800
      2    1              MICROWAVE LHS   200
      2    2              MICROWAVE LHS  1200
      2    3              MICROWAVE LHS   400
      2    4              MICROWAVE LHS  1799
      3    1  HI PRESS FILTER 2 CLOG SW  1250
      3    2  HI PRESS FILTER 2 CLOG SW  1640
      3    3  HI PRESS FILTER 2 CLOG SW  1000
      3    4  HI PRESS FILTER 2 CLOG SW  1798
      3    1 LOW PRESS FILTER 2 CLOG SW   800
      3    2 LOW PRESS FILTER 2 CLOG SW  1200
      3    3 LOW PRESS FILTER 2 CLOG SW   800
      3    4 LOW PRESS FILTER 2 CLOG SW  1798
</code></pre>

<p>(duplication code below)</p>

<pre><code>Rank = c(rep(1,4),rep(2,4),rep(3,8))
Week = c(rep(1:4,4))
Total = c(  1000,1050,900,1800,
        200,1200,400,1799,
        1250,1640,1000,1798,
        800,1200,800,1798) 
Alarm = c(rep(""BELTWEIGHER HIGH HIGH"",4),  
        rep(""MICROWAVE LHS"",4), 
        rep(""HI PRESS FILTER 2 CLOG SW"",4), 
        rep(""LOW PRESS FILTER 2 CLOG SW"",4)) 
spark &lt;- data.frame(Rank, Week, Alarm, Total) 
</code></pre>

<p>Now when I do this...</p>

<pre><code>s &lt;- ggplot(spark, aes(Week, Total)) +          
     opts( 
        panel.background = theme_rect(size = 1, colour = ""lightgray""), 
        panel.grid.major = theme_blank(), 
        panel.grid.minor = theme_blank(), 
        axis.line = theme_blank(), 
        axis.text.x = theme_blank(), 
        axis.text.y = theme_blank(), 
        axis.title.x = theme_blank(), 
        axis.title.y = theme_blank(),  
        axis.ticks = theme_blank(), 
        strip.background = theme_blank(), 
        strip.text.y = theme_text(size = 7, colour = ""red"", angle = 0) 
    ) 

s + facet_grid(Alarm ~ .) + geom_line() 
</code></pre>

<p>I get this....</p>

<p><a href=""http://img101.imageshack.us/img101/9103/ss20100315112108.png"" rel=""nofollow noreferrer"">alt text http://img101.imageshack.us/img101/9103/ss20100315112108.png</a></p>

<p>Notice that it's facetted according to Alarm and that the facets are arranged alphabetically. </p>

<p>Two Questions:</p>

<ol>
<li>How can I can I keep it facetted by alarm but displayed in the correct order? (Rank asc, Alarm asc).</li>
</ol>

<p><a href=""http://img17.imageshack.us/img17/6986/ss20100315113243.png"" rel=""nofollow noreferrer"">alt text http://img17.imageshack.us/img17/6986/ss20100315113243.png</a></p>

<ol start=""2"">
<li>Also, how can I keep it facetted by Alarm but show labels from Rank instead of Alarm?</li>
</ol>

<p><a href=""http://img85.imageshack.us/img85/470/ss20100315113529.png"" rel=""nofollow noreferrer"">alt text http://img85.imageshack.us/img85/470/ss20100315113529.png</a></p>

<p>Note that I can't just facet on Rank because ggplot2 would see only 3 facets to plot where there are really 4 different Alarms.</p>
"
2447454,17523,2010-03-15T13:35:44Z,24,Converting python objects for rpy2,"<p>The following code is supposed to create a heatmap in rpy2</p>

<pre><code>import numpy as np
from rpy2.robjects import r
data = np.random.random((10,10))
r.heatmap(data)    
</code></pre>

<p>However, it results in the following error</p>

<pre><code>Traceback (most recent call last):
  File ""z.py"", line 8, in &lt;module&gt;
    labRow=rowNames, labCol=colNames)
  File ""C:\Python25\lib\site-packages\rpy2\robjects\__init__.py"", line 418, in __call__
    new_args = [conversion.py2ri(a) for a in args]
  File ""C:\Python25\lib\site-packages\rpy2\robjects\__init__.py"", line 93, in default_py2ri
    raise(ValueError(""Nothing can be done for the type %s at the moment."" %(type(o))))
ValueError: Nothing can be done for the type &lt;type 'numpy.ndarray'&gt; at the moment.
</code></pre>

<p>From the documentation I learn that r.heatmap expects ""a numeric matrix"". How do I convert np.array to the required data type?</p>
"
2449083,152159,2010-03-15T17:22:34Z,13,Faster way to split a string and count characters using R?,"<p>I'm looking for a faster way to calculate GC content for DNA strings read in from a FASTA file. This boils down to taking a string and counting the number of times that the letter 'G' or 'C' appears. I also want to specify the range of characters to consider.  </p>

<p>I have a working function that is fairly slow, and it's causing a bottleneck in my code. It looks like this:</p>

<pre><code>##
## count the number of GCs in the characters between start and stop
##
gcCount &lt;-  function(line, st, sp){
  chars = strsplit(as.character(line),"""")[[1]]
  numGC = 0
  for(j in st:sp){
    ##nested ifs faster than an OR (|) construction
    if(chars[[j]] == ""g""){
      numGC &lt;- numGC + 1
    }else if(chars[[j]] == ""G""){
      numGC &lt;- numGC + 1
    }else if(chars[[j]] == ""c""){
      numGC &lt;- numGC + 1
    }else if(chars[[j]] == ""C""){
      numGC &lt;- numGC + 1
    }
  }
  return(numGC)
}
</code></pre>

<p>Running Rprof gives me the following output:</p>

<pre><code>&gt; a = ""GCCCAAAATTTTCCGGatttaagcagacataaattcgagg""
&gt; Rprof(filename=""Rprof.out"")
&gt; for(i in 1:500000){gcCount(a,1,40)};
&gt; Rprof(NULL)
&gt; summaryRprof(filename=""Rprof.out"")

                   self.time self.pct total.time total.pct
""gcCount""          77.36     76.8     100.74     100.0
""==""               18.30     18.2      18.30      18.2
""strsplit""          3.58      3.6       3.64       3.6
""+""                 1.14      1.1       1.14       1.1
"":""                 0.30      0.3       0.30       0.3
""as.logical""        0.04      0.0       0.04       0.0
""as.character""      0.02      0.0       0.02       0.0

$by.total
               total.time total.pct self.time self.pct
""gcCount""          100.74     100.0     77.36     76.8
""==""                18.30      18.2     18.30     18.2
""strsplit""           3.64       3.6      3.58      3.6
""+""                  1.14       1.1      1.14      1.1
"":""                  0.30       0.3      0.30      0.3
""as.logical""         0.04       0.0      0.04      0.0
""as.character""       0.02       0.0      0.02      0.0

$sampling.time
[1] 100.74
</code></pre>

<p>Any advice for making this code faster?</p>
"
2449226,170792,2010-03-15T17:46:41Z,1,Randomized experiments in R,"<p>Here is a simple randomized experiment. </p>

<p>In the following code I calculate the p-value under the null hypothesis that two different fertilizers applied to tomato plants have no effect in plants yields.
The first random sample (x) comes from plants where a standard fertilizer has been used, while an ""improved"" one has been used in the plants where the second sample (y) comes from.</p>

<pre><code>x &lt;- c(11.4,25.3,29.9,16.5,21.1)
y &lt;- c(23.7,26.6,28.5,14.2,17.9,24.3)
total &lt;- c(x,y)
first &lt;- combn(total,length(x))
second &lt;- apply(first,2,function(z) total[is.na(pmatch(total,z))])
dif.treat &lt;- apply(second,2,mean) - apply(first,2,mean)
# the first element of dif.treat is the one that I'm interested in 
(p.value &lt;- length(dif.treat[dif.treat &gt;= dif.treat[1]]) / length(dif.treat))
</code></pre>

<p>Do you know of any R function that performs tests like this one?</p>

<p>EDIT</p>

<pre><code># this is the equivalent independent t.test
t.test(x,y,alternative = ""less"",var.equal = T)
</code></pre>
"
2451411,207258,2010-03-16T00:29:14Z,0,R regex to validate user input is correct,"<p>I'm trying to practice writing better code, so I wanted to validate my input sequence with regex to make sure that the first thing I get is a single letter A to H only, and the second is a number 1 to 12 only.  I'm new to regex and not sure what the expression should look like.  I'm also not sure what type of error R would throw if this is invalidated?</p>

<p>In Perl it would be something like this I think: =~ m/([A-M]?))/)</p>

<p>Here is what I have so far for R:</p>

<pre><code>input_string = ""A1""
first_well_row = unlist(strsplit(input_string, """"))[1]  # get the letter out
first_well_col = unlist(strsplit(input_string, """"))[2]  # get the number out  
</code></pre>
"
2453326,235984,2010-03-16T09:54:16Z,103,Fastest way to find second (third...) highest/lowest value in vector or column,"<p>R offers max and min, but I do not see a really fast way to find the another value in the order apart from sorting the whole vector and than picking value x from this vector.</p>

<p>Is there a faster way to get the second highest value (e.g.)?</p>

<p>Thanks</p>
"
2453462,256662,2010-03-16T10:13:00Z,1,"How to parse a string (by a ""new"" markup) with R?","<p>I want to use R to do string parsing that (I think) is like a simplistic HTML parsing.</p>

<p>For example, let's say we have the following two variables:</p>

<pre><code>Seq &lt;- ""GCCTCGATAGCTCAGTTGGGAGAGCGTACGACTGAAGATCGTAAGGtCACCAGTTCGATCCTGGTTCGGGGCA""
Str &lt;- ""&gt;&gt;&gt;&gt;&gt;&gt;&gt;..&gt;&gt;&gt;&gt;........&lt;&lt;&lt;&lt;.&gt;&gt;&gt;&gt;&gt;.......&lt;&lt;&lt;&lt;&lt;.....&gt;&gt;&gt;&gt;&gt;.......&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;.""
</code></pre>

<p>Say that I want to parse ""Seq"" According to ""Str"", by using the legend here </p>

<pre><code>Seq: GCCTCGATAGCTCAGTTGGGAGAGCGTACGACTGAAGATCGTAAGGtCACCAGTTCGATCCTGGTTCGGGGCA
Str: &gt;&gt;&gt;&gt;&gt;&gt;&gt;..&gt;&gt;&gt;&gt;........&lt;&lt;&lt;&lt;.&gt;&gt;&gt;&gt;&gt;.......&lt;&lt;&lt;&lt;&lt;.....&gt;&gt;&gt;&gt;&gt;.......&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;.
     |     |  |              | |               |     |               ||     |
     +-----+  +--------------+ +---------------+     +---------------++-----+
        |        Stem 1            Stem 2                 Stem 3         |
        |                                                                |
        +----------------------------------------------------------------+
                                Stem 0
</code></pre>

<p>Assume that we always have 4 stems (0 to 3), but that the length of letters before and after each of them can very.</p>

<p>The output should be something like the following list structure:</p>

<pre><code>list(
    ""Stem 0 opening"" = ""GCCTCGA"",
    ""before Stem 1"" = ""TA"",
    ""Stem 1"" = list(opening = ""GCTC"",
                inside = ""AGTTGGGA"",
                closing = ""GAGC""
            ),
    ""between Stem 1 and 2"" = ""G"",
    ""Stem 2"" = list(opening = ""TACGA"",
                inside = ""CTGAAGA"",
                closing = ""TCGTA""
            ),
    ""between Stem 2 and 3"" = ""AGGtC"",
    ""Stem 3"" = list(opening = ""ACCAG"",
                inside = ""TTCGATC"",
                closing = ""CTGGT""
            ),
    ""After Stem 3"" = """",
    ""Stem 0 closing"" = ""TCGGGGC""
)
</code></pre>

<p>I don't have any experience with programming a parser, and would like advices as to what strategy to use when programming something like this (and any recommended R commands to use).</p>

<p>What I was thinking of is to first get rid of the ""Stem 0"", then go through the inner string with a recursive function (let's call it ""seperate.stem"") that each time will split the string into:
1. before stem
2. opening stem
3. inside stem
4. closing stem
5. after stem</p>

<p>Where the ""after stem"" will then be recursively entered into the same function (""seperate.stem"")</p>

<p>The thing is that I am not sure how to try and do this coding without using a loop.</p>

<p>Any advices will be most welcomed.</p>

<p><strong>Update</strong>: someone sent me a bunch of question, here they are.</p>

<p><strong>Q: Does each sequence have the same number of "">>>>"" for the opening sequence as it does for ""&lt;&lt;&lt;&lt;"" on the ending sequence?</strong><br>
A: Yes</p>

<p><strong>Q: Does the parsing always start with a partial stem 0 as your example shows?</strong> 
A: No. Sometimes it will start with a few "".""</p>

<p><strong>Q: Is there a way of making sure you have the right sequences when you start?</strong> 
A: I am not sure I understand what you mean.</p>

<p><strong>Q: Is there a chance of error in the middle of the string that you have to restart from?</strong>
A: Sadly, yes. In which case, I'll need to ignore one of the inner stems...</p>

<p><strong>Q: How long are these strings that you want to parse?</strong> 
A: Each string has between 60 to 150 characters (and I have tens of thousands of them...)</p>

<p><strong>Q: Is each one a self contained sequence like you show in your example, or do they go on for thousands of characters?</strong> 
A: each sequence is self contained.</p>

<p><strong>Q: Is there always at least one '.' between stems?</strong><br>
A: No.</p>

<p><strong>Q: A full set of rules as to how the parsing should be done would be useful.</strong>
A: I agree.  But since I don't have even a basic idea on how to start coding this, I thought first to have some help on the beginning and try to tweak with the other cases that will come up before turning back for help.</p>

<p><strong>Q: Do you have the BNF syntax for parsing?</strong>
A: No. Your e-mail is the first time I came across it (<a href=""http://en.wikipedia.org/wiki/Backus"" rel=""nofollow noreferrer"">http://en.wikipedia.org/wiki/Backus</a>–Naur_Form).</p>
"
2456696,230849,2010-03-16T17:34:44Z,3,Adding multiple vectors in R,"<p>I have a problem where I have to add thirty-three integer vectors of equal length from a dataset in R. I know the simple solution would be</p>

<pre><code>Vector1 + Vector2 + Vector3 +VectorN
</code></pre>

<p>But I am sure there is a way to code this. Also some vectors have NA in place of integers so I need a way to skip those. I know this may be very basic but I am new to this.</p>
"
2456864,207258,2010-03-16T18:01:57Z,4,How to print a character list from A to Z?,"<p>In R, how can I print a character list from A to Z?  With integers I can say:</p>

<pre><code>my_list = c(1:10)
&gt; my_list
 [1]  1  2  3  4  5  6  7  8  9 10
</code></pre>

<p>But can I do the same with characters?  e.g. </p>

<pre><code>my_char_list = c(A:Z)
my_char_list = c(""A"":""Z"")
</code></pre>

<p>These don't work, I want the output to be: <code>""A"" ""B"" ""C"" ""D""</code>, or separated by commas.</p>
"
2457112,295037,2010-03-16T18:36:59Z,1,HashMap as return value from Java method in R?,"<p>Is it possible to return a HashMap to R with the rJava extension of R?
E.g. I have a method in Java, which returns a HashMap and I want this HashMap use in R. I tried:</p>

<pre><code>.jcall(javaObj, ""Ljava/util/HashMap"", ""getDbInfoMap"")
</code></pre>

<p>This doesn't work.<br/>
Do I have to put everything into a String[], that I want to pass to R from Java?
Or is there another possibility?</p>

<p>Any help/info on this would be greatly appreciated.</p>
"
2457129,220120,2010-03-16T18:40:15Z,18,Converting unix seconds in milliseconds to POSIXct/POSIXlt,"<p>Why do I see a difference when I convert a unix timestamp to datetime object in R?</p>

<pre><code>&gt; as.POSIXlt(1268736919, origin=""1970-01-01"", tz=""America/New_York"")
[1] ""2010-03-16 06:55:19 EDT""

&gt; as.POSIXct(1268736919, origin=""1970-01-01"", tz=""America/New_York"")
[1] ""2010-03-16 11:55:19 EDT""
</code></pre>

<p>The result from POSIXlt is actually correct.</p>

<p>Also, is there a way to do this conversion without specifying the origin?</p>

<p>Thanks</p>
"
2457871,207258,2010-03-16T20:28:05Z,1,How to get the index of a letter from a list A-Z?,"<p>I want to get the index of a particular letter, e.g. </p>

<pre><code>&gt;  match(LETTERS,""G"")
 [1] NA NA NA NA NA NA  1 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
</code></pre>

<p>Gives me that the letter exists, but I want it to return 6 in this case for the 6th element of the list.</p>
"
2458013,256662,2010-03-16T20:47:50Z,35,What ways are there to edit a function in R?,"<p>Let's say we have the following function:</p>

<pre><code>foo &lt;- function(x)
{
    line1 &lt;- x
    line2 &lt;- 0
    line3 &lt;- line1 + line2
    return(line3)
}
</code></pre>

<p>And that we want to change the second line to be:</p>

<pre><code>    line2 &lt;- 2
</code></pre>

<p>How would you do that?</p>

<p>One way is to use</p>

<pre><code>fix(foo)
</code></pre>

<p>And change the function.</p>

<p>Another way is to just write the function again.</p>

<p>Is there another way? (Remember, the task was to change just the second line)</p>

<p>What I would like is for some way to represent the function as a vector of strings (well, characters), then change one of it's values, and then turn it into a function again.</p>
"
2462708,142477,2010-03-17T13:51:40Z,4,can't get syntax highlighting to work with R code in vim,"<p>This is a naive (and likely dumb) question, but I can't seem to get the R syntax highlighting to work with my Linux setup.  </p>

<p>I've downloaded a <code>r.vim</code> file that has improved syntax highlighting, and it works on my Windows gvim setup.  Does this <code>r.vim</code> file need to be in the <code>/usr/share/vim/v70/syntax</code> directory?  Right now, I have it in my home directory and trying out <code>source ~/r.vim</code> in the <code>~/.vimrc</code> file.  However, this doesn't seem to do anything.  Perhaps I'm barking up the wrong tree?</p>
"
2463437,1432,2010-03-17T15:15:43Z,16,R from C -- Simplest Possible Helloworld,"<p>What is the simplest possible C function for starting the R interpreter, passing in a small expression (eg, 2+2), and getting out the result?  I'm trying to compile with MingW on Windows.</p>
"
2464680,256662,2010-03-17T18:05:28Z,3,Is there a Pair-Wise PostHoc Comparisons for the Chi-Square Test in R?,"<p>I am wondering if there exists in R a package/function to perform the: ""Post Hoc Pair-Wise Comparisons for the Chi-Square Test of Homogeneity of Proportions"" (or an equivalent of it) Which is described here: 
<a href=""http://epm.sagepub.com/cgi/content/abstract/53/4/951"" rel=""nofollow noreferrer"">http://epm.sagepub.com/cgi/content/abstract/53/4/951</a></p>

<p>My situation is of just making a chi test, on a 2 by X matrix. I found a difference, but I want to know which of the columns is ""responsible"" for the difference.</p>

<p>Thanks, 
Tal</p>
"
2464721,294729,2010-03-17T18:12:11Z,3,R looking for the wrong java version,"<p>I installed/uninstalled java jre/jdk now many times and finally installed the older version 1.6.0_17 which is now located at ""C:\Program Files\Java\jre6\bin"". Now after all if I call 'java -version' within R i can see that R is looking for Java at the old path which is now wrong. The question is: Why is R looking for Java at the wrong path even so the windows path is set correctly? There are no double entrys within the windows path as far as I can see and I restarted R as well as Windows more then once since then. Any Ideas where R takes the wrong path from?</p>

<p>On windows shell:<br><code> 
$>set <br> 
[..]<br>
OS=Windows_NT<br> 
Path=C:\Program Files\Java\jre6\bin;<br> 
[..]<br></code> </p>

<p><code> 
$> java -version<br>
java version ""1.6.0_17""<br>
Java(TM) SE Runtime Environment (build 1.6.0_17-b04)<br>
Java HotSpot(TM) 64-Bit Server VM (build 14.3-b01, mixed mode)<br></code> </p>

<p>within R: <br><code> 
$>system(""java -version"")<br> 
Error: could not open `C:\Program Files (x86)\Java\jre6\lib\i386\jvm.cfg' <br></code></p>
"
2467019,296155,2010-03-18T01:11:33Z,2,HT create a new vector in data frame that takes correlation of existing vectors,"<p>I have a time series of two indexes, with each row representing the closing price on the same day. I'd like to go to row 30 and lookback over the last 30 'days' and calculate the pearson correlation. And then store that value in a new vector. Then, repeat the calculation for the entire time series. </p>

<p>It is a trivial task in Excel, so I'm convinced it can be done in R. I don't know the method to use though.</p>
"
2467329,278320,2010-03-18T03:05:15Z,5,How to do introspection in R,"<p>I am somewhat new to R, and i have this piece of code which generates a variable that i don't know the type for. Are there any introspection facility in R which will tell me which type this variable belongs to?</p>

<p>The following illustrates the property of this variable:</p>

<p>I am working on linear model selection, and the resource I have is <code>lm</code> result from another model. Now I want to retrieve the <code>lm</code> call by the command summary(model)$call so that I don't need to hardcode the model structure. However, since I have to change the dataset, I need to do a bit of modification on the ""string"", but apparently it is not a simple string. I wonder if there is any command similar to string.replace so that I can manipulate this variable from the variable $call.</p>

<pre><code>&gt; str&lt;-summary(rdnM)$call
&gt; str
lm(formula = y ~ x1, data = rdndat)
&gt; str[1]
lm()
&gt; str[2]
y ~ x1()
&gt; str[3]
rdndat()
&gt; str[3] &lt;- data
Warning message:
In str[3] &lt;- data :
  number of items to replace is not a multiple of replacement length
&gt; str
lm(formula = y ~ x1, data = c(10, 20, 30, 40))
&gt; str&lt;-summary(rdnM)$call
&gt; str
lm(formula = y ~ x1, data = rdndat)
&gt; str[3] &lt;- 'data'
&gt; str
lm(formula = y ~ x1, data = ""data"")
&gt; str&lt;-summary(rdnM)$call
&gt; type str
Error: unexpected symbol in ""type str""
&gt; 
</code></pre>
"
2470248,3306,2010-03-18T13:51:59Z,230,Write lines of text to a file in R,"<p>In the R scripting language, how do I write lines of text, e.g. the following two lines</p>

<pre><code>Hello
World
</code></pre>

<p>to a file named ""output.txt""?</p>
"
2470295,296564,2010-03-18T13:56:26Z,1,Is there a way to extract continuous feature in an 2D array,"<p>Say I have an array of number </p>

<p>a &lt;- c(1,2,3,6,7,8,9,10,20)</p>

<p>if there a way to tell R to output just the range of the continuous sequence from ""a""
e.g., the continuous sequences in ""a"" are the following</p>

<p>1,3
6,10
20</p>

<p>Thanks a lot!
Derek</p>
"
2470654,279497,2010-03-18T14:42:01Z,1,Calling rchisq with vector parameters,"<p>What happens when I call <code>rchisq(100,1:100,1:100)</code>:</p>

<ul>
<li>does R generate 100 numbers with df=1,ncp=1?</li>
<li>or does it generate 100 numbers each with df=k,ncp=k for  k=1...100?</li>
</ul>

<p>What I want to know is whether  df and ncp can be vectors or not. It is not clear in the documentation (when compared with rnorm). I suspect that they can also be vectors and recycling happens if the lengths differ(?) </p>
"
2471075,256662,2010-03-18T15:32:02Z,3,"How to read.table with ""Hebrew"" column names (in R)?","<p>I am trying to read a .txt file, with Hebrew column names, but without success.</p>

<p>I uploaded an example file to:
<a href=""http://www.talgalili.com/files/aa.txt"" rel=""nofollow noreferrer"">http://www.talgalili.com/files/aa.txt</a></p>

<p>And am trying the command:</p>

<pre><code>read.table(""http://www.talgalili.com/files/aa.txt"", header = T, sep = ""\t"")
</code></pre>

<p>This returns me with:</p>

<pre><code>  X.....ª X...ª...... X...œ....
1      12          97         6
2     123         354        44
3       6           1         3
</code></pre>

<p>Instead of:</p>

<pre><code>אחת שתיים   שלוש
12  97  6
123 354 44
6   1   3
</code></pre>

<p>My output for:</p>

<pre><code>l10n_info()
</code></pre>

<p>Is:</p>

<pre><code>$MBCS
[1] FALSE

$`UTF-8`
[1] FALSE

$`Latin-1`
[1] TRUE

$codepage
[1] 1252
</code></pre>

<p>And for:</p>

<pre><code>Sys.getlocale()
</code></pre>

<p>Is:</p>

<pre><code>[1] ""LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252""
</code></pre>

<p>Can you suggest to me what to try and change to allow me to load the file correctly ?</p>

<p><strong>Update:</strong>
Trying to use:</p>

<pre><code>read.table(""http://www.talgalili.com/files/aa.txt"",fileEncoding =""iso8859-8"")
</code></pre>

<p>Has resulted in:</p>

<pre><code> V1
1  ?
Warning messages:
1: In read.table(""http://www.talgalili.com/files/aa.txt"", fileEncoding = ""iso8859-8"") :
  invalid input found on input connection 'http://www.talgalili.com/files/aa.txt'
2: In read.table(""http://www.talgalili.com/files/aa.txt"", fileEncoding = ""iso8859-8"") :
  incomplete final line found by readTableHeader on 'http://www.talgalili.com/files/aa.txt'
</code></pre>

<p>While also trying this:</p>

<pre><code>Sys.setlocale(""LC_ALL"", ""en_US.UTF-8"")
</code></pre>

<p>Or this:</p>

<pre><code>Sys.setlocale(""LC_ALL"", ""en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8"")
</code></pre>

<p>Get's me this:</p>

<pre><code>[1] """"
Warning message:
In Sys.setlocale(""LC_ALL"", ""en_US.UTF-8"") :
  OS reports request to set locale to ""en_US.UTF-8"" cannot be honored
</code></pre>

<p>Finally, here is the > sessionInfo() </p>

<pre><code>R version 2.10.1 (2009-12-14) 
i386-pc-mingw32 

locale:
[1] LC_COLLATE=English_United States.1255  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_2.10.1
</code></pre>

<p>Any suggestion or clarification will be appreciated.</p>

<p>Best,
Tal</p>
"
2471188,142477,2010-03-18T15:45:58Z,7,converting a matrix to a list,"<p>Suppose I have a matrix <code>foo</code> as follows:</p>

<pre><code>foo &lt;- cbind(c(1,2,3), c(15,16,17))

&gt; foo
     [,1] [,2]
[1,]    1   15
[2,]    2   16
[3,]    3   17
</code></pre>

<p>I'd like to turn it into a list that looks like</p>

<pre><code>[[1]]
[1]  1 15

[[2]]
[1]  2 16

[[3]]
[1]  3 17
</code></pre>

<p>You can do it as follows:</p>

<p><code>lapply(apply(foo, 1, function(x) list(c(x[1], x[2]))), function(y) unlist(y))</code></p>

<p>I'm interested in an alternative method that isn't as complicated.  Note, if you just do <code>apply(foo, 1, function(x) list(c(x[1], x[2])))</code>, it returns a list within a list, which I'm hoping to avoid.</p>
"
2471750,296746,2010-03-18T16:49:30Z,1,help with boxplot needed,"<p>I am new to R, can anyone help me with boxplot for a dataset like:</p>

<p>file1</p>

<pre><code>     col1 col2     col3     col4  col5
050350005  101   56.625   48.318 RED    
051010002  106   50.625   46.990 GREEN    
051190007   25   65.875   74.545 BLUE    
051191002  246   52.875   57.070 RED    
220050004   55   70       80.274 BLUE    
220150008   75   67.750   62.749 RED    
220170001   77   65.750   54.307 GREEN
</code></pre>

<p>file2</p>

<pre><code>     col1 col2     col3     col4  col5
050350005  101   56.625   57     RED
051010002  106   50.625   77     GREEN    
051190007   25   65.875   51.6   BLUE    
051191002  246   52.875   55.070 RED    
220050004   55   70       32     BLUE    
220150008   75   67.750   32.49  RED
220170001   77   65.750   84.07  GREEN
</code></pre>

<p>for each color (red,green and blue), I need to compare file1 and file2 by making box plot with MB and RMSE for (col4-col3) for file1 and file2 by dividing col2 in different group: if col2&lt;20,20&lt;=col2&lt;50, 50 &lt;= col2 &lt;70, col2 >=70. That is, for the boxplot, the x is (&lt;20, 20-50,50-70, >70), while y is MB (and RMSE) of the difference of col4 and col3</p>

<p>I hope I didn't confuse anybody. Thank you so much.</p>
"
2472107,209467,2010-03-18T17:38:13Z,3,R code in Sweave,"<p>I have a scientific paper under review, and a referee asked for my R code to be provided as a Sweave document. I've never heard of Sweave before, do you know what's the better way to do it?</p>

<p>Thanks a lot :-)</p>
"
2472599,291877,2010-03-18T19:00:39Z,1,R segfault when running via Rpy on linux,"<p>I'm running R via Rpy on a redhat linux distribution. Periodically I'll encounter this error message:</p>

<pre><code>*** caught segfault ***
address (nil), cause 'unknown'
</code></pre>

<p>And the entire program dies right there. It usually occurs when I run a lot of regression <code>r.lm()</code>. But by simply running the identical code again, the problem may or may not go away (so not always reproduceable). Does anyone know what might be causing this, and/or how I can prevent it from happening?</p>
"
2472958,207258,2010-03-18T19:57:42Z,0,R: How to separate character output in a loop?,"<p>I'm blanking on the best way to paste a list of strings together to go into an SQL statement...  I'm having trouble with the separator bar | printing at the beginning when I don't want it to:</p>

<pre><code>foo = ""blah""
paste_all_together = NULL
for (n in 1:4) {
    paste_together =     paste(foo ,sep = """")
    paste_all_together = paste(paste_all_together, paste_together, sep = ""|"")
    }

&gt; paste_all_together
[1] ""|blah|blah|blah|blah""
</code></pre>

<p>I just want it to print out ""blah|blah|blah|blah"".   Do I need a nested loop, or is there a better itterator in R for doing this?  Or perhaps a better way to input SQL statements?</p>
"
2473336,235984,2010-03-18T21:04:06Z,0,Simple and short if clauses for combind statements,"<p>TRUE/FALSE if clauses are easily and quickly done in R. However, if the argument gets more complex, it also gets ugly very soon.</p>

<p>For instance: 
I might want to execute different operations for a row(foo) dependent on the value in one cell (<code>foo[1]</code>).
Let the intervals be 0:39 and 40:59 and 60:100</p>

<p>Something like does not exit:</p>

<pre><code>(if foo[1] ""in"" 40:60){...
</code></pre>

<p>In fact, I only see ways of at least two if clauses and two else statements and the action for the first interval somewhere at the bottom of the code. With more intervals(or any other condition) it is getting more complex.</p>

<p>Is there a best practice (for this purpose or others) with a simple construction and nice design to read?</p>
"
2473659,207258,2010-03-18T22:06:29Z,3,R: What are the best functions to deal with concatenating and averaging values in a data.frame?,"<p>I have a data.frame from this code:</p>

<pre><code>   my_df = data.frame(""read_time"" = c(""2010-02-15"", ""2010-02-15"", 
                                      ""2010-02-16"", ""2010-02-16"", 
                                       ""2010-02-16"", ""2010-02-17""), 
                      ""OD"" = c(0.1, 0.2, 0.1, 0.2, 0.4, 0.5) )
</code></pre>

<p>which produces this:</p>

<pre><code>&gt; my_df
   read_time  OD
1 2010-02-15 0.1
2 2010-02-15 0.2
3 2010-02-16 0.1
4 2010-02-16 0.2
5 2010-02-16 0.4
6 2010-02-17 0.5
</code></pre>

<p>I want to average the OD column over each distinct read_time (notice some are replicated others are not) and I also would like to calculate the standard deviation, producing a table like this:</p>

<pre><code>&gt; my_df
   read_time  OD        stdev
1 2010-02-15 0.15       0.05
5 2010-02-16 0.3         0.1
6 2010-02-17 0.5         0
</code></pre>

<p>Which are the best functions to deal with concatenating such values in a data.frame?</p>
"
2474808,67405,2010-03-19T03:27:15Z,1,Howto plot two cumulative frequency graph together,"<p>I have data that looks like this:</p>

<pre><code>#val  Freq1 Freq2
0.000 178 202
0.001 4611 5300
0.002 99 112
0.003 26 30
0.004 17 20
0.005 15 20
0.006 11 14
0.007 11 13
0.008 13 13
...many more lines..
</code></pre>

<p>Full data can be found here:
<a href=""http://dpaste.com/173536/plain/"" rel=""nofollow noreferrer"">http://dpaste.com/173536/plain/</a></p>

<p>What I intend to do is to have a cumulative graph
with ""val"" as x-axis with ""Freq1"" &amp; ""Freq2"" as
y-axis, plot together in 1 graph.</p>

<p>I have this code. But it creates two plots instead of 1.</p>

<pre><code>dat &lt;- read.table(""stat.txt"",header=F);
val&lt;-dat$V1
freq1&lt;-dat$V2
freq2&lt;-dat$V3

valf1&lt;-rep(val,freq1)
valf2&lt;-rep(val,freq2)

valfreq1table&lt;- table(valf1)
valfreq2table&lt;- table(valf2)
cumfreq1=c(0,cumsum(valfreq1table))
cumfreq2=c(0,cumsum(valfreq2table))

plot(cumfreq1, ylab=""CumFreq"",xlab=""Loglik Ratio"")
lines(cumfreq1)
plot(cumfreq2, ylab=""CumFreq"",xlab=""Loglik Ratio"")
lines(cumfreq2)
</code></pre>

<p>What's the right way to approach this?</p>
"
2475511,67405,2010-03-19T07:01:25Z,3,"How to Plot ""Reverse"" Cumulative Frequency Graph With ECDF","<p>I have no problem plotting the following cumulative <strong>frequency</strong> graph plot
like this.</p>

<pre><code>     library(Hmisc)
     pre.test &lt;- rnorm(100,50,10)
     post.test &lt;- rnorm(100,55,10)
     x &lt;- c(pre.test, post.test)
     g &lt;- c(rep('Pre',length(pre.test)),rep('Post',length(post.test)))
     Ecdf(x, group=g, what=""f"", xlab='Test Results', label.curves=list(keys=1:2))
</code></pre>

<p>But I want to show the graph in forms of the ""reverse"" cumulative frequency of values > x.
(i.e. something equivalent to what=""1-f"").</p>

<p>Is there a way to do it?</p>

<p>Other suggestions in R other than using Hmisc are also very much welcomed.</p>
"
2476946,203420,2010-03-19T11:53:44Z,1,Creating large XML Trees in R,"<p>I'm trying to create a large XML tree in R. Here's a simplified version of the code:</p>

<pre><code>library(XML)
N = 100000#In practice is larger  10^8/ 10^9
seq = newXMLNode(""sequence"")
pars = as.character(1:N)
for(i in 1:N)
    newXMLNode(""Parameter"", parent=seq, attrs=c(id=pars[i]))
</code></pre>

<p>When N is about N^6 this takes about a minute, N^7 takes about forty minutes. Is there anyway to speed this up?</p>

<p>Using the paste command:</p>

<pre><code>par_tmp = paste('&lt;Parameter id=""', pars, '""/&gt;', sep="""")
</code></pre>

<p>takes less than a second.</p>
"
2477398,12388,2010-03-19T12:57:32Z,2,Problem loading R own created libraries in Java/JRI code,"<p>I created my own new R library (called ""Media""). There is no problem when I try to load it with RGui, and I can call the functions defined in the new package.  This is how I load it:</p>

<pre><code>   &gt; library(Media)
</code></pre>

<p>But, I'm also trying to call that functions from <a href=""http://www.rforge.net/JRI/"" rel=""nofollow noreferrer"">Java/JRI</a> code, and when I load the new R package, Java doesn't seem to find the pacakge, throwing the message ""Error in library(Media) : object 'Media' not found""</p>

<p>This is my current code using JRI:</p>

<pre><code>    REXP rexpSetFolder = re.eval(""setwd('C:/Users/Albert/Documents')"");
    REXP rexpFolder = re.eval(""getwd()"");
    System.out.println(rexpFolder.asString());

    REXP rexpLoad = re.eval(""library(Media)""); // fails
</code></pre>

<p>It also fails without the 'setwd' command, and simple calls to existing R functions work fine.  I'm using R 2.10 and the latest JRI 0.5-0 under Windows.</p>

<p>Any help would be appreciated.
Thank you very much.</p>

<p><strong>Edit:</strong></p>

<p>The parameter <code>lib.loc</code> seems to work, at least this sentence does not return an error:</p>

<pre><code>library(""Media"", lib.loc = ""c:/Users/Albert/Documents"")
</code></pre>

<p>But after that, calling a function in the package with <code>re.eval(""myfunction()"");</code> still fails, as the function is not properly found.</p>
"
2478259,296564,2010-03-19T14:59:19Z,0,How to transform a matrix with 2 columns into a multimap like structure?,"<p>I am wondering if there is a way to transform a matrix of 2 columns into a multimap or list of list.</p>

<p>The first column of the matrix is an id (with possibly duplicated entries) and the 2nd column is some value.</p>

<p>For example,
if I have to following matrix</p>

<pre><code>m &lt;- matrix(c(1,2,1,3,2,4), c(3,2))
</code></pre>

<p>I would like to transform it into the following list</p>

<pre><code>[[1]]
3,4
[[2]]
2
</code></pre>
"
2478272,95048,2010-03-19T15:00:12Z,10,Kruskal-Wallis test with details on pairwise comparisons,"<p>The standard stats::kruskal.test module allows to calculate the kruskal-wallis test on a dataset:</p>

<pre><code>&gt;&gt;&gt; data(diamonds)
&gt;&gt;&gt; kruskal.test(price~carat, data=diamonds)

Kruskal-Wallis rank sum test

data:  price by carat by color 
Kruskal-Wallis chi-squared = 50570.15, df = 272, p-value &lt; 2.2e-16
</code></pre>

<p>This is correct, it is giving me a probability that all the groups in the data have the same mean.</p>

<p>However, I would like to have the details for each pair comparison, like if diamonds of colors D and E have the same mean price, as some other softwares do (SPSS) when you ask for a Kruskal test.</p>

<p>I have found <a href=""http://bm2.genes.nig.ac.jp/RGM2/R_current/library/pgirmess/man/kruskalmc.html"" rel=""noreferrer"">kruskalmc</a> from the package pgirmess which allows me to do what I want to do:</p>

<pre><code>&gt; kruskalmc(diamonds$price, diamonds$color)
Multiple comparison test after Kruskal-Wallis 
p.value: 0.05 
Comparisons
      obs.dif critical.dif difference
D-E  571.7459     747.4962      FALSE
D-F 2237.4309     751.5684       TRUE
D-G 2643.1778     726.9854       TRUE
D-H 4539.4392     774.4809       TRUE
D-I 6002.6286     862.0150       TRUE
D-J 8077.2871    1061.7451       TRUE
E-F 2809.1767     680.4144       TRUE
E-G 3214.9237     653.1587       TRUE
E-H 5111.1851     705.6410       TRUE
E-I 6574.3744     800.7362       TRUE
E-J 8649.0330    1012.6260       TRUE
F-G  405.7470     657.8152      FALSE
F-H 2302.0083     709.9533       TRUE
F-I 3765.1977     804.5390       TRUE
F-J 5839.8562    1015.6357       TRUE
G-H 1896.2614     683.8760       TRUE
G-I 3359.4507     781.6237       TRUE
G-J 5434.1093     997.5813       TRUE
H-I 1463.1894     825.9834       TRUE
H-J 3537.8479    1032.7058       TRUE
I-J 2074.6585    1099.8776       TRUE
</code></pre>

<p>However, this package only allows for one categoric variable (e.g. I can't study the prices clustered by color and by carat, as I can do with kruskal.test), and I don't know anything about the pgirmess package, whether it is maintained or not, or if it is tested.</p>

<p>Can you recommend me a package to execute the Kruskal-Wallis test which returns details for every comparison? How would you handle the problem?</p>
"
2478352,183988,2010-03-19T15:09:10Z,65,write.table writes unwanted leading empty column to header when has rownames,"<p>check this example:</p>

<pre><code>&gt; a = matrix(1:9, nrow = 3, ncol = 3, dimnames = list(LETTERS[1:3], LETTERS[1:3]))
&gt; a
  A B C
A 1 4 7
B 2 5 8
C 3 6 9
</code></pre>

<p>the table displays correctly. There are two different ways of writing it to file... </p>

<p><code>write.csv(a, 'a.csv')</code> which gives as expected:</p>

<pre><code>"""",""A"",""B"",""C""
""A"",1,4,7
""B"",2,5,8
""C"",3,6,9
</code></pre>

<p>and <code>write.table(a, 'a.txt')</code> which screws up</p>

<pre><code>""A"" ""B"" ""C""
""A"" 1 4 7
""B"" 2 5 8
""C"" 3 6 9
</code></pre>

<p>indeed, an empty tab is missing.... which is a pain in the butt for downstream things.
Is this a bug or a feature?
Is there a workaround? (other than <code>write.table(cbind(rownames(a), a), 'a.txt', row.names=FALSE</code>)</p>

<p>Cheers,
yannick</p>
"
2479059,193210,2010-03-19T16:51:25Z,6,How can I add an en dash to a plot in R?,"<p>I'm creating a plot in R, and need to add an en dash to some axis labels, as opposed to your everyday hyphen.  </p>

<pre><code>axis(1, at=c(0:2), labels=c(""0-10"",""11-30"",""31-70""))
</code></pre>

<p>I'm running R version 2.8.1 on Linux.</p>
"
2479689,297626,2010-03-19T18:28:11Z,7,Crosstab with multiple items,"<p>In SPSS, it is (relatively) easy to create a cross tab with multiple variables using the factors (or values) as the table heading.  So, something like the following (made up data, etc.).  Q1, Q2, and Q3 each have either a 1, a 2, or a 3 for each person.  I just left these as numbers, but they could be factors, neither seemed to help solve the problem.</p>

<pre>
                        1 (very Often)   2 (Rarely)   3 (Never)
   Q1. Likes it           12              15             13
   Q2. Recommends it      22              11             10
   Q3. Used it            22              12             9
</pre>

<p>In SPSS, one can even request row, column, or total percentages.</p>

<p>I've tried table(), ftable(), xtab(), CrossTable() from gmodels, and CrossTable() from descr, and none of these can handle (afaik) multiple variables; they mostly seem to handle 1 variable crossed with another variable, and the 3rd creates layers.</p>

<p>Is there a package with some good cross tabbing/table examples that I could use to figure this out?   I'm sure I'm missing something simple, so I appreciate you pointing out what I missed.  Perhaps I have to generate each row as a separate list and then make a dataframe and print the dataframe?</p>

<p>UPDATE: I've now discovered ctab() in package catspec, which is also on the right track.  It's interesting that R has no consistent equivalent to Ctables in SPSS, which is basically a ""tabbing"" tool ala the old tabulate tools used for survey research.   ctab() is trying, and is an admirable 1st step... but you still can't make this table (above) with it.</p>
"
2480984,138470,2010-03-19T22:36:34Z,3,"In R, when using named rows, can a sparse matrix column be added (concatenated) to another sparse matrix?","<p>I have two sparse matrices, <code>m1</code> and <code>m2</code>:</p>

<pre><code>&gt; m1 &lt;- Matrix(data=0,nrow=2, ncol=1, sparse=TRUE, dimnames=list(c(""b"",""d""),NULL))
&gt; m2 &lt;- Matrix(data=0,nrow=2, ncol=1, sparse=TRUE, dimnames=list(c(""a"",""b""),NULL))
&gt; m1[""b"",1]&lt;- 4
&gt; m2[""a"",1]&lt;- 5
&gt; m1
2 x 1 sparse Matrix of class ""dgCMatrix""

b 4
d .
&gt; m2
2 x 1 sparse Matrix of class ""dgCMatrix""

a 5
b .
&gt;
</code></pre>

<p>and I want to <code>cbind()</code> them to make a sparse matrix like:</p>

<pre><code>  [,1] [,2] 
a    .    5
b    4    .
d    .    .
</code></pre>

<p>however <code>cbind()</code> ignores the named rows:</p>

<pre><code>&gt; cbind(m1[,1],m2[,1])
  [,1] [,2]
b    4    5
d    0    0
</code></pre>

<p>is there some way to do this without a brute force loop?</p>
"
2482125,218244,2010-03-20T05:56:40Z,7,Using sapply on vector of POSIXct,"<p>I have what may be a very simple question.  I want to process a column of POSIXct objects from a dataframe and generate a vector of datetime strings.  I tried to use the following sapply call</p>

<pre><code>dt &lt;- sapply(df$datetime, function(x) format(x,""%Y-%m-%dT%H:%M:%S""))
</code></pre>

<p>but to no avail.  I keep getting the following error:</p>

<pre><code>&gt; Error in prettyNum(.Internal(format(x, trim, digits, nsmall, width, 3L,  :
invalid 'trim' argument
</code></pre>

<p>When I apply this function to a single POSIXct object from the column, I have no problem. So I'm stumped at the moment about what the problem is.  Do I need to do something special with POSIXct objects?</p>
"
2485639,151410,2010-03-21T02:28:39Z,4,Removing object from parent environment using rm(),"<p>I am trying to remove an object from the parent environment.</p>

<pre><code>rm_obj &lt;- function(obj){
  a &lt;-deparse(substitute(obj))
  print (a)
  print(ls(envir=sys.frame(-1)))  
  rm(a,envir=sys.frame(-1))
}
&gt; x&lt;-c(1,2,3)
&gt; rm_obj(x)
[1] ""x""

[1] ""rm_obj"" ""x""    
Warning message:
In rm(a, envir = sys.frame(-1)) : object 'a' not found
</code></pre>

<p>This will help clarify my misunderstanding regarding frames.</p>
"
2486130,298308,2010-03-21T06:02:22Z,7,Programming R/Sweave for proper \Sexpr output,"<p>I'm having a bit of a problem programming R for Sweave, and the #rstats twitter group often points here, so I thought I'd put this question to the SO crowd. I'm an analyst- not a programmer- so go easy on my first post. </p>

<p>Here's the problem: I am drafting a survey report in Sweave with R and would like to report the marginal returns in line using <code>\Sexpr{}</code>. For example, rather than saying:</p>

<blockquote>
  <p>Only 14% of respondents said 'X'.</p>
</blockquote>

<p>I want to write the report like this:</p>

<blockquote>
  <p>Only \Sexpr{p.mean(variable)}$\%$ of respondents said 'X'. </p>
</blockquote>

<p>The problem is that Sweave converts the results of the expression in <code>\Sexpr{}</code> to a character string, which means that the output from the expression in R and the output that appears in my document are different. For example, above I use the function 'p.mean':</p>

<blockquote>
<pre><code>p.mean&lt;- function (x) {options(digits=1)  
mmm&lt;-weighted.mean(x, weight=weight, na.rm=T)  
print(100*mmm)  
}
</code></pre>
</blockquote>

<p>In R, the output looks like this:</p>

<blockquote>
<pre><code>p.mean(variable)
&gt;14
</code></pre>
</blockquote>

<p>but when I use <code>\Sexpr{p.mean(variable)}</code>, I get an unrounded character string (in this case: 13.5857142857143) in my document. I have tried to limit the output of my function to <code>digits=1</code> in the global environment, in the function itself, and and in various commands. It only seems to contain what R prints, not the character transformation that is the result of the expression and which eventually prints in the LaTeX file. </p>

<blockquote>
<pre><code>as.character(p.mean(variable))  
&gt;[1] 14  
&gt;[1] ""13.5857142857143""  
</code></pre>
</blockquote>

<p>Does anyone know what I can do to limit the digits printed in the LaTeX file, either by reprogramming the R function or with a setting in Sweave or <code>\Sexpr{}</code>?</p>
"
2487922,170792,2010-03-21T17:11:15Z,4,How can I get the complement of vector y in vector x,"<p>That's <code>x \ y</code> using mathematical notation. Suppose</p>

<pre><code>x &lt;- c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,2,1,1,1,3) 
y &lt;- c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1)
</code></pre>

<p>How can I get a vector with ALL the values in x that are not in y. i.e the result should be:</p>

<pre><code>2,1,1,3
</code></pre>

<p>There is a similar question <a href=""https://stackoverflow.com/questions/1837968/r-how-to-tell-what-is-in-one-vector-and-not-another"">here</a>. However, none of the answers returns the result that I want.</p>
"
2488853,207258,2010-03-21T21:44:09Z,1,R: What's the easiest way to print out pairs of values from a data.frame?,"<p>I have a data.frame: </p>

<pre><code>df&lt;-data.frame(a=c(""x"",""x"",""y"",""y""),b=c(1,2,3,4))

&gt; df
      a b
    1 x 1
    2 x 2
    3 y 3
    4 y 4
</code></pre>

<p>What's the easiest way to print out each pair of values as a list of strings like this:</p>

<blockquote>
  <p>""x1"", ""x2"", ""y1"", ""y2""</p>
</blockquote>
"
2490860,170792,2010-03-22T08:49:55Z,2,"Getting the excluded elements for each of the combn(n,k) combinations","<p>Suppose we have generated a matrix <code>A</code> where each column contains one of the combinations of <code>n</code> elements in groups of <code>k</code>. So, its dimensions will be <code>k,choose(n,k)</code>. Such a matrix is produced giving the command <code>combn(n,k)</code>. What I would like to get is another matrix <code>B</code> with dimensions <code>(n-k),choose(n,k)</code>, where each column <code>B[,j]</code> will contain the excluded <code>n-k</code> elements of <code>A[,j]</code>.  </p>

<p>Here is an example of the way I use tho get table <code>B</code>. Do you think it is a safe method to use? Is there another way?</p>

<pre><code>n &lt;- 5 ; k &lt;- 3
(A &lt;- combn(n,k))
(B &lt;- combn(n,n-k)[,choose(n,k):1])
</code></pre>

<p>Another example</p>

<pre><code>x&lt;-c(0,1,0,2,0,1) ; k&lt;- 4
(A &lt;- combn(x,k))
(B &lt;- combn(x,length(x)-k)[,choose(length(x),k):1])
</code></pre>

<p>That <a href=""https://stackoverflow.com/questions/2487922/r-how-can-i-get-the-complement-of-vector-y-in-vector-x"">previous question</a> of mine is part of this problem.<br>
Thank you.</p>
"
2492947,299077,2010-03-22T14:27:39Z,21,Boxplot in R showing the mean,"<p>Does anybody know of a way of generating a boxplot in R with a line (or another symbol) in the value corresponding to the mean?</p>

<p>Thank you!</p>
"
2494676,207258,2010-03-22T18:15:12Z,0,Can I access a Mac Numbers (.num) document from within R?,"<p>I know I can use the RODBC library for accessing excel (.xls) docs from within Windows, but is there something similar for the Numbers program that come with iWorks?   If not, what other solutions are there for easily editing a spreadsheet (like a lookup table) and accessing it within R?  I know there the is an internal R editor, but I don't like it very much.</p>
"
2497111,207258,2010-03-23T02:08:14Z,9,R: How can I use apply on rows of a data.frame and get out $column_name?,"<p>I'm trying to access $a using the following example: </p>

<pre><code>df&lt;-data.frame(a=c(""x"",""x"",""y"",""y""),b=c(1,2,3,4))

&gt; df
  a b
1 x 1
2 x 2
3 y 3
4 y 4

test_fun &lt;- function (data.frame_in) {
    print (data.frame_in[1])
    }
</code></pre>

<p>I can now access $a if I use an index for the first column:</p>

<blockquote>
  <p>apply(df, 1, test_fun)</p>
</blockquote>

<pre><code>  a 
""x"" 
  a 
""x"" 
  a 
""y"" 
  a 
""y"" 
[1] ""x"" ""x"" ""y"" ""y""
</code></pre>

<p>But I cannot access column $a with the $ notation:  error: ""$ operator is invalid for atomic vectors""</p>

<pre><code>test_fun_2 &lt;- function (data.frame_in) {
    print (data.frame_in$a)
    }

&gt;apply(df, 1, test_fun_2)
Error in data.frame_in$a : $ operator is invalid for atomic vectors
</code></pre>

<p>Is this not possible?</p>
"
2498285,74658,2010-03-23T07:47:18Z,10,What are good example R packages written using RUnit or roxygen?,"<p>I'm writing an <a href=""http://en.wikipedia.org/wiki/R_%28programming_language%29"" rel=""nofollow noreferrer"">R</a> package that's going to be used by others, so I'm trying to get this one right!  I want to use <a href=""http://cran.r-project.org/web/packages/roxygen/index.html"" rel=""nofollow noreferrer"">roxygen</a> for documentation and <a href=""http://cran.r-project.org/web/packages/RUnit/index.html"" rel=""nofollow noreferrer"">RUnit</a> for unit testing, but I haven't used them before.</p>

<p>What packages exist (either on CRAN or elsewhere) that use either of these tools well?</p>
"
2500896,300013,2010-03-23T14:58:40Z,13,decode tinyurl in R to get full url path?,"<p>Is there a way to decode tinyURL links in R so that I can see which web pages they actually refer to?</p>
"
2501369,162832,2010-03-23T15:50:53Z,0,"Installing odfWeave gets hung up on ""checking for xml2-config...""","<p>I can't install odfWeave - it looks like the problem is with the package XML, which gets as far as ""checking for xml2-config..."" and then cannot find it. :</p>

<pre><code>checking for xml2-config... no Cannot find xml2-config 
ERROR: configuration failed for package ‘XML’
* removing ‘/home/andreas/R/i486-pc-linux-gnu-library/2.10/XML’
* installing *source* package ‘odfWeave’ ...
** R
** inst
** preparing package for lazy loading Warning in library(pkg, character.only
= TRUE, logical.return = TRUE, lib.loc = lib.loc) :   there is no package called 'XML' Error : package 'XML'
could not be loaded ERROR: lazy
loading failed for package ‘odfWeave’
* removing ‘/home/andreas/R/i486-pc-linux-gnu-library/2.10/odfWeave’
</code></pre>
"
2501895,296564,2010-03-23T16:54:42Z,13,How to suppress output,"<p>I would like to suppress output in R when I run my R script from the command prompt. </p>

<p>I tried numerous options including <code>--slave</code> and <code>--vanilla</code>. Those options lessens the amount of text outputted.</p>

<p>I also tried to pipe the output to <code>NUL</code> but that didn't help.</p>
"
2502485,168139,2010-03-23T18:14:47Z,6,How does one overcome overlapping points without jitter or transparency in ggplot2,"<p>I am starting to use ggplot2. I have some small n (about 30 or so) granular data with lots of overlap. Neither jitter nor alpha (transparency) are suitable. Instead a stripchart with stack and offset do it best but I do not know how to do it in ggplot2. Do you know?</p>

<p>To see what the end result should be click on this <a href=""http://www.biomedcentral.com/1471-2180/7/56/figure/F1"" rel=""noreferrer"">graphic</a>.</p>

<p>Here is the script I used a few years ago.</p>

<pre><code>stripchart(SystData$DayTo1Syst~SystData$strain,vertical=TRUE,method=""stack"",pch=19,offset=.3,xlab=""Strain"",main=""Rapidity of Systemic Disease Onset"",ylab=""Days post inoculation"")
</code></pre>
"
2504543,300416,2010-03-24T00:10:08Z,6,"Merge multiple data frames - Error in match.names(clabs, names(xi)) : names do not match previous names","<p>I'm getting some really bizarre stuff while trying to merge multiple data frames. Help!</p>

<p>I need to merge a bunch of data frames by the columns 'RID' and 'VISCODE'. Here is an example of what it looks like:</p>

<pre><code>d1 = data.frame(ID = sample(9, 1:100), RID = c(2, 5, 7, 9, 12),
            VISCODE = rep('bl', 5),
            value1 = rep(16, 5))

d2 = data.frame(ID = sample(9, 1:100), RID = c(2, 2, 2, 5, 5, 5, 7, 7, 7),
            VISCODE = rep(c('bl', 'm06', 'm12'), 3),
            value2 = rep(100, 9))

d3 = data.frame(ID = sample(9, 1:100), RID = c(2, 2, 2, 5, 5, 5, 9,9,9),
            VISCODE = rep(c('bl', 'm06', 'm12'), 3),
            value3 = rep(""a"", 9),
            values3.5 = rep(""c"", 9))

d4 = data.frame(ID =sample(8, 1:100), RID = c(2, 2, 5, 5, 5, 7, 7, 7, 9),
            VISCODE = c(c('bl', 'm12'), rep(c('bl', 'm06', 'm12'), 2), 'bl'),
            value4 = rep(""b"", 9))

dataList = list(d1, d2, d3, d4)
</code></pre>

<p>I looked at the answers to the question titled ""Merge several data.frames into one data.frame with a loop."" I used the reduce method suggested there as well as a loop I wrote:</p>

<pre><code>try1 = mymerge(dataList)

try2 &lt;- Reduce(function(x, y) merge(x, y, all= TRUE,
by=c(""RID"", ""VISCODE"")), dataList, accumulate=F)
</code></pre>

<p>where dataList is a list of data frames and mymerge is:</p>

<pre><code>mymerge = function(dataList){

L = length(dataList)

mdat = dataList[[1]]

  for(i in 2:L){

    mdat = merge(mdat, dataList[[i]], by.x = c(""RID"", ""VISCODE""),
                                  by.y = c(""RID"", ""VISCODE""), all = TRUE)
  }

mdat
}
</code></pre>

<p>For my test data and subsets of my real data, both of these work fine and produce exactly the same results. However, when I use larger subsets of my data, they both break down and give me the following error: Error in match.names(clabs, names(xi)) : names do not match previous names.</p>

<p>The really weird thing is that using this works:</p>

<pre><code>  dataList = list(demog[1:50,],
            neurobat[1:50,],
            apoe[1:50,],
            mmse[1:50,],
            faq[1:47, ])
</code></pre>

<p>And using this fails:</p>

<pre><code>  dataList = list(demog[1:50,],
            neurobat[1:50,],
            apoe[1:50,],
            mmse[1:50,],
            faq[1:48, ])
</code></pre>

<p>As far as I can tell, there is nothing special about row 48 of faq. Likewise, using this works:</p>

<pre><code>dataList = list(demog[1:50,],
            neurobat[1:50,],
            apoe[1:50,],
            mmse[1:50,],
            pdx[1:47, ])
</code></pre>

<p>And using this fails:</p>

<pre><code>dataList = list(demog[1:50,],
            neurobat[1:50,],
            apoe[1:50,],
            mmse[1:50,],
            pdx[1:48, ])
</code></pre>

<p>Row 48 in faq and row 48 in pdx have the same values for RID and VISCODE, the same value for EXAMDATE (something I'm not matching on) and different values for ID (another thing I'm not matching on). Besides the matching RID and VISCODE, I see anything special about them. They don't share any other variable names. This same scenario occurs elsewhere in the data without problems. </p>

<p>To add icing on the complication cake, this doesn't even work:</p>

<pre><code>dataList = list(demog[1:50,],
            neurobat[1:50,],
            apoe[1:50,],
            mmse[1:50,],
            faq[1:48, 2:3])
</code></pre>

<p>where columns 2 and 3 are ""RID"" and ""VISCODE"". </p>

<p>48 isn't even the magic number because this works:</p>

<pre><code> dataList = list(demog[1:500,],
            neurobat[1:500,],
            apoe[1:500,],
            mmse[1:457,])
</code></pre>

<p>while using mmse[1:458, ] fails. </p>

<p>I can't seem to come up with test data that causes the problem. Has anyone had this problem before? Any better ideas on how to merge?</p>

<p>Thanks for your help!
Jasmine</p>
"
2504827,176696,2010-03-24T01:41:13Z,10,Binning a numeric variable in R,"<p>I have a vector X that contains positive numbers that I want to bin/discretize.  For this vector, I want the numbers [0, 10) to show up just as they exist in the vector, but numbers [10,&infin;)  to be 10+.  </p>

<p>I'm using:</p>

<pre><code>x &lt;- c(0,1,3,4,2,4,2,5,43,432,34,2,34,2,342,3,4,2)
binned.x &lt;- as.factor(ifelse(x &gt; 10,""10+"",x))
</code></pre>

<p>but this feels klugey to me.  Does anyone know a better solution or a different approach?</p>
"
2508897,300936,2010-03-24T15:21:26Z,0,Zelig: Error message,"<p>I'm running an logit model using the Zelig package. I get the following error...what could be wrong?</p>

<pre><code>anes96two &lt;- zelig(trade962a ~ age962 + education962 + personal962 + economy962 + partisan962 + employment962 + union962 + home962 + market962 + race962 + income962, model=""mlogit"", data=data96)

 #Error in attr(tt, ""depFactors"")$depFactorVar : 
#  $ operator is invalid for atomic vectors
</code></pre>
"
2513142,142477,2010-03-25T04:52:05Z,8,breaking out of for loop when running a function inside a for loop in R,"<p>Suppose you have the following function <code>foo</code>.  When I'm running a <code>for</code> loop, I'd like it to skip the remainder of <code>foo</code> when <code>foo</code> initially returns the value of <code>0</code>.  However, <code>break</code> doesn't work when it's inside a function.  </p>

<p>As it's currently written, I get an error message, <code>no loop to break from, jumping to top level</code>.  </p>

<p>Any suggestions?</p>

<pre><code>foo &lt;- function(x) {
    y &lt;- x-2
    if (y==0) {break} # how do I tell the for loop to skip this
    z &lt;- y + 100
    z
}


for (i in 1:3) {
    print(foo(i))
}
</code></pre>
"
2515985,144297,2010-03-25T13:42:48Z,2,Annotating axis in ggplot2,"<p>I am looking for the way to annotate axis in ggplot2. The example of the problem can be found here: <a href=""http://learnr.wordpress.com/2009/09/24/ggplot2-back-to-back-bar-charts"" rel=""nofollow noreferrer"">http://learnr.wordpress.com/2009/09/24/ggplot2-back-to-back-bar-charts</a>. </p>

<p>The y axis of the chart (example graph in the link) has an annotation: (million euro). Is there a way to create such types of annotations in ggplot2? Looking at the documentation there is no obvious way, since the ggplot does not explicitly let you put objects outside plotting area. But maybe there is some workaround?</p>

<p>One of the possible workarounds I thought about is using scales:</p>

<pre><code>data=data.frame(x=1:10,y=1:10)
qplot(x=x,y=y,data=data)+scale_y_continuous(breaks=10.1,label=""Millions"")
</code></pre>

<p>But then how do I remove the tick? And it seems that since ggplot does not support multiple scales, I will need to grab the output of the scale_y_continuous, when it calculates the scales automaticaly and then add my custom break and label by hand. Maybe there is a better way?</p>
"
2516400,163053,2010-03-25T14:40:14Z,6,Writing temporary data from R,"<p>I want to write some temporary data to disk in an R package, and I want to be sure that it can run on every OS without assuming the user has admin rights.  Is there an existing R function that can provide a path to a temporary directory on all major OS's?  Or a way to reference a user's home directory?  </p>

<p>Otherwise, I was thinking of trying this: </p>

<pre><code>Sys.getenv(""temp"")
</code></pre>

<p>I presume that I can't expect people to have write access to their R locations, otherwise I could reference a path within the package directory: <code>.find.package(""package.name"")</code>.</p>
"
2517868,152159,2010-03-25T17:23:18Z,5,R optimization: How can I avoid a for loop in this situation?,"<p>I'm trying to do a simple genomic track intersection in R, and running into major performance problems, probably related to my use of for loops.  </p>

<p>In this situation, I have pre-defined windows at intervals of 100bp and I'm trying to calculate how much of each window is covered by the annotations in mylist.  Graphically, it looks something like this:</p>

<pre><code>          0    100   200    300    400   500   600  
windows: |-----|-----|-----|-----|-----|-----|

mylist:    |-|   |-----------|
</code></pre>

<p>So I wrote some code to do just that, but it's fairly slow and has become a bottleneck in my code:</p>

<pre><code>##window for each 100-bp segment    
windows &lt;- numeric(6)

##second track
mylist = vector(""list"")
mylist[[1]] = c(1,20)
mylist[[2]] = c(120,320)


##do the intersection
for(i in 1:length(mylist)){
  st &lt;- floor(mylist[[i]][1]/100)+1
  sp &lt;- floor(mylist[[i]][2]/100)+1
  for(j in st:sp){       
    b &lt;- max((j-1)*100, mylist[[i]][1])
    e &lt;- min(j*100, mylist[[i]][2])
    windows[j] &lt;- windows[j] + e - b + 1
  }
}

print(windows)
[1]  20  81 101  21   0   0
</code></pre>

<p>Naturally, this is being used on data sets that are much larger than the example I provide here. Through some profiling, I can see that the bottleneck is in the for loops, but my clumsy attempt to vectorize it using *apply functions resulted in code that runs an order of magnitude more slowly.</p>

<p>I suppose I could write something in C, but I'd like to avoid that if possible. Can anyone suggest another approach that will speed this calculation up? </p>
"
2520780,142477,2010-03-26T02:15:08Z,13,determining name of object loaded in R,"<p>Imagine you have an object <code>foo</code> that you saved as <code>saved.file.rda</code> as follows:</p>

<pre><code>foo &lt;- 'a'
save(foo, file='saved.file.rda')
</code></pre>

<p>Suppose you load <code>saved.file.rda</code> into an environment with multiple objects but forgot the name of the object that is in <code>saved.file.rda</code>.  Is there a way in R to determine that name?  </p>

<p>You can do it the following way, which seems a little clunky:</p>

<pre><code>bar &lt;- load('saved.file.rda')
eval(parse(text=bar)) # this will pull up the object that was in saved.file.rda
</code></pre>

<p>However, is there a better way of doing this?</p>
"
2521941,302378,2010-03-26T08:38:55Z,2,How can one create a double horizontal axis for a plot in ggplot2?,"<p>I need to show the values on the horizontal axis (aka abscissa, aka x-axis) converted into other units. Hence the need for a second axis.</p>
"
2522396,134830,2010-03-26T10:13:47Z,4,"Generating lognormally distributed random number from mean, coeff of variation","<p>Most functions for generating lognormally distributed random numbers take the mean and standard deviation of the associated normal distribution as parameters.</p>

<p>My problem is that I only know the mean and the coefficient of variation of the lognormal distribution.  It is reasonably straight forward to derive the parameters I need for the standard functions from what I have:</p>

<p>If <code>mu</code> and <code>sigma</code> are the mean and standard deviation of the associated normal distribution, we know that</p>

<pre><code>coeffOfVar^2 = variance / mean^2
             = (exp(sigma^2) - 1) * exp(2*mu + sigma^2) / exp(mu + sigma^2/2)^2
             = exp(sigma^2) - 1
</code></pre>

<p>We can rearrange this to </p>

<pre><code>sigma = sqrt(log(coeffOfVar^2 + 1))
</code></pre>

<p>We also know that</p>

<pre><code>mean = exp(mu + sigma^2/2)
</code></pre>

<p>This rearranges to </p>

<pre><code>mu = log(mean) - sigma^2/2
</code></pre>

<p>Here's my R implementation</p>

<pre><code>rlnorm0 &lt;- function(mean, coeffOfVar, n = 1e6)
{
   sigma &lt;- sqrt(log(coeffOfVar^2 + 1))
   mu &lt;- log(mean) - sigma^2 / 2
   rlnorm(n, mu, sigma)
}
</code></pre>

<p>It works okay for small coefficients of variation</p>

<pre><code>r1 &lt;- rlnorm0(2, 0.5)
mean(r1)                 # 2.000095
sd(r1) / mean(r1)        # 0.4998437
</code></pre>

<p>But not for larger values</p>

<pre><code>r2 &lt;- rlnorm0(2, 50)
mean(r2)                 # 2.048509
sd(r2) / mean(r2)        # 68.55871
</code></pre>

<p>To check that it wasn't an R-specific issue, I reimplemented it in MATLAB. (Uses stats toolbox.)</p>

<pre><code>function y = lognrnd0(mean, coeffOfVar, sizeOut)
if nargin &lt; 3 || isempty(sizeOut)
   sizeOut = [1e6 1];
end
sigma = sqrt(log(coeffOfVar.^2 + 1));
mu = log(mean) - sigma.^2 ./ 2;
y = lognrnd(mu, sigma, sizeOut);
end

r1 = lognrnd0(2, 0.5);
mean(r1)                  % 2.0013
std(r1) ./ mean(r1)       % 0.5008

r2 = lognrnd0(2, 50);
mean(r2)                  % 1.9611
std(r2) ./ mean(r2)       % 22.61
</code></pre>

<p>Same problem.  The question is, why is this happening?  Is it just that the standard deviation is not robust when the variation is that wide?  Or have I screwed up somewhere?</p>
"
2526305,226041,2010-03-26T19:53:16Z,1,R from java with no graphics: is it worth moving to JRI,"<p>I have a system set up that's been happily running R from a java servlet, spawning processed &amp; hooking into the process's stdin, stdout, and stderr streams, as in the second andwer to <a href=""https://stackoverflow.com/questions/2180235/r-from-within-java"">this question</a>.  </p>

<p>After a system upgrade (that included glibc), the input is no longer reaching the R process.*  </p>

<p>Until now, 'R --vanilla --slave -f [file] ...' was working fine for me.  I also have no swing dependencies right now, so I'm somewhat reluctant to add them. (I may actually not be <em>able</em> to add swing dependencies; am I right that using REngine automatically brings swing in?  The examples import all of swing.)</p>

<p>Are there advantages to switching to JRI?  What changes would I need to make to my R script?  (It currently reads from stdin and writes to stdout).  I'm not finding the provided examples terribly helpful for how to use JRI in this situation. </p>

<p>Thanks for your help &amp; comments.</p>

<p>*I can't even tell if the problem is data being written too soon or too late, but that's a separate issue/question; if I move to JRI I'm hoping it all becomes moot.</p>
"
2527713,302970,2010-03-27T00:46:29Z,7,R: Are there any alternatives to loops for subsetting from an optimization standpoint?,"<p>A recurring analysis paradigm I encounter in my research is the need to subset based on all different group id values, performing statistical analysis on each group in turn, and putting the results in an output matrix for further processing/summarizing.</p>

<p>How I typically do this in R is something like the following:</p>

<blockquote>
  <p>data.mat &lt;- read.csv(""..."")<br>
     groupids &lt;- unique(data.mat$ID)  #Assume there are then 100 unique groups</p>
  
  <p>results &lt;- matrix(rep(""NA"",300),ncol=3,nrow=100)  </p>
  
  <p>for(i in 1:100) {<br>
     <code></code>tempmat &lt;- subset(data.mat,ID==groupids[i])  </p>
  
  <p><code>#</code>Run various stats on tempmat (correlations, regressions, etc), checking to<br>
     <code>#</code>make sure this specific group doesn't have NAs in the variables I'm using<br>
     <code>#</code>and assign results to x, y, and z, for example.  </p>
  
  <p><code></code>results[i,1] &lt;- x<br>
     <code></code>results[i,2] &lt;- y<br>
     <code></code>results[i,3] &lt;- z<br>
     }  </p>
</blockquote>

<p>This ends up working for me, but depending on the size of the data and the number of groups I'm working with, this can take up to three days. </p>

<p>Besides branching out into parallel processing, is there any ""trick"" for making something like this run faster? For instance, converting the loops into something else (something like an apply with a function containing the stats I want to run inside the loop), or eliminating the need to actually assign the subset of data to a variable?</p>

<p>EDIT:</p>

<p>Maybe this is just common knowledge (or sampling error), but I tried subsetting with brackets in some of my code rather than using the subset command, and it seemed to provide a slight performance gain which surprised me. I have some code I used and output below using the same object names as above:</p>

<blockquote>
  <p><code>&gt;</code>system.time(for(i in 1:1000){data.mat[data.mat$ID==groupids[i],]})<br>
        user  system elapsed<br>
      361.41   92.62  458.32 </p>
  
  <p><code>&gt;</code> system.time(for(i in 1:1000){subset(data.mat,ID==groupids[i])})<br>
        user  system elapsed<br>
      378.44  102.03  485.94   </p>
</blockquote>

<p>UPDATE:<br>
In one of the answers, jorgusch suggested that I use the data.table package to speed up my subsetting. So, I applied it to a problem I ran earlier this week. In a dataset with a little over 1,500,000 rows, and 4 columns (ID,Var1,Var2,Var3), I wanted to calculate two correlations in each group (indexed by the ""ID"" variable). There are slightly more than 50,000 groups. Below is my initial code (which is very similar to the above):  </p>

<blockquote>
  <p>data.mat &lt;- read.csv(""//home...."")<br>
     groupids &lt;- unique(data.mat$ID)</p>
  
  <p>results &lt;- matrix(rep(""NA"",(length(groupids) * 3)),ncol=3,nrow=length(groupids))  </p>
  
  <p>for(i in 1:length(groupids)) {<br>
     <code></code>tempmat &lt;- data.mat[data.mat$ID==groupids[i],] </p>
  
  <p><code></code>results[i,1] &lt;- groupids[i]<br>
     <code></code>results[i,2] &lt;- cor(tempmat$Var1,tempmat$Var2,use=""pairwise.complete.obs"")<br>
     <code></code>results[i,3] &lt;- cor(tempmat$Var1,tempmat$Var3,use=""pairwise.complete.obs"")    </p>
  
  <p>}  </p>
</blockquote>

<p>I'm re-running that right now for an exact measure of how long that took, but from what I remember, I started it running when I got into the office in the morning and it finished sometime in mid-afternoon. Figure 5-7 hours.  </p>

<p>Restructuring my code to use data.table....</p>

<blockquote>
  <p>data.mat &lt;- read.csv(""//home...."")<br>
     data.mat &lt;- data.table(data.mat)  </p>
  
  <p>testfunc &lt;- function(x,y,z) {<br>
     <code></code>temp1 &lt;- cor(x,y,use=""pairwise.complete.obs"")<br>
     <code></code>temp2 &lt;- cor(x,z,use=""pairwise.complete.obs"")<br>
     <code></code>res &lt;- list(temp1,temp2)<br>
     <code></code>res<br>
     }  </p>
  
  <p>system.time(test &lt;- data.mat[,testfunc(Var1,Var2,Var3),by=""ID""])  </p>
  
  <p>user  system  elapsed<br>
    16.41   0.05    17.44  </p>
</blockquote>

<p>Comparing the results using data.table to the ones I got from using a for loop to subset all IDs and record results manually, they seem to have given me the same answers(though I'll have to check that a bit more thoroughly). That looks to be a pretty big speed increase.</p>

<p>UPDATE 2: Running the code using subsets finally finished up again:</p>

<blockquote>
<pre><code>   user     system   elapsed  
17575.79  4247.41   23477.00
</code></pre>
</blockquote>

<p>UPDATE 3:<br>
I wanted to see if anything worked out differently using the plyr package that was also recommended. This is my first time using it, so I may have done things somewhat inefficiently, but it still helped substantially compared to the for loop with subsetting.  </p>

<p>Using the same variables and setup as before...  </p>

<blockquote>
  <p><code>&gt;</code>data.mat &lt;- read.csv(""//home...."")<br>
     <code>&gt;</code>system.time(hmm &lt;- ddply(data.mat,""ID"",function(df)c(cor(df$Var1,df$Var2,  use=""pairwise.complete.obs""),cor(df$Var1,df$Var3,use=""pairwise.complete.obs""))))  </p>

<pre><code>  user  system elapsed  
250.25    7.35  272.09  
</code></pre>
</blockquote>
"
2531372,30636,2010-03-27T23:45:54Z,43,How to stop emacs from replacing underbar with <- in ess-mode,"<p><code>ess-mode</code> is ""Emacs speaks statistics."" This mode is useful for editing programs for R or Splus (two separate statistics packages).</p>

<p>In my buffer, when ever I type <code>_</code> the character is replaced with <code>&lt;-</code>, which is very frustrating.  Is there an emacs lisp statement to turn off this behavior?</p>

<p>emacs: 22.1.1
ess-mode release (unknown)</p>
"
2531402,180626,2010-03-28T00:02:00Z,9,How can I superimpose modified loess lines on a ggplot2 qplot?,"<h3>Background</h3>

<p>Right now, I'm creating a multiple-predictor linear model and generating diagnostic plots to assess regression assumptions. (It's for a multiple regression analysis stats class that I'm loving at the moment :-)</p>

<p>My textbook (Cohen, Cohen, West, and Aiken 2003) recommends plotting each predictor against the residuals to make sure that:</p>

<ol>
<li>The residuals don't systematically covary with the predictor</li>
<li>The residuals are homoscedastic with respect to each predictor in the model</li>
</ol>

<p>On point (2), my textbook has this to say:</p>

<blockquote>
  <p>Some statistical packages allow the analyst to plot lowess fit lines at the mean of the residuals (0-line), 1 standard deviation above the mean, and 1 standard deviation below the mean of the residuals....In the present case {their example}, the two lines {mean + 1sd and mean - 1sd} remain roughly parallel to the lowess {0} line, consistent with the interpretation that the variance of the residuals does not change as a function of X. (p. 131)</p>
</blockquote>

<h3>How can I modify loess lines?</h3>

<p>I know how to generate a scatterplot with a ""0-line,"":</p>

<pre><code>    # First, I'll make a simple linear model and get its diagnostic stats
    library(ggplot2)
    data(cars)
    mod &lt;- fortify(lm(speed ~ dist, data = cars))
    attach(mod)
    str(mod)

    # Now I want to make sure the residuals are homoscedastic
    qplot (x = dist, y = .resid, data = mod) + 
    geom_smooth(se = FALSE) # ""se = FALSE"" Removes the standard error bands
</code></pre>

<p>But does anyone know how I can use <code>ggplot2</code> and <code>qplot</code> to generate plots where the 0-line, ""mean + 1sd"" AND ""mean - 1sd"" lines would be superimposed? Is that a weird/complex question to be asking?</p>
"
2531489,303400,2010-03-28T00:40:23Z,7,Understanding glm$residuals and resid(glm),"<p>Can you tell me what is returned by <strong>glm$residuals</strong> and <strong>resid(glm)</strong> where glm is a quasipoisson object.  e.g. How would I create them using glm$y and glm$linear.predictors. </p>

<p><strong>glm$residuals</strong></p>

<pre><code> n missing  unique    Mean     .05     .10   .25  .50     .75     .90     .95
</code></pre>

<p>37715   10042    2174 -0.2574 -2.7538 -2.2661 -1.4480 -0.4381  0.7542  1.9845  2.7749</p>

<p>lowest : -4.243 -3.552 -3.509 -3.481 -3.464
highest:  8.195  8.319  8.592  9.089  9.416</p>

<p><strong>resid(glm)</strong></p>

<pre><code>    n    missing     unique       Mean        .05        .10        .25
37715          0       2048 -2.727e-10    -1.0000    -1.0000    -0.6276
  .50        .75        .90        .95
</code></pre>

<p>-0.2080     0.4106     1.1766     1.7333</p>

<p>lowest : -1.0000 -0.8415 -0.8350 -0.8333 -0.8288
highest:  7.2491  7.6110  7.6486  7.9574 10.1932</p>
"
2535234,296564,2010-03-29T00:44:56Z,15,Find cosine similarity between two arrays,"<p>I'm wondering if there is a built in function in R that can find the cosine similarity (or cosine distance) between two arrays?</p>

<p>Currently, I implemented my own function, but I can't help but think that R should already come with one.</p>
"
2535740,NA,2010-03-29T04:06:31Z,1,Avoiding seasonality assumption for stl() or decompose() in R,"<p>I have high frequency commodity price data that I need to analyze. My objective is to not assume any seasonal component and just identify a trend. Here is where I run into problems with R. There are two main functions that I know of to analyze this time series: decompose() and stl(). The problem is that they both take a ts object type with a frequency parameter greater than or equal to 2. Is there some way I can assume a frequency of 1 per unit time and still analyze this time series using R? I'm afraid that if I assume frequency greater than 1 per unit time, and seasonality is calculated using the frequency parameter, then my forecasts are going to depend on that assumption. </p>

<pre><code>names(crude.data)=c('Date','Time','Price')
names(crude.data)
freq = 2
win.graph()
plot(crude.data$Time,crude.data$Price, type=""l"")
crude.data$Price = ts(crude.data$Price,frequency=freq) 
</code></pre>

<p>I want frequency to be 1 per unit time but then decompose() and stl() don't work!</p>

<pre><code>dim(crude.data$Price)
decom = decompose(crude.data$Price)
win.graph()
plot(decom$random[2:200],type=""line"")
acf(decom$random[freq:length(decom$random-freq)])
</code></pre>

<p>Thank you.</p>
"
2540129,304454,2010-03-29T17:58:12Z,48,Lattice: multiple plots in one window?,"<p>I'm trying to put multiple lattice plots in one window using <code>levelplot</code> by setting <code>par(mfrow=c(2,1))</code> but it seems to be ignoring this.</p>

<p>Is there a particular function for setting multiple plots in <code>lattice</code>?</p>
"
2540232,304468,2010-03-29T18:16:46Z,5,How to allow multiple inputs from user using R?,"<p>For example, if I need that the user specifies the number of rows and columns of a matrix:</p>

<p>PROMPT: Number of rows?: </p>

<p>USER INPUT: [a number]</p>

<p>I need that R 'waits' for the input. Then save [a number] into a variable v1. Next, </p>

<p>PROMPT: Number of columns?: </p>

<p>USER INPUT: [another number]</p>

<p>Also save [another number] into a variable v2. At the end, I will have two variables (v1, v2) that will be used in the rest of the code.</p>

<p>""readline"" only works for one input at a time. I can't run the two lines together</p>

<pre><code>v1 &lt;- readline(""Number of rows?: "")
v2 &lt;- readline(""Number of columns?: "")
</code></pre>

<p>Any ideas or suggestions?</p>

<p>Thank you in advance</p>
"
2545228,299077,2010-03-30T12:48:04Z,36,Converting a dataframe to a vector (by rows),"<p>I have a dataframe with numeric entries like this one</p>

<pre><code>test &lt;- data.frame(x=c(26,21,20),y=c(34,29,28))
</code></pre>

<p>How can I get the following vector?</p>

<pre><code>&gt; 26,34,21,29,20,28
</code></pre>

<p>I was able to get it using the following, but I guess there should be a much more elegant way</p>

<pre><code>X &lt;- test[1,]
for (i in 2:dim(test)[1]){
X &lt;- cbind(X,test[i,])
} 
</code></pre>
"
2545668,278616,2010-03-30T13:46:03Z,1,Creating a spreadsheet from an XML file,"<p>I am trying to convert a 120mb XML database of terrorist incidents (the first file for download available here <a href=""http://wits.nctc.gov/Export.do"" rel=""nofollow noreferrer"">http://wits.nctc.gov/Export.do</a>) to spreadsheet form so I can merge it with other data and do statistical analysis.</p>

<p>So far I have worked with Stata, which is useless now because it wont read XML. the site offers smaller files by month which can be opened via excel, but excel does not display them in the form I want and there ought to be a better way to transform the complete file rather than opening over a hundred single files, manually saving them as tab separated and then merging them.</p>

<p>I am looking for a way to convert the complete WITS.xml file to a spreadsheet where one row represents a single terrorist incident, and no info from the xml should be missing. even a differently structured XML is probably fine. I have tried converters but they are either not free, do not perform in the way I want them to or the file size is too large, and I have no idea how to use xslt. I am studying economics, and my programming knowledge is virtually nonexistent, which is increasingly becoming a drawback. I have seen that there is a package for R that I could use, maybe now is the right moment to start learning R or some other language. However, if there is a quick and easy way to do it, I'd sure prefer it.</p>
"
2545879,299077,2010-03-30T14:13:37Z,21,Row/column counter in 'apply' functions,"<p>What if one wants to <code>apply</code> a functon i.e. to each row of a matrix, but also wants to use as an argument for this function the number of that row. As an example, suppose you wanted to get the n-th root of the numbers in each row of a matrix, where n is the row number. Is there another way (using <code>apply</code> only) than column-binding the row numbers to the initial matrix, like this?</p>

<pre><code>test &lt;- data.frame(x=c(26,21,20),y=c(34,29,28))

t(apply(cbind(as.numeric(rownames(test)),test),1,function(x) x[2:3]^(1/x[1])))
</code></pre>

<p>P.S. Actually if <em>test</em> was really a matrix :  <code>test &lt;- matrix(c(26,21,20,34,29,28),nrow=3)</code>  , rownames(test) doesn't help :(
Thank you.</p>
"
2546016,162832,2010-03-30T14:33:16Z,8,how to define fill colours in ggplot histogram?,"<p>I have the following simple data</p>

<pre><code>data &lt;- structure(list(status = c(9, 5, 9, 10, 11, 10, 8, 6, 6, 7, 10, 
10, 7, 11, 11, 7, NA, 9, 11, 9, 10, 8, 9, 10, 7, 11, 9, 10, 9, 
9, 8, 9, 11, 9, 11, 7, 8, 6, 11, 10, 9, 11, 11, 10, 11, 10, 9, 
11, 7, 8, 8, 9, 4, 11, 11, 8, 7, 7, 11, 11, 11, 6, 7, 11, 6, 
10, 10, 9, 10, 10, 8, 8, 10, 4, 8, 5, 8, 7), statusgruppe = c(0, 
0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, NA, 0, 1, 0, 1, 
0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 
1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 
1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0)), .Names = c(""status"", 
""statusgruppe""), class = ""data.frame"", row.names = c(NA, -78L
))
</code></pre>

<p>from that I'd like to make a histogram:</p>

<pre><code>ggplot(data, aes(status))+
geom_histogram(aes(y=..density..),
     binwidth=1, colour = ""black"",
     fill=""white"")+
theme_bw()+
scale_x_continuous(""Staus"", breaks=c(min(data$status,na.rm=T), median(data$status, na.rm=T), max(data$status, na.rm=T)),labels=c(""Low"", ""Middle"", ""High""))+
scale_y_continuous(""Percent"", formatter=""percent"")
</code></pre>

<p>Now - i'd like for the bins to take colou according to value - e.g. bins with value > 9 gets  dark grey - everything else should be light grey.</p>

<p>I have tried with <code>fill=statusgruppe</code>, <code>scale_fill_grey(breaks=9)</code> etc. - but I can't get it to work. Any ideas?</p>
"
2547306,165787,2010-03-30T17:40:06Z,24,Generate multiple graphics from within an R function,"<p>I'd like to spawn several graphics windows from within a function in R using ggplot graphics...</p>

<pre><code>testf &lt;- function(a, b) {
  devAskNewPage(TRUE)
  qplot(a, b);
  # grid.newpage(recording = TRUE)
  dev.new()
  qplot(a, a+a);
  # grid.newpage(recording = TRUE)
  dev.new()
  qplot(b, b+b);
}

library(ggplot2)

x &lt;- rnorm(50)
y &lt;- rnorm(50)
testf(x, y)
</code></pre>

<p>However, neither dev.new() nor grid.newpage() seems to flush the preceding plot.</p>

<p>I know that, in R, functions normally only produce the last thing they evaluate, but I'd like to understand the process better and to learn of any possible workarounds. </p>

<p>Thoughts?</p>
"
2547402,5222,2010-03-30T17:55:07Z,259,Is there a built-in function for finding the mode?,"<p>In R, <code>mean()</code> and <code>median()</code> are standard functions which do what you'd expect.  <code>mode()</code> tells you the internal storage mode of the object, not the value that occurs the most in its argument. But is there is a standard library function that implements the statistical mode for a vector (or list)?</p>
"
2547447,74658,2010-03-30T18:02:07Z,41,What is the current state of Unit testing support in the R language,"<p><a href=""http://en.wikipedia.org/wiki/R_%28programming_language%29"" rel=""noreferrer"">R</a> is a statistics programming language.  Part of R is the use of Packages, which themselves are written in the R language.  Programming best practice includes the use of unit-testing to test the functions within these packages while they are being written and when they are used.</p>

<p>I am aware of a few packages for unit testing within R, these being</p>

<ul>
<li><a href=""http://cran.r-project.org/web/packages/RUnit/index.html"" rel=""noreferrer"">RUnit</a></li>
<li><a href=""http://cran.r-project.org/web/packages/svUnit/index.html"" rel=""noreferrer"">Svunit</a></li>
<li><a href=""http://cran.r-project.org/web/packages/testthat/index.html"" rel=""noreferrer"">Testthat</a></li>
</ul>

<p>I'm interested to know;</p>

<p>Are there any other packages out there ?
Given peoples experience, do these packages excel at different things ?
What's the current state of the art in unit testing for R ?</p>
"
2548815,296564,2010-03-30T21:16:37Z,92,Find file name from full file path,"<p>Is there a way to extract the file name from the file full path (part of a file path) without the hassle of manipulating string?</p>

<p>The equivalent in Java would be:</p>

<pre><code>File f = new File (""C:/some_dir/a"")
f.getName() //output a
f.getFullAbsolutePath() //output c:/some_dir/a
</code></pre>
"
2551921,457898,2010-03-31T10:00:59Z,10,Show frequencies along with barplot in ggplot2,"<p>I'm trying to display frequencies within barplot ... well, I want them <strong>somewhere</strong> in the graph: under the bars, within bars, above bars or in the legend area. And I recall (I may be wrong) that it can be done in <code>ggplot2</code>. This is probably an easy one... at least it seems easy. Here's the code:</p>

<pre><code>p &lt;- ggplot(mtcars)
p + aes(factor(cyl)) + geom_bar()
</code></pre>

<p>Is there any chance that I can get frequencies embedded in the graph?</p>
"
2553108,74658,2010-03-31T13:07:38Z,3,Replace values in a dataframe based on another factor which contains NA's in R,"<p>I have a dataframe which contains (among other things) a numeric column with a concentration, and a factor column with a status flag.  This status flag contains NA's.</p>

<p>Here's an example</p>

<pre><code>df&lt;-structure(list(conc = c(101.769, 1.734, 62.944, 92.697, 25.091, 27.377, 24.343, 55.084, 0.335, 23.280), status = structure(c(NA, NA, NA, NA, NA, NA, 2L, NA, 1L, NA), .Label = c(""&lt;LLOQ"", ""NR""), class = ""factor"")), .Names = c(""conc"", ""status""), row.names = c(NA, -10L), class = ""data.frame"")
</code></pre>

<p>I want to replace the concentration column with a string for some values of the flag column, or with the concentration value formatted to a certain number of significant digits.</p>

<p>When I try this</p>

<pre><code>ifelse(df$status==""NR"",""NR"",df$conc)
</code></pre>

<p>The NA's in the status flag don't trigger either the true or false condition (and return NA) - as the documentation suggests it will.  I could loop over the rows and use IF then else on each one but this seems inefficient.</p>

<p>Am I missing something ?  I've tried as.character(df$status) as well which doesn't work.  My mojo must be getting low....</p>
"
2557863,143383,2010-04-01T02:51:15Z,14,Measures of association in R -- Kendall's tau-b and tau-c,"<p>Are there any R packages for the calculation of Kendall's tau-b and tau-c, and their associated standard errors?  My searches on Google and Rseek have turned up nothing, but surely someone has implemented these in R.</p>
"
2558191,302378,2010-04-01T04:49:36Z,11,"How can I collapse a dataframe by some variables, taking mean across others","<p>I need to summarize a data frame by some variables, ignoring the others. This is sometimes referred to as collapsing. E.g. if I have a dataframe like this:  </p>

<pre><code>Widget Type Energy  
egg 1 20  
egg 2 30  
jap 3 50  
jap 1 60
</code></pre>

<p>Then collapsing by Widget, with Energy the dependent variable,   Energy~Widget, would yield  </p>

<pre><code>Widget Energy  
egg  25  
jap  55  
</code></pre>

<p>In Excel the closest functionality might be ""Pivot tables"" and I've worked out how to do it in python ( <a href=""http://alexholcombe.wordpress.com/2009/01/26/summarizing-data-by-combinations-of-variables-with-python/"" rel=""noreferrer"">http://alexholcombe.wordpress.com/2009/01/26/summarizing-data-by-combinations-of-variables-with-python/</a>), and here's an example with R using doBy library to do something very related ( <a href=""http://www.mail-archive.com/r-help@r-project.org/msg02643.html"" rel=""noreferrer"">http://www.mail-archive.com/r-help@r-project.org/msg02643.html</a>), but is there an easy way to do the above?  And even better is there anything built into the ggplot2 library to create plots that collapse across some variables?</p>
"
2560431,306879,2010-04-01T12:53:59Z,1,How to create a data.frame with a unknow number of columns?,"<p>I would like to create, in a function, a boucle to create a data.frame with a variable number of columns.</p>

<p>WIth something like :</p>

<pre><code>a = c(""a"",""b"")
b = c(list(1,2,3), list(4,5,6))
data.frame(a,b)
</code></pre>

<p>I would like to get a data-frame like :</p>

<pre><code>a 1 2 3
b 4 5 6
</code></pre>

<p>Instead of I obtain :</p>

<pre><code>a  1  2  3  4  5  6
b  1  2  3  4  5  6
</code></pre>

<p>Thank you !</p>

<p>PS : I also try with rbind, but it's doesn't work...</p>
"
2563511,256662,2010-04-01T20:37:56Z,3,In R: How can I know if my packages are up to date?,"<p>I am looking for a function that will tell me, for a list of packages, which of them is up to date and which is not (I need it so to trace back an R crash).</p>

<p>Thanks,</p>

<p>Tal</p>
"
2563824,253579,2010-04-01T21:30:44Z,15,writing to a dataframe from a for-loop in R,"<p>I'm trying to write from a loop to a data frame in R, for example a loop like this></p>

<pre><code>for (i in 1:20) {
print(c(i+i,i*i,i/1))}
</code></pre>

<p>and to write each line of 3 values to a data frame with three columns, so that each iteration takes on a new row. I've tried using matrix, with ncol=3 and filled by rows, but only get the last item from the loop.</p>

<p>Thanks.</p>
"
2564141,143813,2010-04-01T22:45:11Z,1,Problem installing packages,"<p>I am installing Matrix on a Linux x86_64 multicore system. I receive a message:</p>

<pre><code>Warning message:
In install.packages(""Matrix"", dependencies = TRUE) :
  package 'Matrix' is not available
</code></pre>

<p>Sure enough, there are not many details on package troubleshooting. It appears that Matrix is available for x86_64, but it's not available in any repository. How come?</p>
"
2564258,256439,2010-04-01T23:28:14Z,391,Plot two graphs in same plot in R,"<p>I would like to plot y1 and y2 in the same plot.</p>

<pre><code>x  &lt;- seq(-2, 2, 0.05)
y1 &lt;- pnorm(x)
y2 &lt;- pnorm(x,1,1)
plot(x,y1,type=""l"",col=""red"")
plot(x,y2,type=""l"",col=""green"")
</code></pre>

<p>But when I do it like this, they are not plotted in the same plot together.</p>

<p>In Matlab one can do <code>hold on</code>, but does anyone know how to do this in R?</p>
"
2564275,162832,2010-04-01T23:32:50Z,0,for (i in xxx) ggplot problem,"<p>This is strange - I think?</p>

<pre><code>library(ggplot2)
tf &lt;- which(sapply(diamonds, is.factor))
diamonds.tf &lt;- diamonds[,tf]
</code></pre>

<p>So far so good. But next comes the trouble:</p>

<pre><code>pl.f &lt;- ggplot(diamonds.tf, aes(x=diamonds.tf[,i]))+
geom_bar()+
xlab(names(diamonds.tf[i]))

for (i in 1:ncol(diamonds.tf)) {
ggsave(paste(""plot.f"",i,"".png"",sep=""""), plot=pl.f, height=3.5, width=5.5)
}
</code></pre>

<p>This saves the plots in my working directory - but with the wrong x-label. I think this is strange since calling ggplot directly produces the right plot:</p>

<pre><code>i &lt;- 2
ggplot(diamonds, aes(x=diamonds[,i]))+geom_bar()+xlab(names(diamonds)[i])
</code></pre>

<p>I don't really know how to describe this as a fitting title - suggestions as to a more descriptive question-title is most welcome.</p>

<p>Thanks in advance</p>
"
2564765,253579,2010-04-02T02:42:16Z,12,"class ""By"" into dataframe in R","<p>I'm using by() to evaluate a function by factors in my dataframe, but I need to use the results in a table form.</p>

<p>I've seen a use of as.data.frame.table to get a ""By"" class object into a data frame, but I'm not sure if this only works when the number of factors employed in the by() function is the same as the length of the ""by"" output. Using as.data.frame.table I get the following error</p>

<p>""...arguments imply differing number of rows: 10, 33""</p>

<p>Is there another way of doing this? 
Can tapply be used instead of by() to get a different output class?</p>

<p>btw, I'm using by() to convert my data into a frequency table and then regroup by standard bins</p>

<pre><code>BT_by &lt;- by(BT_H, BT_H$Tax_pp, function(BT_H) hist(rep.int(BT_H$Altitude, BT_H$Count), breaks = seq(0,6600,200), plot = FALSE)$counts)
</code></pre>

<p>Any help would be appreciated. </p>
"
2566128,216064,2010-04-02T10:21:34Z,9,How to escape % in roxygen literate programming?,"<p>The default value of a parameter of my function contains a ""%"". This seems to be a problem for roxygen, it produces a lot of warnings and R CMD check fails when trying to build latex documentation.</p>

<p>How can I make this function (and its documentation) work? Using %% or \% instead of % does not help.</p>

<pre><code>#' Test escape \% from in-source documentation (roxygen).
#'
#' What happens when parameters contain special latex characters? 
#'
#' @param x unsuspicious parameter 
#' @param format sprintf format string (default ""\%5.0f"")
#'
#' @return formatted string
#' @export
#' @author Karsten Weinert
testroxy &lt;- function(x, format = ""%5.0f"") {
  sprintf(format,x)
}
</code></pre>
"
2566766,269476,2010-04-02T13:06:16Z,4,Margin totals in xtabs,"<p>If you have 2 cross classifying variables you can use <code>rowSums</code> and <code>colSums</code> to produce margin totals on an <code>xtabs</code> output. But how can it be done if you have 3 classifying variables (ie margin totals in each sub table)?</p>
"
2568234,3306,2010-04-02T17:50:19Z,11,"How to plot data grouped by a factor, but not as a boxplot","<p>In R, given a vector</p>

<pre><code>casp6 &lt;- c(0.9478638, 0.7477657, 0.9742675, 0.9008372, 0.4873001, 0.5097587, 0.6476510, 0.4552577, 0.5578296, 0.5728478, 0.1927945, 0.2624068, 0.2732615)
</code></pre>

<p>and a factor:</p>

<pre><code>trans.factor &lt;- factor (rep (c(""t0"", ""t12"", ""t24"", ""t72""), c(4,3,3,3)))
</code></pre>

<p>I want to create a plot where the data points are grouped as defined by the factor. So the categories should be on the x-axis, values in the same category should have the same x coordinate.</p>

<p>Simply doing <code>plot(trans.factor, casp6)</code> does almost what I want, it produces a boxplot, but I want to see the individual data points.</p>
"
2568840,3306,2010-04-02T19:50:20Z,7,Select subset of dataframe by non-unique ids,"<p>Suppose I have a dataframe like this one:</p>

<pre><code>df &lt;- data.frame (id = c(""a"", ""b"", ""a"", ""c"", ""e"", ""d"", ""e""), n=1:7)
</code></pre>

<p>and a vector with ids like this one:</p>

<pre><code>v &lt;- c(""a"", ""b"")
</code></pre>

<p>How can I select the rows of the dataframe that match the ids in v? I can't use the id column for rownames because they are not unique. When I try that, I get:</p>

<pre><code> rownames(df) &lt;- df[[""id""]]
Error in `row.names&lt;-.data.frame`(`*tmp*`, value = c(1L, 2L, 1L, 3L, 5L,  : 
  duplicate 'row.names' are not allowed
In addition: Warning message:
non-unique values when setting 'row.names': ‘a’, ‘e’ 
</code></pre>
"
2572001,308375,2010-04-03T17:17:08Z,3,R selecting duplicate rows,"<p>Okay, I'm fairly new to R and I've tried to search the documentation for what I need to do but here is the problem.</p>

<p>I have a data.frame called heeds.data in the following form (some columns omitted for simplicity)
eval.num, eval.count, ... fitness, fitness.mean, green.h.0, green.v.0, offset.0, green.h.1, green.v.1,...green.h.7, green.v.7, offset.7...</p>

<p>And I have selected a row meeting the following criteria:</p>

<pre><code>best.fitness &lt;- min(heeds.data$fitness.mean[heeds.data$eval.count &gt;= 10])
best.row &lt;- heeds.data[heeds.data$fitness.mean == best.fitness]
</code></pre>

<p>Now, what I want are all of the other rows with that have columns green.h.0 to offset.7 (a contiguous section of columns) equal to the best.row</p>

<p>I was thinking this might work</p>

<pre><code>heeds.best &lt;- heeds.data$fitness[
  heeds.data$green.h.0 == best.row$green.h.0 &amp; ...
]
</code></pre>

<p>But with 24 columns it seems like a stupid method.  Looking for something a bit simpler with less manual typing.</p>

<p>Here is a short data sample to show what I want</p>

<pre><code>eval.num, eval.count, fitness, fitness.mean, green.h.0, green.v.0, offset.0
1         1           1500     1500          100        120        40
2         2           1000     1250          100        120        40
3         3           1250     1250          100        120        40
4         4           1000     1187.5        100        120        40
5         1           2000     2000          200        100        40
6         1           3000     3000          150        90         10
7         1           2000     2000          90         90         100
8         2           1800     1900          90         90         100
</code></pre>

<p>Should select the ""best"" as row 4
Then I want to grab the results as follows</p>

<pre><code>eval.num, eval.count, fitness, fitness.mean, green.h.0, green.v.0, offset.0
1         1           1500     1500          100        120        40
2         2           1000     1250          100        120        40
3         3           1250     1250          100        120        40
4         4           1000     1187.5        100        120        40
</code></pre>

<p>Data isn't actually sorted and there are many more columns but that is the concept</p>

<p>Thanks!</p>
"
2572330,308375,2010-04-03T19:06:07Z,2,R data frame select by global variable,"<p>I'm not sure how to do this without getting an error.  Here is a simplified example of my problem.</p>

<p>Say I have this data frame DF</p>

<pre><code>a   b  c  d
1   2  3  4
2   3  4  5
3   4  5  6
</code></pre>

<p>Then I have a variable</p>

<pre><code>x &lt;- min(c(1,2,3))
</code></pre>

<p>Now I want do do the following</p>

<pre><code>y &lt;- DF[a == x]
</code></pre>

<p>But when I try to refer to some variable like ""x"" I get an error because R is looking for a column ""x"" in my data frame. I get the ""undefined columns selected"" error</p>

<p>How can I do what I am trying to do in R?</p>
"
2572559,308375,2010-04-03T20:25:14Z,3,R counting the occurrences of similar rows of data frame,"<p>I have data in the following format called DF (this is just a made up simplified sample):</p>

<pre><code>eval.num, eval.count, fitness, fitness.mean, green.h.0, green.v.0, offset.0 random
1         1           1500     1500          100        120        40       232342
2         2           1000     1250          100        120        40       11843
3         3           1250     1250          100        120        40       981340234
4         4           1000     1187.5        100        120        40       4363453
5         1           2000     2000          200        100        40       345902
6         1           3000     3000          150        90         10       943
7         1           2000     2000          90         90         100      9304358
8         2           1800     1900          90         90         100      284333
</code></pre>

<p>However, the eval.count column is incorrect and I need to fix it.  It should report the number of rows with the same values for (green.h.0, green.v.0, and offset.0) by only looking at the previous rows.</p>

<p>The example above uses the expected values, but assume they are incorrect.</p>

<p>How can I add a new column (say ""count"") which will count all previous rows which have the same values of the specified variables?</p>

<p>I have gotten help on a similar problem of just selecting all rows with the same values for specified columns, so I supposed I <em>could</em> just write a loop around that, but it seems inefficient to me.</p>
"
2573132,293037,2010-04-04T00:25:43Z,12,What is the best interface from Python 3.1.1 to R?,"<p>I am using Python 3.1.1 on Mac OS X 10.6.2 and need an interface to R. When browsing the internet I found out about RPy. Is this the right choice? </p>

<p>Currently, a program in Python computes a distance matrix and, stores it in a file. I invoke R separately in an interactive way and read in the matrix for cluster analysis. In order to
simplify computation one could prepare a script file for R then call it from Python and read back the results. Since I am new to Python, I would not like to go back to 2.6. </p>
"
2576876,308883,2010-04-05T04:07:56Z,6,Converting a ts (Time Series) object to a Vector in R,"<p>I need to use a function on a vector that does not take a ts object. I'm trying to convert it to a plain old vector but I just can't seem to figure it out. I googled around but mostly people are trying to convert data types into ts object. I want to go the other way. Any help would be appreciated. </p>
"
2577636,192377,2010-04-05T09:11:56Z,2,Should I continue using R v2.8.1?,"<p>I've been using R v2.8.1 for a long time. Normally I would upgrade it to the latest version but something keeps me away from the builds later than 2.8.1:</p>

<p>I use </p>

<p><code>read.table(file=file.choose(),header=TRUE)</code></p>

<p>frequently in my libraries. After upgrading to 2.9.0, R started not to remember the latest directory used while selecting file. I downgraded to 2.8.1 and now R can remember again the last directory used. I don't know why they changed that behavior in this direction but this is absolutely crucial for me. It wastes my time in v2.9.0 every time I try to find a specific directory when R cannot remember it. </p>

<p>Now R 2.10.1 is released. I don't know if they have corrected this issue. Should I upgrade or is it just enough to continue using v2.8.1? Will I miss something if I stick at 2.8.1?</p>
"
2578961,298308,2010-04-05T14:46:15Z,9,How to better create stacked bar graphs with multiple variables from ggplot2?,"<p>I often have to make stacked barplots to compare variables, and because I do all my stats in R, I prefer to do all my graphics in R with ggplot2. I would like to learn how to do two things:</p>

<p>First, I would like to be able to add proper percentage tick marks for each variable rather than tick marks by count. Counts would be confusing, which is why I take out the axis labels completely.</p>

<p>Second, there must be a simpler way to reorganize my data to make this happen. It seems like the sort of thing I should be able to do natively in ggplot2 with plyR, but the documentation for plyR is not very clear (and I have read both the ggplot2 book and the online plyR documentation. </p>

<p>My best graph looks like this, the code to create it follows:</p>

<p><img src=""https://farm5.static.flickr.com/4016/4493625638_bb46924571_d.jpg"" alt=""example graph""></p>

<p>The R code I use to get it is the following:</p>

<pre><code>library(epicalc)  

### recode the variables to factors ###
recode(c(int_newcoun, int_newneigh, int_neweur, int_newusa, int_neweco, int_newit, int_newen, int_newsp, int_newhr, int_newlit, int_newent, int_newrel, int_newhth, int_bapo, int_wopo, int_eupo, int_educ), c(1,2,3,4,5,6,7,8,9, NA), 
c('Very Interested','Somewhat Interested','Not Very Interested','Not At All interested',NA,NA,NA,NA,NA,NA))

### Combine recoded variables to a common vector
Interest1&lt;-c(int_newcoun, int_newneigh, int_neweur, int_newusa, int_neweco, int_newit, int_newen, int_newsp, int_newhr, int_newlit, int_newent, int_newrel, int_newhth, int_bapo, int_wopo, int_eupo, int_educ)


### Create a second vector to label the first vector by original variable ###  
a1&lt;-rep(""News about Bangladesh"", length(int_newcoun))
a2&lt;-rep(""Neighboring Countries"", length(int_newneigh))
[...]
a17&lt;-rep(""Education"", length(int_educ))


Interest2&lt;-c(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14, a15, a16, a17)

### Create a Weighting vector of the proper length ###
Interest.weight&lt;-rep(weight, 17)

### Make and save a new data frame from the three vectors ###
Interest.df&lt;-cbind(Interest1, Interest2, Interest.weight)
Interest.df&lt;-as.data.frame(Interest.df)

write.csv(Interest.df, 'C:\\Documents and Settings\\[name]\\Desktop\\Sweave\\InterestBangladesh.csv')

### Sort the factor levels to display properly ###

Interest.df$Interest1&lt;-relevel(Interest$Interest1, ref='Not Very Interested')
Interest.df$Interest1&lt;-relevel(Interest$Interest1, ref='Somewhat Interested')
Interest.df$Interest1&lt;-relevel(Interest$Interest1, ref='Very Interested')

Interest.df$Interest2&lt;-relevel(Interest$Interest2, ref='News about Bangladesh')
Interest.df$Interest2&lt;-relevel(Interest$Interest2, ref='Education')
[...]
Interest.df$Interest2&lt;-relevel(Interest$Interest2, ref='European Politics')

detach(Interest)
attach(Interest)

### Finally create the graph in ggplot2 ###

library(ggplot2)
p&lt;-ggplot(Interest, aes(Interest2, ..count..))
p&lt;-p+geom_bar((aes(weight=Interest.weight, fill=Interest1)))
p&lt;-p+coord_flip()
p&lt;-p+scale_y_continuous("""", breaks=NA)
p&lt;-p+scale_fill_manual(value = rev(brewer.pal(5, ""Purples"")))
p
update_labels(p, list(fill='', x='', y=''))
</code></pre>

<p>I'd very much appreciate any tips, tricks or hints. </p>
"
2579995,5222,2010-04-05T17:54:33Z,77,Control the size of points in an R scatterplot?,"<p>In R, the <code>plot()</code> function takes a <code>pch</code> argument that controls the appearance of the points in the plot.  I'm making scatterplots with tens of thousands of points and prefer a small, but not too small dot.  Basically, I find <code>pch='.'</code> to be too small, but <code>pch=19</code> to be too fat.  Is there something in the middle or some way to scale the dots down somehow?</p>
"
2581698,142879,2010-04-05T23:04:10Z,10,How to manually add a legend to a ggplot object,"<p>I have this data frame:</p>

<pre><code>structure(list(month_num = 1:24, founded_month = c(4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 1L, 2L, 3L), founded_year = c(2008L, 2008L, 2008L, 
2008L, 2008L, 2008L, 2008L, 2008L, 2008L, 2009L, 2009L, 2009L, 
2009L, 2009L, 2009L, 2009L, 2009L, 2009L, 2009L, 2009L, 2009L, 
2010L, 2010L, 2010L), count = c(270L, 222L, 256L, 250L, 277L, 
268L, 246L, 214L, 167L, 408L, 201L, 225L, 203L, 220L, 230L, 225L, 
177L, 207L, 166L, 135L, 116L, 122L, 69L, 42L), month_abb = c(""Apr"", 
""May"", ""Jun"", ""Jul"", ""Aug"", ""Sep"", ""Oct"", ""Nov"", ""Dec"", ""Jan"", 
""Feb"", ""Mar"", ""Apr"", ""May"", ""Jun"", ""Jul"", ""Aug"", ""Sep"", ""Oct"", 
""Nov"", ""Dec"", ""Jan"", ""Feb"", ""Mar""), short_year = c(""08"", ""08"", 
""08"", ""08"", ""08"", ""08"", ""08"", ""08"", ""08"", ""09"", ""09"", ""09"", ""09"", 
""09"", ""09"", ""09"", ""09"", ""09"", ""09"", ""09"", ""09"", ""10"", ""10"", ""10""
), proj = c(282, 246, 292, 298, 337, 340, 330, 310, 275, 528, 
333, 369, 359, 388, 410, 417, 381, 423, 394, 375, 368, 386, 345, 
330), label = c(""Apr"", ""May"", ""Jun"", ""Jul"", ""Aug"", ""Sep"", ""Oct"", 
""Nov"", ""Dec"", ""Jan\n09"", ""Feb"", ""Mar"", ""Apr"", ""May"", ""Jun"", ""Jul"", 
""Aug"", ""Sep"", ""Oct"", ""Nov"", ""Dec"", ""Jan\n10"", ""Feb"", ""Mar"")), .Names = c(""month_num"", 
""founded_month"", ""founded_year"", ""count"", ""month_abb"", ""short_year"", 
""proj"", ""label""), row.names = c(NA, -24L), class = ""data.frame"")
</code></pre>

<p>and i've got all of this done (I know the code's a bit ugly looking, pointers appreciated):</p>

<pre><code>p &lt;- ggplot(m_summary2, aes(x = month_num, y = count))
p + 
geom_line(colour = rgb(0/255, 172/255, 0/255)) + geom_point(colour = rgb(0/255, 172/255,          
    0/255)) + 
geom_line(aes(x = m_summary2$month_num, y = m_summary2$proj), 
    colour = rgb(18/255, 111/255, 150/255)) + 
geom_point(aes(x = m_summary2$month_num, y = m_summary2$proj), colour = rgb(18/255,   
    111/255, 150/255)) +     
scale_x_continuous(""Month"", breaks = m_summary2$month_num, labels = m_summary2$label) + 
scale_y_continuous(""# Startups Founded"") + 
opts(title = paste(""# Startups Founded:"", m_summary2$month_abb[1], 
    m_summary2$short_year[1], ""-"", m_summary2$month_abb[nrow(m_summary2)],  
    m_summary2$short_year[nrow(m_summary2)]))
</code></pre>

<p>Now I would like to add a legend to clarify that the blue line is a projection and the green line is the current data. I would like to make the changes without altering the dataframe if possible.</p>

<p>Thanks in advance!</p>
"
2582150,296564,2010-04-06T01:33:21Z,6,Run R script from Powershell,"<p>In batch script, I can run an R script with the following syntax:</p>

<pre><code>Rterm.exe --quiet --slave --vanilla &lt; ""C:\some_script.R""
</code></pre>

<p>However, Powershell seems to have reserved ""&lt;"" for future expansion. I am wondering if there is a direct way to run R script within another Powershell script. </p>
"
2584806,74658,2010-04-06T12:37:54Z,3,Is there a better (i.e vectorised) way to put part of a column name into a row of a data frame in R,"<p>I have a data frame in R that has come about from running some stats on the result of a melt/cast operation.  I want to add a row into this dataframe containing a Nominal value.  That Nominal Value is present in the names for each column</p>

<pre><code>df&lt;-as.data.frame(cbind(x=c(1,2,3,4,5),`Var A_100`=c(5,4,3,2,1),`Var B_5`=c(9,8,7,6,5)))
&gt; df
  x Var A_100 Var B_5
1 1         5       9
2 2         4       8
3 3         3       7
4 4         2       6
5 5         1       5
</code></pre>

<p>So, I want to create a new row, that contains '100' in the column Var A_100 and '5' in Var B_5.  Currently this is what I'm doing but I'm sure there must be a better, vectorised way to do this.</p>

<pre><code>temp_nom&lt;-NULL
for (l in 1:length(names(df))){
 temp_nom[l]&lt;-strsplit(names(df),""_"")[[l]][2]
 }
temp_nom
[1] NA    ""100"" ""5""  
df[6,]&lt;-temp_nom
&gt; df
     x Var A_100 Var B_5
1    1         5       9
2    2         4       8
3    3         3       7
4    4         2       6
5    5         1       5
6 &lt;NA&gt;       100       5
rm(temp_nom)
</code></pre>

<p>Typically I'd have 16-24 columns. Any ideas?</p>
"
2585583,74658,2010-04-06T14:29:49Z,1,How to create a column containing a string of stars to inidcate levels of a factor in a data frame in R,"<p>(second question today - must be a bad day)</p>

<p>I have a dataframe with various columns, inculding a concentration column (numeric), a flag highlighting invalid results (boolean) and a description of the problem (character)</p>

<pre><code>df &lt;- structure(list(x = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), rawconc = c(77.4, 
52.6, 86.5, 44.5, 167, 16.2, 59.3, 123, 1.95, 181), reason = structure(c(NA, 
NA, 2L, NA, NA, NA, 2L, 1L, NA, NA), .Label = c(""Fails Acceptance Criteria"", 
""Poor Injection""), class = ""factor""), flag = c(""False"", ""False"", 
""True"", ""False"", ""False"", ""False"", ""True"", ""True"", ""False"", ""False""
)), .Names = c(""x"", ""rawconc"", ""reason"", ""flag""), row.names = c(NA, 
-10L), class = ""data.frame"")
</code></pre>

<p>I can create a column with the numeric level of the reason column</p>

<pre><code>df$level&lt;-as.numeric(df$reason)
df
    x rawconc                    reason  flag level
1   1   77.40                      &lt;NA&gt; False    NA
2   2   52.60                      &lt;NA&gt; False    NA
3   3   86.50            Poor Injection  True     2
4   4   44.50                      &lt;NA&gt; False    NA
5   5  167.00                      &lt;NA&gt; False    NA
6   6   16.20                      &lt;NA&gt; False    NA
7   7   59.30            Poor Injection  True     2
8   8  123.00 Fails Acceptance Criteria  True     1
9   9    1.95                      &lt;NA&gt; False    NA
10 10  181.00                      &lt;NA&gt; False    NA
</code></pre>

<p>and here's what I want to do to create a column with 'level' many stars, but it fails</p>

<pre><code>df$stars&lt;-paste(rep(""*"",df$level)sep="""",collapse="""")
Error: unexpected symbol in ""df$stars&lt;-paste(rep(""*"",df$level)sep""

df$stars&lt;-paste(rep(""*"",df$level),sep="""",collapse="""")
Error in rep(""*"", df$level) : invalid 'times' argument

rep(""*"",df$level)
Error in rep(""*"", df$level) : invalid 'times' argument

df$stars&lt;-paste(rep(""*"",pmax(df$level,0,na.rm=TRUE)),sep="""",collapse="""")
Error in rep(""*"", pmax(df$level, 0, na.rm = TRUE)) : 
  invalid 'times' argument
</code></pre>

<p>It seems that rep needs to be fed one value at a time.  I feel that this should be possible (and my gut says 'use lapply' but my apply fu is v. poor)</p>

<p>Any one want to try ?</p>
"
2588130,163053,2010-04-06T20:39:35Z,4,Alter a function as a parameter before evaluating it in R?,"<p>Is there any way, given a function passed as a parameter, to alter its input parameter string before evaluating it?  </p>

<p>Here's pseudo-code for what I'm hoping to achieve:</p>

<pre><code>test.func &lt;- function(a, b) {
    # here I want to alter the b expression before evaluating it:
    b(..., val1=a)
}
</code></pre>

<p>Given the function call passed to <code>b</code>, I want to add in <code>a</code> as another parameter without needing to always specify <code>...</code> in the <code>b</code> call.  So the output from this <code>test.func</code> call should be:</p>

<pre><code>test.func(a=""a"", b=paste(1, 2))
""1""  ""2""  ""a""
</code></pre>

<p><em>Edit</em>: </p>

<p>Another way I could see doing something like this would be if I could assign the additional parameter within the scope of the parent function (again, as pseudo-code); in this case <code>a</code> would be within the scope of t1 and hence t2, but not globally assigned:</p>

<pre><code>t2 &lt;- function(...) {
  paste(a=a, ...)
}

t1 &lt;- function(a, b) {
  local( { a &lt;&lt;- a; b } )
}

t1(a=""a"", b=t2(1, 2))
</code></pre>

<p>This is somewhat akin to currying in that I'm nesting the parameter within the function itself.</p>

<p><em>Edit 2</em>:</p>

<p>Just to add one more comment to this: I realize that one related approach could be to use ""<a href=""http://en.wikipedia.org/wiki/Prototype-based_programming"" rel=""nofollow noreferrer"">prototype-based programming</a>"" such that things would be inherited (which could be achieved with <a href=""http://cran.r-project.org/web/packages/proto/index.html"" rel=""nofollow noreferrer"">the proto package</a>).  But I was hoping for a easier way to simply alter the input parameters before evaluating in R.</p>
"
2589275,207258,2010-04-07T00:35:58Z,22,How to tell lapply to ignore an error and process the next thing in the list?,"<p>I have an example function below that reads in a date as a string and returns it as a date object.  If it reads a string that it cannot convert to a date, it returns an error.</p>

<pre><code>testFunction &lt;- function (date_in) {
    return(as.Date(date_in))
    }

testFunction(""2010-04-06"")  # this works fine
testFunction(""foo"")  # this returns an error
</code></pre>

<p>Now, I want to use lapply and apply this function over a list of dates:</p>

<pre><code>dates1 = c(""2010-04-06"", ""2010-04-07"", ""2010-04-08"")
lapply(dates1, testFunction)  # this works fine
</code></pre>

<p>But if I want to apply the function over a list when one string in the middle of two good dates returns an error, what is the best way to deal with this?   </p>

<pre><code>dates2 = c(""2010-04-06"", ""foo"", ""2010-04-08"")
lapply(dates2, testFunction)
</code></pre>

<p>I presume that I want a try catch in there, but is there a way to catch the error for the ""foo"" string whilst asking lapply to continue and read the third date?</p>
"
2590043,310608,2010-04-07T04:40:14Z,2,Creating a series of vectors from a vector,"<p>I have a simple two vector dataframe (length=30) that looks something like this:  </p>

<pre><code>&gt; mDF
    Param1 w.IL.L
1   AuZgFw    0.5
2   AuZfFw      2
3   AuZgVw   74.3
4   AuZfVw  20.52
5   AuTgIL   80.9
6   AuTfIL  193.3
7   AuCgFL    0.2
8   ...
</code></pre>

<p>I'd like to use each of the rows to form 30 single value numeric vectors with the name of the vector taken from <code>mDF$Param1</code>, so that:  </p>

<pre><code>&gt; AuZgFw       
[1] 0.5     
</code></pre>

<p>etc  </p>

<p>I've tried melting and casting, but I suspect there may be an easier way? </p>
"
2591795,256662,2010-04-07T11:00:09Z,4,Downloading RGoogleDocs for R (it fails),"<p>I am trying:</p>

<pre><code>install.packages(""RGoogleDocs"", repos = ""http://www.omegahat.org/R"")
</code></pre>

<p>As suggested <a href=""https://stackoverflow.com/questions/1794318/rgoogledocs-and-now-rgoogledata"">here</a>, but it doesn't work.</p>

<p>I ended up manually downloading the file from <a href=""http://www.omegahat.org/R/bin/windows/contrib/R-2.9/"" rel=""nofollow noreferrer"">here</a>.</p>

<p>What other ways are there for me to get to the file directly?</p>

<p>Thanks,
Tal</p>
"
2593412,142068,2010-04-07T14:47:20Z,2,Writing a script for reading many .csv files with similar filenames,"<p>I have several .csv files with similar filenames except a numeric month (i.e. 03_data.csv, 04_data.csv, 05_data.csv, etc.) that I'd like to read into R.</p>

<p>I have two questions:</p>

<ul>
<li>Is there a function in R similar to
MATLAB's varname and assignin that
will let me create/declare a variable name
within a function or loop that will allow me to 
read the respective .csv file - i.e.
03_data.csv into 03_data data.frame,
etc.? I want to write a quick loop to
do this because the filenames are
similar.</li>
<li>As an alternative, is it better to
create one dataframe with the first
file and then append the rest using a
for loop? How would I do that?</li>
</ul>
"
2593643,256662,2010-04-07T15:16:12Z,5,Correlation Scatter-matrix plot with different point size (in R),"<p>I just came a cross <a href=""http://addictedtor.free.fr/graphiques/graphcode.php?graph=137"" rel=""nofollow noreferrer"">this nice code</a> that makes this scatter matrix plot:</p>

<p><a href=""http://addictedtor.free.fr/graphiques/graphiques/graph_137.png"" rel=""nofollow noreferrer"">alt text http://addictedtor.free.fr/graphiques/graphiques/graph_137.png</a></p>

<p>And wanted to implement it to a likret scale variables (integers of 1 to 5) by making the dot's sizes/colors (in the lower triangle) differ according to how many options of that type occurs (like the effect the jitter might have given me).</p>

<p>Any idea on how to do this on the base plotting mechanism ?</p>

<p>Update:</p>

<p>I made the following function, but don't know how to have the scale of the dots always be ""good"", what do you think ?</p>

<pre><code>panel.smooth2 &lt;- function (x, y, col = par(""col""), bg = NA, pch = par(""pch""), 
                    cex = 1, col.smooth = ""red"", span = 2/3, iter = 3, ...) 
{
    require(reshape)
    z &lt;- merge(data.frame(x,y), melt(table(x ,y)),sort =F)$value
    z &lt;- z/ (4*max(z)) 

    symbols( x, y,  circles = z,#rep(0.1, length(x)), #sample(1:2, length(x), replace = T) ,
            inches=F, bg=""blue"", fg = bg, add = T)

    # points(x, y, pch = pch, col = col, bg = bg, cex = cex)
    ok &lt;- is.finite(x) &amp; is.finite(y)
    if (any(ok)) 
        lines(stats::lowess(x[ok], y[ok], f = span, iter = iter), 
            col = col.smooth, ...)
}



a1 &lt;- sample(1:5, 100, replace = T)
a2 &lt;- sample(1:5, 100, replace = T)
a3 &lt;- sample(1:5, 100, replace = T)
aa &lt;- data.frame(a1,a2,a3)


pairs(aa , lower.panel=panel.smooth2)
</code></pre>
"
2597062,296155,2010-04-08T01:49:26Z,4,How do you re-arrange vector order in R?,"<p>I have three vectors in an xts R object. Call them V1, V2, V3. After merging, the order of them left to right is V2, V3, V1. How do I re-arrange them so they read (from left to right) as V1, V2, V3?</p>
"
2597310,281537,2010-04-08T02:59:15Z,4,How do I interpret rpart splits on factor variables when building classification trees in R?,"<p>If the factor variable is Climate, with 4 possible values: Tropical, Arid, Temperate, Snow, and a node in my <code>rpart</code> tree is labeled as ""Climate:ab"", what is the split?</p>
"
2600640,293843,2010-04-08T14:20:30Z,2,RODBC sqlSave() and mapping column names,"<p>I've a question about using sqlSave. How does R map RODBC data in the data frame to the database table columns?</p>

<p>If I've a table with columns X and Y and a data frame with columns X and Y, RODBC puts X into X and Y into Y (I found out by trail-and-error). But can I explicitly tell R how to map data.frame columns to database table columns, like put A in X and B in Y.</p>

<p>I'm rather new to R and think the RODBC manual is a bit cryptic. Nor can I find an example on the internet.</p>
"
2602583,66549,2010-04-08T18:49:53Z,65,Geometric Mean: is there a built-in?,"<p>i tried to find a built-in for geometric mean but couldn't.</p>

<p>(Obviously a built-in isn't going to save me any time while working in the shell, nor do i suspect there's any difference in accuracy; for scripts i try to use built-ins as often as possible, where the (cumulative) performance gain is often noticeable.</p>

<p>In case there isn't one (which i doubt is the case) here's mine. </p>

<pre><code>gm_mean = function(a){prod(a)^(1/length(a))}
</code></pre>
"
2603184,58082,2010-04-08T20:23:37Z,41,R: Pass by reference,"<p>Can you pass by reference with ""R"" ?
for example, in the following code:</p>

<pre><code>setClass(""MyClass"",
    representation(
    name=""character""
    ))


instance1 &lt;-new(""MyClass"",name=""Hello1"")
instance2 &lt;-new(""MyClass"",name=""Hello2"")

array = c(instance1,instance2)

instance1
array

instance1@name=""World!""

instance1
array
</code></pre>

<p>the output is</p>

<pre><code>&gt; instance1
An object of class “MyClass”
Slot ""name"":
[1] ""World!""

&gt; array
[[1]]
An object of class “MyClass”
Slot ""name"":
[1] ""Hello1""


[[2]]
An object of class “MyClass”
Slot ""name"":
[1] ""Hello2""
</code></pre>

<p>but I wish it was</p>

<pre><code>&gt; instance1
An object of class “MyClass”
Slot ""name"":
[1] ""World!""

&gt; array
[[1]]
An object of class “MyClass”
Slot ""name"":
[1] ""World!""


[[2]]
An object of class “MyClass”
Slot ""name"":
[1] ""Hello2""
</code></pre>

<p>is it possible ?</p>

<p>Thanks</p>

<p>Pierre</p>
"
2607221,279497,2010-04-09T12:11:15Z,2,R: ESS shell.exec speed,"<p>I am using ESS in Windows XP. I have noticed that <code>shell.exec</code> is much slower with ESS than with RGui (the problem occurs when I try <code>help(ls)</code> for example, the help is displayed much faster in RGui, I tracked it down and it is due to <code>shell.exec</code>). Is there any reason for this? How can I fix it? My default browser is Firefox.</p>
"
2609647,207258,2010-04-09T17:51:31Z,1,R: How to pass a list of selection expressions (strings in this case) to the subset function?,"<p>Here is some example data:</p>

<pre><code>data = data.frame(series = c(""1a"", ""1b"", ""1e""), reading = c(0.1, 0.4, 0.6))

&gt; data
  series reading
1     1a     0.1
2     1b     0.4
3     1e     0.6
</code></pre>

<p>Which I can pull out selective single rows using subset:</p>

<pre><code>&gt; subset (data, series == ""1a"")
  series reading
1     1a     0.1
</code></pre>

<p>And pull out multiple rows using a logical OR</p>

<pre><code>&gt; subset (data, series == ""1a"" | series  == ""1e"")
  series reading
1     1a     0.1
3     1e     0.6
</code></pre>

<p>But if I have a long list of series expressions, this gets really annoying to input, so I'd prefer to define them in a better way, something like this: </p>

<pre><code>series_you_want = c(""1a"", ""1e"")  (although even this sucks a little)
</code></pre>

<p>and be able to do something like this,  </p>

<pre><code>subset (data, series == series_you_want)
</code></pre>

<p>The above obviously fails, I'm just not sure what the best way to do this is? </p>
"
2610521,313145,2010-04-09T20:00:31Z,5,R: Calculating deltas in a timeseries,"<p>I have a timeseries of samples in R:</p>

<pre><code>&gt; str(d)
 'data.frame': 5 obs. of  3 variables:
 $ date: POSIXct, format: ""2010-03-04 20:47:00"" ""2010-03-04 21:47:00"" ...
 $ x   : num  0 10 11 15.2 20
 $ y   : num  0 5 7.5 8.4 12.5
&gt; d
                 date    x    y
1 2010-03-04 20:47:00  0.0  0.0
2 2010-03-04 21:47:00 10.0  5.0
3 2010-03-04 22:47:00 11.0  7.5
4 2010-03-04 23:47:00 15.2  8.4
5 2010-03-05 00:47:00 20.0 12.5
</code></pre>

<p>In this example samples for x and y are taken every hour (but the time delta is not fix). 
The x and y values are always growing (like a milage counter in a car). I need the deltas,
how much was the growth in between, something like this:</p>

<pre><code>1 2010-03-04 20:47:00  0.0  0.0
2 2010-03-04 21:47:00 10.0  5.0
3 2010-03-04 22:47:00 1.0   2.5
4 2010-03-04 23:47:00 4.2   0.9
5 2010-03-05 00:47:00 4.8   4.1
</code></pre>

<p>And I also need the deltas per time (x and y delta, divided by the time - delta per hour)</p>

<p>How would I do this in R?</p>
"
2612495,207258,2010-04-10T06:27:03Z,5,R: How to remove outliers from a smoother in ggplot2?,"<p>I have the following data set that I am trying to plot with ggplot2, it is a time series of three experiments A1, B1 and C1 and each experiment had three replicates.  </p>

<p>I am trying to add a stat which detects and removes outliers before returning a smoother (mean and variance?).  I have written my own outlier function (not shown) but I expect there is already a function to do this, I just have not found it.  </p>

<p>I've looked at stat_sum_df(""median_hilow"", geom = ""smooth"") from some examples in the ggplot2 book, but I didn't understand the help doc from Hmisc to see if it removes outliers or not.  </p>

<p>Is there a function to remove outliers like this in ggplot, or where would I amend my code below to add my own function?</p>

<p>EDIT: I just saw this (<a href=""https://stackoverflow.com/questions/1444306/how-to-use-outlier-tests-in-r-code"">How to use Outlier Tests in R Code</a>) and notice that Hadley recommends using a robust method such as rlm.   I am plotting bacterial growth curves, so I don't think a linear model is best, but any advice on  other models or using or using robust models in this situation would be appreciated.</p>

<pre><code>library (ggplot2)  

data = data.frame (day = c(1,3,5,7,1,3,5,7,1,3,5,7,1,3,5,7,1,3,5,7,1,3,5,7,1,3,5,7,1,3,5,7,1,3,5,7), od = 
c(
0.1,1.0,0.5,0.7
,0.13,0.33,0.54,0.76
,0.1,0.35,0.54,0.73
,1.3,1.5,1.75,1.7
,1.3,1.3,1.0,1.6
,1.7,1.6,1.75,1.7
,2.1,2.3,2.5,2.7
,2.5,2.6,2.6,2.8
,2.3,2.5,2.8,3.8), 
series_id = c(
""A1"", ""A1"", ""A1"",""A1"",
""A1"", ""A1"", ""A1"",""A1"",
""A1"", ""A1"", ""A1"",""A1"",
""B1"", ""B1"",""B1"", ""B1"",
""B1"", ""B1"",""B1"", ""B1"",
""B1"", ""B1"",""B1"", ""B1"",
""C1"",""C1"", ""C1"", ""C1"",
""C1"",""C1"", ""C1"", ""C1"",
""C1"",""C1"", ""C1"", ""C1""),
replicate = c(
""A1.1"",""A1.1"",""A1.1"",""A1.1"",
""A1.2"",""A1.2"",""A1.2"",""A1.2"",
""A1.3"",""A1.3"",""A1.3"",""A1.3"",
""B1.1"",""B1.1"",""B1.1"",""B1.1"",
""B1.2"",""B1.2"",""B1.2"",""B1.2"",
""B1.3"",""B1.3"",""B1.3"",""B1.3"",
""C1.1"",""C1.1"",""C1.1"",""C1.1"",
""C1.2"",""C1.2"",""C1.2"",""C1.2"",
""C1.3"",""C1.3"",""C1.3"",""C1.3""))

&gt; data
   day   od series_id replicate
1    1 0.10        A1      A1.1
2    3 1.00        A1      A1.1
3    5 0.50        A1      A1.1
4    7 0.70        A1      A1.1
5    1 0.13        A1      A1.2
6    3 0.33        A1      A1.2
7    5 0.54        A1      A1.2
8    7 0.76        A1      A1.2
9    1 0.10        A1      A1.3
10   3 0.35        A1      A1.3
11   5 0.54        A1      A1.3
12   7 0.73        A1      A1.3
13   1 1.30        B1      B1.1
... etc...
</code></pre>

<p>This is what I have so far and is working nicely, but outliers are not removed:</p>

<pre><code>r &lt;- ggplot(data = data, aes(x = day, y = od))
r + geom_point(aes(group = replicate, color = series_id)) + # add points
   geom_line(aes(group = replicate, color = series_id)) + # add lines
   geom_smooth(aes(group = series_id))  # add smoother, average of each replicate
</code></pre>

<p>EDIT: I just added two charts below showing examples of the outlier problems that I'm having from the real data rather than the example data above.</p>

<p>The first plots shows series p26s4 and around day 32 something really weird went on in two of the replicates, showing 2 outliers.</p>

<p>The second plots shows series p22s5 and on day 18, something weird went on with the reading that day, likely machine error I think.</p>

<p>At the moment I am eye-balling the data, to check that the growth curves look OK.  After taking Hadley's advice and setting family = ""symmetric"", I am confident that the loess smoother does a decent job of ignoring the outliers.</p>

<p><a href=""http://img696.imageshack.us/img696/8743/p26s4loess.png"" rel=""nofollow noreferrer"">p26s4 shows around day 32 something really weird went on in two of the replicates, showing 2 outliers http://img696.imageshack.us/img696/8743/p26s4loess.png</a>
<a href=""http://img521.imageshack.us/img521/8083/p22s5loess.png"" rel=""nofollow noreferrer"">p22s5 shows that on day 18, something weird went on with the reading that day, likely machine error I think http://img521.imageshack.us/img521/8083/p22s5loess.png</a></p>

<p>@Peter/@hadley, the next thing I'd like to do is to try and fit a logistic, gompertz or richard's growth curve to this data instead of a loess and calculate the growth rate in the exponential stage.  Eventually I plan to use the grofit package in R (<a href=""http://cran.r-project.org/web/packages/grofit/index.html"" rel=""nofollow noreferrer"">http://cran.r-project.org/web/packages/grofit/index.html</a>), but for now I'd like to plot these manually using ggplot2 if possible.  If you have any pointers then it would be much appreciated.</p>
"
2613420,66549,2010-04-10T12:52:47Z,25,Handling missing/incomplete data in R--is there function to mask but not remove NAs?,"<p>As you would expect from a DSL aimed at data analysis, R handles missing/incomplete data very well, for instance:</p>

<p>Many R functions have an <strong><em>na.rm</em></strong> flag that when set to <em>TRUE</em>, remove the NAs:</p>

<pre><code>&gt;&gt;&gt; v = mean( c(5, NA, 6, 12, NA, 87, 9, NA, 43, 67), na.rm=T)
&gt;&gt;&gt; v
      (5, 6, 12, 87, 9, 43, 67)
</code></pre>

<p>But if you want to deal with NAs <em>before</em> the function call, you need to do something like this:</p>

<p>to remove each 'NA' from a vector:</p>

<pre><code>vx = vx[!is.na(a)]
</code></pre>

<p>to remove each 'NA' from a vector and replace it w/ a '0':</p>

<pre><code>ifelse(is.na(vx), 0, vx)
</code></pre>

<p>to remove entire each row that contains 'NA' from a data frame:</p>

<pre><code>dfx = dfx[complete.cases(dfx),]
</code></pre>

<p>All of these functions permanently <em>remove</em> 'NA' or rows with an 'NA' in them.</p>

<p>Sometimes this isn't quite what you want though--making an 'NA'-excised copy of the data frame might be necessary for the next step in the workflow but in subsequent steps you often want those rows back (e.g., to calculate a column-wise statistic for a column that has missing rows caused by a prior call to 'complete cases' yet that column has no 'NA' values in it).</p>

<p>to be as clear as possible about what i'm looking for: python/numpy has a class, <em>masked array</em>, with a <em>mask</em> method, which lets you <strong>conceal</strong>--but not remove--NAs during a function call. Is there an analogous function in R?</p>
"
2614400,313564,2010-04-10T18:17:24Z,8,Accessing Arbitrary Columns from an R Data Frame using with(),"<p>Suppose that I have a data frame with a column whose name is stored in a variable. Accessing this column using the variable is easy using bracket notation:</p>

<pre><code>df &lt;- data.frame(A = rep(1, 10), B = rep(2, 10))
column.name &lt;- 'B'

df[,column.name]
</code></pre>

<p>But it is not obvious how to access an arbitrary column using a call to <code>with()</code>. The naive approach</p>

<pre><code>with(df, column.name)
</code></pre>

<p>effectively evaluates <code>column.name</code> in the caller's environment. How can I delay evaluation sufficiently that <code>with()</code> will provide the same results that brackets give?</p>
"
2614767,235349,2010-04-10T20:02:10Z,9,Using R to Analyze Balance Sheets and Income Statements,"<p>I am interested in analyzing balance sheets and income statements using R. I have seen that there are R packages that pull information from Yahoo and Google Finance, but all the examples I have seen concern historical stock price information. Is there a way I can pull historical information from balance sheets and income statements using R?</p>
"
2614949,256662,2010-04-10T20:58:16Z,3,How to analyse Wikipedia article's data base with R?,"<p>This is a ""big"" question, that I don't know how to start, so I hope some of you can give me a direction.  And if this is not a ""good"" question, I will close the thread with an apology.</p>

<p>I wish to go through the database of Wikipedia (let's say the English one), and do statistics.  For example, I am interested in how many active editors (which should be defined) Wikipedia had at each point of time (let's say in the last 2 years).</p>

<p>I don't know how to build such a database, how to access it, how to know which types of data it has and so on.  So my questions are:</p>

<ol>
<li>What tools do I need for this (besides basic R) ? MySQL on my computer? RODBC database connection?</li>
<li>How do you start planning for such a project?</li>
</ol>
"
2615128,296155,2010-04-10T21:46:20Z,130,Where does R store packages?,"<p>The <code>install.packages()</code> function in R is the automatic unzipping utility that gets and install packages in R.</p>

<ol>
<li><p>How do I find out what directory R has chosen to store packages?</p></li>
<li><p>How can I change the directory in which R stores and accesses packages?</p></li>
</ol>
"
2615907,742,2010-04-11T03:05:37Z,5,Operate on pairs of rows of a data frame,"<p>I've got a data frame in R, and I'd like to perform a calculation on all pairs of rows. Is there a simpler way to do this than using a nested for loop?</p>

<p>To make this concrete, consider a data frame with ten rows, and I want to calculate the difference of scores between all (45) possible pairs. </p>

<pre><code>&gt; data.frame(ID=1:10,Score=4*10:1)
   ID Score
1   1    40
2   2    36
3   3    32
4   4    28
5   5    24
6   6    20
7   7    16
8   8    12
9   9     8
10 10     4
</code></pre>

<p>I know I could do this calculation with a nested for loop, but is there a better (more R-ish) way to do it? </p>
"
2617600,313967,2010-04-11T15:54:39Z,103,Importing data from a JSON file into R,"<p>Is there a way to import data from a JSON file into R? More specifically, the file is an array of JSON objects with string fields, objects, and arrays. The RJSON Package isn't very clear on how to deal with this <a href=""http://cran.r-project.org/web/packages/rjson/rjson.pdf"" rel=""noreferrer"">http://cran.r-project.org/web/packages/rjson/rjson.pdf</a>.</p>
"
2617842,271844,2010-04-11T16:59:25Z,3,Error when trying to create a faceted plot in ggplot2,"<p>I am trying to make a faceted plot in ggplot2 of the coefficients on the regressors from 
two linear models with the same predictors. The data frame I constructed is this:  </p>

<pre><code>r.together&gt;
          reg         coef        se      y
1  (Intercept)  5.068608671 0.6990873 Labels
2     goodTRUE  0.310575129 0.5228815 Labels
3    indiaTRUE -1.196868662 0.5192330 Labels
4    moneyTRUE -0.586451273 0.6011257 Labels
5     maleTRUE -0.157618168 0.5332040 Labels
6  (Intercept)  4.225580743 0.6010509  Bonus
7     goodTRUE  1.272760149 0.4524954  Bonus
8    indiaTRUE -0.829588862 0.4492838  Bonus
9    moneyTRUE -0.003571476 0.5175601  Bonus
10    maleTRUE  0.977011737 0.4602726  Bonus
</code></pre>

<p>The ""y"" column is a label for the model, reg are the regressors and coef and se are what you would think. </p>

<p>I want to plot:</p>

<pre><code>g &lt;- qplot(reg, coef, facets=.~y, data = r.together) + coord_flip() 
</code></pre>

<p>But when I try to display the plot, I get: </p>

<pre><code>&gt; print(g)
Error in names(df) &lt;- output : 
'names' attribute [2] must be the same length as the vector [1]
</code></pre>

<p>What's strange is that </p>

<pre><code>qplot(reg, coef, colour=y, data = r.together) + coord_flip()
</code></pre>

<p>plots as you would expect. </p>
"
2618248,57458,2010-04-11T18:48:48Z,13,How can I make the output from tapply() into a data.frame,"<p>I have a data.frame in R that looks like this:</p>

<pre><code>      score    rms  template   aln_id       description
1  -261.410  4.951 2f22A.pdb  2F22A_1 S_00001_0000002_0
2  -231.987 21.813 1wb9A.pdb  1WB9A_4 S_00002_0000002_0
3  -263.722  4.903 2f22A.pdb  2F22A_3 S_00003_0000002_0
4  -269.681 17.732 1wbbA.pdb  1WBBA_6 S_00004_0000002_0
5  -258.621 19.098 1rxqA.pdb  1RXQA_3 S_00005_0000002_0
6  -246.805  6.889 1rxqA.pdb 1RXQA_15 S_00006_0000002_0
7  -281.300 16.262 1wbdA.pdb 1WBDA_11 S_00007_0000002_0
8  -271.666  4.193 2f22A.pdb  2F22A_2 S_00008_0000002_0
9  -277.964 13.066 1wb9A.pdb  1WB9A_5 S_00009_0000002_0
10 -261.024 17.153 1yy9A.pdb  1YY9A_2 S_00001_0000003_0
</code></pre>

<p>I can calculate summary statistics on the data.frame like this:</p>

<pre><code>&gt; tapply( d$score, d$template, mean )
1rxqA.pdb 1wb9A.pdb 1wbbA.pdb 1wbdA.pdb 1yy9A.pdb 2f22A.pdb 
-252.7130 -254.9755 -269.6810 -281.3000 -261.0240 -265.5993 
</code></pre>

<p>Is there an easy way that I coerce this output back into a data.frame? I'd like for it to have these two columns:</p>

<pre><code>d$template
mean
</code></pre>

<p>I love tapply, but right now I'm cutting and pasting the results from tapply into a text file and hacking it up a bit to get the summary statistics that I want with appropriate names. This feels very wrong, and I'd like to do something better!</p>
"
2619069,314121,2010-04-11T23:09:39Z,2,"R programming: creating a stacked bar graph, with variable colors for each stacked bar","<p>I'm trying to create a stacked bar graph with variable coloring in each stacked bar; that is, one bar has say blue on top of red, the next one red on top of purple, etc. I also wanted to preserve the ability to stack graphs. Thank you so much guys.</p>

<p>Adam</p>
"
2619346,207258,2010-04-12T00:51:56Z,2,"R: ggplot2, why does my legend show faded colors?","<p>Why is my legend faded in these examples below?  Notice how the colours in the legend are not as vivid as the colours in the plot:  </p>

<pre><code>library(ggplot2)
r &lt;- ggplot(data = diamonds, aes(x = carat, y = price, color = cut, group = cut))
r + geom_smooth() #(left)
r + geom_smooth(size = 2)  #(right)
</code></pre>

<p><a href=""http://img64.imageshack.us/img64/1340/screenshot20100411at549.png"" rel=""nofollow noreferrer"">alt text http://img64.imageshack.us/img64/1340/screenshot20100411at549.png</a></p>

<p>EDIT: added a close-up
<a href=""http://img163.imageshack.us/img163/4715/screenshot20100411at725.png"" rel=""nofollow noreferrer"">alt text http://img163.imageshack.us/img163/4715/screenshot20100411at725.png</a></p>
"
2619400,207258,2010-04-12T01:16:19Z,3,"R: ggplot2, how to add a number of layers to a plot at once to reduce code","<pre><code>library(ggplot2)
</code></pre>

<p>This code produces a nice looking plot:</p>

<pre><code>qplot(cty, hwy, data = mpg, colour = displ) +
scale_y_log2() + 
labs(x=""x axis"") + 
labs(y=""y axis"") +
opts(title = ""my title"")
</code></pre>

<p>But I want to setup variables to try and to reduce code repetition:</p>

<pre><code>log_scale &lt;- scale_y_log2()
xscale &lt;-   labs(x=""x axis"")
yscale &lt;-   labs(y=""y axis"") 
title &lt;- opts(title = ""my title"")
my_scales &lt;- c(log_scale, xscale, yscale, title) 
# make a variable to hold the scale info changes above
</code></pre>

<p>So that I can do this and add a bunch of things at the same time: </p>

<pre><code>qplot(cty, hwy, data = mpg, colour = displ) + my_scales  
# add these to your plot.   
</code></pre>

<p>but I get this error: </p>

<pre><code>Error in object$class : $ operator is invalid for atomic vectors
</code></pre>

<p>I realize that the things going into my_scales need to be layers / different types of objects, but I don't see what they should be.</p>
"
2619543,239923,2010-04-12T02:23:53Z,27,How do I obtain the machine epsilon in R?,"<p>Is there a constant that stores the machine epsilon in R?</p>
"
2619618,742,2010-04-12T02:48:08Z,16,"Convert a ""by"" object to a data frame in R","<p>I'm using the ""by"" function in R to chop up a data frame and apply a function to different parts, like this:</p>

<pre><code>pairwise.compare &lt;- function(x) {
Nright &lt;- ...
Nwrong &lt;- ...
Ntied &lt;- ...
return(c(Nright=Nright, Nwrong=Nwrong, Ntied=Ntied))
}
Z.by &lt;- by(rankings, INDICES=list(rankings$Rater, rankings$Class), FUN=pairwise.compare)
</code></pre>

<p>The result (Z.by) looks something like this:</p>

<pre><code>: 4 
: 357 
Nright Nwrong Ntied
     3      0     0
------------------------------------------------------------
: 8 
: 357 
NULL
------------------------------------------------------------
: 10 
: 470 
Nright Nwrong Ntied
     3      4     1 
------------------------------------------------------------ 
: 11 
: 470 
Nright Nwrong Ntied
    12      4     1
</code></pre>

<p>What I would like is to have this result converted into a data frame (with the NULL entries not present) so it looks like this:</p>

<pre><code>  Rater Class Nright Nwrong Ntied
1     4   357      3      0     0
2    10   470      3      4     1
3    11   470     12      4     1
</code></pre>

<p>How do I do that? </p>
"
2624164,160794,2010-04-12T17:53:47Z,5,How to Profile R Code that Includes SNOW Cluster,"<p>I have a nested loop that I'm using foreach, DoSNOW, and a SNOW socket cluster to solve for. How should I go about profiling the code to make sure I'm not doing something grossly inefficient.</p>

<p>Also is there anyway to measure the data flows going between the master and nodes in a Snow cluster?</p>

<p>Thanks,</p>

<p>James</p>
"
2624688,299077,2010-04-12T19:15:01Z,8,2-way anova on unbalanced dataset,"<p>Is <code>aov</code> appropriate for unbalanced datasets. According to help <code>...provides a wrapper to lm for fitting linear models to balanced or unbalanced experimental designs</code>. But later on it says <code>aov is designed for balanced designs, and the results can be hard to interpret without balance</code>.</p>

<p>How should I perform a 2-way anova on an unbalanced dataset in R? </p>

<p>I would like to reproduce the different results for type I and type III sum of squares of <code>SAS</code> output (when using <code>proc glm</code>). I remember we were using <code>type III sum of squares</code> for unbalanced datasets.</p>

<p>Thank you in advance.</p>
"
2624791,295037,2010-04-12T19:28:45Z,10,How to create a vector of lists in R?,"<p>I have a list (tmpList), which looks like this:</p>

<pre><code>$op
[1] ""empty""

$termset
$termset$field
[1] ""entry""

$termset[[2]]
$termset[[2]]$explode
[1] ""Y""
</code></pre>

<p>This is a list with a list inside.
If I add this list to a vector</p>

<pre><code>theOneVector = c(theOneVector, tmpList)
</code></pre>

<p>Now the resulting vector is of the length 2, because the first entry (""op"") of the list is separated from the tmpList.
Is it possible to append the complete tmpList into this vector?
<br>
I already tried it with</p>

<pre><code>theOneVector = c(theOneVector, list(tmpList))
</code></pre>

<p>which gives a vector with the length of 1, but it is very cumbersome to access the elements of the list with this extra list around the list. (Too much list in one sentence I think.)<br></p>

<p></p>

<p>Any help would be appreciated,<br>
Martin</p>
"
2626236,302378,2010-04-13T00:14:16Z,15,Changing ylim (axis limits) drops data falling outside range. How can this be prevented?,"<pre><code>df &lt;- data.frame(age=c(10,10,20,20,25,25,25),veg=c(0,1,0,1,1,0,1))
g=ggplot(data=df,aes(x=age,y=veg))
g=g+stat_summary(fun.y=mean,geom=""point"")
</code></pre>

<p>Points reflect mean of veg at each age, which is what I expected and want to preserve after changing axis limits with the command below.</p>

<pre><code>g=g+ylim(0.2,1)
</code></pre>

<p>Changing axis limits with the above command unfortunately causes veg==0 subset to be dropped from the data, yielding </p>

<blockquote>
  <p>""Warning message: Removed 4 rows containing missing values (stat_summary)""</p>
</blockquote>

<p>This is bad because now the data plot (stat_summary mean) omits the veg==0 points. How can this be prevented? I simply want to avoid showing the empty part of the plot- the ordinate from 0 to .2, but not drop the associated data from the stat_summary calculation.</p>
"
2626567,315062,2010-04-13T02:17:18Z,16,Collapsing data frame by selecting one row per group,"<p>I'm trying to collapse a data frame by removing all but one row from each group of rows with identical values in a particular column. In other words, the first row from each group.</p>

<p>For example, I'd like to convert this</p>

<pre><code>&gt; d = data.frame(x=c(1,1,2,4),y=c(10,11,12,13),z=c(20,19,18,17))
&gt; d
  x  y  z
1 1 10 20
2 1 11 19
3 2 12 18
4 4 13 17
</code></pre>

<p>Into this:</p>

<pre><code>    x  y  z
1   1 11 19
2   2 12 18
3   4 13 17
</code></pre>

<p>I'm using aggregate to do this currently, but the performance is unacceptable with more data:</p>

<pre><code>&gt; d.ordered = d[order(-d$y),]
&gt; aggregate(d.ordered,by=list(key=d.ordered$x),FUN=function(x){x[1]})
</code></pre>

<p>I've tried split/unsplit with the same function argument as here, but unsplit complains about duplicate row numbers.</p>

<p>Is rle a possibility? Is there an R idiom to convert rle's length vector into the indices of the rows that start each run, which I can then use to pluck those rows out of the data frame?</p>
"
2627431,313558,2010-04-13T06:31:06Z,0,"Reading numeric Date value from CSV file to data.frame in ""R""","<pre><code>&gt; D &lt;- read.csv(""sample1.csv"", header = FALSE, sep = "","")

&gt; D
        V1     V2     V3     V4
1 20100316 109825 352120 239065
2 20100317 108625 352020 239000
3 20100318 109125 352324 241065

&gt; D[,1]
[1] 20100316 20100317 20100318
</code></pre>

<p>In the above example how do I get the data in <code>D[,1]</code> to be read, and stored as date values: 2010-03-16, 2010-03-17, 2010-03-18? I have lots of data files in this format.</p>

<p>TIA,</p>
"
2628621,256662,2010-04-13T10:04:46Z,89,"How do you use ""<<-"" (scoping assignment) in R?","<p>I just finished reading about <a href=""http://cran.r-project.org/doc/manuals/R-intro.html#Scope"" rel=""noreferrer"">scoping in the R intro</a>, and am very curious about the <code>&lt;&lt;-</code> assignment.</p>

<p>The manual showed one (very interesting) example for <code>&lt;&lt;-</code>, which I feel I understood. What I am still missing is the context of when this can be useful.</p>

<p>So what I would love to read from you are examples (or links to examples) on when the use of <code>&lt;&lt;-</code> can be interesting/useful.  What might be the dangers of using it (it looks easy to loose track of), and any tips you might feel like sharing.</p>
"
2628680,74658,2010-04-13T10:14:35Z,7,How to Import a CSV file containing multiple sections into R?,"<p>I want to import the contents of a csv file into R, the csv file contains multiple sections of data vertically, seperated by blank lines and asterisks.  For example</p>

<pre><code>********************************************************
* SAMPLE DATA ******************************************
********************************************************
Name, DOB, Sex
Rod, 1/1/1970, M
Jane, 5/7/1980, F
Freddy, 9.12,1965, M

*******************************************************
*  Income Data ****************************************
*******************************************************
Name, Income
Rod, 10000
Jane, 15000
Freddy, 7500
</code></pre>

<p>I would like to import this into R as two seperate dataframes.  Currently I'm manually cutting the csv file up into smaller files, but I think I could do it using read.csv and the skip and nrows settings of read.csv, If I could work out where the secion breaks are.</p>

<p>This gives me a logical TRUE for every blank line</p>

<pre><code>ifelse(readLines(""DATA.csv"")=="""",TRUE,FALSE)
</code></pre>

<p>I'm hoping someone has already solved this problem.</p>
"
2630333,415635,2010-04-13T14:29:07Z,2,Choropleth mapping issue in R,"<p>EDIT: I have realized the source of my problem. I only have count information for the counties which I have data for, which is less than the number of counties in the area I'm plotting against.</p>

<p>It stands to reason that the problem lines of code are here:</p>

<pre><code>mapnames &lt;- map(""county"",plot=FALSE)[4]$names
colorsmatched &lt;- d$colorBuckets [na.omit(match(mapnames ,d$stcon))]
</code></pre>

<p>Does anyone have advice on how to generate a vector of the appropriate length that would match the # of counties in NY, NJ, CT, and PA from the maps library? I want to merge the count data I have and include zeros for the counties I don't have information on.</p>

<p>I am trying to follow the tutorial described here: <a href=""http://www.thisisthegreenroom.com/2009/choropleths-in-r/"" rel=""nofollow noreferrer"">http://www.thisisthegreenroom.com/2009/choropleths-in-r/</a></p>

<p>The below code executes, but it is either not matching my dataset with the maps_counties data properly, or it isn't plotting it in the order I would expect. For example, the resulting areas for the greater NYC area show no density while random counties in PA show the highest density.</p>

<p>The general format of my data table is:</p>

<pre><code>county state count
fairfield connecticut 17
hartford connecticut 6
litchfield connecticut 3
new haven connecticut 12
...
...
westchester new york 70
yates new york 1
luzerne pennsylvania 1
</code></pre>

<p>Note this data is in order by state and then county and includes data for CT, NJ, NY, &amp; PA. </p>

<p>First, I read in my data set:</p>

<pre><code>library(maps)
library(RColorBrewer)
d &lt;- read.table(""gissum.txt"", sep=""\t"", header=TRUE)

#Concatenate state and county info to match maps library
d$stcon &lt;- paste(d$state, d$county, sep="","")

#Color bins
colors = brewer.pal(5, ""PuBu"")
d$colorBuckets &lt;- as.factor(as.numeric(cut(d$count,c(0,10,20,30,40,50,300))))
</code></pre>

<p>Here is my matching</p>

<pre><code>mapnames &lt;- map(""county"",plot=FALSE)[4]$names
colorsmatched &lt;- d$colorBuckets [na.omit(match(mapnames ,d$stcon))]
</code></pre>

<p>Plotting:</p>

<pre><code>map(""county""
  ,c(""new york"",""new jersey"", ""connecticut"", ""pennsylvania"")
  ,col = colors[d$colorBuckets[na.omit(match(mapnames ,d$stcon))]]
  ,fill = TRUE
  ,resolution = 0
  ,lty = 0
  ,lwd= 0.5
)
map(""state""
  ,c(""new york"",""new jersey"", ""connecticut"", ""pennsylvania"")
  ,col = ""black""
  ,fill=FALSE
  ,add=TRUE
  ,lty=1
  ,lwd=2
)

map(""county""
   ,c(""new york"",""new jersey"", ""connecticut"", ""pennsylvania"")
   ,col = ""black""
   ,fill=FALSE
   ,add=TRUE
  , lty=1
  , lwd=.5
)
title(main=""Respondent Home ZIP Codes by County"")
</code></pre>

<p>I am sure I am missing something basic re: the order in which the maps function plots items - but I can't seem to figure it out. Thanks for the help. Please let me know if you need any more information.</p>
"
2630541,270572,2010-04-13T14:54:03Z,5,"R: getting ""inside"" environments","<p>Given an <code>environment</code> object <code>e</code>:</p>

<pre><code>&gt; e
&lt;environment: 0x10f0a6e98&gt;
&gt; class(e)
[1] ""environment""
</code></pre>

<p>How do you access the variables inside the environment?</p>

<p>Just in case you're curious, I have found myself with this <code>environment</code> object. I didn't make it, a package in Bioconductor made it. You can make it, too, using these commands:</p>

<pre><code>library('GEOquery')
eset &lt;- getGEO(""GSE4142"")[[1]]
e &lt;- assayData(eset)
</code></pre>
"
2631057,315640,2010-04-13T15:54:19Z,0,Change elements of a vector,"<p>Say I have a vector which has thousands of elements. What is the R code necessary if I want to make the elements at indices between 100-200 become 0?</p>

<p>Additionally how would I count the length between two different values, for example if I want  to know the length of time when the 'share price' is between 30-40?</p>
"
2631141,315664,2010-04-13T16:05:49Z,0,Manipulate conditional statement using regex in R,"<p>I am trying to manipulate a conditional string outputted from SAS into the right format for a conditional statement in R.  Here is an example of the conditional outputted from SAS:</p>

<pre><code>. &lt; var1_a&lt;=80 and var2_a&gt;50.8
</code></pre>

<p>I've written a function that handles some of the transformation necessary:</p>

<pre><code>conditonalsub &lt;- function(x) {
subnew &lt;- gsub(""&lt;="", "" &lt;= "", x)
subnew &lt;- gsub(""&gt;="", "" &gt;= "", subnew)
subnew &lt;- gsub(""&gt;"", "" &gt; "", subnew)
subnew &lt;- gsub(""and"", ""&amp;"", subnew)
subnew &lt;- gsub(""\\.\\s"", ""NA "", subnew)
return(subnew)
</code></pre>

<p>which produces the following string:</p>

<pre><code>NA &lt; var1_a &lt;= 80 &amp; var2_a &gt; 50.8
</code></pre>

<p>I am using these conditional statements to subset the observations of a data frame.  So in this example I want R to select all observations with var1_a values that are either missing or less than or equal to 80 AND have var2_a greater than 50.8.  How can I modify the above function so that I get a conditional statement that is able to take missing values like the var1_a portion of the conditional statement above?  My guess is the format of the new conditional statement would look something like this?</p>

<pre><code>(var1_a == NA | var1_a &lt;= 80) &amp; (var2_a &gt; 50.8) 
</code></pre>
"
2631780,207258,2010-04-13T17:35:54Z,13,"R: ggplot2, can I set the plot title to wrap around and shrink the text to fit the plot?","<pre><code>library(ggplot2)

my_title = ""This is a really long title of a plot that I want to nicely wrap \n and fit onto the plot without having to manually add the backslash n, but at the moment it does not""

r &lt;- ggplot(data = cars, aes(x = speed, y = dist))
r + geom_smooth() + #(left) 
opts(title = my_title)
</code></pre>

<p>can I set the plot title to wrap around and shrink the text to fit the plot?</p>
"
2632441,228220,2010-04-13T19:08:34Z,2,How would you program Pascal's triangle in R?,"<p>I am reading, on my own (not for HW) about programming, and one exercise involved programming Pascal's triangle in R.  My first idea was to make a list and then append things to it, but that didn't work too well.  Then I thought of starting with a vector, and making a list out of that, at the end.  Then I thought of making a matrix, and making a list out of that at the end.</p>

<p>Not sure which way to even approach this.</p>

<p>Any hints?</p>

<p>thanks</p>
"
2633595,207258,2010-04-13T22:16:00Z,3,R: How to write out a data.frame so that I can paste it into SO for others to read?,"<p>I have a large data.frame displaying some weird properties when plotted.  I'd like to ask a question about it on Stackoverflow, to do that I'd like to write the data.frame out in a form that I can paste it into SO and somebody else can easily run it and have it back into a data.frame object again.  Is there an easy way to accomplish this?  Also, if it is really long, should I use paste bin instead of directly paste it here?</p>
"
2634386,160794,2010-04-14T01:54:55Z,1,How do you save the state of a computation in while using SNOW (or Multicore or ...),"<p>From hard experience I've found it useful to occasionally save the state of my long computations to disk to start them up later if something fails.  Can I do this in a distributed computation package in R (like SNOW or multicore)?<br>
It does not seem clear how this could be done since the master is collecting things from the slaves in a non-transparent way.</p>
"
2634512,88198,2010-04-14T02:28:35Z,5,R: disentangling scopes,"<p>My question is about avoiding namespace pollution when writing modules in R.</p>

<p>Right now, in my R project, I have <code>functions1.R</code> with <code>doFoo()</code> and <code>doBar()</code>, <code>functions2.R</code> with other functions, and <code>main.R</code> with the main program in it, which first does <code>source('functions1.R'); source('functions2.R')</code>, and then calls the other functions.</p>

<p>I've been starting the program from the R GUI in Mac OS X, with <code>source('main.R')</code>.  This is fine the first time, but after that, the variables that were defined the first time through the program are defined for the second time <code>functions*.R</code> are sourced, and so the functions get a whole bunch of extra variables defined.</p>

<p>I don't want that!  I want an ""undefined variable"" error when my function uses a variable it shouldn't!  Twice this has given me very late nights of debugging!</p>

<p>So how do other people deal with this sort of problem?  Is there something like <code>source()</code>, but that makes an independent namespace that doesn't fall through to the main one?  Making a package seems like one solution, but it seems like a big pain in the butt compared to e.g. Python, where a source file is automatically a separate namespace.</p>

<p>Any tips?  Thank you!</p>
"
2635938,235630,2010-04-14T08:36:52Z,0,Creating a facet_wrap plot with ggplot2 with less annotations than plots,"<p>I am using ggplot2 to plot a figure that contains nine facets. Each facet represents the relationship between two variables and I would like to annotate the facets that display statistically significant results with a star '<em>'. This would result in only two of the nine facets with a '</em>'. However, I end up with all nine facets displaying the annotation.</p>

<p>How can I fix this?</p>

<pre><code>library(ggplot2)

Sig&lt;-c("""",""*"","""","""","""","""","""",""*"","""") # Only the second and the second to last facets should receive significance stars.
Data.annot&lt;-data.frame(unique(Aspects),Sig)

qplot(Labels,Es,data=Data1) + geom_pointrange(aes(x=Labels,y=Es,ymin=Low,ymax=Up)) + geom_hline(yintercept=0, linetype=""dashed"") + coord_flip() + facet_wrap(~Aspects, scales=""free"") + geom_text(data=Data.annot, aes(x= 0.5, y= 1, label = Sig)) + scale_y_continuous(""Correlation coefficient\n(effect size)"",limits=c(-0.5,1),breaks=c(-0.5,0,0.5,1.0)) + scale_x_discrete("""")
</code></pre>
"
2637594,291877,2010-04-14T13:13:48Z,1,prcomp error in R,"<p>I am using R. I want to run <code>prcomp</code> on a matrix. The code works fine with one installation of R on a Linux box but breaks on another identical (or so I thought) installation of R on a different Linux box. The codes are</p>

<pre><code>dataf = read.table(""~/data/testdata.txt"")
pca = prcomp(dataf)
</code></pre>

<p>The error msg on the bad instance is</p>

<pre><code>&gt; dataf = read.table(""~/data/testdata.txt"")
&gt; pca = prcomp(dataf)
Error in La.svd(x, nu, nv) :
  BLAS/LAPACK routine 'DGESDD' gave error code -12
</code></pre>

<p>Both instances of R has <code>R version 2.9.2 (2009-08-24)</code> and, as far as I can tell, all the R libraries and environmental variables are configured in identical ways as well. </p>

<p>So does anyone have suggestions on what might be wrong? What does that error code mean? (I searched internet and found nothing helpful...) Thanks a lot in advance!</p>
"
2639430,255312,2010-04-14T17:07:45Z,15,Graphing perpendicular offsets in a least squares regression plot in R,"<p>I'm interested in making a plot with a least squares regression line and line segments connecting the datapoints to the regression line as illustrated here in the graphic called perpendicular offsets:
<a href=""http://mathworld.wolfram.com/LeastSquaresFitting.html"" rel=""noreferrer"">http://mathworld.wolfram.com/LeastSquaresFitting.html</a>
<a href=""http://mathworld.wolfram.com/images/eps-gif/LeastSquaresOffsets_1000.gif"" rel=""noreferrer"">alt text http://mathworld.wolfram.com/images/eps-gif/LeastSquaresOffsets_1000.gif</a></p>

<p>I have the plot and regression line done here:</p>

<pre><code>## Dataset from http://www.apsnet.org/education/advancedplantpath/topics/RModules/doc1/04_Linear_regression.html

## Disease severity as a function of temperature

# Response variable, disease severity
diseasesev&lt;-c(1.9,3.1,3.3,4.8,5.3,6.1,6.4,7.6,9.8,12.4)

# Predictor variable, (Centigrade)
temperature&lt;-c(2,1,5,5,20,20,23,10,30,25)

## For convenience, the data may be formatted into a dataframe
severity &lt;- as.data.frame(cbind(diseasesev,temperature))

## Fit a linear model for the data and summarize the output from function lm()
severity.lm &lt;- lm(diseasesev~temperature,data=severity)

# Take a look at the data
plot(
 diseasesev~temperature,
        data=severity,
        xlab=""Temperature"",
        ylab=""% Disease Severity"",
        pch=16,
        pty=""s"",
        xlim=c(0,30),
        ylim=c(0,30)
)
abline(severity.lm,lty=1)
title(main=""Graph of % Disease Severity vs Temperature"")
</code></pre>

<p>Should I use some kind of for loop and segments <a href=""http://www.iiap.res.in/astrostat/School07/R/html/graphics/html/segments.html"" rel=""noreferrer"">http://www.iiap.res.in/astrostat/School07/R/html/graphics/html/segments.html</a> to do the perpendicular offsets?  Is there a more efficient way?  Please provide an example if possible.</p>
"
2640525,315664,2010-04-14T19:49:18Z,4,Enable scratch buffer to execute R code in emacs-ess,"<p>I have switched to using emacs-ess for my R code development and it is working great. I would like to be able to write some small R code I am using for debugging my R script into the scratch buffer, and be able to execute the scratch buffer code in the R process buffer. I've found how I could change the scratch buffer's mode to text by putting the following in the .emacs file:</p>

<pre><code>(setq initial-major-mode 'text-mode)
</code></pre>

<p>Is there a similar statement I can put in my .emacs file that would make the scratch buffer have the ess-mode?  I tried the following which results in an error about wrong type argument:</p>

<pre><code>(setq initial-major-mode 'ess-mode)
</code></pre>
"
2641653,168137,2010-04-14T23:04:18Z,60,Pass a data.frame column name to a function,"<p>I'm trying to write a function to accept a data.frame (<code>x</code>) and a <code>column</code> from it. The function performs some calculations on x and later returns another data.frame. I'm stuck on the best-practices method to pass the column name to the function.</p>

<p>The two minimal examples <code>fun1</code> and <code>fun2</code> below produce the desired result, being able to perform operations on <code>x$column</code>, using <code>max()</code> as an example. However, both rely on the seemingly (at least to me) inelegant </p>

<ol>
<li>call to <code>substitute()</code> and possibly <code>eval()</code> </li>
<li>the need to pass the column name as a character vector. </li>
</ol>

<p></p>

<pre><code>fun1 &lt;- function(x, column){
  do.call(""max"", list(substitute(x[a], list(a = column))))
}

fun2 &lt;- function(x, column){
  max(eval((substitute(x[a], list(a = column)))))
}

df &lt;- data.frame(B = rnorm(10))
fun1(df, ""B"")
fun2(df, ""B"")
</code></pre>

<p>I would like to be able to call the function as <code>fun(df, B)</code>, for example. Other options I have considered but have not tried:</p>

<ul>
<li>Pass <code>column</code> as an integer of the column number. I think this would avoid <code>substitute()</code>. Ideally, the function could accept either.</li>
<li><code>with(x, get(column))</code>, but, even if it works, I think this would still require <code>substitute</code> </li>
<li>Make use of <code>formula()</code> and <code>match.call()</code>, neither of which I have much experience with.</li>
</ul>

<p><em>Subquestion</em>: Is <code>do.call()</code> preferred over <code>eval()</code>?</p>
"
2642783,140823,2010-04-15T04:43:10Z,2,Summarising grouped records in a dataframe in R,"<p>I have a data frame in R that looks like this:</p>

<pre><code>&gt; TimeOffset, Source, Length 
&gt; 0         1           1500
&gt; 0.1       1           1000    
&gt; 0.2       1           50
&gt; 0.4       2           25
&gt; 0.6       2           3
&gt; 1.1       1           1500
&gt; 1.4       1           18
&gt; 1.6       2           2500
&gt; 1.9       2           18
&gt; 2.1       1           37
&gt; ...
</code></pre>

<p>and I want to convert it to</p>

<pre><code>&gt; TimeOffset, Source, Length
&gt; 0.2         1       2550
&gt; 0.6         2       28
&gt; 1.4         1       1518
&gt; 1.9         2       2518
&gt; ...
</code></pre>

<p>Trying to put this into English, I want to group consecutive records with the same 'Source' together, then printing out a single record per group showing the highest time offset in that group, the source, and the sum of the lengths in that group.</p>

<p>The TimeOffset values will always increase.</p>

<p>I suspect this is possible in R, but I really don't know where to start.  In a pinch I could export the data frame out and do it in e.g. Python, but I'd prefer to stay within R if possible.</p>

<p>Thanks in advance for any assistance you can provide</p>
"
2643719,78912,2010-04-15T08:23:32Z,1,find contiguous stretches of equal data in a vector,"<p>I have a numeric vector, it contains patches of elements that are repeating, something like:</p>

<pre><code>R&gt; data &lt;- c(1,1,1,2,2,2,3,3,2,2,2,2,2,3,3,1,1,1,1,1)
R&gt; data
 [1] 1 1 1 2 2 2 3 3 2 2 2 2 2 3 3 1 1 1 1 1
R&gt; 
</code></pre>

<p>I need to extract contiguous patches of elements equals to a specific value...  but I'm only interested in the patch around a specific position.  so, my input is: (1) the numeric vector, (2) the desired value, (3) the position.  I want to return a logic vector indicating which positions satisfy the request.</p>

<p>if at that position the data does not equal the value, I return all <code>FALSE</code>.</p>

<p>possible outcomes that are not all <code>F</code> would be:</p>

<pre><code> [1] 1 1 1 2 2 2 3 3 2 2 2 2 2 3 3 1 1 1 1 1

 [1] T T T F F F F F F F F F F F F F F F F F
 [2] F F F T T T F F F F F F F F F F F F F F
 [3] F F F F F F T T F F F F F F F F F F F F
 [4] F F F F F F F F T T T T T F F F F F F F
 [5] F F F F F F F F F F F F F T T F F F F F
 [6] F F F F F F F F F F F F F F F T T T T T
</code></pre>
"
2643939,162154,2010-04-15T08:59:52Z,69,Remove columns from dataframe where ALL values are NA,"<p>I'm having trouble with a data frame and couldn't really resolve that issue myself:<br>
The <b>dataframe</b> has arbitrary <b>properties as columns</b> and <b>each row</b> represents one <b>data set</b>.<p>
The question is:<br>
How to <b>get rid of columns where for <i>ALL</i> rows the value is NA</b>?</p>
"
2645578,140823,2010-04-15T13:20:27Z,2,Summarising grouped records in a dataframe in R (...again),"<p>(I tried to ask this question earlier today, but later realised I over-simplified the question; the answers I received were correct, but I couldn't use them because of my over-simplification of the problem in the original question.  Here's my 2nd attempt...)</p>

<p>I have a data frame in R that looks like:</p>

<pre><code>""Timestamp"", ""Source"", ""Target"", ""Length"", ""Content""
0.1        , P1      , P2      , 5       , ""ABCDE""
0.2        , P1      , P2      , 3       , ""HIJ""
0.4        , P1      , P2      , 4       , ""PQRS""
0.5        , P2      , P1      , 2       , ""ZY""
0.9        , P2      , P1      , 4       , ""SRQP""
1.1        , P1      , P2      , 1       , ""B""
1.6        , P1      , P2      , 3       , ""DEF""
2.0        , P2      , P1      , 3       , ""IJK""
...
</code></pre>

<p>and I want to convert this to:</p>

<pre><code>""StartTime"", ""EndTime"", ""Duration"", ""Source"", ""Target"", ""Length"", ""Content""
0.1        , 0.4      , 0.3       , P1      , P2      , 12      , ""ABCDEHIJPQRS""
0.5        , 0.9      , 0.4       , P2      , P1      , 6       , ""ZYSRQP""
1.1        , 1.6      , 0.5       , P1      , P2      , 4       , ""BDEF""
...
</code></pre>

<p>Trying to put this into English, I want to group consecutive records with the same 'Source' and 'Target' together, then print out a single record per group showing the StartTime, EndTime &amp; Duration (=EndTime-StartTime) for that group, along with the sum of the Lengths for that group, and a concatenation of the Content (which will all be strings) in that group.</p>

<p>The TimeOffset values will always increase throughout the data frame.</p>

<p>I had a look at melt/recast and have a feeling that it could be used to solve the problem, but couldn't get my head around the documentation.  I suspect it's possible to do this within R, but I really don't know where to start. In a pinch I could export the data frame out and do it in e.g. Python, but I'd prefer to stay within R if possible.</p>

<p>Thanks in advance for any assistance you can provide</p>
"
2646402,143377,2010-04-15T14:55:53Z,3,Using functions and environments,"<p>Following the recent discussions here (e.g. <a href=""https://stackoverflow.com/questions/2628621/how-do-you-use-scoping-assignment-in-r"">1</a>, <a href=""https://stackoverflow.com/questions/2630541/r-getting-inside-environments"">2</a> ) I am now using environments in some of my code. My question is, how do I create functions that modify environments according to its arguments? For example:</p>

<pre><code>y &lt;- new.env()
with(y, x &lt;- 1)
f &lt;- function(env,z) {
    with(env, x+z)
}
f(y,z=1)
</code></pre>

<p>throws</p>

<pre><code>Error in eval(expr, envir, enclos) : object 'z' not found
</code></pre>

<p>I am using environments to keep concurrently two sets of simulations apart (without refactoring my code, which I wrote for a single set of experiments). </p>
"
2647639,163809,2010-04-15T17:36:23Z,8,Create categorical variable in R based on range,"<p>I have a dataframe with a column of integers that I would like to use as a reference to make a new categorical variable.  I want to divide the variable into three groups and set the ranges myself (ie 0-5, 6-10, etc).  I tried <code>cut</code> but that divides the variable into groups based on a normal distribution and my data is right skewed.  I have also tried to use if/then statements but this outputs a true/false value and I would like to keep my original variable.  I am sure that there is a simple way to do this but I cannot seem to figure it out.  Any advice on a simple way to do this quickly?</p>

<p>I had something in mind like this:</p>

<pre><code>x   x.range
3   0-5
4   0-5
6   6-10
12  11-15
</code></pre>
"
2651497,258334,2010-04-16T08:05:12Z,1,Calculating Growth-Rates by applying log-differences,"<p>I am trying to transform my data.frame by calculating the <code>log-differences</code> of each column
and controlling for the rows <code>id</code>. So <strong>basically I like to calculate the growth rates for each id's variable</strong>.
So here is a random df with an id column, a time period colum p and three variable columns:</p>

<pre><code>df &lt;- data.frame (id = c(""a"",""a"",""a"",""c"",""c"",""d"",""d"",""d"",""d"",""d""),
                  p = c(1,2,3,1,2,1,2,3,4,5),
                  var1 = rnorm(10, 5),
                  var2 = rnorm(10, 5),
                  var3 = rnorm(10, 5)
                  )
df
     id p     var1     var2     var3
1     a 1 5.375797 4.110324 5.773473
2     a 2 4.574700 6.541862 6.116153
3     a 3 3.029428 4.931924 5.631847
4     c 1 5.375855 4.181034 5.756510
5     c 2 5.067131 6.053009 6.746442
6     d 1 3.846438 4.515268 6.920389
7     d 2 4.910792 5.525340 4.625942
8     d 3 6.410238 5.138040 7.404533
9     d 4 4.637469 3.522542 3.661668
10    d 5 5.519138 4.599829 5.566892
</code></pre>

<p>Now I have written a function which does exactly what I want BUT I had to take a detour which is possibly unnecessary and can be removed. However, somehow I am not able to locate
the shortcut.
Here is the function and the output for the posted data frame:</p>

<pre><code>fct.logDiff &lt;- function (df) {
df.log &lt;- dlply (df, ""code"", function(x) data.frame (p = x$p, log(x[, -c(1,2)])))
list.nalog &lt;- llply (df.log, function(x) data.frame (p = x$p, rbind(NA, sapply(x[,-1], diff))))
ldply (list.nalog, data.frame)
}

 fct.logDiff(df)
     id p        var1        var2        var3
1     a 1          NA          NA          NA
2     a 2 -0.16136569  0.46472004  0.05765945
3     a 3 -0.41216720 -0.28249264 -0.08249587
4     c 1          NA          NA          NA
5     c 2 -0.05914281  0.36999681  0.15868378
6     d 1          NA          NA          NA
7     d 2  0.24428771  0.20188025 -0.40279188
8     d 3  0.26646102 -0.07267311  0.47041227
9     d 4 -0.32372771 -0.37748866 -0.70417351
10    d 5  0.17405309  0.26683625  0.41891802
</code></pre>

<p>The trouble is due to the added <code>NA</code>-rows. I don't want to collapse the frame and reduce it, which would be automatically done by the <code>diff()</code> function. So I had 10 rows in my original frame and am keeping the same amount of rows after the transformation. In order to keep the same length I had to add some <code>NAs</code>. I have taken a detour by transforming the data.frame into a list, add the <code>NAs</code> to each id's first line, and afterwards transform the list back into a data.frame. That looks tedious. </p>

<p>Any ideas to avoid the data.frame-list-data.frame class transformation and optimize the function?</p>
"
2653035,415635,2010-04-16T12:52:55Z,2,ca plotting text attributes,"<p>Does anyone know of a way to control the font size/color/weight of the row and column names when plotting a correspondence plot with the ca package?</p>

<p>The following code will produce a very nice looking chart, though if there were more attributes (very heavy, super heavy, something more than super heavy) or more classes of workers (peons, underlings, etc) then the graph will get a little cluttered and hard to tell what was what.</p>

<p>It would be nice if you could list all the attributes in a separate color than the categories of workers.</p>

<pre><code>library(ca)
data(""smoke"")

plot(ca(smoke)
  , map = ""symmetric""
  , what =c(""active"",""active"")
  , mass = c(T,T)
  , contrib = ""absolute""
  , col = c(""red"",""blue"")
  , pch = c(15,17,15,17)
  , labels = c(2,2)
  , arrows = c(T,F)
)
</code></pre>

<p>Alternatively, does anyone know if there is a way to reproduce something along these lines with ggplot2? I didn't find anything on the website that seemed comparable, but I don't know much about the package.</p>

<p>Thanks,
-Chase</p>
"
2654397,168139,2010-04-16T15:59:17Z,5,How safe am I signing into Google Spreadsheets with yeroon.net/ggplot2,"<p>I am impressed by what I have seen of <a href=""http://yeroon.net/ggplot2/"" rel=""noreferrer"">yeroon.net/ggplot2</a> which is a web interface for Hadley Wickham's R package ggplot2. I want to try it out on my own data. The part that has me very excited is that one can use data stored in one's own Google spreadsheet as the data. One just signs into their Google Account so that yeroon.net/ggplot2 can access the spreadsheet list. I have been hesitant to do it. If I sign in whilst on yeroon.net am I handing over my username and password to a third party? It would not be wise of me to divulge my google password to third parties since Google is fast becoming my repository of everything. </p>

<p>How do I know if Jeroon's application is using <a href=""http://code.google.com/apis/accounts/docs/AuthForInstalledApps.html"" rel=""noreferrer"">ClientLogin</a> or <a href=""http://code.google.com/apis/accounts/docs/OAuthForInstalledApps.html#"" rel=""noreferrer"">OAuth</a>? My understanding is very basic and may be wrong but nevertheless here it is. OAuth would be better since it does not actually pass the password onto the third party application. </p>
"
2656529,207258,2010-04-16T22:59:15Z,5,Update a package and keep it from reverting to the original,"<p>I want to upgrade the package ggplot2:</p>

<pre><code>library(ggplot2)
packageDescription(""ggplot2"")[""Version""]
&gt; 0.8.3
</code></pre>

<p>But the current version is 0.8.7.</p>

<p>I tried update.packages(), which seemed to work OK.  But it still returned older version 0.8.3.</p>

<p>So I downloaded and installed the package source from Cran, which says 0.8.7 in the download page.
I then install it via the GUI menu in R.  It returns </p>

<pre><code>** building package indices ...
* DONE (ggplot2)
</code></pre>

<p>I then run:</p>

<pre><code>packageDescription(""ggplot2"")[""Version""]
&gt; 0.8.3
</code></pre>

<p>And still I have the older version!</p>

<p>I don't know why this is not working, what's more I had already come across this problem before and solved it (I can't remember exactly what) but now it has gone back to the older version!  What's the easiest way to keep packages like this updated automatically and not have them refer back to older packages?</p>
"
2656731,318976,2010-04-17T00:22:21Z,3,What is the best way to run a loop of regressions in R?,"<p>Assume that I have sources of data X and Y that are indexable, say matrices. And I want to run a set of independent regressions and store the result. My initial approach would be</p>

<pre><code>results = matrix(nrow=nrow(X), ncol=(2))
for(i in 1:ncol(X)) {
        matrix[i,] = coefficients(lm(Y[i,] ~ X[i,])

}
</code></pre>

<p>But, loops are bad, so I could do it with lapply as</p>

<pre><code>out &lt;- lapply(1:nrow(X), function(i) { coefficients(lm(Y[i,] ~ X[i,])) } )
</code></pre>

<p>Is there a better way to do this?</p>
"
2656792,318976,2010-04-17T00:48:39Z,10,can lapply not modify variables in a higher scope,"<p>I often want to do essentially the following:</p>

<pre><code>mat &lt;- matrix(0,nrow=10,ncol=1)
lapply(1:10, function(i) { mat[i,] &lt;- rnorm(1,mean=i)})
</code></pre>

<p>But, I would expect that mat would have 10 random numbers in it, but rather it has 0. (I am not worried about the rnorm part. Clearly there is a right way to do that. I am worry about affecting mat from within an anonymous function of lapply) Can I not affect matrix mat from inside lapply? Why not? Is there a scoping rule of R that is blocking this?</p>
"
2657434,319081,2010-04-17T05:57:34Z,3,length between 2 values,"<p>In R, what is the most efficient way to count the length between 2 values. for example, i have vector x , which are all randomly choose from 1 to 100, how can i find out the length between the first""2"" and first""40"", 
x=(1,2,<strong>3,4,5,6,7</strong>,40,1,2,<strong>3,21,4,1,23,4</strong>,43,23,4,12,3,43,5,36,3,45,12,31,3,4,23,41,23,5,53,45,3,7,6,36)
for this vector, the answer should be 5 and 6</p>
"
2658338,183828,2010-04-17T12:33:58Z,0,The internal implementation of R's dataset,"<p>I am trying to build a data processing program. Currently I use a double matrix to represent the data table, each row is an instance, each column represents a feature. I also have an extra vector as the target value for each instance, it is of double type for regression, it is of integer for classification. </p>

<p>I want to make it more general. I am wondering what kind of structure R uses to store a dataset, i.e. the internal implementation in R. </p>
"
2658752,319262,2010-04-17T14:53:03Z,1,Matrix multiplication in java,"<p>I wanted to do matrix multiplication in Java, and the speed needs to be very good.</p>

<p>I was thinking of calling R through java to achieve this.</p>

<p>I had a couple of Qs though:</p>

<ol>
<li><p>Is calling R using Java a good idea? If yes, are there any code samples that can be shared?</p></li>
<li><p>What are the other ways that can be considered to do matrix multiplication in Java?</p></li>
</ol>

<h3>Update:</h3>

<p>My colleague who quit the firm was a C# programmer, who was forced to write Java code that involved matrix multiplication.</p>

<p>-- He has written his own DataTable class in Java, in order to be able to </p>

<p>a) create indexes to sort and join with other DataTables</p>

<p>b) matrix multiplication.</p>

<p>So, I want to essentially clean up the code, and thought using something like R within Java will help me focus on business logic rather than sorting, joining, matrix multiplication, etc.</p>
"
2659308,318976,2010-04-17T17:27:34Z,0,"editing Rnw in Emacs, gets confused if in math mode or not","<p>When editing .Rnw files with emacs, sometimes it gets confused as to if I am in math mode or not. Then, the syntax highlighting gets messed up, and C-f-i inserts \textit{} and \mathit{} opposite to how it normally should. Is seems like there is some bool storing the state of math mode or not, and it gets inadvertently flipped. Is there a way I can manually flip it back?</p>
"
2659337,319337,2010-04-17T17:34:33Z,2,regressions with many nested categorical covariates,"<p>I have a few hundred thousand measurements where the dependent
variable is a probability, and would like to use logistic regression.
However, the covariates I have are all categorical, and worse, are all
nested. By this I mean that if a certain measurement has ""city -
Phoenix"" then obviously it is certain to have ""state - Arizona"" and
""country - U.S."" I have four such factors - the most granular has
some 20k levels, but if need be I could do without that one, I think.
I also have a few non-nested categorical covariates (only four or so,
with maybe three different levels each).
What I am most interested in
is prediction - given a new observation in some city, I would like to
know the relevant probability/dependent variable. I am not interested
as much in the related inferential machinery - standard deviations,
etc - at least as of now. I am hoping I can afford to be sloppy.
However, I would love to have that information unless it requires
methods that are more computationally expensive.
Does anyone have any advice on how to attack this? I have looked into
mixed effects, but am not sure it is what I am looking for.</p>
"
2659609,162832,2010-04-17T19:03:01Z,2,"add several variables to dataframe, based on vector","<p>I am sure this is easy - but I can't figure it out right now.</p>

<p>Basically: I have a long vector of variables:</p>

<pre><code>names &lt;- c(""first"",""second"", ""third"")
</code></pre>

<p>I have some data, and I now need to add the variables. I could do:</p>

<pre><code>data$first &lt;- NA
</code></pre>

<p>But since I have a long list, and I would like an automated solution. <strong>This doesn't work</strong>.</p>

<pre><code>for (i in 1:length(names)) (paste(""data$"", names[i],sep="""") &lt;- NA)
</code></pre>

<p>The reason I want this, is that I need to vertically merge to dataframes, where one doesn't have all the variables it should have.</p>

<p>Thanks in advance</p>
"
2661402,58394,2010-04-18T06:57:44Z,28,"Given a set of random numbers drawn from a continuous univariate distribution, find the distribution","<p>Given a set of real numbers drawn from a unknown continuous univariate distribution (let's say is is one of beta, Cauchy, chi-square, exponential, F, gamma, Laplace, log-normal, normal, Pareto, Student's t, uniform and Weibull) ..</p>

<pre><code>x &lt;- c(7.7495976,12.1007857,5.8663491,9.9137894,11.3822335,7.4406175,8.6997212,9.4456074,11.8370711,6.4251469,9.3597039,8.7625700,10.3171063,8.0983110,11.7564283,11.7583461,7.3760516,14.5713098,14.3289690,12.8436795,7.1834376,12.2530520,8.9362235,11.8964391,5.4378782,7.8083060,0.1356370,14.9341847,6.8625143,9.0285873,10.2251998,10.3348486,7.7518365,2.8757024,9.2676577,10.6879259,11.7623207,14.0745924,9.3478318,7.6788852,9.7491924,14.9409955,11.0297640,8.5541261,8.6129808,9.2192320,12.3507414,8.9156903,11.6892831,10.2571897,11.1673235,10.5883741,8.2396129,7.3505839,3.4437525,8.3660082,10.5779227,8.5382177,13.6647484,9.0712034,4.1090454,13.4238382,16.1965937,14.2539891,14.6498816,6.9662381,12.3282141,10.9628268,10.8859495,11.6742822,12.0469869,9.1764119,4.2324549,12.6665295,10.7467579,6.4153703,10.3090806,12.0267082,9.2375369,13.8011813,13.0457227,14.0147179,6.9224316,7.1164269,10.7577799,8.0965571,13.3371566,14.6997535,8.8248384,8.0634834,10.2226001,8.5112199,8.1701147,8.1970784,10.5432878,5.9603389,6.6287037,13.3417943,3.1122822,10.4241008,11.4281520,9.4647825,10.5480176,14.2357819,9.4220778,9.7012755,10.9251006,5.3073151,10.8228672,12.0936384,8.5146227,8.4115865,7.7244591,7.2801474,7.3412563,4.5385940,7.8822841,12.7327836,11.5509252,13.0300876,10.0458138,11.3862972,11.3644867,12.6585391,5.8567192,9.8764841,7.6447620,8.7806429,9.2089114,9.1961781,7.2400724,14.7575303,8.6874476,4.6276043,14.0592724,10.3519708,8.2222625,8.7710501,8.5724602,11.4279232,9.6734741,12.1972490,10.1250074,4.8571327,8.0019245,9.8036286,17.7386541,10.8935339,4.7258581,14.2681556,7.4236474,9.4520797,9.2066764,7.7805317,0.4938756,13.0306624,8.0225287,11.1801478,8.7481126,16.5873192,6.0404763,9.5674318,10.8915023,13.2473727,5.5877557,1.4474869,10.9504070,10.8879749,10.7765684,9.1501230,11.0798794,10.0961631,9.5913525,14.0855129,7.3918195,16.6303158,9.1436327,11.9848346,11.4691572,16.0934172,13.1431040,8.2455786,10.7388841,13.7107201,9.6223990,7.6363513,9.5731838,7.0150930,14.1341888,7.5834625,13.8362695,12.9790060,10.4156690,6.4108920,6.3731019,6.3302824,8.4924571,11.2175143,11.6346609,6.0958761,12.8728176,10.2689647,9.7923411,11.3962741,7.3723701,8.1169299,9.7926014,8.7266379,10.7350973,12.7639103,7.4425159,15.9422109,9.9073852,6.2421614,5.2925668,9.9822059,13.9768971,9.3481404,6.8102106,12.6482884,9.8595946,12.8946675,6.3519119,9.2698768,4.9538608,13.8062408,14.7438135,8.5583994,12.4232260,9.4205371,13.6507205,11.7807767,10.9747222,15.9299602,10.0202244,11.9209419,12.8159324,7.0107459,7.8076222,8.0086965,14.7694984,6.4810687,6.6833260,3.9660939,16.2414479,9.3474497,10.2626126,11.7672786,10.1245905,2.3416774,9.2548226,12.3498943,9.1731074,8.6703280,3.8079927,12.0858349,11.1027140,11.9034505,11.1981903,9.5554276,11.5333311,4.1374535,7.9397446,10.6732513,5.4928081,5.9026714,7.1902350,7.3516027,9.5251792,12.8827838,8.6051567,9.9074448,4.7244414,9.4681156,17.4316786,15.0770196,7.4215510,7.2839984,8.2040354,11.2938556,12.2308244,17.2933409,5.7154747,9.9383524,7.9912142,10.2087560,13.0489301,10.2092634,11.4029668,10.3103281,10.2810316,8.9487624,14.2699307,12.8538251,10.7545354,18.0638133,7.2115769,7.4020585,7.9737234,13.1687588,13.7186238,9.6881618,4.2991770,11.4829896,8.0113006,10.0285544,8.3325591,8.8476239,9.3618137,11.0913308,10.2702207,12.0215701,11.8083744,8.1575837,10.0413629,11.7291752,13.8315537,12.4823312,13.3289096,8.5874403,9.8624401,7.0444818,13.9701389,10.0250634,14.3841966,17.4074390,13.1290358,8.3764673,7.8796107,6.4597773,12.4989708,11.3617236,5.0730931,13.5990536,9.4800716,11.1247161,12.6283343,12.5711367,10.8075848,13.2183856,12.4566869,17.0046899,9.9132293,13.8912393,10.4806343,6.7550983,18.4982020,4.6835563,4.6068688,8.4304188,7.8747286,9.4440702,12.1033704,10.7397568,12.4483258,12.0952273,9.4609549,16.1755646,13.2110564,12.5244792,14.5511670,14.9365263,6.6852081,14.6988321,9.8833093,11.1549852,14.4090081,6.2565184,8.3488705,10.8509966,7.6795679,13.5814813,10.1733942,12.1773482,4.7032686,9.9248308,17.7067155,8.2378404,12.8208154,12.7675305,9.0907063,9.5720411,4.5536981,5.2252539,10.7393508,8.1761239,7.8011878,10.8517959,12.8793471,10.1738281,9.0522516,9.7020267,8.5743543,7.1063673,9.4366173,7.5154902,9.2420952,13.7275687,8.2097051,12.4686117,8.6426135,10.6854081,14.8617929,14.2631291,11.1449327,8.4807248,5.9399190,6.7772300,7.2566033,10.3215210,9.2483564,10.8592844,13.8227188,5.8955118,6.8936159,11.4641992,8.6535466,14.1301887,10.2194653,9.3929177,11.8592296,9.3153675,10.8574024,9.5293558,14.1394531,7.1224090,5.6785198,13.1351723,7.1031658,7.6344684,8.6918016,6.8426780,8.6902514,9.9025967,6.1603559,6.3995948,6.7157089,14.9359341,13.1275476,11.2493476,10.7684760,8.5263731,5.1711855,10.2432689,6.7908688,9.2634794,5.6242460,7.7319788,13.7579540,10.5344149,11.2123002,9.5503450,11.3042249,6.6581916,13.0363709,9.0141363,6.8815546,8.6309000,9.4825677,6.9816465,9.4836443,8.5629547,12.5643187,13.2918150,4.9542483,3.8941388,12.0723769,14.6818075,6.2067566,8.6538934,11.4860264,9.6481396,12.7096758,7.8361298,12.0167492,9.2011051,6.7472607,13.5725275,15.0862343,12.5248807,10.8804527,12.7291198,7.7527975,7.8537703,10.5257599,11.2615216,5.2586963,9.3935784,4.8959811,14.9649019,9.7550081,9.0961317,3.0822901,10.4690830,11.4116176,11.8268286,9.6303294,12.6595176,10.3003485,10.6738841,7.1545388,13.1700952,8.8394611,11.7666496,5.3739818,12.5156287,10.5998309,7.9280247,11.3985509,9.3435626,9.1445783,7.5190392,10.5207065,5.5194295,14.4021779,7.9815022,7.3148241,5.0131517,12.1867856,3.4892615,14.7278153,10.0177503,9.0080577,6.2549383,11.5792232,10.0743671,4.6603495,9.1943305,10.0549778,13.3946923,11.0435648,11.9903902,7.5212459,6.9752799,9.7793759,3.0074422,9.9630136,8.2949444,14.4448033,8.8767257,10.4919437,12.8309614,11.9987884,9.4450733,7.1909711,7.7836130,12.0111407,7.8110426,8.8857522,7.2070115,6.1091037,15.5397454,12.4138856,11.0948175,10.3384724,4.0731303,11.9523302,11.7543732,8.6845056,11.3963952,9.1248950,9.8663549,14.4536098,10.5610537,9.6523570,9.9533877,10.1019772,12.0909679,12.1466894,9.8986813,14.2406526,10.1251599,13.5607593,8.3409267,7.3538062,9.2187909,8.3878572,9.6934979,6.8270478,6.9754722,14.7438670,6.2118150,4.3408116,11.4874280,12.9580969,9.5487183,10.2743684,11.2433385,14.4445854,10.3395096,5.7534609,10.5550234,10.9322053,10.2105928,11.3020951,12.9484069,6.5904212,8.4368601,11.3280691,8.6031823,7.6938566,11.3733151,12.3900593,11.7711757,11.2307516,13.4915701,10.7228153,7.3886924,8.4401787,10.2753493,8.4389663,12.1972728,10.4918743,10.6289742,10.5594228,6.7236908,11.2358099,8.5938861,12.3906280,14.4511787,7.4746119,15.8803774,2.5522927,9.6801286,8.5697501,10.8271935,13.5280438,10.6818935,13.5646711,3.5187030,10.4440143,9.8327296,9.7382627,14.1669606,6.9083257,3.8266181,13.6244062,11.0284378,9.5523319,8.9891586,9.9055215,8.3856238,8.7478998,6.6987620,14.7248918,9.2529918,10.2082195,4.9534370,9.2030317,5.2269606,8.0661516,13.1779369,5.2971835,15.0037013,7.2702621,6.9997505,9.6490126,13.9149660,10.7425870,9.7558964,12.5752855,10.5098261,20.2689637,9.8681830,7.8259004,9.4911900,9.6024895,7.6085691,12.0086596,6.6780724,8.2764670,8.9880572,15.9231426,5.9905542,13.5816388,8.9839322,9.5235545,10.1314783,13.1174616,8.1648447,12.5653484,12.4941364,10.5916275,12.7761500,9.8608664,8.1374522,10.6055768,6.5465219,11.7945966,7.0397647,4.4046833,12.4284773,0.4180241,12.0268339,10.0441325,5.3276329,8.4208769,8.5484829,9.8222639,9.4951750,9.3263556,13.7433301,10.1112279,12.3558939,10.8694158,9.7864777,5.5161601,7.0906274,14.5786803,12.9236138,8.9206195,7.0104273,5.8283839,7.6944516,6.2924265,10.0766522,10.3576597,8.5793193,11.2022858,4.9360148,6.5907700,13.0853471,9.5498965,10.8132248,7.3545704,9.3583861,10.5726301,6.8032692,9.5914570,6.1383186,7.0176580,16.8026498,6.7959168,9.2745414,7.7390857,12.5977623,8.6116698,13.6735060,10.8476068,9.6710713,10.1086791,9.6101003,11.2849373,14.3841286,10.0175111,5.9766042,9.2654916,12.3336237,11.0695365,9.4801954,6.6405542,11.7110714,9.2962742,4.5557592,7.9725970,10.3105591,9.1068024,8.1585631,14.9021906,9.2015137,15.0472571,9.1225965,13.9551835,15.1033478,10.6360240,12.0867865,15.6969704,9.5818060,8.1641150,8.2950194,8.6544478,7.9130456,8.8904450,13.9381998,8.9913977,14.0155779,6.2856039,10.7923301,8.8070441,11.2657258,10.7901363,9.1724396,6.6433443,9.5172255,12.3402514,2.7254577,12.4006210,13.2697124,10.0670987,15.3858112,8.2044828,10.7534955,7.9282064,10.9170642,12.8222748,18.2680638,9.0601854,13.2616197,7.0193571,12.2447467,5.3729936,14.8064727,10.5359554,10.4851627,11.8312380,13.3435483,10.5894537,5.0047413,7.5532502,11.9171854,12.1777692,7.6730359,5.5515027,12.3027227,10.1575062,14.8505769,9.6526219,11.2016182,10.7898901,13.6303578,12.8561220,13.3002161,9.0945849,4.9117132,8.0514791,8.3684288,4.7461608,6.3118847,14.3888758,15.8801467,11.6563489,7.9043481,6.1992280,10.4055679,6.4948166,11.8656277,3.8399970,9.5901581,8.6379262,7.4541442,7.1135626,7.9164363,9.6439593,15.6259631,7.3244170,8.4635798,12.0317526,17.1847365,12.5357554,6.0369018,12.9830581,11.2712555,12.3488084,9.3935706,8.1248854,11.4523131,9.6710694,9.5978474,15.1563587,7.5582530,10.8587757,13.5890062,10.1390991,8.1443215,16.1032757,6.5988579,9.6915113,7.6946942,10.5688193,7.9222074,6.0964578,7.0383112,11.5956154,6.6059072,13.5679685,15.1021379,10.2625096,10.2202339,15.7814051,16.3342713,6.1339245,0.9275113,15.8169582,11.0888355,7.8822788,15.2039942,9.6944328,11.7292036,11.6230714,8.4657438,7.6462181,7.1888162,8.1788400,13.7221572,12.4793501,10.4488461,8.9233659,8.9305724,7.4913262,12.5882791,10.6825315,10.8527571,12.1660301,12.4390247,13.8529219,8.5372836,11.2575812,6.4922496,9.5404721,10.7082122,11.2365487,10.2713802,14.8685632,10.7735798,10.6526134,4.8455022,8.3135583,10.8120056,7.2903999,7.0497880,4.9958942,5.9730174,9.8642732,11.5609671,10.1178216,6.6279774,9.2441754,9.9419299,13.4710469,6.0601435,8.2095239,7.9456672,12.7039825,7.4197810,9.5928275,8.2267352,2.8314614,11.5653497,6.0828073,11.3926117,10.5403929,14.9751607,11.7647580,8.2867261,10.0291522,7.7132033,6.3337642,14.6066222,11.3436587,11.2717791,10.8818323,8.0320657,6.7354041,9.1871676,13.4381778,7.4353197,8.9210043,10.2010750,11.9442048,11.0081195,4.3369520,13.2562675,15.9945674,8.7528248,14.4948086,14.3577443,6.7438382,9.1434984,15.4599419,13.1424011,7.0481925,7.4823108,10.5743730,6.4166006,11.8225244,8.9388744,10.3698150,10.3965596,13.5226492,16.0069239,6.1139247,11.0838351,9.1659242,7.9896031,10.7282936,14.2666492,13.6478802,10.6248561,15.3834373,11.5096033,14.5806570,10.7648690,5.3407430,7.7535042,7.1942866,9.8867927,12.7413156,10.8127809,8.1726772,8.3965665)
</code></pre>

<p>.. is there some easy way in R to <b>programmatically and automatically</b> find the most likely distribution and the estimated distribution parameters?</p>

<p>Please note that the distribution identification code will be part of an automated process, so manual intervention in the identification won't be possible.</p>
"
2662364,319081,2010-04-18T13:25:01Z,0,"in R, the arguments of ""for loop""","<p>Could anyone please tell me what is wrong with the R code below:</p>

<pre><code>i = 1.001
#make SAV and STO become vector
SAV = c()
STO = c()
#set the initial values for the vector
SAV[1] = 0
STO[1] = 100


for (t in 2:1000) {
if ((price[t]&gt;9.9)&amp;（price[t]&lt;10.1）&amp;(SAV[t-1]!=0))
      SAV[t]=SAV[t-1]*i 
      STO[t]=0 
}

for (t in 2:1000) {
if ((price[t]&gt;9.9)&amp;（price[t]&lt;10.1）&amp;(SAV[t-1]=0))
      STO[t] = STO [t-1]
      SAV[t] = 0
}

SAV
STO
</code></pre>

<p>What I am trying to do is to find vector for both SAV and STO.</p>
"
2664655,271844,2010-04-19T00:58:19Z,4,Sweave/R - Automatically generating an appendix that contains all the model summaries/plots/data profiles from an analysis,"<p>I like the idea of making research available at multiple levels of detail i.e., abstract for the casually curious, full text for the more interested, and finally the data and code for those working in the same area/trying to reproduce your results. In between the actual text and the data/code level, I'd like to insert another layer. Namely, I'd like to create a kind of automatically generated appendix that contains the full regression output, diagnostic plots, exploratory graphs data profiles etc. from the analysis, regardless of 
whether those plots/regressions etc. made it into the final paper.  </p>

<p>One idea I had was to write a script that would examine the .Rnw file and automatically: </p>

<ul>
<li>Profile all data sets that are loaded (sort of like the Hmisc(?) package)  </li>
<li>Summarize all regressions - i.e., run summary(model) for all models </li>
<li>Present all plots (regardless of whether they made it in the final version) </li>
</ul>

<p>The idea is to make this kind of a low-effort, push-button sort of thing as opposed to a formal appendix written like the rest of a paper. What I'm looking for is some ideas on how to do this in R in a relatively simple way. My hunch is that there is some way of going through the namespace, figuring out what something is and then dumping into a PDF. </p>

<p>Thoughts? Does something like this already exist? </p>
"
2665499,170792,2010-04-19T06:21:35Z,2,Error closing R commander when package rgl is loaded,"<pre><code>library(ca)
# Loading required package: rgl
library(Rcmdr)
# R Commander starts

# When trying to close R Commander window
Error in unloadNamespace(""rgl"") : name space 'rgl' is still used by: 'ca'
</code></pre>

<p>What is the suggested way to close R Commander in such a situation?</p>
"
2665532,57458,2010-04-19T06:30:19Z,23,Is there a good R API for accessing Google Docs?,"<p>I'm using R for data analysis, and I'm sharing some data with collaborators via Google docs. Is there a simple interface that I can use to access a R data.frame object to and from a Google Docs spreadsheet? If not, is there a similar API in other languages? </p>
"
2666799,256662,2010-04-19T11:01:40Z,2,Extracting the fitted terms in the local polynomial function of a loess (in R) (NOT predict()),"<p>How can I extract what the parameters that the loess function fitted for the polynomial function it uses, for a particular x of my data?</p>

<p>For example, in:</p>

<pre><code> cars.lo &lt;- loess(dist ~ speed, cars)
 cars.lo
</code></pre>

<p>What did it fit for when cars.lo$x == 5 ?</p>

<p><strong>Update</strong>: I want the parameters of the polynomial function, not the prediction (predict) of the loess.</p>

<p>I am asking for it to get an estimate of the slope in that point.</p>

<p>Thanks,
Tal</p>
"
2666805,302378,2010-04-19T11:02:52Z,2,Can one extract model fit parameters after a ggplot stat_smooth call?,"<p>Using stat_smooth, I can fit models to data. E.g.</p>

<pre><code>g=ggplot(tips,aes(x=tip,y=as.numeric(unclass(factor(tips$sex))-1))) +facet_grid(time~.) 
g=g+ stat_summary(fun.y=mean,geom=""point"") 
g=g+ stat_smooth(method=""glm"", family=""binomial"")
</code></pre>

<p>I would like to know the coefficients of the glm binomial fits. I could re-do the fit with dlply and get the coefficients with ldply, but I'd like to avoid such duplication.</p>

<p>Calling str(g) reveals the hierarchy of objects that ggplot creates, perhaps there's some way to get to the coefficients through that?</p>
"
2667478,319081,2010-04-19T12:49:56Z,2,"R - how can I save the value of ""print""?","<p>In R , when I use ""print"", I can see all the values, but how can I save this as a vector?
   For example, in a 'for' loop: 
   <code>for(i in 1:10)</code>, I would like the value of A , when i= 1,2,3,4..... but if I use <code>x=A</code>, it only saves the final value of A which is the value when i = 10. So, how can I save the values in print(A)?
    Additionally, I use more than one 'for' loop e.g.:</p>

<pre><code>for (i in 1:9) {
  for (k in 1:4) {
  }
}
</code></pre>

<p>Consequently, x[i]=A..does not work very well here.</p>
"
2667673,320366,2010-04-19T13:21:25Z,61,Select first 4 rows of a data.frame in R,"<p>How can I select the first 4 rows of a <code>data.frame</code>:</p>

<pre><code>              Weight Response
1   Control     59      0.0
2 Treatment     90      0.8
3 Treatment     47      0.1
4 Treamment    106      0.1
5   Control     85      0.7
6 Treatment     73      0.6
7   Control     61      0.2
</code></pre>
"
2668938,302274,2010-04-19T16:03:48Z,2,How to insert variables in R twitteR updates?,"<p>I am using the twitteR package in R to update my twitter status with results from analysis. The static tweet function works:</p>

<pre><code>library(twitteR)

sess = initSession('username','password')

tweet = tweet('I am a tweet', sess)
</code></pre>

<p>However, when I add a variable to display some specific results I get an error. </p>

<pre><code>library(twitteR)

sess = initSession('username','password')

res = c(3,5,8)
msg = cat('Results are: ', res, ', that is nice right?')

tweet = tweet(msg, sess)
</code></pre>

<p>Results in:</p>

<pre><code>Error in twFromJSON(rawToChar(out)) : 
  Error: Client must provide a 'status' parameter with a value.
</code></pre>

<p>Any suggestions are appreciated. </p>
"
2669137,319081,2010-04-19T16:35:16Z,6,"IN r, how to combine the summary together","<p>say i have 5 summary for 5 sets of data. how can i get those number out or combine the summary in to 1 rather than 5</p>

<pre><code>       V1               V2               V3               V4        
 Min.   : 670.2   Min.   : 682.3   Min.   : 690.7   Min.   : 637.6  
 1st Qu.: 739.9   1st Qu.: 737.2   1st Qu.: 707.7   1st Qu.: 690.7  
 Median : 838.6   Median : 798.6   Median : 748.3   Median : 748.3  
 Mean   : 886.7   Mean   : 871.0   Mean   : 869.6   Mean   : 865.4  
 3rd Qu.:1076.8   3rd Qu.:1027.6   3rd Qu.:1070.0   3rd Qu.: 960.8  
 Max.   :1107.8   Max.   :1109.3   Max.   :1131.3   Max.   :1289.6  
       V5        
 Min.   : 637.6  
 1st Qu.: 690.7  
 Median : 748.3  
 Mean   : 924.3  
 3rd Qu.: 960.8  
 Max.   :1584.3  
</code></pre>

<p>how can i have 1 table looks like</p>

<pre><code>        v1  v2 v3 v4 v5
  Min.   :   
 1st Qu.:   
 Median : 
 Mean   :   
 3rd Qu.:   
 Max.   :  
</code></pre>

<p>or how to save those number as vector so i can use matrix to generate a table</p>
"
2669427,270572,2010-04-19T17:18:19Z,7,rpy2: Converting a data.frame to a numpy array,"<p>I have a data.frame in R. It contains a lot of data : gene expression levels from many (125) arrays. I'd like the data in Python, due mostly to my incompetence in R and the fact that this was supposed to be a 30 minute job.</p>

<p>I would like the following code to work. To understand this code, know that the variable <code>path</code> contains the full path to my data set which, when loaded, gives me a variable called <code>immgen</code>. Know that <code>immgen</code> is an object (a Bioconductor <code>ExpressionSet</code> object) and that <code>exprs(immgen)</code> returns a data frame with 125 columns (experiments) and tens of thousands of rows (named genes). (Just in case it's not clear, this is Python code, using robjects.r to call R code)</p>

<pre><code>import numpy as np
import rpy2.robjects as robjects
# ... some code to build path
robjects.r(""load('%s')""%path) # loads immgen
e = robjects.r['data.frame'](""exprs(immgen)"")
expression_data = np.array(e)
</code></pre>

<p>This code runs, but <code>expression_data</code> is simply <code>array([[1]])</code>. </p>

<p>I'm pretty sure that <code>e</code> doesn't represent the data frame generated by <code>exprs()</code> due to things like:</p>

<pre><code>In [40]: e._get_ncol()
Out[40]: 1

In [41]: e._get_nrow()
Out[41]: 1
</code></pre>

<p>But then again who knows? Even if <code>e</code> did represent my data.frame, that it doesn't convert straight to an array would be fair enough - a data frame has more in it than an array (rownames and colnames) and so maybe life shouldn't be this easy. However I still can't work out how to perform the conversion. The documentation is a bit too terse for me, though my limited understanding of the headings in the docs implies that this should be possible.</p>

<p>Anyone any thoughts?</p>
"
2669598,320602,2010-04-19T17:44:26Z,3,Calling R Script from within C-Code,"<p>Is there a way to call an R-Script within C-Code? </p>

<p>I did find the R Api for C (chaper 6. of the 'Writing R Extensions' manual), but as far as I understood this does ""only"" allow to call the C-Implementation of R. Of cause I could call the R-Script via shell, but that's no solution for me, since this does not allow proper passing of data (at least no if I don't what to write the data into a Csv-File or something like this). </p>

<p>Is there a easy way of using the R to C parser beforehand?</p>
"
2673504,177390,2010-04-20T08:01:37Z,0,Document/Scripts management for R code,"<p>I am looking for a solution that allows me to keep a track of a multitude of R scripts that I create for various projects and purposes. Some scripts are easily tracked to specific projects, whereas others are ""convenience"" functions created to serve a set of tasks.</p>

<p>Is there a way I can create a central DB and query it to find which scripts match most appropriately?
I could create a system using a DBMS manually, but are users aware of anything in general or specific to R, that comes in the form of a software tool (maybe FOSS) ?</p>

<p>EDIT: Thank you for the responses. My current system is just a set of scripts with comments that allow me to identify their intended task. Though I use StatET with SVN, I would like a search utility along the lines of the ""sos"" package. </p>
"
2675502,296155,2010-04-20T13:38:19Z,8,What does the symbol ::: mean in R,"<p>I came across this in the following context from B. Pfaff's ""Analysis of Integrated and Cointegrated Time Series in R""</p>

<pre><code>## Impulse response analysis of SVAR A−type model 1
args (vars ::: irf.svarest) 2
irf.svara &lt;− irf (svar.A, impulse = ”y1 ” , 3
response = ”y2 ” , boot = FALSE) 4
args (vars ::: plot.varirf) 5
plot (irf.svara)
</code></pre>
"
2675517,320366,2010-04-20T13:40:21Z,2,"In R, How to add Row for Information:","<p>I'm trying to add a Row to my data.frame to spit out the average of the column.</p>

<p><strong>This is my data frame:</strong></p>

<pre><code>              Weight Response
1   Control     59      0.0
2 Treatment     90      0.8
3 Treatment     47      0.1
4 Treamment    106      0.1
5   Control     85      0.7
6 Treatment     73      0.6
7   Control     61      0.2
</code></pre>

<p><strong>I'd like it to become:</strong></p>

<pre><code>              Weight Response
1   Control     59      0.0
2 Treatment     90      0.8
3 Treatment     47      0.1
4 Treamment    106      0.1
5   Control     85      0.7
6 Treatment     73      0.6
7   Control     61      0.2
8 AVERAGES      74      0.3
</code></pre>

<p>Thanks!</p>
"
2676554,319081,2010-04-20T15:49:24Z,62,"In R, how to find the standard error of the mean?","<p>Is there any command to find the standard error of the mean in R?</p>
"
2676926,319081,2010-04-20T16:36:51Z,0,"in R, question about generate table","<pre><code>a = matrix(1:25,5,5)
B = capture.output(for (X in 1:5){
    A = c(min(a[,X]),quantile(a[,X],0.25),median(a[,X]),quantile(a[,X],0.75),max(a[,X]),mean(a[,X]),sd(a[,X])/m^(1/2),var(a[,X]))
    cat(A,""\n"")
})

matrix(B,8,5)
</code></pre>

<p>What I was trying to do is to generate a table which each column has those element in A and in that order. I try to use the matrix, but seems like it doesn't really work here. Can anyone help?</p>

<pre><code>               |  1  |  2  |  3  |  4  |  5  |
|---------------------------------------------
| min          |     |     |     |     |     |
|---------------------------------------------
| 1st quartile |     |     |     |     |     |
|---------------------------------------------
| median       |     |     |     |     |     |
|---------------------------------------------
| SEM          |     |     |     |     |     |
|---------------------------------------------
| VAR          |     |     |     |     |     |
</code></pre>

<p>The above is what I want the table to look like.</p>
"
2678141,154697,2010-04-20T19:47:55Z,39,How can I suppress the vertical gridlines in a ggplot2 plot?,"<p>I am building a bar chart for which bars suffice as indications of horizontal (x) placement, so I'd like to avoid drawing the superfluous vertical gridlines.</p>

<p>I understand how to style the minor and major gridlines in opts(), but I can't for the life of me figure out how to suppress just the vertical gridlines.</p>

<pre><code>library(ggplot2)

data &lt;- data.frame(x = 1:10, y = c(3,5,2,5,6,2,7,6,5,4))

ggplot(data, aes(x, y)) +
  geom_bar(stat = 'identity') +
  opts(
    panel.grid.major = theme_line(size = 0.5, colour = '#1391FF'),
    panel.grid.minor = theme_line(colour = NA),
    panel.background = theme_rect(colour = NA),
    axis.ticks = theme_segment(colour = NA)
  )
</code></pre>

<p>At this point, it's looking like I'm going to have to suppress all of the gridlines and then draw them back in with geom_hline(), which seems like kind of a pain (also, it's not entirely clear how I can find the tick/major gridline positions to feed to geom_hline().)</p>

<p>Any thoughts would be appreciated!</p>
"
2679193,313163,2010-04-20T22:38:26Z,63,How to name variables on the fly?,"<p>Is it possible to create new variable names on the fly?</p>

<p>I'd like to read data frames from a list into new variables with numbers at the end. Something like orca1, orca2, orca3...</p>

<p>If I try something like</p>

<pre><code>paste(""orca"",i,sep="""")=list_name[[i]]
</code></pre>

<p>I get this error</p>

<pre><code>target of assignment expands to non-language object
</code></pre>

<p>Is there another way around this?</p>
"
2679830,155406,2010-04-21T01:57:29Z,5,Connect R to Quickbooks,"<p>Has anyone connected the R package to QuickBooks?  I know there is an ODBC driver than can be bought.  Just wondering if anyone has already gone down this road.</p>

<p>Any insight will be much appreciated!</p>

<p>~ Brock</p>
"
2682144,17523,2010-04-21T10:40:18Z,22,matplotlib analog of R's `pairs`,"<p>R has a useful function <code>pairs</code> that provides nice matrix of plots of pairwise connections between variables in a data set. The resulting plot looks similar to the following figure, copied from <a href=""http://statisticsr.blogspot.com/2009/12/r-pairs-plot.html"" rel=""noreferrer"">this blog post</a>:</p>

<p><img src=""https://2.bp.blogspot.com/_xLDEmoNB_RM/SzRINMDPNbI/AAAAAAAAFDc/N5gUwj7JHWA/s640/screenshot_001.png"" alt=""pairs""></p>

<p>Is there any ready to use function based on python's matplolib? I have searched its <a href=""http://matplotlib.sourceforge.net/gallery.html"" rel=""noreferrer"">gallery</a>, but couldn't find anything that resembles what I need.  Technically, this should be a simple task, but proper handling of all the possible cases, labels, titles, etc is very tedious.</p>

<p><strong>UPDATE</strong> see below my answer with a quick and dirty approximation.</p>
"
2682514,322233,2010-04-21T11:40:44Z,0,mlbench example,"<p>I heard R is the ""de facto"" language amongst statistical software developers, and I'm giving it a try. I already know the basics, but it still looks ""weird"" to me (a C developer). I think it would be very useful to see a working example to see how a real R program is built.
I thought that an R solution for any of the mlbench problems would be optimal, because I'm already familiar with it and it would allow me to compare it to other languages, but any other ""toy problem"" example is welcome.</p>

<p>The <code>mlbench</code> package is pointed out in the answers below, but it seems that it provides only sample data and functions to generate sample data, with the exception of a generic bayes classifier. I'm searching for solutions of any of the mlbench data problems (DNA, Glass, Ionosphere, etc.). Maybe I'm missing something?</p>
"
2682629,134830,2010-04-21T12:00:43Z,6,How do you refresh the contents of an R gWidget?,"<p>I'm creating a GUI in R using <code>gWidgets</code> (more specifically <code>gWidgetstcltk</code>).  I'd like to know how to update the contents of selection-type widgets, such as <code>gdroplist</code> and <code>gtable</code>.  I currently have a rather hackish method of deleting the widget and re-creating it.  I'm sure there's a better way.</p>

<p>This simple example displays all the variables in the global environment.</p>

<pre><code>library(gWidgets)
library(gWidgetstcltk)

create.widgets &lt;- function()
{
  grp &lt;- ggroup(container = win)
  ddl &lt;- gdroplist(ls(envir = globalenv()), 
    container = grp)
  refresh &lt;- gimage(""refresh"", 
    dirname   = ""stock"",
    container = grp,
    handler   = function(h, ...)
    {
      if(exists(""grp"") &amp;&amp; !is.null(grp)) 
      {
        delete(win, grp)
      }
      create.widgets()   
    }
  )
}

win &lt;- gwindow()
create.widgets()
</code></pre>
"
2684361,74658,2010-04-21T15:38:51Z,4,Is it possible to include a Sexpr before the expression has been evaluated in Sweave / R?,"<p>I'm writing a Sweave document, and I want to include a small section that details the R and package versions, platofrms and how long ti took to evalute the doucment, however, I want to put this in the middle of the document !</p>

<p>I was using a \Sexpr{elapsed} to do this (which didn't work), but thought if I put the code printing elapsed in a chunk that evaluates at the end, I could then include the chunk half way through, which also fails.</p>

<p>My document looks something like this </p>

<pre><code>% 
\documentclass[a4paper]{article}
\usepackage[OT1]{fontenc}
\usepackage{longtable}
\usepackage{geometry}
\usepackage{Sweave}
\geometry{left=1.25in, right=1.25in, top=1in, bottom=1in}
\begin{document}

&lt;&lt;label=start, echo=FALSE, include=FALSE&gt;&gt;=
startt&lt;-proc.time()[3]
@ 
Text and Sweave Code in here
% 
This document was created on \today, with \Sexpr{print(version$version.string)} running
 on a \Sexpr{print(version$platform)} platform. It took approx sec to process.
&lt;&lt;&gt;&gt;=
    &lt;&lt;elapsed&gt;&gt;
@ 
More text and Sweave code in here
&lt;&lt;label=bye, include=FALSE, echo=FALSE&gt;&gt;= 
odbcCloseAll()
endt&lt;-proc.time()[3]
elapsedtime&lt;-as.numeric(endt-startt)
@ 
&lt;&lt;label=elapsed, include=FALSE, echo=FALSE&gt;&gt;=
print(elapsedtime)
@ 
\end{document}
</code></pre>

<p>But this doesn't seem to work (amazingly !)</p>

<p>Does anyone know how I could do this ?</p>

<p>Thanks</p>

<p>Paul.</p>
"
2684479,194742,2010-04-21T15:54:11Z,11,Explaining the forecasts from an ARIMA model,"<p>I am trying to explain to myself the forecasting result from applying an ARIMA model to a time-series dataset. The data is from the M1-Competition, the series is MNB65. I am trying to fit the data to an ARIMA(1,0,0) model and get the forecasts. I am using R. Here are some output snippets:</p>

<pre><code>&gt; arima(x, order = c(1,0,0))
Series: x 
ARIMA(1,0,0) with non-zero mean 
Call: arima(x = x, order = c(1, 0, 0)) 
Coefficients:
         ar1  intercept
      0.9421  12260.298
s.e.  0.0474    202.717

&gt; predict(arima(x, order = c(1,0,0)), n.ahead=12)
$pred
Time Series:
Start = 53 
End = 64 
Frequency = 1 
[1] 11757.39 11786.50 11813.92 11839.75 11864.09 11887.02 11908.62 11928.97 11948.15 11966.21 11983.23 11999.27
</code></pre>

<p>I have a few questions:</p>

<p>(1) How do I explain that although the dataset shows a clear downward trend, the forecast from this model trends upward. This also happens for ARIMA(2,0,0), which is the best ARIMA fit for the data using auto.arima (forecast package) and for an ARIMA(1,0,1) model.</p>

<p>(2) The intercept value for the ARIMA(1,0,0) model is 12260.298. Shouldn't the intercept satisfy the equation: C = mean * (1 - sum(AR coeffs)), in which case, the value should be 715.52. I must be missing something basic here.</p>

<p>(3) This is clearly a series with non-stationary mean. Why is an AR(2) model still selected as the best model by auto.arima? Could there be an intuitive explanation?</p>

<p>Thanks.</p>
"
2684715,270572,2010-04-21T16:24:58Z,3,R: manipulating data.frames containing strings and booleans,"<p>I have a data.frame in R; it's called <code>p</code>. Each element in the data.frame is either True or False. My variable <code>p</code> has, say, <em>m</em> rows and <em>n</em> columns. For every row there is strictly only one <code>TRUE</code> element.</p>

<p>It also has column names, which are strings. What I would like to do is the following:</p>

<ol>
<li>For every row in <code>p</code> I see a <code>TRUE</code> I would like to replace with the name of the corresponding column</li>
<li>I would then like to collapse the data.frame, which now contains <code>FALSE</code>s and column names, to a single vector, which will have <em>m</em> elements.</li>
<li>I would like to do this in an R-thonic manner, so as to continue my enlightenment in R and contribute to a world without for-loops.</li>
</ol>

<p>I can do step 1 using the following for loop:</p>

<pre><code>for (i in seq(length(colnames(p)))) {
    p[p[,i]==TRUE,i]=colnames(p)[i]
}
</code></pre>

<p>but theres's no beauty here and I have totally subscribed to this for-loops-in-R-are-probably-wrong mentality. Maybe wrong is too strong but they're certainly not great.</p>

<p>I don't really know how to do step 2. I kind of hoped that the sum of a string and <code>FALSE</code> would return the string but it doesn't. I kind of hoped I could use an OR operator of some kind but can't quite figure that out (Python responds to <code>False or 'bob'</code> with <code>'bob'</code>). Hence, yet again, I appeal to you beautiful Rstats people for help!</p>
"
2684966,154697,2010-04-21T17:02:58Z,10,How can I suppress the vertical gridlines in a ggplot2 plot while retaining the x-axis labels?,"<p>This is a follow-on from <a href=""https://stackoverflow.com/questions/2678141/how-can-i-suppress-the-vertical-gridlines-in-a-ggplot2-plot"">this question, in which I was trying to suppress the vertical gridlines</a>.</p>

<p>The solution, as provided by learnr, was to add scale_x_continuous(breaks = NA), but this had the side effect of also suppressing the x-axis labels, as well.  I am totally happy to write the labels back in by hand, but it's not clear to me how to figure out where the labels should go.</p>

<p>The other option is to suppress all gridlines (using opts( panel.grid.major = theme_blank()) or some such) and then drawing back in just the major horizontal gridlines.  Again, the problem here is how to figure out what the breaks are in the plot to supply to geom_hline().</p>

<p>So, essentially, my options are:</p>

<ol>
<li>Suppress vertical gridlines and x-axis labels (using scale_x_continuous(breaks = NA) ) and add the x-axis labels back in.</li>
<li>Suppress all gridlines (using opts( panel.grid.major = theme_blank()) ) and add the major horizontal gridlines back in using geom_hline().</li>
</ol>

<p>Here are the two options:</p>

<pre><code>library(ggplot2)

data &lt;- data.frame(x = 1:10, y = c(3,5,2,5,6,2,7,6,5,4))

# suppressing vertical gridlines and x-axis labels
# need to re-draw x-axis labels
ggplot(data, aes(x, y)) +
  geom_bar(stat = 'identity') +
  scale_x_continuous(breaks = NA) +
  opts(
    panel.grid.major = theme_line(size = 0.5, colour = '#1391FF'),
    panel.grid.minor = theme_blank(),
    panel.background = theme_blank(),
    axis.ticks = theme_blank()
  )

# suppressing all gridlines
# need to re-draw horizontal gridlines, probably with geom_hbar() 
ggplot(data, aes(x, y)) +
  geom_bar(stat = 'identity') +
  scale_x_continuous(breaks = NA) +
  opts(
    panel.grid.major = theme_blank(),
    panel.grid.minor = theme_blank(),
    panel.background = theme_blank(),
    axis.ticks = theme_blank()
  )
</code></pre>
"
2685127,322525,2010-04-21T17:25:34Z,0,How do I get confidence intervals without inverting a singular Hessian matrix in R?,"<p>I'm a student working on an epidemiology model in R, using maximum likelihood methods. I created my negative log likelihood function. It's sort of gross looking, but here it is:</p>

<pre><code>NLLdiff = function(v1, CV1, v2, CV2, st1 = (czI01 - czV01), st2 = (czI02 - czV02), st01 = czI01, st02 = czI02, tt1 = czT01, tt2 = czT02) { 
    prob1 = (1 + v1 * CV1 * tt1)^(-1/CV1)
    prob2 = ( 1 + v2 * CV2 * tt2)^(-1/CV2) 
    -(sum(dbinom(st1, st01, prob1, log = T)) + sum(dbinom(st2, st02, prob2, log = T)))
 }
</code></pre>

<p>The reason the first line looks so awful is because most of the data it takes is input there. <code>czI01</code>, for example, is already declared. I did this simply so that my later calls to the function don't all have to have awful vectors in them.</p>

<p>I then optimized for CV1, CV2, v1 and v2 using mle2 (library bbmle). That's also a bit gross looking, and looks like:</p>

<pre><code>ml.cz.diff = mle2 (NLLdiff, start=list(v1 = vguess, CV1 = cguess, v2 = vguess, CV2 = cguess), method=""L-BFGS-B"", lower = 0.0001)
</code></pre>

<p>Now, everything works fine up until here. ml.cz.diff gives me values that I can turn into a plot that reasonably fits my data. I also have several different models, and can get AICc values to compare them. However, when I try to get confidence intervals around v1, CV1, v2 and CV2 I have problems. Basically, I get a negative bound on CV1, which is impossible as it actually represents a square number in the biological model as well as some warnings.</p>

<p>Is there a better way to get confidence intervals? Or, really, a way to get confidence intervals that make sense here? </p>

<p>What I see happening is that, by coincidence, my hessian matrix is singular for some values in the optimization space. But, since I'm optimizing over 4 variables and don't have overly extensive programming knowledge, I can't come up with a good method of optimization that doesn't rely on the hessian. I have googled the problem - it suggested that my model's bad, but I'm reconstructing some work done before which suggests that my model's really not awful (the plots I make using the ml.cz.diff look like the plots of the original work). I have also read the relevant parts of the manual as well as Bolker's book <em>Ecological Models in R</em>. I have also tried different optimization methods, which resulted in a longer run time but the same errors. The ""SANN"" method didn't finish running within an hour, so I didn't wait around to see the result.</p>

<p>In a nutshell: my confidence intervals are bad.  Is there a relatively straightforward way to fix them in R?</p>

<p>My vectors are: </p>

<pre><code>czT01 = c(5, 5, 5, 5, 5, 5, 5, 25, 25, 25, 25, 25, 25, 25, 50, 50, 50, 50, 50, 50, 50)
czT02 = c(5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25, 50, 50, 50, 50, 50, 75, 75, 75, 75, 75)
czI01 = c(25, 24, 22, 22, 26, 23, 25, 25, 25, 23, 25, 18, 21, 24, 22, 23, 25, 23, 25, 25, 25)
czI02 = c(13, 16, 5, 18, 16, 13, 17, 22, 13, 15, 15, 22, 12, 12, 13, 13, 11, 19, 21, 13, 21, 18, 16, 15, 11)
czV01 = c(1, 4, 5, 5, 2, 3, 4, 11, 8, 1, 11, 12, 10, 16, 5, 15, 18, 12, 23, 13, 22)
czV02 = c(0, 3, 1, 5, 1, 6, 3, 4, 7, 12, 2, 8, 8, 5, 3, 6, 4, 6, 11, 5, 11, 1, 13, 9, 7)
</code></pre>

<p>and I get my guesses by:</p>

<pre><code>v = -log((c(czI01, czI02) - c(czV01, czV02))/c(czI01, czI02))/c(czT01, czT02)
vguess = mean(v)
cguess = var(v)/vguess^2
</code></pre>

<p>It's also possible that I'm doing something else completely wrong, but my results seem reasonable so I haven't caught it.</p>
"
2685707,271844,2010-04-21T18:52:14Z,4,Trying to keep filled bars in a faceted plot,"<p>Not sure what I'm doing wrong here. I have this plot: </p>

<pre><code>ggplot(data.PE5, aes(ybands,fill=factor(decide))) + geom_bar(position=""dodge"") 
</code></pre>

<p>which produces: 
<img src=""https://dl.dropbox.com/u/420874/colored.png""></p>

<p>Then I want to facet by a factor, creating two stacked plots w/ dodged, colored bars</p>

<pre><code>ggplot(data.PE5, aes(ybands,fill=factor(decide))) + geom_bar(position=""dodge"") + 
facet_grid(~group_label) 
</code></pre>

<p>However, I lose the factor-based coloring, which I want to keep: </p>

<p><img src=""https://dl.dropbox.com/u/420874/non_colored.png""></p>
"
2686320,74658,2010-04-21T20:28:58Z,16,How to put a newline into a column header in an xtable in R,"<p>I have a dataframe that I am putting into a <a href=""http://www.stat.uni-muenchen.de/~leisch/Sweave/"" rel=""noreferrer"">sweave</a> document using xtable, however one of my column names is quite long, and I would like to break it over two lines to save space</p>

<pre><code>calqc_table&lt;-structure(list(RUNID = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L), ANALYTEINDEX = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L), ID = structure(1:11, .Label = c(""Cal A"", ""Cal B"", ""Cal C"", 
""Cal D"", ""Cal E"", ""Cal F"", ""Cal G"", ""Cal H"", ""Cal High"", ""Cal Low"", 
""Cal Mid""), class = ""factor""), mean_conc = c(200.619459644855, 
158.264703128903, 102.469121407733, 50.3551544728544, 9.88296440865076, 
4.41727762501703, 2.53494715706024, 1.00602831741361, 199.065054555735, 
2.48063347296935, 50.1499780776199), sd_conc = c(2.3275711264554, 
NA, NA, NA, NA, NA, NA, 0.101636943231162, 0, 0, 0), nrow = c(3, 
1, 1, 1, 1, 1, 1, 3, 2, 2, 2)), .Names = c(""Identifier of the Run within the Study"", ""ANALYTEINDEX"", 
""ID"", ""mean_conc"", ""sd_conc"", ""nrow""), row.names = c(NA, -11L
), class = ""data.frame"")
calqc_xtable&lt;-xtable(calqc_table)
</code></pre>

<p>I have tried putting a newline into the name, but this didn't seem to work</p>

<pre><code>names(calqc_table)[1]&lt;-""Identifier of the \nRun within the Study""
</code></pre>

<p>Is there a way to do this ?  I have seen someone suggest using the latex function from the <a href=""http://cran.r-project.org/web/packages/Hmisc/index.html"" rel=""noreferrer"">hmisc</a> package to manually iterate over the table and write it out in latex manually, including the newline, but this seems like a bit of a faf !</p>
"
2686437,322676,2010-04-21T20:46:55Z,3,R problems using rpart with 4000 records and 13 attributes,"<p>I have attempted to email the author of this package without success,
just wondering if anybody else has experienced this.</p>

<p>I am having an using <code>rpart</code> on 4000 rows of data with 13 attributes.
I can run the same test on 300 rows of the same data with no issue.
When I run on 4000 rows, Rgui.exe runs consistently at 50% CPU and the
UI hangs; it will stay like this for at least 4-5hours if I let it
run, and never exit or become responsive.</p>

<p>here is the code I am using both on the 300 and 4000 size subset:</p>

<pre><code>train &lt;- read.csv(""input.csv"", header=T)
y &lt;- train[, 18]
x &lt;- train[, 3:17]
library(rpart)
fit &lt;- rpart(y ~ ., x)
</code></pre>

<p>Is this a known limitation of <code>rpart</code>, am I doing something wrong?
potential workarounds?</p>
"
2686438,249487,2010-04-21T20:47:01Z,4,how do you loop over a global variable in Sweave,"<p>I have a big Sweave file with a variable called ""specialty"" near the top. The rest of this file is Latex and R, and uses this variable.</p>

<p>How can I loop over various values for ""specialty""?</p>

<p>Two possibilities are:</p>

<ol>
<li>Make the file be one big loop (and convert the Latex parts to R).</li>
<li>Write a script that copies the Sweave file, replace the value of ""specialty"", and run Sweave on each copy.</li>
</ol>

<p>Can you comment on these ideas, or suggest better ones?</p>
"
2687212,255312,2010-04-21T23:21:17Z,7,Conditionally colour data points outside of confidence bands in R,"<p>I need to colour datapoints that are outside of the the confidence bands on the plot below differently from those within the bands.  Should I add a separate column to my dataset to record whether the data points are within the confidence bands?  Can you provide an example please?</p>

<p><img src=""https://lh3.ggpht.com/_NlGxmxSBXvU/S8-GODJ7j8I/AAAAAAAAAe0/2NME354m3lE/confidenceBands.jpg"" alt=""Plot with confidence bands""></p>

<h1>Example dataset:</h1>

<pre><code>## Dataset from http://www.apsnet.org/education/advancedplantpath/topics/RModules/doc1/04_Linear_regression.html

## Disease severity as a function of temperature

# Response variable, disease severity
diseasesev&lt;-c(1.9,3.1,3.3,4.8,5.3,6.1,6.4,7.6,9.8,12.4)

# Predictor variable, (Centigrade)
temperature&lt;-c(2,1,5,5,20,20,23,10,30,25)

## For convenience, the data may be formatted into a dataframe
severity &lt;- as.data.frame(cbind(diseasesev,temperature))

## Fit a linear model for the data and summarize the output from function lm()
severity.lm &lt;- lm(diseasesev~temperature,data=severity)

# Take a look at the data
plot(
  diseasesev~temperature,
  data=severity,
  xlab=""Temperature"",
  ylab=""% Disease Severity"",
  pch=16,
  pty=""s"",
  xlim=c(0,30),
  ylim=c(0,30)
)
title(main=""Graph of % Disease Severity vs Temperature"")
par(new=TRUE) # don't start a new plot

## Get datapoints predicted by best fit line and confidence bands
## at every 0.01 interval
xRange=data.frame(temperature=seq(min(temperature),max(temperature),0.01))
pred4plot &lt;- predict(
                        lm(diseasesev~temperature),
                        xRange,
                        level=0.95,
                        interval=""confidence""
                    )

## Plot lines derrived from best fit line and confidence band datapoints
matplot(
  xRange,
  pred4plot,
  lty=c(1,2,2),   #vector of line types and widths
  type=""l"",       #type of plot for each column of y
  xlim=c(0,30),
  ylim=c(0,30),
  xlab="""",
  ylab=""""
)
</code></pre>
"
2687547,143319,2010-04-22T00:53:54Z,5,What makes these two R data frames not identical?,"<p>I have two small data frames, <code>this_tx</code> and <code>last_tx</code>.  They are, in every way that I can tell, completely identical.  <code>this_tx</code> == <code>last_tx</code> results in a frame of identical dimensions, all <code>TRUE</code>.  <code>this_tx %in% last_tx</code>, two <code>TRUEs</code>.  Inspected visually, clearly identical.  But when I call</p>

<p><code>identical(this_tx, last_tx)</code></p>

<p>I get a <code>FALSE</code>.  Hilariously, even</p>

<p><code>identical(str(this_tx), str(last_tx))</code></p>

<p>will return a <code>TRUE</code>.  If I set <code>this_tx &lt;- last_tx</code>, I'll get a <code>TRUE</code>.</p>

<p>What is going on?  I don't have the deepest understanding of R's internal mechanics, but I can't find a single difference between the two data frames.  If it's relevant, the two variables in the frames are both factors - same levels, same numeric coding for the levels, both just subsets of the same original data frame.  Converting them to character vectors doesn't help.</p>

<p>Background (because I wouldn't mind help on this, either): I have records of drug treatments given to patients.  Each treatment record essentially specifies a person and a date.  A second table has a record for each drug and dose given during a particular treatment (usually, a few drugs are given each treatment).  I'm trying to identify contiguous periods during which the person was taking the same combinations of drugs at the same doses.</p>

<p>The best plan I've come up with is to check the treatments chronologically.  If the combination of drugs and doses for treatment[i] is identical to the combination at treatment[i-1], then treatment[i] is a part of the same phase as treatment[i-1].  Of course, if I can't compare drug/dose combinations, that's right out.</p>
"
2689900,320602,2010-04-22T10:16:00Z,2,Pass commands to a running R-Runtime,"<p>Is there a way to pass commands (from a shell) to an already running R-runtime/R-GUI, without copy and past.</p>

<p>So far I only know how to call R via shell with the <code>-f</code> or <code>-e</code> options, but in both cases a new R-Runtime will process the R-Script or R-Command I passed to it.</p>

<p>I rather would like to have an open R-Runtime waiting for commands passed to it via whatever connection is possible. </p>
"
2696341,215244,2010-04-23T05:08:45Z,8,multi-core processing in R on windows XP - via doMC and foreach,"<p>I'm posting this question to ask for advice on how to optimize the use of multiple processors from R on a Windows XP machine.</p>

<p>At the moment I'm creating 4 scripts (each script with e.g. for (i in 1:100) and (i in 101:200), etc) which I run in 4 different R sessions at the same time. This seems to use all the available cpu.</p>

<p>I however would like to do this a bit more efficient. One solution could be to use the ""doMC"" and the ""foreach"" package but this is not possible in R on a Windows machine.</p>

<p>e.g.</p>

<pre><code>library(""foreach"")
library(""strucchange"")
library(""doMC"") # would this be possible on a windows machine?
registerDoMC(2)  # for a computer with two cores (processors)
## Nile data with one breakpoint: the annual flows drop in 1898
## because the first Ashwan dam was built
data(""Nile"")
plot(Nile)

## F statistics indicate one breakpoint
fs.nile &lt;- Fstats(Nile ~ 1)
plot(fs.nile)
breakpoints(fs.nile)     # , hpc = ""foreach"" --&gt; It would be great to test this.
lines(breakpoints(fs.nile))
</code></pre>

<p>Any solutions or advice?</p>
"
2703517,322912,2010-04-24T06:47:15Z,2,stored values within a custom function,"<p>My program takes a data.frame and crunches the numbers. At one point, values from j-th column are multiplied by a predefined values that depends on the column name (species name, actually - it's en ecological index). So far, I've been providing these values via a second data.frame by matching column names. What would be an efficient way of integrating fixed variable values within a function? I would like my program to be as portable as possible, without the need for a second data.frame file.</p>

<p><em>EDIT</em></p>

<p>This is the function. I'm trying to improve the second line (index &lt;- read.table...) so that it would not depend on the outside source.</p>

<pre><code>macroIndex &lt;- function(obj, index) {
    index &lt;- read.table(""conv.csv"", header=T, dec="","")
    a &lt;- c()
    b &lt;- names(obj)
    for (i in 2:length(obj)) {
        obj[i] &lt;- obj[i] * index[which(index==b[i]), 2]
    }
    obj
}
</code></pre>

<p>Another solution I tried, while it may not seem pretty, it gets the job done. I use dput(index) and create a permanent object which I then insert into my function.</p>
"
2708994,162832,2010-04-25T16:46:42Z,0,ggplot geom_bar - bars too wide,"<p>I am sorry for the non-informative title. </p>

<pre><code>&gt; y=read.csv(textConnection(scan("""",sep=""\n"",what=""raw"")))
"""",""org"",""art"",""type"",""length""
""191"",""gk"",""Finish"",""short"",4
""147"",""ik"",""Attending"",""short"",7
""175"",""gl"",""Finish"",""long"",11
""192"",""il"",""Attending"",""long"",95
""144"",""gm"",""Finish"",""between"",5
""161"",""im"",""Attending"",""between"",15
""164"",""tu"",""Something"",""young"",8
""190"",""tv"",""Something"",""old"",4

&gt; decompress=function(x)x[rep(1:nrow(x),x$length),-ncol(x)]
&gt; exstatus=decompress(y)
</code></pre>

<p>and then the plot</p>

<pre><code>ggplot(exstatus, aes(x=type, fill=art))+
geom_bar(aes(y=..count../sum(..count..)),position=""dodge"")
</code></pre>

<p>The problem is that the two rightmost bars (""young"", ""old"") are too thick - ""something"" takes up the whole width - which is not what I intended. </p>

<p><a href=""http://www.imagechicken.com/uploads/1272295176088679800.png"" rel=""nofollow noreferrer"">alt text http://www.imagechicken.com/uploads/1272295176088679800.png</a></p>

<p>I am sorry that I can not explain it better. </p>
"
2710442,318976,2010-04-25T23:53:55Z,15,"In ESS/Emacs, how can I get the R process buffer to scroll to the bottom after a C-c C-j or C-c C-r","<p>In ESS when I am evaluating chunks of code in a .R file using C-c C-j or C-c C-r (to send the line or region to a running R process), how can I get the R buffer to scroll down automatically, such that after evaluating a region the cursor is at the bottom, at the prompt?</p>

<p>Thanks.</p>
"
2712121,325800,2010-04-26T08:50:17Z,3,Can ggplot2 work with R's canvas backend,"<p>Having installed canvas from here <a href=""http://www.rforge.net/canvas/files/"" rel=""nofollow noreferrer"">http://www.rforge.net/canvas/files/</a></p>

<p>I try to plot:</p>

<pre><code>&gt; canvas('test.js')
&gt; qplot(rnorm(100), geom='histogram')
stat_bin: binwidth defaulted to range/30. Use 'binwidth = x' to adjust this.
Error in grid.Call.graphics(""L_setviewport"", pvp, TRUE) : 
  Non-finite location and/or size for viewport
&gt; 
</code></pre>
"
2712421,180892,2010-04-26T09:46:43Z,134,R and version control for the solo data analyst,"<p>Many data analysts that I respect use version control.
For example: </p>

<ul>
<li><a href=""http://github.com/hadley/"" rel=""noreferrer"">http://github.com/hadley/</a></li>
<li>See comments on <a href=""http://permut.wordpress.com/2010/04/21/revision-control-statistics-bleg/"" rel=""noreferrer"">http://permut.wordpress.com/2010/04/21/revision-control-statistics-bleg/</a></li>
</ul>

<p>However, I'm evaluating whether adopting a version control system such as git would be worthwhile.</p>

<p><b>A brief overview:</b>
I'm a social scientist who uses R to analyse data for research publications.
I don't currently produce R packages.
My R code for a project typically includes a few thousand lines of code for data input, cleaning, manipulation, analyses, and output generation.
Publications are typically written using LaTeX.</p>

<p>With regards to version control there are many benefits which I have read about, yet they seem to be less relevant to the solo data analyst.</p>

<ul>
<li><b>Backup:</b> I have a backup system already in place. </li>
<li><b>Forking and rewinding:</b> I've never felt the need to do this, 
   but I can see how it could be useful (e.g., you are preparing multiple 
  journal articles based on the same dataset; you are preparing a report 
  that is updated monthly, etc)</li>
<li><b>Collaboration:</b> Most of the time I am
analysing data myself, thus, I
wouldn't get the collaboration
benefits of version control.</li>
</ul>

<p>There are also several potential costs involved with adopting version control:</p>

<ul>
<li>Time to evaluate and learn a version control system</li>
<li>A possible increase in complexity over my current file management system</li>
</ul>

<p>However, I still have the feeling that I'm missing something.
General guides on version control seem to be addressed more towards computer scientists than data analysts.</p>

<p>Thus, specifically <b>in relation to data analysts</b> in circumstances similar to those listed above:</p>

<ol>
<li>Is version control worth the effort?</li>
<li>What are the main pros and cons of adopting version control? </li>
<li>What is a good strategy for getting started with version control
 for data analysis with R (e.g., examples, workflow ideas, software, links to guides)?</li>
</ol>
"
2714851,142477,2010-04-26T15:53:24Z,3,as.data.frame of table() to summarize frequencies,"<p>In <strong>R</strong>, I'm looking for a memory-efficient way to create a summary of tabular data as follows.</p>

<p>Take for example the <code>data.frame</code> <code>foo</code> which I've used <code>table()</code> to summarize, followed by <code>as.data.frame()</code> to obtain the frequency counts.</p>

<pre><code>foo &lt;- data.frame(x= c('a', 'a', 'a', 'b', 'b', 'b'), y=c('ab', 'ac', 'ad', 'ae', 'fx', 'fy'))
bar &lt;- as.data.frame(table(foo), stringsAsFactors=F)
</code></pre>

<p>This results in the following frequency count for <code>bar</code></p>

<pre><code>   x  y Freq
1  a ab    1
2  b ab    0
3  a ac    1
4  b ac    0
5  a ad    1
6  b ad    0
7  a ae    0
8  b ae    1
9  a fx    0
10 b fx    1
11 a fy    0
12 b fy    1
</code></pre>

<p>The problem I'm running into is when there are many levels of <code>x</code> and <code>y</code>, it starts using up significant amounts of memory >64 GB.  I was wondering if there was an alternative way of doing this kind of frequency count.  As a first step, I set <code>stringsAsFactors=F</code>, however this doesn't completely solve the problem.</p>
"
2717757,296155,2010-04-26T23:46:11Z,15,How do I rename an R object?,"<p>I'm using the quantmod package to import financial series data from Yahoo.</p>

<pre><code>library(quantmod)
getSymbols(""^GSPC"")
[1] ""GSPC""
</code></pre>

<p>I'd like to change the name of object ""GSPC"" to ""SPX"". I've tried the rename function in the reshape package, but it only changes the variable names. The ""GSPC"" object has vectors GSPC.Open, GSPC.High, etc. I'd like my renaming of ""GSPC"" to ""SPX"" to also change GSPC.Open to SPX.Open and so on.</p>
"
2719295,168168,2010-04-27T06:57:51Z,1,stats::reorder vs Hmisc::reorder,"<p>I am trying to get around the strange overlap of <code>stats::reorder</code> vs <code>Hmisc::reorder</code>.</p>

<p>Without <code>Hmisc</code> loaded I get the result I want, i.e. an unordered factor:</p>

<pre><code>&gt; with(InsectSprays, reorder(spray, count, median))
 [1] A A A A A A A A A A A A B B B B B B B B B B B B C C C C C C C C C C C C D D
[39] D D D D D D D D D D E E E E E E E E E E E E F F F F F F F F F F F F
attr(,""scores"")
   A    B    C    D    E    F 
14.0 16.5  1.5  5.0  3.0 15.0 
Levels: C E D A F B
</code></pre>

<p>Now after loading <code>Hmisc</code> the result is an ordered factor:</p>

<pre><code>&gt; library(Hmisc)
Loading required package: survival
Loading required package: splines

Attaching package: 'Hmisc'

The following object(s) are masked from 'package:survival':

    untangle.specials

The following object(s) are masked from 'package:base':

    format.pval, round.POSIXt, trunc.POSIXt, units

&gt; with(InsectSprays, reorder(spray, count, median))
 [1] A A A A A A A A A A A A B B B B B B B B B B B B C C C C C C C C C C C C D D
[39] D D D D D D D D D D E E E E E E E E E E E E F F F F F F F F F F F F
Levels: C &lt; E &lt; D &lt; A &lt; F &lt; B
</code></pre>

<p>In calling <code>stats::reorder</code> directly, I now for some reason get an ordered factor.</p>

<pre><code>&gt; with(InsectSprays, stats::reorder(spray, count, median))
 [1] A A A A A A A A A A A A B B B B B B B B B B B B C C C C C C C C C C C C D D
[39] D D D D D D D D D D E E E E E E E E E E E E F F F F F F F F F F F F
Levels: C &lt; E &lt; D &lt; A &lt; F &lt; B
</code></pre>

<p>Specifying, that I would need an unordered factor results in an error suggesting that <code>stats::reorder</code> is not used?</p>

<pre><code>&gt; with(InsectSprays, stats::reorder(spray, count, median, order = FALSE))
Error in FUN(X[[1L]], ...) : unused argument(s) (order = FALSE)
</code></pre>

<p>So the question really is <strong>how do I get an unordered factor with Hmisc loaded?</strong></p>
"
2723034,245292,2010-04-27T16:30:44Z,51,Suppress one command's output in R,"<p>I'm looking to suppress the output of <strong>one</strong> command (in this case, the <code>apply</code> function).</p>

<p>Is it possible to do this without using <code>sink()</code>?  I've found the described solution below, but would like to do this in one line if possible.</p>

<p><a href=""https://stackoverflow.com/questions/2501895/how-to-suppress-output-in-r"">How to suppress output</a></p>
"
2723730,260533,2010-04-27T18:04:57Z,0,How to change the icon in the title bar in R?,"<p>I just installed R 2.11.0-x64 onto my Windows 7 Professional machine.</p>

<p>With my previous installations of R (2.10.1 32 bit was the most recent) the little icon that appeared in the title bar and in the taskbar at the bottom of windows was the R ""R.""  Now however, the icon almost looks like a small windows Task Manager.</p>

<p>I know this isn't a code issue, but it affects me as I flip between windows.</p>

<p>Is there a way to put the ""R"" icon back in there?  Would it be an R setting or a Windows setting?</p>
"
2727446,234233,2010-04-28T07:13:09Z,1,Calculating a Sample Covariance Matrix for Groups with plyr,"<p>I'm going to use the sample code from <a href=""http://gettinggeneticsdone.blogspot.com/2009/11/split-apply-and-combine-in-r-using-plyr.html"" rel=""nofollow noreferrer"">http://gettinggeneticsdone.blogspot.com/2009/11/split-apply-and-combine-in-r-using-plyr.html</a> for this example.  So, first, let's copy their example data:</p>

<pre><code>mydata=data.frame(X1=rnorm(30), X2=rnorm(30,5,2),
SNP1=c(rep(""AA"",10), rep(""Aa"",10), rep(""aa"",10)),
SNP2=c(rep(""BB"",10), rep(""Bb"",10), rep(""bb"",10)))
</code></pre>

<p>I am going to ignore SNP2 in this example and just pretend the values in SNP1 denote group membership.  So then, I may want some summary statistics about each group in SNP1: ""AA"", ""Aa"", ""aa"".</p>

<p>Then if I want to calculate the means for each variable, it makes sense (modifying their code slightly) to use:</p>

<pre><code>&gt; ddply(mydata, c(""SNP1""), function(df)
data.frame(meanX1=mean(df$X1), meanX2=mean(df$X2)))
  SNP1      meanX1   meanX2
1   aa  0.05178028 4.812302
2   Aa  0.30586206 4.820739
3   AA -0.26862500 4.856006
</code></pre>

<p>But what if I want the sample covariance matrix for each group? Ideally, I would like a 3D array, where the I have the covariance matrix for each group, and the third dimension denotes the corresponding group. I tried a modified version of the previous code and got the following results that have convinced me that I'm doing something wrong.</p>

<pre><code>&gt; daply(mydata, c(""SNP1""), function(df) cov(cbind(df$X1, df$X2)))
, ,  = 1


SNP1         1          2
  aa 1.4961210 -0.9496134
  Aa 0.8833190 -0.1640711
  AA 0.9942357 -0.9955837

, ,  = 2


SNP1          1        2
  aa -0.9496134 2.881515
  Aa -0.1640711 2.466105
  AA -0.9955837 4.938320
</code></pre>

<p>I was thinking that the dim() of the 3rd dimension would be 3, but instead, it is 2. Really this is a sliced up version of the covariance matrix for each group.  If we manually compute the sample covariance matrix for aa, we get:</p>

<pre><code>           [,1]       [,2]
[1,]  1.4961210 -0.9496134
[2,] -0.9496134  2.8815146
</code></pre>

<p>Using plyr, the following gives me what I want in list() form:</p>

<pre><code>&gt; dlply(mydata, c(""SNP1""), function(df) cov(cbind(df$X1, df$X2)))
$aa
           [,1]       [,2]
[1,]  1.4961210 -0.9496134
[2,] -0.9496134  2.8815146

$Aa
           [,1]       [,2]
[1,]  0.8833190 -0.1640711
[2,] -0.1640711  2.4661046

$AA
           [,1]       [,2]
[1,]  0.9942357 -0.9955837
[2,] -0.9955837  4.9383196

attr(,""split_type"")
[1] ""data.frame""
attr(,""split_labels"")
  SNP1
1   aa
2   Aa
3   AA
</code></pre>

<p>But like I said earlier, I would really like this in a 3D array. Any thoughts on where I went wrong with daply() or suggestions? Of course, I could typecast the list from dlply() to a 3D array, but I'd rather not do this because I will be repeating this process many times in a simulation.</p>

<p>As a side note, I found one method (<a href=""http://www.mail-archive.com/r-help@r-project.org/msg86328.html"" rel=""nofollow noreferrer"">http://www.mail-archive.com/r-help@r-project.org/msg86328.html</a>) that provides the sample covariance matrix for each group, but the outputted object is bloated. </p>

<p>Thanks in advance.</p>
"
2730490,74658,2010-04-28T14:45:32Z,6,How to include multiple tables programmatically into a Sweave document using R,"<p>I want to have a sweave document that will include a variable number of tables in.  I thought the example below would work, but it doesn't.  I want to loop over the list foo and print each element as it's own table.</p>

<pre><code>% 
\documentclass[a4paper]{article}
\usepackage[OT1]{fontenc}
\usepackage{longtable}
\usepackage{geometry}
\usepackage{Sweave}
\geometry{left=1.25in, right=1.25in, top=1in, bottom=1in}
\listfiles
\begin{document}

&lt;&lt;label=start, echo=FALSE, include=FALSE&gt;&gt;=
startt&lt;-proc.time()[3]
library(RODBC)
library(psych)
library(xtable)
library(plyr)
library(ggplot2)
options(width=80)

#Produce some example data, here I'm creating some dummy dataframes and putting them in a list
foo&lt;-list()
foo[[1]]&lt;-data.frame(GRP=c(rep(""AA"",10), rep(""Aa"",10), rep(""aa"",10)), X1=rnorm(30), X2=rnorm(30,5,2))
foo[[2]]&lt;-data.frame(GRP=c(rep(""BB"",10), rep(""bB"",10), rep(""BB"",10)), X1=rnorm(30), X2=rnorm(30,5,2))
foo[[3]]&lt;-data.frame(GRP=c(rep(""CC"",12), rep(""cc"",18)), X1=rnorm(30), X2=rnorm(30,5,2))
foo[[4]]&lt;-data.frame(GRP=c(rep(""DD"",10), rep(""Dd"",10), rep(""dd"",10)), X1=rnorm(30), X2=rnorm(30,5,2))
@ 

\title{Docuemnt to test putting a variable number of tables into a sweave Document}
\author{""Paul Hurley""}
\maketitle

\section{Text}

This document was created on \today, with \Sexpr{print(version$version.string)} running
 on a \Sexpr{print(version$platform)} platform. It took approx \input{time} sec to process.

&lt;&lt;label=test, echo=FALSE, results=tex&gt;&gt;= 
cat(""Foo"")
@ 
that was a test, so is this
&lt;&lt;label=table1test, echo=FALSE, results=tex&gt;&gt;=
print(xtable(foo[[1]]))
@ 
\newpage

\subsection{Tables}

&lt;&lt;label=Tables, echo=FALSE, results=tex&gt;&gt;=
for(i in seq(foo)){
    cat(""\n"")
    cat(paste(""Table_"",i,sep=""""))
    cat(""\n"")
    print(xtable(foo[[i]]))
    cat(""\n"")
    }
#cat(""&lt;&lt;label=endofTables&gt;&gt;= "")
@ 


&lt;&lt;label=bye, include=FALSE, echo=FALSE&gt;&gt;= 
endt&lt;-proc.time()[3]
elapsedtime&lt;-as.numeric(endt-startt)
@ 
&lt;&lt;label=elapsed, include=FALSE, echo=FALSE&gt;&gt;=
fileConn&lt;-file(""time.tex"", ""wt"") 
writeLines(as.character(elapsedtime), fileConn) 
close(fileConn) 
@ 

\end{document}
</code></pre>

<p>Here, the table1test chunk works as expected, and produced a table based on the dataframe in foo[[1]], however the loop only produces Table(underscore)1....</p>
"
2731299,197321,2010-04-28T16:20:39Z,3,Specifying column names from a list in the data.frame command,"<p>I have a list called <code>cols</code> with column names in it:</p>

<p><code>cols &lt;- c('Column1','Column2','Column3')</code></p>

<p>I'd like to reproduce this command, but with a call to the list:</p>

<p><code>data.frame(Column1=rnorm(10))</code></p>

<p>Here's what happens when I try it:</p>

<p><code>&gt; data.frame(cols[1]=rnorm(10))</code></p>

<p><code>Error: unexpected '=' in ""data.frame(I(cols[1])=""</code></p>

<p>The same thing happens if I wrap <code>cols[1]</code> in <code>I()</code> or <code>eval()</code>.</p>

<p>How can I feed that item from the vector into the <code>data.frame()</code> command?</p>

<p><strong>Update:</strong></p>

<p>For some background, I have defined a function <code>calc.means()</code> that takes a data frame and a list of variables and performs a large and complicated ddply operation, summarizing at the level specified by the variables. </p>

<p>What I'm trying to do with the <code>data.frame()</code> command is walk back up the aggregation levels to the very top, re-running <code>calc.means()</code> at each step and using <code>rbind()</code> to glue the results onto one another. I need to add dummy columns with 'All' values in order to get the rbind to work properly. </p>

<p>I'm rolling <code>cast</code>-like margin functionality into ddply, basically, and I'd like to not retype the column names for each run. Here's the full code:</p>

<pre><code>cols &lt;- c('Col1','Col2','Col3')
rbind ( calc.means(dat,cols),
    data.frame(cols[1]='All', calc.means(dat, cols[2:3])),
    data.frame(cols[1]='All', cols[2]='All', calc.means(dat, cols[3]))
)
</code></pre>
"
2731754,275455,2010-04-28T17:26:32Z,2,R substitute on expression with assignment,"<p>Why do these two cases behave differently?</p>

<pre><code>&gt;substitute(c1&lt;-100,list(c1=100))
100 &lt;- 100
</code></pre>

<p>vs</p>

<pre><code>&gt; substitute(c1=100,list(c1=100))
[1] 100
</code></pre>
"
2732397,170792,2010-04-28T19:05:41Z,6,Why the field separator character must be only one byte?,"<pre><code>data &lt;- read.delim(""C:\\test.txt"", header = FALSE, sep = ""$$$$$"")
Error in scan(file, what = """", sep = sep, quote = quote, nlines = 1, quiet = TRUE,  : 
  invalid 'sep' value: must be one byte
</code></pre>

<p>Why there is a restriction like this? Can I overcome it?</p>
"
2735537,170792,2010-04-29T07:44:27Z,3,Reading correctly (alpha)numeric fields into R,"<p>A tab-delimited text file, which is actually an export (using bcp) of a database table, is of that form (first 5 columns):</p>

<pre><code>102 1   01  e113c   3224.96     12  
102 1   01  e185    101127.25   12
102 2   01  e185    176417.90   12
102A   3    01  e185    26261.03    12
</code></pre>

<p>I tried to import it in R with a command like </p>

<pre><code>data &lt;- read.delim(""C:\\test.txt"", header = FALSE, sep = ""\t"")
</code></pre>

<p>The problem is that the 3rd column which is actually a varchar field (alphanumeric) is mistakenly read as integer (as there are no letters in the entire column) and the leading zeros disappeared. The same thing happened when I imported the data directly from the database, using odbcConnect. Again that column was read as integer.</p>

<pre><code>str(data)
$ code: int  1 1 1 1 1 1 6 1 1 8 ...
</code></pre>

<p>How can I import such a dataset in R correctly, so as to be able to safely populate that db table again, after doing some data manipulations?</p>

<p><strong>EDIT</strong></p>

<p>I did it adding the following parameter in read.delim</p>

<pre><code> colClasses = c(""factor"",""integer"",""factor"",""factor"",""numeric"",""character"",""factor"",""factor"",""factor"",""factor"",""integer"",""character"",""factor"")
</code></pre>

<ul>
<li><p>Would you suggest ""character"" or ""factor"" for varchar fields?</p></li>
<li><p>Is it ok to use ""character"" for datetime ones?</p></li>
<li><p>What should I do in order to be able to read a numeric field like this 540912.68999999994 exactly as is and not as 540912.69?</p></li>
</ul>

<p>I would like an -as automatic as possible- creation of that <code>colClasses</code> vector, depending on the datatypes defined in the relevant table's schema. </p>
"
2736631,900119,2010-04-29T10:44:07Z,1,Select values from vector using Date as index,"<p>Suppose I have a named vector, <code>bar</code>:</p>

<pre><code>bar=c()
bar[""1997-10-14""]=1
bar[""2001-10-14""]=2
bar[""2007-10-14""]=1
</code></pre>

<p>How can I select from <code>bar</code> all values for which the index is within a specific date range? So, if I look for all values between <code>""1995-01-01""</code> and <code>""2000-06-01""</code>, I should get <code>1</code>. And similarly for the period between <code>""2001-09-01""</code> and <code>""2007-11-04""</code>, I should get <code>2</code> and <code>1</code>.</p>
"
2737680,78912,2010-04-29T13:29:02Z,31,How can a test script inform R CMD check that it should emit a custom message?,"<p>I'm writing a R package (<a href=""https://r-forge.r-project.org/projects/delftfews/"" rel=""nofollow noreferrer""><code>delftfews</code></a>) here at office.  we are using <a href=""https://r-forge.r-project.org/projects/sciviews"" rel=""nofollow noreferrer""><code>svUnit</code></a> for unit testing. </p>

<p>our process for describing new functionality: we define new unit tests, initially marked as <code>DEACTIVATED</code>; one block of tests at a time we activate them and implement the function described by the tests.  almost all the time we have a small amount of DEACTIVATED tests, relative to functions that might be dropped or will be implemented.</p>

<p>my problem/question is: can I alter the <a href=""http://rwiki.sciviews.org/doku.php?id=developers:runit#another_approach_using_svunit"" rel=""nofollow noreferrer"">doSvUnit.R</a> so that <code>R CMD check pkg</code> emits a NOTE (i.e. a custom message ""NOTE"" instead of ""OK"") in case there are DEACTIVATED tests?  </p>

<p>as of now, we see only that the active tests don't give error:</p>

<pre><code>.
.
* checking for unstated dependencies in tests ... OK
* checking tests ...
  Running ‘doSvUnit.R’
 OK
* checking PDF version of manual ... OK
</code></pre>

<p>which is all right if all tests succeed, but less all right if there are skipped tests and definitely wrong if there are failing tests.  In this case, I'd actually like to see a NOTE or a WARNING like the following:</p>

<pre><code>.
.
* checking for unstated dependencies in tests ... OK
* checking tests ...
  Running ‘doSvUnit.R’
 NOTE
6 test(s) were skipped.
 WARNING
1 test(s) are failing.
* checking PDF version of manual ... OK
</code></pre>

<p>As of now, we have to open the <code>doSvUnit.Rout</code> to check the real test results.</p>

<hr>

<p>I contacted two of the maintainers at r-forge and CRAN and they pointed me to the <a href=""https://svn.r-project.org/R/trunk/"" rel=""nofollow noreferrer"">sources of R</a>, in particular the <a href=""https://svn.r-project.org/R/trunk/src/library/tools/R/testing.R"" rel=""nofollow noreferrer""><code>testing.R</code></a> script.</p>

<p>if I understand it correctly, to answer this question we need patching the <code>tools</code> package: </p>

<ul>
<li>scripts in the tests directory are called using a <code>system</code> call,</li>
<li>output (stdout and stderr) go to one single file,</li>
<li>there are two possible outcomes: <strong>ok</strong> or <strong>not ok</strong>,</li>
</ul>

<p>so I opened a <a href=""https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14702"" rel=""nofollow noreferrer"">change request</a> on R, proposing something like bit-coding the return status, bit-0 for ERROR (as it is now), bit-1 for WARNING, bit-2 for NOTE.  </p>

<p>with my modification, it would be easy producing this output:</p>

<pre><code>.
.
* checking for unstated dependencies in tests ... OK
* checking tests ...
  Running ‘doSvUnit.R’
 NOTE - please check doSvUnit.Rout.
 WARNING - please check doSvUnit.Rout.
* checking PDF version of manual ... OK
</code></pre>

<hr>

<p>Brian Ripley replied ""There are however several packages with properly written unit tests
that do signal as required. Please do take this discussion elsewhere: R-bugs is not the place to ask
questions."" and closed the change request.</p>

<hr>

<p>anybody has hints?</p>
"
2738322,249487,2010-04-29T14:52:39Z,7,"What is a simple way to combine two Emacs major modes, or to change an existing mode?","<p>In Emacs, I'm working with a file that is a hybrid of two languages.</p>

<p><strong>Question 1: Is there a simple way to write a major mode file that combines two major modes?</strong></p>

<p>Details:</p>

<ul>
<li><p>The language is called ""brew"" (not the ""BREW"" of ""Binary Runtime Environment for Wireless"").</p></li>
<li><p>brew is made up of the languages R and Latex, whose modes are R-mode and latex-mode.</p></li>
<li><p>The R code appears between the tags &lt;% and %>. Everything else is Latex.</p></li>
<li><p>How can I write a brew-mode.el file? (Or is one already available?)</p></li>
</ul>

<p>One idea, which I got from this <a href=""http://mail-archives.apache.org/mod_mbox/perl-modperl/200002.mbox/%3CNDBBIDIMBKMLMLLCGCNAEEFPCBAA.jreid@ocireland.com%3E"" rel=""nofollow noreferrer"">posting</a>, is to use Latex mode, and treat the code of the form  &lt;% ... %> as a comment.</p>
"
2740004,183988,2010-04-29T19:00:45Z,2,Is there an RUnit checkException for warning()?,"<p>checkException will validate if meeting a stop() call, but not a warning() call. 
Is there a workaround or hack to check for warnings? (and make them silent during testing)</p>

<p>thanks </p>
"
2743204,322912,2010-04-30T08:26:37Z,8,improve my code for collapsing a list of data.frames,"<p>Dear StackOverFlowers (flowers in short),</p>

<p>I have a list of data.frames (walk.sample) that I would like to collapse into a single (giant) data.frame. While collapsing, I would like to mark (adding another column) which rows have came from which element of the list. This is what I've got so far.</p>

<p>This is the data.frame that needs to be collapsed/stacked.</p>

<pre><code>&gt; walk.sample
[[1]]
     walker        x         y
1073      3 228.8756 -726.9198
1086      3 226.7393 -722.5561
1081      3 219.8005 -728.3990
1089      3 225.2239 -727.7422
1032      3 233.1753 -731.5526

[[2]]
     walker        x         y
1008      3 205.9104 -775.7488
1022      3 208.3638 -723.8616
1072      3 233.8807 -718.0974
1064      3 217.0028 -689.7917
1026      3 234.1824 -723.7423

[[3]]
[1] 3

[[4]]
     walker        x         y
546       2 629.9041  831.0852
524       2 627.8698  873.3774
578       2 572.3312  838.7587
513       2 633.0598  871.7559
538       2 636.3088  836.6325
1079      3 206.3683 -729.6257
1095      3 239.9884 -748.2637
1005      3 197.2960 -780.4704
1045      3 245.1900 -694.3566
1026      3 234.1824 -723.7423
</code></pre>

<p>I have written a function to add a column that denote from which element the rows came followed by appending it to an existing data.frame.</p>

<pre><code>collapseToDataFrame &lt;- function(x) { # collapse list to a dataframe with a twist
    walk.df &lt;- data.frame()
    for (i in 1:length(x)) {
        n.rows &lt;- nrow(x[[i]])
        if (length(x[[i]])&gt;1) {
            temp.df &lt;- cbind(x[[i]], rep(i, n.rows))
            names(temp.df) &lt;- c(""walker"", ""x"", ""y"", ""session"")
            walk.df &lt;- rbind(walk.df, temp.df)
        } else {
            cat(""Empty list"", ""\n"")
        }
    }
    return(walk.df)
}


&gt; collapseToDataFrame(walk.sample)
Empty list 
Empty list 
     walker         x          y session
3         1 -604.5055 -123.18759       1
60        1 -562.0078  -61.24912       1
84        1 -594.4661  -57.20730       1
9         1 -604.2893 -110.09168       1
43        1 -632.2491  -54.52548       1
1028      3  240.3905 -724.67284       1
1040      3  232.5545 -681.61225       1
1073      3  228.8756 -726.91980       1
1091      3  209.0373 -740.96173       1
1036      3  248.7123 -694.47380       1
</code></pre>

<p>I'm curious whether this can be done more elegantly, with perhaps do.call() or some other more generic function?</p>
"
2743466,203420,2010-04-30T09:15:37Z,7,How can I determine if a function generates a graph,"<p>Is there a way to determine if a function generates a figure in <strong>R</strong>?</p>

<p>For example, if we have functions <em>f</em> and <em>g</em></p>

<pre><code>f = function(x,y){plot(x,y)}
g = function(x,y){mean(x*y)}
</code></pre>

<p>I would like able to run </p>

<pre><code>createFigure(f(x,y))#Returns TRUE
createFigure(g(x,y))#Returns FALSE
</code></pre>

<p>Thanks</p>
"
2748381,207258,2010-05-01T00:27:56Z,4,"R: ggplot2, how to get the parameters from a plotted linear model smoother?","<p>I have a data.frame with 3 time series in it, shown below.   When I plot them with a smoother time series, I want to be able to get the parameters of the linear model that I plot, but I can't see how to do that?  </p>

<pre><code>   &gt; data
   day   od series_id
    1    1 0.10        A1
    2    3 1.00        A1
    3    5 0.50        A1
    4    7 0.70        A1
    5    1 1.70        B1
    6    3 1.60        B1
    7    5 1.75        B1
    8    7 1.70        B1
    9    1 2.10        C1
    10   3 2.30        C1
    11   5 2.50        C1
    12   7 2.70        C1

    data = data.frame (day = c(1,3,5,7,1,3,5,7,1,3,5,7), 
    od = c(0.1,1.0,0.5,0.7 ,1.7,1.6,1.75,1.7 ,2.1,2.3,2.5,2.7), 
    series_id = c(""A1"", ""A1"", ""A1"",""A1"", ""B1"", ""B1"",""B1"", ""B1"", ""C1"",""C1"", ""C1"", ""C1""))

    r &lt;- ggplot(data = data, aes(x = day, y = od))
    r + stat_smooth(aes(group = series_id, color = series_id),method=""lm"")   
</code></pre>
"
2748725,325113,2010-05-01T03:04:42Z,21,Is there a weighted.median() function for R?,"<p>I'm looking for something similar in form to weighted.mean().  Sorry for posting such a banal question...  new to R.  I've found some solutions via search that write out the entire function but would appreciate something a bit more user friendly.</p>
"
2749390,299077,2010-05-01T09:11:50Z,19,Command history in R,"<p>Is there any IDE -from the ones supporting R-, that gives access to the command history (at least to the current session's commands)? Or is there a way to get a (character or expression) vector with those commands in R?  </p>

<p>For those of you that have been using MATLAB, I mean something like the <a href=""http://www.mathworks.com/access/helpdesk/help/techdoc/matlab_env/command_history_overview.gif"" rel=""noreferrer"">Command History</a> window there..</p>

<p>Thank you </p>
"
2751035,144278,2010-05-01T18:14:58Z,3,Creating a Large Matrix in ff,"<p>I am trying to create a huge matrix in ff, and I know that ff is good for this sort of thing. </p>

<p>But, there is a major problem. The dimensions of the matrix exceed .Machine$max_integer! I am running on a 64 bit machine, using 64bit R and 64bit ff. </p>

<p>Is there any way to get around this problem? </p>

<p>It's been suggested that R is using the MAXINT value from stdint.h. Is there any way to fix this without changing that file and possibly breaking build?</p>

<pre><code>&gt; ffMatrix &lt;- ff(vmode=""boolean"", dim=c(300000,300000))
Error in if (length &lt; 0 || length &gt; .Machine$integer.max) stop(""length must be between 1 and .Machine$integer.max"") : 
  missing value where TRUE/FALSE needed
In addition: Warning message:
In ff(vmode = ""boolean"", dim = c(300000, 300000)) :
  NAs introduced by coercion

&gt; 300000**2 &gt; .Machine$integer.max
[1] TRUE
</code></pre>
"
2751065,180626,2010-05-01T18:23:40Z,66,How can I manipulate the strip text of facet_grid plots?,"<p>I'm wondering how I can manipulate the size of strip text in facetted plots. My question
is similar to <a href=""https://stackoverflow.com/questions/2631780/r-ggplot2-can-i-set-the-plot-title-to-wrap-around-and-shrink-the-text-to-fit-th"">a question on plot titles</a>, but I'm specifically concerned with
manipulating not the plot title but the text that appears in facet titles (strip_h).</p>

<p>As an example, consider the mpg dataset.</p>

<pre><code>    library(ggplot2) 
    qplot(hwy, cty, data = mpg) + facet_grid( . ~ manufacturer)
</code></pre>

<p>The resulting <a href=""http://skitch.com/capbri/dbx1n/quartz-2"" rel=""nofollow noreferrer"">output</a> produces some facet titles that don't fit in the strip.</p>

<p>I'm thinking there must be a way to use <code>grid</code> to deal with the strip text. But I'm
still a novice and wasn't sure from the <code>grid</code> appendix in <a href=""http://rads.stackoverflow.com/amzn/click/0387981403"" rel=""nofollow noreferrer"">Hadley's book</a> how,
precisely, to do it. Also, I was afraid if I did it wrong it would break my washing
machine, since I believe all technology is connected through The Force :-(</p>

<p>Many thanks in advance.</p>
"
2754469,318976,2010-05-02T18:23:39Z,8,R library for discrete Markov chain simulation,"<p>I am looking for something like the 'msm' package, but for discrete Markov chains. For example, if I had a transition matrix defined as such</p>

<pre><code>Pi &lt;- matrix(c(1/3,1/3,1/3,
0,2/3,1/6,
2/3,0,1/2))
</code></pre>

<p>for states A,B,C. How can I simulate a Markov chain according to that transition matrix?</p>

<p>Thanks,</p>
"
2754658,43729,2010-05-02T19:21:48Z,6,What is the simplest method to fill the area under a geom_freqpoly line?,"<p>The x-axis is time broken up into time intervals.  There is an <em>interval</em> column in the data frame that specifies the time for each row.  The column is a factor, where each interval is a different factor level.</p>

<p>Plotting a histogram or line using geom_histogram and geom_freqpoly works great, but I'd like to have a line, like that provided by geom_freqpoly, with the area filled.</p>

<p>Currently I'm using geom_freqpoly like this:</p>

<pre><code>ggplot(quake.data, aes(interval, fill=tweet.type)) + geom_freqpoly(aes(group = tweet.type, colour = tweet.type)) + opts(axis.text.x=theme_text(angle=-60, hjust=0, size = 6))
</code></pre>

<p><img src=""https://i.stack.imgur.com/ZFSUV.png"" alt=""plots""></p>

<p>I would prefer to have a filled area, such as provided by <code>geom_density</code>, but without smoothing the line:</p>

<p><img src=""https://i.stack.imgur.com/JKCj5.png"" alt=""smoooth""></p>

<p>The <code>geom_area</code> has been suggested, is there any way to use a ggplot2-generated statistic, such as ..count.., for the geom_area's y-values?  Or, does the count aggregation need to occur prior to using ggplot2?</p>

<hr>

<p>As stated in the answer, geom_area(..., stat = ""bin"") is the solution: </p>

<pre><code>ggplot(quake.data, aes(interval)) + geom_area(aes(y = ..count.., fill = tweet.type, group = tweet.type), stat = ""bin"") + opts(axis.text.x=theme_text(angle=-60, hjust=0, size = 6))
</code></pre>

<p>produces:</p>

<p><img src=""https://i.stack.imgur.com/leK6T.png"" alt=""desired""> </p>
"
2755716,318976,2010-05-03T01:18:57Z,2,using R to estimate finite mixture model with underlying Markov process,"<p>My apologies if this is more of a statistics question than an R question. I am trying to estimate the following model in R.</p>

<p>y_t = mu0 (1 - S_t) + mu1 S_t + e_t    e_t ~ N(0, sigma_t^2)
sigma_t^2 = sigma_0^2 (1 - S_t) + sigma_1^2 S_t</p>

<p>where mu_t = mu0 if S_t = 0, mu_t = mu1 if S_t = 1, and S_t is a Markov process, either 0 or 1, with transition probabilities P(S_t = 1 | S_t-1 = 1 ) = p and P(S_t = 0 | S_t-1 = 0 ) = q.</p>

<p>Would 'flexmix' be a good library to use for this? I am new to this kind of statistics so any pointer to the right library would be appreciated.</p>

<p>Thanks,</p>
"
2756886,183988,2010-05-03T08:27:37Z,4,Click to get scatterplot coordinates,"<p>Say I make a scatterplot with thousands of points:</p>

<pre><code>ggplot(head(data, n=2000), aes(length, coverage))+ 
    geom_point(alpha = 0.5, color = 'navyblue')  + coord_trans(x='log', y='log')
</code></pre>

<p><a href=""http://fourmidable.unil.ch/temp/scatterplot.png"" rel=""nofollow noreferrer"">alt text http://fourmidable.unil.ch/temp/scatterplot.png</a></p>

<p>I want to add the labels of ""the 20 or so most extreme points"" (in the upper right and bottom right corners). They are easy to identify visually. But getting at them programatically seems a bit of a burden. (requiring many if statements).</p>

<p>Is there any way I can click on R's graphic output to obtain their precise coordinates?</p>

<p>Thanks,
yannick</p>
"
2756929,322912,2010-05-03T08:38:41Z,3,unexpected behavior when extracting factor levels,"<p>Can someone explain why levels() shows three factor levels, while you can see that the vector has only two?</p>

<pre><code>&gt; str(walk.df)
'data.frame':   10 obs. of  4 variables:
 $ walker : Factor w/ 3 levels ""1"",""2"",""3"": 1 1 1 1 1 2 2 2 2 2

&gt; walk.df$walker
 [1] 1 1 1 1 1 2 2 2 2 2
Levels: 1 2 3
</code></pre>

<p>I would like to extract a vector of levels, and I thought this was the proper way, but as you can see, a three sneaks in there which is messing up my function.</p>

<pre><code>&gt; as.numeric(levels(walk.df$walker))
[1] 1 2 3
</code></pre>
"
2757657,15985,2010-05-03T11:22:57Z,0,R: Is it possible to use RGL in x64 Windows?,"<p>Is it possible to use the R package 'RGL' in x64 Windows?</p>

<p><a href=""http://r-forge.r-project.org/R/?group_id=234"" rel=""nofollow noreferrer"">RGL Website</a></p>
"
2758559,171659,2010-05-03T14:02:04Z,1,Export symbol as png,"<p>I'd like to export plotting symbols form R as a png graphic. But I haven't found a perfect way yet.</p>

<p>Using </p>

<pre><code>png(""symbol.png"",width=20, height=20, bg=""transparent"")
par(mar=c(0,0,0,0))
plot.new()
symbols(1, 1, circles=0.3, bg=2, inches=FALSE, lwd=2, bty=""n"")
dev.off()
</code></pre>

<p>creates a little border around the symbol (I'd like it to be transparent) and the symbol isn't filling the whole space.</p>

<p><a href=""http://i42.tinypic.com/2s1tytk.png"" rel=""nofollow noreferrer"">symbol http://i42.tinypic.com/2s1tytk.png</a></p>

<p>Is there a more specific way of doing this ?</p>
"
2759394,262085,2010-05-03T16:05:57Z,12,Get rid of rows with duplicate attributes in R,"<p>I have a big dataframe with columns such as:</p>

<pre><code>ID, time, OS, IP
</code></pre>

<p>Each row of that dataframe corresponds to one entry. Within that dataframe for some <b>IDs</b> several entries (rows) exist. I would like to get rid of those multiple rows (obviously the other attributes will differ for the same ID). Or put different: I only want one single entry (row) for each ID.</p>

<p>When I use <code>unique</code> on the ID column, I only receive the levels (or each unique ID), but I want to keep the other attributes as well.
I have tried to use <code>apply(x,2,unique(data$ID))</code>, but this does not work either.</p>
"
2760702,12388,2010-05-03T19:39:23Z,3,How to represent a list of points in R,"<p>I am working with a large list of points (each point has three dimensions x,y,z).</p>

<p>I am pretty new with R, so I would like to know what is the best way to represent that kind of information.  As far as I know, an array allows me to represent any multidimensional data, so currently I am using:</p>

<pre><code>&gt; points&lt;-array( c(1,2,0,1,3,0,2,4,0,2,5,0,2,7,0,3,8,0), dim=c(3,6) )
&gt; points
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    1    1    2    2    2    3  -- x dim
[2,]    2    3    4    5    7    8  -- y dim
[3,]    0    0    0    0    0    0  -- z dim
</code></pre>

<p>The aim is to perform some computations to calculate the euclidean distance between two sets of points such as:</p>

<pre><code>points1&lt;-array( c(1,2,0,1,3,0,2,4,0,2,5,0,2,7,0,3,8,0), dim=c(3,6) )
points2&lt;-array( c(2,2,0,1,4,0,2,3,0,2,4,0,2,6,0,2,8,0), dim=c(3,6) )
</code></pre>

<p>(any hint in this sense would also be highly appreciated)</p>
"
2760898,256662,2010-05-03T20:13:21Z,6,Adding trend lines/boxplots (by group) in ggplot2,"<p>I have 40 subjects, of two groups, over 15 weeks, with some measured variable (Y).</p>

<p>I wish to have a plot where: x = time, y = T, lines are by subjects and colours by groups.</p>

<p>I found it can be done like this:</p>

<pre><code>TIME &lt;- paste(""week"",5:20)
ID &lt;- 1:40
GROUP &lt;- sample(c(""a"",""b""),length(ID), replace = T)
group.id &lt;- data.frame(GROUP, ID)
a &lt;- expand.grid(TIME, ID)
colnames(a) &lt;-c(""TIME"", ""ID"")
group.id.time &lt;- merge(a, group.id)
Y &lt;- rnorm(dim(group.id.time)[1], mean = ifelse(group.id.time$GROUP ==""a"",1,3) )
DATA &lt;- cbind(group.id.time, Y)
qplot(data = DATA,
        x=TIME, y=Y, 
        group=ID,       
        geom = c(""line""),colour = GROUP) 
</code></pre>

<p>But now I wish to add to the plot something to show the difference between the two groups (for example, a trend line for each group, with some CI shadelines) - how can it be done?</p>

<p>I remember once seeing the ggplot2 can (easily) do this with geom_smooth, but I am missing something about how to make it work.</p>

<p>Also, I wondered at maybe having the lines be like a boxplot for each group (with a line for the different quantiles and fences and so on).  But I imagine answering the first question would help me resolve the second.</p>

<p>Thanks.</p>
"
2764760,457898,2010-05-04T11:20:32Z,2,Return call from ggplot object,"<p>I've been using <code>ggplot2</code> for a while now, and I can't find a way to get formula from <code>ggplot</code> object. Though I can get basic info with <code>summary(&lt;ggplot_object&gt;)</code>, in order to get complete formula, usually I was combing up and down through <code>.Rhistory</code> file. And this becomes frustrating when you experiment with new graphs, especially when code gets a bit lengthy... so searching through history file isn't quite convenient way of doing this... Is there a more efficient way of doing this? Just an illustration:</p>

<pre><code>p &lt;- qplot(data = mtcars, x = factor(cyl), geom = ""bar"", fill = factor(cyl)) + 
     scale_fill_manual(name = ""Cylinders"", value = c(""firebrick3"", ""gold2"", ""chartreuse3"")) + 
     stat_bin(aes(label = ..count..), vjust = -0.2, geom = ""text"", position = ""identity"") + 
     xlab(""# of cylinders"") + ylab(""Frequency"") + 
     opts(title = ""Barplot: # of cylinders"")
</code></pre>

<p>I can get some basic info with <code>summary</code>:</p>

<pre><code>&gt; summary(p)
data: mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb [32x11]
mapping:  fill = factor(cyl), x = factor(cyl)
scales:   fill 
faceting: facet_grid(. ~ ., FALSE)
-----------------------------------
geom_bar:  
stat_bin:  
position_stack: (width = NULL, height = NULL)

mapping: label = ..count.. 
geom_text: vjust = -0.2 
stat_bin: width = 0.9, drop = TRUE, right = TRUE 
position_identity: (width = NULL, height = NULL)
</code></pre>

<p>But I want to get code I typed in to get the graph. I reckon that I'm missing something essential here... it's seems impossible that there's no way to get call from <code>ggplot</code> object!</p>
"
2765374,233446,2010-05-04T12:52:55Z,5,Efficient calculation of matrix cumulative standard deviation in r,"<p>I recently posted this question on the r-help mailing list but got no answers, so I thought I would post it here as well and see if there were any suggestions.</p>

<p>I am trying to calculate the cumulative standard deviation of a matrix. I want a function that accepts a matrix and returns a matrix of the same size where output cell (i,j) is set to the standard deviation of input column j between rows 1 and i. NAs should be ignored, unless cell (i,j) of the input matrix itself is NA, in which case cell (i,j) of the output matrix should also be NA.</p>

<p>I could not find a built-in function, so I implemented the following code. Unfortunately, this uses a loop that ends up being somewhat slow for large matrices. Is there a faster built-in function or can someone suggest a better approach?</p>

<pre><code>cumsd &lt;- function(mat)
{
    retval &lt;- mat*NA
    for (i in 2:nrow(mat)) retval[i,] &lt;- sd(mat[1:i,], na.rm=T)
    retval[is.na(mat)] &lt;- NA
    retval
}
</code></pre>

<p>Thanks.</p>
"
2767219,207258,2010-05-04T16:47:06Z,13,R: How to replace elements of a data.frame?,"<p>I'm trying to replace elements of a data.frame containing ""#N/A"" with ""NULL"", and I'm running into problems: </p>

<pre><code>foo &lt;- data.frame(""day""= c(1, 3, 5, 7), ""od"" = c(0.1, ""#N/A"", 0.4, 0.8))

indices_of_NAs &lt;- which(foo == ""#N/A"") 

replace(foo, indices_of_NAs, ""NULL"")
</code></pre>

<p>Error in <code>[&lt;-.data.frame</code>(<code>*tmp*</code>, list, value = ""NULL"") : 
  new columns would leave holes after existing columns</p>

<p>I think that the problem is that my index is treating the data.frame as a vector, but that the replace function is treating it differently somehow, but I'm not sure what the issue is?</p>
"
2768300,256662,2010-05-04T19:18:22Z,0,How to get the stars command to have segments of different angles ? (in R),"<p>I am playing with the ""stars"" ({graphics}) function to create a segment of flowers.</p>

<p>I wish to plot a flower of segments, for example in way the following command will produce:</p>

<pre><code>stars1(mtcars[, 1:7],
  draw.segments = T,
        main = ""Motor Trend Cars : stars(*, full = F)"", full = T, col.radius = 1:8)
</code></pre>

<p>But, I want the segments to not have equal angles, but smaller angles (and between the flowers there could be space).</p>

<p>The goal I am striving for is to be able to give each flower ""weight"" so that some aspects are more important (larger weight) and some are less (and thus, will have a smaller angle).</p>

<p>I understand this can be changes in the following part of the stars command:</p>

<pre><code>   if (draw.segments) {
        aangl &lt;- c(angles, if (full) 2 * pi else pi)
        for (i in 1L:n.loc) {
            px &lt;- py &lt;- numeric()
            for (j in 1L:n.seg) {
                k &lt;- seq.int(from = aangl[j], to = aangl[j + 
                  1], by = 1 * deg)
                px &lt;- c(px, xloc[i], s.x[i, j], x[i, j] * cos(k) + 
                  xloc[i], NA)
                py &lt;- c(py, yloc[i], s.y[i, j], x[i, j] * sin(k) + 
                  yloc[i], NA)
            }
            polygon(px, py, col = col.segments, lwd = lwd, lty = lty)
        }
</code></pre>

<p>But I am unsure as to how to manipulate it in order to achieve my task (of weighted flowers, by different angles)</p>
"
2769510,143319,2010-05-04T22:55:48Z,25,Numeric comparison difficulty in R,"<p>I'm trying to compare two numbers in R as a part of a if-statement condition:</p>

<p><code>(a-b) &gt;= 0.5</code></p>

<p>In this particular instance, a = 0.58 and b = 0.08... and yet <code>(a-b) &gt;= 0.5</code> is false.  I'm aware of the dangers of using <code>==</code> for exact number comparisons, and this seems related:</p>

<p><code>(a - b) == 0.5)</code> is false, while </p>

<p><code>all.equal((a - b), 0.5)</code> is true.</p>

<p>The only solution I can think of is to have two conditions: <code>(a-b) &gt; 0.5 | all.equal((a-b), 0.5)</code>.  This works, but is that really the only solution?  Should I just swear off of the <code>=</code> family of comparison operators forever?</p>

<p><strong>Edit for clarity:</strong> I know that this is a floating point problem.  More fundamentally, what I'm asking is: what should I do about it?  What's a sensible way to deal with greater-than-or-equal-to comparisons in R, since the <code>&gt;=</code> can't really be trusted?</p>
"
